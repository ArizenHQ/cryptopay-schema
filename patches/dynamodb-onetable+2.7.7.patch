diff --git a/node_modules/dynamodb-onetable/README.md b/node_modules/dynamodb-onetable/README.md
index fc4641c..bdc7c8d 100644
--- a/node_modules/dynamodb-onetable/README.md
+++ b/node_modules/dynamodb-onetable/README.md
@@ -1,51 +1,49 @@
-![OneTable](https://www.sensedeep.com/images/ring-short.png?renew)
+![OneTable](https://www.sensedeep.com/images/ring-short.png)
 
-*One Table to Rule Them All*
+_One Table to Rule Them All_
 
-[![Build Status](https://img.shields.io/github/workflow/status/sensedeep/dynamodb-onetable/build)](https://img.shields.io/github/workflow/status/sensedeep/dynamodb-onetable/build)
+[![Build Status](https://img.shields.io/github/actions/workflow/status/sensedeep/dynamodb-onetable/build.yml?branch=main)](https://img.shields.io/github/actions/workflow/status/sensedeep/dynamodb-onetable/build.yml?branch=main)
 [![npm](https://img.shields.io/npm/v/dynamodb-onetable.svg)](https://www.npmjs.com/package/dynamodb-onetable)
 [![npm](https://img.shields.io/npm/l/dynamodb-onetable.svg)](https://www.npmjs.com/package/dynamodb-onetable)
 [![Coverage Status](https://coveralls.io/repos/github/sensedeep/dynamodb-onetable/badge.svg?branch=main)](https://coveralls.io/github/sensedeep/dynamodb-onetable?branch=main)
 
 ## The Easiest Way to Create DynamoDB Single Table Designs.
 
-OneTable is the most evolved API for DynamoDB. It provides a dry, high-level, elegant syntax while enabling full access to DynamoDB API.
+OneTable is the most evolved API for DynamoDB. It provides a dry, high-level, elegant syntax while enabling full access to the DynamoDB API.
 
-OneTable works with AWS V2 and V3 SDKs for JavaScript and TypeScript. For TypeScript, OneTable will create fully typed entities from your data schemas automatically.
+OneTable works with JavaScript and TypeScript. For TypeScript, OneTable will create fully typed entities from your data schemas automatically.
 
 ## Full Documentation
 
-* [OneTable Documentation](https://doc.onetable.io/)
+-   [OneTable Documentation](https://doc.onetable.io/)
 
 ## OneTable Features
 
-* Schema supported one-table access to DynamoDB APIs.
-* Efficient storage and access of multiple entities in a single DynamoDB table.
-* High level API with type marshaling, validations, and extended query capability for get/delete/update operations.
-* Bidirectional conversion of DynamoDB types to Javascript types.
-* Generation of Conditional, Filter, Key and Update expressions.
-* Schema item definitions for attribute types, default values, enums, unique attributes and validations.
-* Option to invoke DynamoDB or simply generate API parameters.
-* Powerful field level validations with "required" and "unique" attributes.
-* Easy parameterization of filter and conditional queries.
-* Detailed metrics for Table, Tenant, Source, Index, Model and Operation.
-* Multi-page response aggregation.
-* Compound and templated key management.
-* Attribute mapping and packing.
-* Support for sparse GSIs that project keys and overloaded attributes.
-* Encrypted fields.
-* CreateTable, DeleteTable table and index admin operations.
-* Support for Batch, Transactions, GSI, LSI indexes.
-* Intercept hooks to modify DynamoDB requests and responses.
-* Controllable logging to see exact parameter, data and responses.
-* Simple and easy to read source.
-* Integrated statistics.
-* Safety options to prevent "rm -fr *".
-* No external module dependencies.
-* Support for the AWS SDK v3.
-* TypeScript type inference from schema for full type validation on APIs, parameters, returns, and entities and attributes.
-* Migrations support via [OneTable Migrate](https://github.com/sensedeep/onetable-migrate) and [OneTable CLI](https://github.com/sensedeep/onetable-cli).
-* Graphical monitoring of single-table performance via [SenseDeep](https://www.sensedeep.com).
+-   Schema supported one-table access to DynamoDB APIs.
+-   Efficient storage and access of multiple entities in a single DynamoDB table.
+-   High level API with type marshaling, validations, and extended query capability for get/delete/update operations.
+-   Bidirectional conversion of DynamoDB types to Javascript types.
+-   Generation of Conditional, Filter, Key and Update expressions.
+-   Schema item definitions for attribute types, default values, enums, unique attributes and validations.
+-   Option to invoke DynamoDB or simply generate API parameters.
+-   Powerful field level validations with "required" and "unique" attributes.
+-   Easy parameterization of filter and conditional queries.
+-   Detailed metrics for Table, Tenant, Source, Index, Model and Operation.
+-   Multi-page response aggregation.
+-   Compound and templated key management.
+-   Attribute mapping and packing.
+-   Support for sparse GSIs that project keys and overloaded attributes.
+-   Encrypted fields.
+-   CreateTable, DeleteTable table and index admin operations.
+-   Support for Batch, Transactions, GSI, LSI indexes.
+-   Intercept hooks to modify DynamoDB requests and responses.
+-   Controllable logging to see exact parameter, data and responses.
+-   Simple and easy to read source.
+-   Integrated statistics.
+-   Safety options to prevent "rm -fr \*".
+-   TypeScript type inference from schema for full type validation on APIs, parameters, returns, and entities and attributes.
+-   Migrations support via [OneTable Migrate](https://github.com/sensedeep/onetable-migrate) and [OneTable CLI](https://github.com/sensedeep/onetable-cli).
+-   Graphical monitoring of single-table performance via [SenseDeep](https://www.sensedeep.com).
 
 ## Installation
 
@@ -59,24 +57,29 @@ Import the OneTable library. If you are not using ES modules or TypeScript, use
 import {Table} from 'dynamodb-onetable'
 ```
 
-If you are using the AWS SDK V2, import the AWS `DynamoDB` class and create a `DocumentClient` instance.
+Import the `DynamoDBClient` class and create a `DynamoDBClient` instance.
 
 ```javascript
-import DynamoDB from 'aws-sdk/clients/dynamodb'
-const client = new DynamoDB.DocumentClient(params)
+import {DynamoDBClient} from '@aws-sdk/client-dynamodb'
+const client = new DynamoDBClient({
+    endpoint: `http://localhost:${PORT}`,
+    region: 'local',
+    credentials: new AWS.Credentials({
+        accessKeyId: 'test',
+        secretAccessKey: 'test',
+    }),
+})
 ```
 
-If you are using the AWS SDK V3, import the AWS V3 `DynamoDBClient` class and the OneTable `Dynamo` helper. Then create a `DynamoDBClient` instance and Dynamo wrapper instance. Note: you will need Node v14 or later for this to work.
-
-Note: you can use the Table.setClient API to defer setting the client or replace the client at any time.
+If you are using the legacy AWS SDK V2, import the AWS `DynamoDB` class and create a `DocumentClient` instance.
 
 ```javascript
-import {Dynamo} from 'dynamodb-onetable/Dynamo'
-import {Model, Table} from 'dynamodb-onetable'
-import {DynamoDBClient} from '@aws-sdk/client-dynamodb'
-const client = new Dynamo({client: new DynamoDBClient(params)})
+import DynamoDB from 'aws-sdk/clients/dynamodb'
+const client = new DynamoDB.DocumentClient(params)
 ```
 
+Note: you can use the Table.setClient API to defer setting the client or replace the client at any time.
+
 Initialize your OneTable `Table` instance and define your models via a schema.
 
 ```javascript
@@ -98,38 +101,38 @@ const MySchema = {
     format: 'onetable:1.1.0',
     version: '0.0.1',
     indexes: {
-        primary: { hash: 'pk', sort: 'sk' },
-        gs1:     { hash: 'gs1pk', sort: 'gs1sk', follow: true },
-        ls1:     { sort: 'id', type: 'local' },
+        primary: {hash: 'pk', sort: 'sk'},
+        gs1: {hash: 'gs1pk', sort: 'gs1sk', follow: true},
+        ls1: {sort: 'id', type: 'local'},
     },
     models: {
         Account: {
-            pk:          { type: String, value: 'account:${id}' },
-            sk:          { type: String, value: 'account:' },
-            id:          { type: String, generate: 'ulid', validate: /^[0123456789ABCDEFGHJKMNPQRSTVWXYZ]{26}$/i },
-            name:        { type: String, required: true },
-            status:      { type: String, default: 'active' },
-            zip:         { type: String },
+            pk: {type: String, value: 'account:${id}'},
+            sk: {type: String, value: 'account:'},
+            id: {type: String, generate: 'ulid', validate: /^[0123456789ABCDEFGHJKMNPQRSTVWXYZ]{26}$/i},
+            name: {type: String, required: true},
+            status: {type: String, default: 'active'},
+            zip: {type: String},
         },
         User: {
-            pk:          { type: String, value: 'account:${accountName}' },
-            sk:          { type: String, value: 'user:${email}', validate: EmailRegExp },
-            id:          { type: String, required: true },
-            accountName: { type: String, required: true },
-            email:       { type: String, required: true },
-            firstName:   { type: String, required: true },
-            lastName:    { type: String, required: true },
-            username:    { type: String, required: true },
-            role:        { type: String, enum: ['user', 'admin'], required: true, default: 'user' },
-            balance:     { type: Number, default: 0 },
-
-            gs1pk:       { type: String, value: 'user-email:${email}' },
-            gs1sk:       { type: String, value: 'user:' },
-        }
+            pk: {type: String, value: 'account:${accountName}'},
+            sk: {type: String, value: 'user:${email}', validate: EmailRegExp},
+            id: {type: String, required: true},
+            accountName: {type: String, required: true},
+            email: {type: String, required: true},
+            firstName: {type: String, required: true},
+            lastName: {type: String, required: true},
+            username: {type: String, required: true},
+            role: {type: String, enum: ['user', 'admin'], required: true, default: 'user'},
+            balance: {type: Number, default: 0},
+
+            gs1pk: {type: String, value: 'user-email:${email}'},
+            gs1sk: {type: String, value: 'user:'},
+        },
     },
     params: {
-        'isoDates': true,
-        'timestamps': true,
+        isoDates: true,
+        timestamps: true,
     },
 }
 ```
@@ -144,6 +147,7 @@ let account = await Account.create({
 ```
 
 This will write the following to DynamoDB:
+
 ```javascript
 {
     pk:         'account:8e7bbe6a-4afc-4117-9218-67081afc935b',
@@ -189,9 +193,12 @@ let users = await User.find({accountId: account.id})
 
 let adminUsers = await User.find({accountId: account.id, role: 'admin'})
 
-let users = await User.find({accountId: account.id}, {
-    where: '${balance} > {100.00}'
-})
+let users = await User.find(
+    {accountId: account.id},
+    {
+        where: '${balance} > {100.00}',
+    }
+)
 
 //  Get a count of matching users without returning the actual items
 let users = await User.find({accountId: account.id, role: 'admin'}, {count: true})
@@ -202,7 +209,7 @@ To update an item:
 
 ```javascript
 await User.update({id: userId, balance: 50})
-await User.update({id: userId}, {add: {balance: 10.00}})
+await User.update({id: userId}, {add: {balance: 10.0}})
 await User.update({id: userId}, {set: {status: '{active}'}})
 ```
 
@@ -238,18 +245,17 @@ const MySchema = {
     } as const     // Required for TypeScript
 }
 
-//  Fully typed Account object based on the schema (must include "as const" after the models above)
-type AccountType = Entity<typeof MySchema.models.Account>
+//  Fully typed Account object based on the schema
+type Account = Entity<typeof MySchema.models.Account>
 
-let account: AccountType = {
+let account: Account = {
     name: 'Coyote',        //  OK
     unknown: 42,           //  Error
 }
 
-//  Get an Account access model (<AccountType> is inferred)
-let Account = table.getModel('Account')
+let AccountModel: Model<Account> = table.getModel('Account')
 
-let account = await Account.create({
+let account = await AccountModel.create({
     name: 'Acme',               //  OK
     unknown: 42,                //  Error
 })
@@ -258,6 +264,37 @@ account.name = 'Coyote'         //  OK
 account.unknown = 42            //  Error
 ```
 
+### DynamoDB Articles
+
+Here is a collection of articles that can help you on your way with DynamoDB and OneTable.
+
+DynamoDB Topic|Link
+-|-
+Intro to DynamoDB| [https://www.sensedeep.com/blog/posts/2021/dynamodb-onetable-tour.html](https://www.sensedeep.com/blog/posts/2021/dynamodb-onetable-tour.html)
+Data Modeling for DynamoDB | [https://www.sensedeep.com/blog/posts/2021/dynamodb-singletable-design.html](https://www.sensedeep.com/blog/posts/2021/dynamodb-singletable-design.html)
+The What and Why of Single Table Design | [https://www.alexdebrie.com/posts/dynamodb-single-table/](https://www.alexdebrie.com/posts/dynamodb-single-table/)
+DynamoDB with OneTable Schemas | [https://www.sensedeep.com/blog/posts/2021/dynamodb-schemas.html](https://www.sensedeep.com/blog/posts/2021/dynamodb-schemas.html)
+DynamoDB OneTable API Overview | [https://www.sensedeep.com/blog/posts/2021/dynamodb-onetable-tour.html](https://www.sensedeep.com/blog/posts/2021/dynamodb-onetable-tour.html)
+DynamoDB Checklist | [https://www.sensedeep.com/blog/posts/2021/dynamodb-checklist.html](https://www.sensedeep.com/blog/posts/2021/dynamodb-checklist.html)
+DynamoDB with TypeScript | [https://www.sensedeep.com/blog/posts/2021/dynamodb-typescript.html](https://www.sensedeep.com/blog/posts/2021/dynamodb-typescript.html)
+DynamoDB Sparse GSIs | [https://www.sensedeep.com/blog/posts/2021/sparse-gsi-indexes.html](https://www.sensedeep.com/blog/posts/2021/sparse-gsi-indexes.html)
+DynamoDB Attribute Packing | [https://www.sensedeep.com/blog/posts/2021/attribute-packing.html](https://www.sensedeep.com/blog/posts/2021/attribute-packing.html)
+Evolving DynamoDB Designs | [https://www.sensedeep.com/blog/posts/2021/evolving-dynamodb-designs.html](https://www.sensedeep.com/blog/posts/2021/evolving-dynamodb-designs.html)
+SenseDeep Migration Manager | [https://www.sensedeep.com/blog/posts/series/dynamodb-studio/migration-manager.html](https://www.sensedeep.com/blog/posts/series/dynamodb-studio/migration-manager.html)
+SenseDeep DynamoDB Studio | [https://www.sensedeep.com/blog/posts/stories/dynamodb-studio.html](https://www.sensedeep.com/blog/posts/stories/dynamodb-studio.html)
+SenseDeep DynamoDB Quick Tour | [https://www.sensedeep.com/blog/posts/product/dynamodb-tour.html](https://www.sensedeep.com/blog/posts/product/dynamodb-tour.html)
+
+
+### Serverless Articles
+
+And a few serverless articles:
+
+Serverless Topic|Link
+-|-
+How to Debug Serverless Apps | [https://www.sensedeep.com/blog/posts/stories/how-to-debug-serverless-apps.html](https://www.sensedeep.com/blog/posts/stories/how-to-debug-serverless-apps.html)
+How to invoke HTTP without Waiting from Lambda | [https://www.sensedeep.com/blog/posts/stories/lambda-fast-http.html](https://www.sensedeep.com/blog/posts/stories/lambda-fast-http.html)
+Fast Logging with Lambda | [https://www.sensedeep.com/blog/posts/senselogs/serverless-logging.html](https://www.sensedeep.com/blog/posts/senselogs/serverless-logging.html)
+
 ### SenseDeep
 
 Please try our [SenseDeep Serverless Developer Studio](https://www.sensedeep.com/) that includes a full DynamoDB suite with single-table aware data browser, single-table designer, migration manager, provisioning planner and metrics.
diff --git a/node_modules/dynamodb-onetable/dist/cjs/Dynamo.d.ts b/node_modules/dynamodb-onetable/dist/cjs/Dynamo.d.ts
index bf9688a..2543ab4 100644
--- a/node_modules/dynamodb-onetable/dist/cjs/Dynamo.d.ts
+++ b/node_modules/dynamodb-onetable/dist/cjs/Dynamo.d.ts
@@ -1,13 +1,12 @@
-
 /*
 export type DynamoParams {
     client?: DynamoDBClient,
 }; */
 
 export class Dynamo {
-    constructor(params?: {});
-    client: any;
-    V3: boolean;
+    constructor(params?: {})
+    client: any
+    V3: boolean
 }
 
 export default Dynamo
diff --git a/node_modules/dynamodb-onetable/dist/cjs/Dynamo.js b/node_modules/dynamodb-onetable/dist/cjs/Dynamo.js
index bad88be..fd36e38 100644
--- a/node_modules/dynamodb-onetable/dist/cjs/Dynamo.js
+++ b/node_modules/dynamodb-onetable/dist/cjs/Dynamo.js
@@ -4,23 +4,7 @@
 
     This module provides a wrapper and convenience API over the AWS V3 SDK.
     It is used by OneTable internally and is not a public API.
-
-    Use:
-        import {Model, Table} from 'dynamodb-onetable'
-        import Dynamo from 'dynamodb-onetable/Dynamo'
-
-        const dynamo = new Dynamo(params)
-        const table = new Table({ dynamo, ... })
 */
-var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
-    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
-    return new (P || (P = Promise))(function (resolve, reject) {
-        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
-        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
-        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
-        step((generator = generator.apply(thisArg, _arguments || [])).next());
-    });
-};
 Object.defineProperty(exports, "__esModule", { value: true });
 exports.Dynamo = void 0;
 const client_dynamodb_1 = require("@aws-sdk/client-dynamodb");
@@ -33,94 +17,72 @@ class Dynamo {
         this.unmarshall = util_dynamodb_1.unmarshall;
         this.V3 = true;
     }
-    createTable(params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            let command = new client_dynamodb_1.CreateTableCommand(params);
-            return yield this.send(command);
-        });
-    }
-    deleteTable(params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            let command = new client_dynamodb_1.DeleteTableCommand(params);
-            return yield this.send(command);
-        });
-    }
-    delete(params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            let command = new client_dynamodb_1.DeleteItemCommand(params);
-            return yield this.send(command);
-        });
-    }
-    describeTable(params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            let command = new client_dynamodb_1.DescribeTableCommand(params);
-            return yield this.send(command);
-        });
-    }
-    get(params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            let command = new client_dynamodb_1.GetItemCommand(params);
-            return yield this.send(command);
-        });
-    }
-    find(params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            let command = new client_dynamodb_1.QueryCommand(params);
-            return yield this.send(command);
-        });
-    }
-    listTables(params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            let command = new client_dynamodb_1.ListTablesCommand(params);
-            return yield this.send(command);
-        });
-    }
-    put(params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            let command = new client_dynamodb_1.PutItemCommand(params);
-            return yield this.send(command);
-        });
-    }
-    scan(params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            let command = new client_dynamodb_1.ScanCommand(params);
-            return yield this.send(command);
-        });
-    }
-    update(params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            let command = new client_dynamodb_1.UpdateItemCommand(params);
-            return yield this.send(command);
-        });
-    }
-    batchGet(params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            let command = new client_dynamodb_1.BatchGetItemCommand(params);
-            return yield this.send(command);
-        });
-    }
-    batchWrite(params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            let command = new client_dynamodb_1.BatchWriteItemCommand(params);
-            return yield this.send(command);
-        });
-    }
-    transactGet(params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            let command = new client_dynamodb_1.TransactGetItemsCommand(params);
-            return yield this.send(command);
-        });
-    }
-    transactWrite(params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            let command = new client_dynamodb_1.TransactWriteItemsCommand(params);
-            return yield this.send(command);
-        });
-    }
-    send(cmd) {
-        return __awaiter(this, void 0, void 0, function* () {
-            return yield this.client.send(cmd);
-        });
+    async createTable(params) {
+        let command = new client_dynamodb_1.CreateTableCommand(params);
+        return await this.send(command);
+    }
+    async deleteTable(params) {
+        let command = new client_dynamodb_1.DeleteTableCommand(params);
+        return await this.send(command);
+    }
+    async delete(params) {
+        let command = new client_dynamodb_1.DeleteItemCommand(params);
+        return await this.send(command);
+    }
+    async describeTable(params) {
+        let command = new client_dynamodb_1.DescribeTableCommand(params);
+        return await this.send(command);
+    }
+    async get(params) {
+        let command = new client_dynamodb_1.GetItemCommand(params);
+        return await this.send(command);
+    }
+    async find(params) {
+        let command = new client_dynamodb_1.QueryCommand(params);
+        return await this.send(command);
+    }
+    async listTables(params) {
+        let command = new client_dynamodb_1.ListTablesCommand(params);
+        return await this.send(command);
+    }
+    async put(params) {
+        let command = new client_dynamodb_1.PutItemCommand(params);
+        return await this.send(command);
+    }
+    async scan(params) {
+        let command = new client_dynamodb_1.ScanCommand(params);
+        return await this.send(command);
+    }
+    async update(params) {
+        let command = new client_dynamodb_1.UpdateItemCommand(params);
+        return await this.send(command);
+    }
+    async updateTable(params) {
+        let command = new client_dynamodb_1.UpdateTableCommand(params);
+        return await this.send(command);
+    }
+    async updateTimeToLive(params) {
+        let command = new client_dynamodb_1.UpdateTimeToLiveCommand(params);
+        return await this.send(command);
+    }
+    async batchGet(params) {
+        let command = new client_dynamodb_1.BatchGetItemCommand(params);
+        return await this.send(command);
+    }
+    async batchWrite(params) {
+        let command = new client_dynamodb_1.BatchWriteItemCommand(params);
+        return await this.send(command);
+    }
+    async transactGet(params) {
+        let command = new client_dynamodb_1.TransactGetItemsCommand(params);
+        return await this.send(command);
+    }
+    async transactWrite(params) {
+        let command = new client_dynamodb_1.TransactWriteItemsCommand(params);
+        return await this.send(command);
+    }
+    async send(cmd) {
+        return await this.client.send(cmd);
     }
 }
 exports.Dynamo = Dynamo;
diff --git a/node_modules/dynamodb-onetable/dist/cjs/Error.d.ts b/node_modules/dynamodb-onetable/dist/cjs/Error.d.ts
index 5135d50..000cf5f 100644
--- a/node_modules/dynamodb-onetable/dist/cjs/Error.d.ts
+++ b/node_modules/dynamodb-onetable/dist/cjs/Error.d.ts
@@ -1,10 +1,10 @@
 export class OneTableError extends Error {
-    constructor(message: any, context: any);
-    context: any;
-    code?: string;
+    constructor(message: any, context: any)
+    context: any
+    code?: string
 }
 
 export class OneTableArgError extends Error {
-    constructor(message: any, context?: any);
-    code: any;
+    constructor(message: any, context?: any)
+    code: any
 }
diff --git a/node_modules/dynamodb-onetable/dist/cjs/Error.js b/node_modules/dynamodb-onetable/dist/cjs/Error.js
index f80647b..7e19105 100644
--- a/node_modules/dynamodb-onetable/dist/cjs/Error.js
+++ b/node_modules/dynamodb-onetable/dist/cjs/Error.js
@@ -21,7 +21,7 @@ function init(self, message, context) {
         Error.captureStackTrace(self, self.constructor);
     }
     else {
-        self.stack = (new Error(message)).stack;
+        self.stack = new Error(message).stack;
     }
 }
 class OneTableError extends Error {
diff --git a/node_modules/dynamodb-onetable/dist/cjs/Expression.d.ts b/node_modules/dynamodb-onetable/dist/cjs/Expression.d.ts
index 77e5a96..ecd64ab 100644
--- a/node_modules/dynamodb-onetable/dist/cjs/Expression.d.ts
+++ b/node_modules/dynamodb-onetable/dist/cjs/Expression.d.ts
@@ -1,21 +1,21 @@
-import { OneParams, OneProperties, OneIndex } from './Model'
+import {OneParams, OneProperties, OneIndex} from './Model.js'
 export class Expression<ModelT> {
-    constructor(model: ModelT, op: string, properties: OneProperties, params?: OneParams);
-    add(field: string, value: any): void;
-    expand(where: any): any;
-    addFilter(att: string, value: any): void;
-    addKey(op: string, field: string, value: any): void;
-    addUpdate(field: string, value: any): void;
-    makeTarget(fields: string, name: string): string;
-    command(): any;
-    and(terms: string[]): string;
-    addName(name: string): number;
-    addValue(value: any): number;
+    constructor(model: ModelT, op: string, properties: OneProperties, params?: OneParams)
+    add(field: string, value: any): void
+    expand(where: any): any
+    addFilter(att: string, value: any): void
+    addKey(op: string, field: string, value: any): void
+    addUpdate(field: string, value: any): void
+    makeTarget(fields: string, name: string): string
+    command(): any
+    and(terms: string[]): string
+    addName(name: string): number
+    addValue(value: any): number
     // Internal only methods
-    init(model: ModelT, op: string, properties: OneProperties, params: OneParams): void;
-    prepare(): void;
-    addConditions(op: string): void;
-    addFilters(): void;
-    addUpdates(): void;
-    selectIndex(indexes: Record<string, OneIndex>): OneIndex;
+    init(model: ModelT, op: string, properties: OneProperties, params: OneParams): void
+    prepare(): void
+    addConditions(op: string): void
+    addFilters(): void
+    addUpdates(): void
+    selectIndex(indexes: Record<string, OneIndex>): OneIndex
 }
diff --git a/node_modules/dynamodb-onetable/dist/cjs/Expression.js b/node_modules/dynamodb-onetable/dist/cjs/Expression.js
index 8983c23..d16ae7f 100644
--- a/node_modules/dynamodb-onetable/dist/cjs/Expression.js
+++ b/node_modules/dynamodb-onetable/dist/cjs/Expression.js
@@ -1,11 +1,11 @@
 "use strict";
+Object.defineProperty(exports, "__esModule", { value: true });
+exports.Expression = void 0;
 /*
     Expression.js - DynamoDB API command builder
 
     This module converts API requests into DynamoDB commands.
 */
-Object.defineProperty(exports, "__esModule", { value: true });
-exports.Expression = void 0;
 const Error_js_1 = require("./Error.js");
 //  Operators used on sort keys for get/delete
 const KeyOperators = ['<', '<=', '=', '>=', '>', 'begins', 'begins_with', 'between'];
@@ -58,10 +58,11 @@ class Expression {
     prepare() {
         let { op, params, properties } = this;
         let fields = this.model.block.fields;
+        this.canPut = op == 'put' || (this.params.batch && op == 'update');
         if (op == 'find') {
             this.addWhereFilters();
         }
-        else if (op == 'delete' || op == 'put' || op == 'update') {
+        else if (op == 'delete' || op == 'put' || op == 'update' || op == 'check') {
             this.addConditions(op);
         }
         else if (op == 'scan') {
@@ -77,7 +78,8 @@ class Expression {
                 }
             }
         }
-        this.addProperties(op, fields, properties);
+        //  Batch does not use update expressions (Ugh!)
+        this.puts = this.addProperties(op, this.model.block, properties);
         /*
             Emit mapped attributes that don't correspond to schema fields.
         */
@@ -88,7 +90,9 @@ class Expression {
                 }
             }
             for (let [k, v] of Object.entries(this.mapped)) {
-                this.add(properties, { attribute: [k], name: k, filter: false }, v, properties);
+                let field = { attribute: [k], name: k, filter: false, path: k };
+                this.add(op, properties, field, k, v);
+                this.puts[k] = v;
             }
         }
         if (params.fields) {
@@ -97,6 +101,10 @@ class Expression {
                     //  BatchGet params.project must provide attributes not properties
                     this.project.push(`#_${this.addName(name)}`);
                 }
+                else if (this.model.generic) {
+                    // Generic models don't know which attributes exist, so we allow requesting all
+                    this.project.push(`#_${this.addName(name)}`);
+                }
                 else if (fields[name]) {
                     let att = fields[name].attribute[0];
                     this.project.push(`#_${this.addName(att)}`);
@@ -104,82 +112,106 @@ class Expression {
             }
         }
     }
-    addProperties(op, fields, properties) {
+    /*
+        Add properties to the command. This calls itself recursively for each schema nest level.
+        Emit update/filter expressions if emit is true
+     */
+    addProperties(op, block, properties, ppath = '', emit = true) {
+        let rec = {};
+        let fields = block.fields;
+        if (!properties || typeof properties != 'object') {
+            return properties;
+        }
         for (let [name, value] of Object.entries(properties)) {
-            if (this.already[name]) {
-                continue;
+            let field = fields[name];
+            if (!field) {
+                field = { attribute: [name], name, path: name };
+                if (this.model.generic) {
+                    this.add(op, properties, field, name, value);
+                }
             }
-            if (fields[name]) {
-                if (op != 'put' && this.table.partial && this.params.partial !== false) {
-                    if (fields[name].schema) {
-                        this.addProperties(op, fields[name].block.fields, value);
+            else {
+                let attribute = field.attribute[0];
+                let path = ppath ? `${ppath}.${attribute}` : attribute;
+                if (!field.schema) {
+                    this.add(op, properties, field, path, value, emit);
+                }
+                else {
+                    let partial = this.model.getPartial(field, this.params);
+                    if (field.isArray && Array.isArray(value)) {
+                        value = value.slice(0);
+                        for (let [key, v] of Object.entries(value)) {
+                            let ipath = `${path}[${key}]`;
+                            value[key] = this.addProperties(op, field.block, v, ipath, emit && partial);
+                        }
+                        if (emit && !partial) {
+                            this.add(op, properties, field, path, value, emit);
+                        }
                     }
                     else {
-                        this.add(properties, fields[name], value);
+                        value = this.addProperties(op, field.block, value, path, emit && partial);
+                        if (emit && !partial) {
+                            this.add(op, properties, field, path, value, true);
+                        }
                     }
                 }
-                else {
-                    this.add(properties, fields[name], value);
-                }
-            }
-            else if (this.model.generic) {
-                this.add(properties, { attribute: [name], name }, value);
             }
+            rec[field.attribute[0]] = value;
         }
+        return rec;
     }
     /*
         Add a field to the command expression
+        If emit is true, then emit update/filter expressions for this property
      */
-    add(properties, field, value) {
-        let op = this.op;
-        let attribute = field.attribute;
+    add(op, properties, field, path, value, emit = true) {
+        if (this.already[path]) {
+            return;
+        }
         /*
             Handle mapped and packed attributes.
-            The attribute[0] contains the top level attribute name. Attribute[1] contains a nested mapping name.
+            The attribute[0] contains the top level attribute name and
+            Attribute[1] contains a nested mapping name.
         */
+        let attribute = field.attribute;
         if (attribute.length > 1) {
+            /*
+                Save in mapped[] the mapped attributes which will be processed soon
+             */
             let mapped = this.mapped;
             let [k, v] = attribute;
             mapped[k] = mapped[k] || {};
             mapped[k][v] = value;
-            properties[k] = value;
+            if (op == 'put') {
+                properties[k] = value;
+            }
             return;
         }
-        //  Pathname may contain a '.'
-        let path = attribute[0];
         if (path == this.hash || path == this.sort) {
             if (op == 'find') {
                 this.addKey(op, field, value);
             }
             else if (op == 'scan') {
                 if (properties[field.name] !== undefined && field.filter !== false) {
-                    this.addFilter(field, value);
+                    this.addFilter(field, path, value);
                 }
             }
-            else if ((op == 'delete' || op == 'get' || op == 'update') && field.isIndexed) {
+            else if ((op == 'delete' || op == 'get' || op == 'update' || op == 'check') && field.isIndexed) {
                 this.addKey(op, field, value);
             }
-            else if (op == 'put' || (this.params.batch && op == 'update')) {
-                //  Batch does not use update expressions (Ugh!)
-                this.puts[path] = value;
-            }
         }
-        else {
-            if ((op == 'find' || op == 'scan')) {
+        else if (emit) {
+            if (op == 'find' || op == 'scan') {
                 //  schema.filter == false disables a field from being used in a filter
                 if (properties[field.name] !== undefined && field.filter !== false) {
                     if (!this.params.batch) {
                         //  Batch does not support filter expressions
-                        this.addFilter(field, value);
+                        this.addFilter(field, path, value);
                     }
                 }
             }
-            else if (op == 'put' || (this.params.batch && op == 'update')) {
-                //  Batch does not use update expressions (Ugh!)
-                this.puts[path] = value;
-            }
             else if (op == 'update') {
-                this.addUpdate(field, value);
+                this.addUpdate(field, path, value);
             }
         }
     }
@@ -240,13 +272,13 @@ class Expression {
                 for (let item of substitutions[name]) {
                     indicies.push(this.addValue(item));
                 }
-                return indicies.map(i => `:_${i}`).join(', ');
+                return indicies.map((i) => `:_${i}`).join(', ');
             }
             index = this.addValue(substitutions[name]);
             return `:_${index}`;
         });
         //  Expand value references and make attribute values. Allow new-lines in values.
-        where = where.replace(/{(.*?)}/sg, (match, value) => {
+        where = where.replace(/{(.*?)}/gs, (match, value) => {
             let index;
             if (value.match(/^[-+]?([0-9]+(\.[0-9]*)?|\.[0-9]+)$/)) {
                 index = this.addValue(+value);
@@ -279,14 +311,12 @@ class Expression {
             this.filters.push(this.expand(this.params.where));
         }
     }
-    addFilter(field, value) {
+    addFilter(field, path, value) {
         let { filters } = this;
-        let att = field.attribute[0];
-        let pathname = field.pathname || att;
-        if (pathname == this.hash || pathname == this.sort) {
+        if (path == this.hash || path == this.sort) {
             return;
         }
-        let [target, variable] = this.prepareKeyValue(pathname, value);
+        let [target, variable] = this.prepareKeyValue(path, value);
         filters.push(`${target} = ${variable}`);
     }
     /*
@@ -345,11 +375,9 @@ class Expression {
             return [target, this.addValueExp(value)];
         }
     }
-    addUpdate(field, value) {
+    addUpdate(field, path, value) {
         let { params, updates } = this;
-        let att = field.attribute[0];
-        let pathname = field.pathname || att;
-        if (pathname == this.hash || pathname == this.sort) {
+        if (path == this.hash || path == this.sort) {
             return;
         }
         if (field.name == this.model.typeField) {
@@ -361,8 +389,7 @@ class Expression {
         if (params.remove && params.remove.indexOf(field.name) >= 0) {
             return;
         }
-        // let [target, variable] = this.prepareKeyValue(pathname, value)
-        let target = this.prepareKey(pathname);
+        let target = this.prepareKey(path);
         let variable = this.addValueExp(value);
         updates.set.push(`${target} = ${variable}`);
     }
@@ -493,11 +520,11 @@ class Expression {
             args = {
                 ConditionExpression: conditions.length ? this.and(conditions) : undefined,
                 ExpressionAttributeNames: namesLen > 0 ? names : undefined,
-                ExpressionAttributeValues: (namesLen > 0 && valuesLen > 0) ? values : undefined,
+                ExpressionAttributeValues: namesLen > 0 && valuesLen > 0 ? values : undefined,
                 FilterExpression: filters.length ? this.and(filters) : undefined,
                 KeyConditionExpression: keys.length ? keys.join(' and ') : undefined,
                 ProjectionExpression: project.length ? project.join(', ') : undefined,
-                TableName: this.tableName
+                TableName: this.tableName,
             };
             if (params.select) {
                 //  Select: ALL_ATTRIBUTES | ALL_PROJECTED_ATTRIBUTES | SPECIFIC_ATTRIBUTES | COUNT
@@ -521,7 +548,7 @@ class Expression {
                 if (params.return === true) {
                     returnValues = op === 'delete' ? 'ALL_OLD' : 'ALL_NEW';
                 }
-                else if (params.return === false) {
+                else if (params.return === false || params.return == 'none') {
                     returnValues = 'NONE';
                 }
                 else if (params.return != 'get') {
@@ -545,12 +572,12 @@ class Expression {
             else if (op == 'delete') {
                 args.ReturnValues = returnValues || 'ALL_OLD';
             }
-            if (op == 'delete' || op == 'get' || op == 'update') {
+            if (op == 'delete' || op == 'get' || op == 'update' || op == 'check') {
                 args.Key = key;
             }
             if (op == 'find' || op == 'get' || op == 'scan') {
-                args.ConsistentRead = params.consistent ? true : false,
-                    args.IndexName = params.index ? params.index : null;
+                args.ConsistentRead = params.consistent ? true : false;
+                args.IndexName = params.index ? params.index : null;
             }
             if (op == 'find' || op == 'scan') {
                 args.Limit = params.limit ? params.limit : undefined;
@@ -558,9 +585,28 @@ class Expression {
                     Scan reverse if either reverse or prev is true but not both. (XOR)
                     If both are true, then requesting the previous page of a reverse scan which is actually forwards.
                 */
-                args.ScanIndexForward = (params.reverse == true ^ (params.prev != null && params.next == null)) ? false : true;
-                if (params.next || params.prev) {
-                    args.ExclusiveStartKey = this.table.marshall(params.next || params.start || params.prev, params);
+                args.ScanIndexForward =
+                    (params.reverse == true) ^ (params.prev != null && params.next == null) ? false : true;
+                /*
+                    Cherry pick the required properties from the next/prev param
+                 */
+                let cursor = params.next || params.prev;
+                if (cursor) {
+                    let { hash, sort } = this.index;
+                    let start = { [hash]: cursor[hash] };
+                    if (sort && cursor[sort]) {
+                        start[sort] = cursor[sort];
+                    }
+                    if (this.params.index != 'primary') {
+                        let { hash, sort } = this.model.indexes.primary;
+                        start[hash] = cursor[hash];
+                        if (sort && cursor[sort] != null) {
+                            start[sort] = cursor[sort];
+                        }
+                    }
+                    if (start[hash]) {
+                        args.ExclusiveStartKey = this.table.marshall(start, params);
+                    }
                 }
             }
             if (op == 'scan') {
@@ -588,7 +634,7 @@ class Expression {
         if (terms.length == 1) {
             return terms.join('');
         }
-        return terms.map(t => `(${t})`).join(' and ');
+        return terms.map((t) => `(${t})`).join(' and ');
     }
     /*
         Add a name to the ExpressionAttribute names. Optimize duplicates and only store unique names once.
diff --git a/node_modules/dynamodb-onetable/dist/cjs/Metrics.d.ts b/node_modules/dynamodb-onetable/dist/cjs/Metrics.d.ts
index 6242d88..9fcb36f 100644
--- a/node_modules/dynamodb-onetable/dist/cjs/Metrics.d.ts
+++ b/node_modules/dynamodb-onetable/dist/cjs/Metrics.d.ts
@@ -4,6 +4,7 @@ export class Metrics {
     log: any;
     metrics: {
         chan: string;
+        custom: boolean;
         dimensions: string[];
         enable: boolean;
         env: boolean;
@@ -16,9 +17,11 @@ export class Metrics {
         source: string;
         tenant: any;
     };
-    add(model: any, op: any, result: any, params: any, mark: any): void;
+    add(model: any, op: any, result: any, params: any, mark: any): Promise<void>;
     addMetricGroup(values: any, dimensionValues: any, properties: any): void;
     addMetric(key: any, values: any, dimensions: any, dimensionValues: any, properties: any): void;
-    flushMetrics(timestamp?: number): void;
-    emitMetrics(timestamp: any, rec: any): void;
+    flush(timestamp?: number): Promise<void>;
+    emit(timestamp: any, rec: any): Promise<void>;
+    terminate(): Promise<void>;
+    setLog(log: any): void
 }
diff --git a/node_modules/dynamodb-onetable/dist/cjs/Metrics.js b/node_modules/dynamodb-onetable/dist/cjs/Metrics.js
index 3d5072f..4e20d71 100644
--- a/node_modules/dynamodb-onetable/dist/cjs/Metrics.js
+++ b/node_modules/dynamodb-onetable/dist/cjs/Metrics.js
@@ -4,20 +4,27 @@
  */
 Object.defineProperty(exports, "__esModule", { value: true });
 exports.Metrics = void 0;
+const custom_metrics_1 = require("custom-metrics");
 const DefaultMetrics = {
-    chan: 'dbmetrics',
+    chan: 'dbmetrics', //  Default channel
+    custom: true,
     dimensions: [
-        'Table', 'Tenant', 'Source', 'Index', 'Model', 'Operation' //  Default dimensions
+        // Default dimensions
+        'Table',
+        'Tenant',
+        'Source',
+        'Index',
+        'Model',
+        'Operation',
     ],
-    enable: true,
-    env: true,
-    hot: false,
-    max: 100,
-    namespace: 'SingleTable/Metrics.1',
-    period: 60,
-    properties: {},
-    queries: true,
-    source: process.env.AWS_LAMBDA_FUNCTION_NAME || 'Default',
+    enable: true, //  Enabled
+    env: true, //  Observe LOG_FILTER for dbmetrics
+    hot: false, //  Hot partition tracking
+    max: 100, //  Buffer metrics for 100 requests
+    namespace: 'SingleTable/Metrics.1', //  CloudWatch metrics namespace
+    period: 60, //  or buffer for 60 seconds
+    properties: {}, //  Additional properties to emit
+    source: process.env.AWS_LAMBDA_FUNCTION_NAME || 'Default', //  Default source name
     tenant: null,
 };
 const DynamoOps = {
@@ -44,9 +51,7 @@ const ReadWrite = {
     transactGet: 'read',
     transactWrite: 'write',
 };
-/*
-    Represent a single DynamoDB table
- */
+var Instances = {};
 class Metrics {
     constructor(table, params = {}, prior = {}) {
         this.table = table;
@@ -59,17 +64,34 @@ class Metrics {
             //  Params takes priority
             metrics = Object.assign({}, DefaultMetrics, params);
         }
+        if (metrics.custom && table.V3) {
+            let { hash, sort } = table.schema.indexes.primary;
+            this.custom = new custom_metrics_1.CustomMetrics({
+                table: table.name,
+                client: table.client,
+                primaryKey: hash,
+                sortKey: sort,
+                log: this.log,
+            });
+            Instances[`${table.name}`] = this;
+        }
         if (metrics.env && process.env) {
-            //  Need a better senselogs test than 'metrics'. Senselogs relies on the dbmetrics channel to be enabled.
-            if (!this.log.metrics) {
-                let filter = process.env.LOG_FILTER;
-                if (!filter || filter.indexOf('dbmetrics') < 0) {
-                    metrics.enable = false;
+            let filter = process.env.LOG_FILTER;
+            metrics.enable = false;
+            if (filter && filter.indexOf('dbmetrics') >= 0) {
+                metrics.enable = true;
+            }
+            else {
+                if (process.env.LOG_OVERRIDE != null) {
+                    let [expire, filter] = process.env.LOG_OVERRIDE.split(':');
+                    if (filter && filter.indexOf('dbmetrics') >= 0 && expire > Date.now()) {
+                        metrics.enable = true;
+                    }
                 }
             }
             metrics.dimensions = process.env.LOG_ONETABLE_DIMENSIONS || metrics.dimensions;
             if (!Array.isArray(metrics.dimensions)) {
-                metrics.dimensions = metrics.dimensions.split(',').map(i => i.trim());
+                metrics.dimensions = metrics.dimensions.split(',').map((i) => i.trim());
             }
         }
         metrics.map = { Profile: true };
@@ -84,7 +106,7 @@ class Metrics {
         metrics.properties = metrics.properties || prior.properties;
         this.metrics = metrics;
     }
-    add(model, op, result, params, mark) {
+    async add(model, op, result, params, mark) {
         let metrics = this.metrics;
         if (!metrics.enable || !this.log.enabled(metrics.chan)) {
             return;
@@ -110,16 +132,22 @@ class Metrics {
             count: result.Count || 1,
             latency: timestamp - mark,
             scanned: result.ScannedCount || 1,
-            op, capacity,
+            op,
+            capacity,
         };
-        let dimensionValues = {
+        let dimensions = {
             Table: this.table.name,
-            Tenant: metrics.tenant,
             Source: params.source || metrics.source,
             Index: params.index || 'primary',
             Model: model,
             Operation: DynamoOps[op],
         };
+        if (metrics.tenant) {
+            dimensions.Tenant = metrics.tenant;
+        }
+        /*
+            Add properties to be added to EMF records
+         */
         let properties;
         if (typeof metrics.properties == 'function') {
             properties = metrics.properties(op, params, result);
@@ -127,35 +155,40 @@ class Metrics {
         else {
             properties = metrics.properties || {};
         }
-        this.addMetricGroup(values, dimensionValues, properties);
-        if (metrics.queries && params.profile) {
-            dimensionValues.Profile = params.profile;
-            this.addMetric('Profile', values, ['Profile'], dimensionValues, properties);
+        this.addResultsToGroup(values, dimensions, properties);
+        if (params.profile) {
+            // dimensionValues.Profile = params.profile
+            this.addResults(`Profile-${params.profile}`, values, { Profile: params.profile }, properties);
         }
-        if (++metrics.count >= metrics.max || (metrics.lastFlushed + metrics.period) < timestamp) {
-            this.flushMetrics(timestamp);
+        if (++metrics.count >= metrics.max || metrics.lastFlushed + metrics.period < timestamp) {
+            await this.flush(timestamp);
             metrics.count = 0;
             metrics.lastFlushed = timestamp;
         }
     }
-    addMetricGroup(values, dimensionValues, properties) {
-        let dimensions = [], keys = [];
+    /*
+        Add results to a group of dimensions
+     */
+    addResultsToGroup(values, allDimensions, properties) {
+        let dimensions = {}, keys = [];
         for (let name of this.metrics.dimensions) {
-            let dimension = dimensionValues[name];
+            let dimension = allDimensions[name];
             if (dimension) {
                 keys.push(dimension);
-                dimensions.push(name);
-                this.addMetric(keys.join('.'), values, dimensions, dimensionValues, properties);
+                dimensions[name] = dimension;
+                this.addResults(keys.join('.'), values, dimensions, properties);
             }
         }
     }
-    addMetric(key, values, dimensions, dimensionValues, properties) {
-        let rec = this.metrics.counters[key] = this.metrics.counters[key] || {
+    /*
+        Add results to a specific dimension set
+     */
+    addResults(key, values, dimensions, properties) {
+        let rec = (this.metrics.counters[key] = this.metrics.counters[key] || {
             totals: { count: 0, latency: 0, read: 0, requests: 0, scanned: 0, write: 0 },
-            dimensions: dimensions.slice(0),
-            dimensionValues,
+            dimensions: Object.assign({}, dimensions),
             properties,
-        };
+        });
         let totals = rec.totals;
         totals[ReadWrite[values.op]] += values.capacity; //  RCU, WCU
         totals.latency += values.latency; //  Latency in ms
@@ -163,42 +196,63 @@ class Metrics {
         totals.scanned += values.scanned; //  Items scanned
         totals.requests++; //  Number of requests
     }
-    flushMetrics(timestamp = Date.now()) {
+    static async terminate() {
+        await Metrics.flushAll();
+    }
+    static async flushAll() {
+        for (let instance of Object.values(Instances)) {
+            await instance.flush();
+        }
+    }
+    async flush(timestamp = Date.now()) {
         if (!this.metrics.enable)
             return;
         for (let rec of Object.values(this.metrics.counters)) {
-            Object.keys(rec).forEach(field => rec[field] === 0 && delete rec[field]);
-            this.emitMetrics(timestamp, rec);
+            Object.keys(rec.totals).forEach((field) => rec.totals[field] === 0 && delete rec.totals[field]);
+            await this.emitMetrics(timestamp, rec);
+        }
+        if (this.custom) {
+            await this.custom.flush();
         }
         this.metrics.counters = {};
     }
-    emitMetrics(timestamp, rec) {
-        let { dimensionValues, dimensions, properties, totals } = rec;
-        let metrics = this.metrics;
+    async emitMetrics(timestamp, rec) {
+        let { dimensions, properties, totals } = rec;
         let requests = totals.requests;
         totals.latency = totals.latency / requests;
         totals.count = totals.count / requests;
         totals.scanned = totals.scanned / requests;
-        if (this.log.metrics) {
-            let chan = metrics.chan || 'dbmetrics';
-            this.log.metrics(chan, `OneTable Custom Metrics ${dimensions}`, metrics.namespace, totals, dimensions, { latency: 'Milliseconds', default: 'Count' }, Object.assign({}, dimensionValues, properties));
+        let namespace = this.metrics.namespace;
+        let dkeys = Object.keys(dimensions);
+        if (this.custom) {
+            for (let [metric, value] of Object.entries(totals)) {
+                await this.custom.emit(namespace, metric, value, [dimensions], { buffer: { elapsed: 10 * 1000 } });
+            }
+        }
+        else if (this.log.metrics) {
+            this.log.metrics(this.metrics.chan || 'dbmetrics', `OneTable Custom Metrics`, namespace, totals, dkeys, { latency: 'Milliseconds', default: 'Count' }, Object.assign({}, dimensions, properties));
         }
         else {
-            let metrics = dimensions.map(v => {
+            let metrics = dkeys.map((v) => {
                 return { Name: v, Unit: v == 'latency' ? 'Milliseconds' : 'Count' };
             });
             let data = Object.assign({
                 _aws: {
                     Timestamp: timestamp,
-                    CloudWatchMetrics: [{
-                            Dimensions: [dimensions],
-                            Namespace: metrics.namespace,
+                    CloudWatchMetrics: [
+                        {
+                            dkeys,
+                            Namespace: namespace,
                             Metrics: metrics,
-                        }]
+                        },
+                    ],
                 },
-            }, totals, dimensionValues, properties);
-            console.log(`OneTable Custom Metrics ${dimensions}` + JSON.stringify(data));
+            }, totals, dimensions, properties);
+            console.log(`OneTable Custom Metrics ` + JSON.stringify(data));
         }
     }
+    setLog(log) {
+        this.log = log;
+    }
 }
 exports.Metrics = Metrics;
diff --git a/node_modules/dynamodb-onetable/dist/cjs/Model.d.ts b/node_modules/dynamodb-onetable/dist/cjs/Model.d.ts
index b09c5e5..020d269 100644
--- a/node_modules/dynamodb-onetable/dist/cjs/Model.d.ts
+++ b/node_modules/dynamodb-onetable/dist/cjs/Model.d.ts
@@ -3,60 +3,62 @@
 
     Supports dynamic definition of types based on the Schema.js
 */
-import { Expression } from './Expression'
+import {Expression} from './Expression.js'
 
 /*
     Possible types for a schema field "type" property
  */
 export type OneType =
-    ArrayConstructor |
-    BooleanConstructor |
-    DateConstructor |
-    NumberConstructor |
-    ObjectConstructor |
-    StringConstructor |
-    SetConstructor |
-    ArrayBufferConstructor |
-    string;
+    | ArrayConstructor
+    | BooleanConstructor
+    | DateConstructor
+    | NumberConstructor
+    | ObjectConstructor
+    | StringConstructor
+    | SetConstructor
+    | ArrayBufferConstructor
+    | string
 
 /*
     Schema.indexes signature
  */
 export type OneIndex = {
-    hash?: string,
-    sort?: string,
-    description?: string,
-    project?: string | readonly string[],
-    follow?: boolean,
-    type?: string,
-};
+    hash?: string
+    sort?: string
+    description?: string
+    project?: string | readonly string[]
+    follow?: boolean
+    type?: string
+}
 
 /*
     Schema.models.Model.Field signature
  */
 export type OneField = {
-    crypt?: boolean,
-    default?: string | number | boolean | object,
-    encode?: readonly string[],
-    enum?: readonly string[],
-    filter?: boolean,
-    generate?: string | boolean,
-    hidden?: boolean,
-    map?: string,
-    nulls?: boolean,
-    reference?: string,
-    required?: boolean,
-    timestamp?: boolean,
-    type: OneType,
-    unique?: boolean,
-    validate?: RegExp | string | boolean,
-    value?: boolean | string,
-    schema?: OneModel,
-    ttl?: boolean,
+    crypt?: boolean
+    default?: string | number | boolean | object | Array<any>
+    encode?: readonly (string | RegExp | number)[] | string
+    enum?: readonly string[]
+    filter?: boolean
+    generate?: string | boolean | function
+    hidden?: boolean
     items?: OneField
+    map?: string
+    nulls?: boolean
+    partial?: boolean
+    reference?: string
+    required?: boolean
+    schema?: OneModel
+    scope?: string
+    timestamp?: boolean
+    ttl?: boolean
+    type: OneType
+    unique?: boolean
+    validate?: RegExp | string | boolean
+    value?: boolean | string
 
     //  DEPRECATE 2.3
-    uuid?: boolean | string,
+    uuid?: boolean | string
 }
 
 /*
@@ -64,79 +66,97 @@ export type OneField = {
  */
 export type OneModel = {
     [key: string]: OneField
-};
+}
 
 /*
     Schema signature
  */
 export type OneSchema = {
-    name?: string,
-    version: string,
-    format?: string,
-    params?: OneSchemaParams,
+    name?: string
+    version: string
+    format?: string
+    params?: OneSchemaParams
     models: {
         [key: string]: OneModel
-    },
+    }
+    process?: object
     indexes: {
         [key: string]: OneIndex
-    },
-    queries?: {},
-};
+    }
+    queries?: {}
+}
 
 export type OneSchemaParams = {
-    createdField?: string,          //  Name of "created" timestamp attribute. Default to 'created'.
-    hidden?: boolean,               //  Hide key attributes in Javascript properties. Default false.
-    isoDates?: boolean,             //  Set to true to store dates as Javascript ISO Date strings. Default false.
-    nulls?: boolean,                //  Store nulls in database attributes. Default false.
-    timestamps?: boolean | string,  //  Make "created" and "updated" timestamps. Set to true, 'create' or 'update'. Default true.
-    typeField?: string,             //  Name of model type attribute. Default "_type".
-    updatedField?: string,          //  Name of "updated" timestamp attribute. Default 'updated'.
+    createdField?: string //  Name of "created" timestamp attribute. Default to 'created'.
+    hidden?: boolean //  Hide key attributes in Javascript properties. Default false.
+    isoDates?: boolean //  Set to true to store dates as Javascript ISO Date strings. Default false.
+    nulls?: boolean //  Store nulls in database attributes. Default false.
+    timestamps?: boolean | string //  Make "created" and "updated" timestamps. Set to true, 'create' or 'update'. Default true.
+    separator?: string // Separator string uses in value templates
+    typeField?: string //  Name of model type attribute. Default "_type".
+    updatedField?: string //  Name of "updated" timestamp attribute. Default 'updated'.
+    warn?: boolean // Emit warnings for some conditions. Default false.
+
+    legacyEmpties?: boolean // Remove empty strings
 }
 
 /*
     Entity field signature generated from the schema
  */
-type EntityField<T extends OneField> =
-    T['enum'] extends readonly EntityFieldFromType<T>[] ? T['enum'][number] : (EntityFieldFromType<T>);
-
-type EntityFieldFromType<T extends OneField> =
-      T['type'] extends (ArrayConstructor | 'array') ? ArrayItemType<T>[]
-    : T['type'] extends (BooleanConstructor | 'boolean') ? boolean
-    : T['type'] extends (NumberConstructor | 'number') ? number
-    : T['type'] extends (ObjectConstructor | 'object') ? Entity<Exclude<T["schema"], undefined>>
-    : T['type'] extends (DateConstructor | 'date') ? Date
-    : T['type'] extends (ArrayBufferConstructor) ? ArrayBuffer
-    : T['type'] extends (StringConstructor | 'string') ? string
-    : T['type'] extends (SetConstructor | 'set') ? Set<any>
-    : T['type'] extends 'typed-array' ? EntityFieldFromType<Exclude<T["items"], undefined>>[]
-    : never;
-
-type ArrayItemType<T extends OneField> =
-    T extends {items: OneField} ? EntityFieldFromType<T["items"]> : any
+type EntityField<T extends OneField> = T['enum'] extends readonly EntityFieldFromType<T>[]
+    ? T['enum'][number]
+    : EntityFieldFromType<T>
+
+type EntityFieldFromType<T extends OneField> = T['type'] extends ArrayConstructor | 'array'
+    ? ArrayItemType<T>[]
+    : T['type'] extends BooleanConstructor | 'boolean'
+    ? boolean
+    : T['type'] extends NumberConstructor | 'number'
+    ? number
+    : T['type'] extends ObjectConstructor | 'object'
+    ? (T['schema'] extends object ? Entity<Exclude<T['schema'], undefined>> : Record<any, any>)
+    : T['type'] extends DateConstructor | 'date'
+    ? Date
+    : T['type'] extends ArrayBufferConstructor
+    ? ArrayBuffer
+    : T['type'] extends StringConstructor | 'string'
+    ? string
+    : T['type'] extends SetConstructor | 'set'
+    ? Set<any>
+    : T['type'] extends 'typed-array'
+    ? EntityFieldFromType<Exclude<T['items'], undefined>>[]
+    : never
+
+type ArrayItemType<T extends OneField> = T extends {items: OneField}
+    ? EntityField<T['items']>
+    : any
 /*
     Select the required properties from a model
 */
 export type Required<T extends OneModel> = {
     -readonly [P in keyof T as T[P]['required'] extends true ? P : never]: EntityField<T[P]>
-};
+}
 
 /*
     Select the optional properties from a model
 */
 export type Optional<T extends OneModel> = {
     -readonly [P in keyof T as T[P]['required'] extends true ? never : P]?: EntityField<T[P]>
-};
+}
 
 type OptionalOrNull<T extends OneModel> = {
-    -readonly [P in keyof T as T[P]['required'] extends true ? never : P]?: (EntityField<T[P]> | null)
-};
+    -readonly [P in keyof T as T[P]['required'] extends true ? never : P]?: EntityField<T[P]> | null
+}
+type OptionalOrUndefined<T extends OneModel> = {
+    -readonly [P in keyof T as T[P]['required'] extends true ? never : P]?: EntityField<T[P]> | undefined
+}
 
 /*
     Select properties with generated values
 */
 export type Generated<T extends OneModel> = {
-    -readonly [P in keyof T as T[P]['generate'] extends (string | boolean) ? P : never]?: EntityField<T[P]>
-};
+    -readonly [P in keyof T as T[P]['generate'] extends string | boolean ? P : never]?: EntityField<T[P]>
+}
 
 /*
     Select properties with default values
@@ -144,36 +164,36 @@ export type Generated<T extends OneModel> = {
 type DefinedValue = string | number | bigint | boolean | symbol | object
 export type Defaulted<T extends OneModel> = {
     -readonly [P in keyof T as T[P]['default'] extends DefinedValue ? P : never]: EntityField<T[P]>
-};
+}
 
 /*
     Select value template properties
 */
 export type ValueTemplates<T extends OneModel> = {
     -readonly [P in keyof T as T[P]['value'] extends string ? P : never]: EntityField<T[P]>
-};
+}
 
 /*
     Select timestamp properties
 */
 export type TimestampValue<T extends OneModel> = {
     -readonly [P in keyof T as T[P]['timestamp'] extends true ? P : never]: EntityField<T[P]>
-};
+}
 
 /*
     Merge the properties of two types given preference to A.
 */
 type Merge<A extends any, B extends any> = {
-    [P in keyof (A & B)]: P extends keyof A ? A[P] : (P extends keyof B ? B[P] : never)
-};
+    [P in keyof (A & B)]: P extends keyof A ? A[P] : P extends keyof B ? B[P] : never
+}
 
 /*
     Create entity type which includes required and optional types
     An entity type is not used by the user and is only required internally.
     Merge gives better intellisense, but requires Flatten to make <infer X> work.
 */
-type Flatten<T> = { [P in keyof T]: T[P] };
-type Entity<T extends OneModel> = Flatten<Merge<Required<T>, Optional<T>>>
+type Flatten<T> = {[P in keyof T]: T[P]}
+type Entity<T extends OneModel> = Flatten<Merge<Required<T>, OptionalOrUndefined<T>>>
 
 /*
     Entity Parameters are partial Entities.
@@ -184,7 +204,8 @@ type EntityParameters<Entity> = Partial<Entity>
     Special case for find to allow query operators
 */
 type EntityParametersForFind<T> = Partial<{
-    [K in keyof T]: T[K]
+    [K in keyof T]:
+        | T[K]
         | Begins<T, K>
         | BeginsWith<T, K>
         | Between<T, K>
@@ -196,104 +217,109 @@ type EntityParametersForFind<T> = Partial<{
         | GreaterThan<T, K>
 }>
 
-type Begins<T, K extends keyof T> = { begins: T[K] }
-type BeginsWith<T, K extends keyof T> = { begins_with: T[K] }
-type Between<T, K extends keyof T> = { between: [T[K], T[K]] }
-type LessThan<T, K extends keyof T> = { '<': T[K] }
-type LessThanOrEqual<T, K extends keyof T> = { '<=': T[K] }
-type Equal<T, K extends keyof T> = { '=': T[K] }
-type NotEqual<T, K extends keyof T> = { '<>': T[K] }
-type GreaterThanOrEqual<T, K extends keyof T> = { '>=': T[K] }
-type GreaterThan<T, K extends keyof T> = { '>': T[K] }
+type Begins<T, K extends keyof T> = {begins: T[K]}
+type BeginsWith<T, K extends keyof T> = {begins_with: T[K]}
+type Between<T, K extends keyof T> = {between: [T[K], T[K]]}
+type LessThan<T, K extends keyof T> = {'<': T[K]}
+type LessThanOrEqual<T, K extends keyof T> = {'<=': T[K]}
+type Equal<T, K extends keyof T> = {'=': T[K]}
+type NotEqual<T, K extends keyof T> = {'<>': T[K]}
+type GreaterThanOrEqual<T, K extends keyof T> = {'>=': T[K]}
+type GreaterThan<T, K extends keyof T> = {'>': T[K]}
 
 /*
     Any entity. Essentially untyped.
  */
 export type AnyEntity = {
     [key: string]: any
-};
+}
 
 type ModelConstructorOptions = {
     fields?: OneModel
     indexes?: {
         [key: string]: OneIndex
-    },
-    timestamps?: boolean | string,
-};
+    }
+    timestamps?: boolean | string
+}
 
 /*
     Possible params options for all APIs
  */
 export type OneParams = {
-    add?: object,
-    batch?: object,
-    capacity?: string,
-    consistent?: boolean,
-    context?: object,
-    count?: boolean,
-    delete?: object,
-    execute?: boolean,
-    exists?: boolean | null,
-    fields?: string[],
-    follow?: boolean,
-    hidden?: boolean,
-    index?: string,
-    limit?: number,
-    log?: boolean,
-    many?: boolean,
-    maxPages?: number,
-    next?: object,
-    parse?: boolean,
-    partial?: boolean,
-    postFormat?: (model: AnyModel, cmd: {}) => {},
-    prev?: object,
-    push?: object,
-    remove?: string[],
-    reprocess?: boolean,
-    return?: string | boolean,
-    reverse?: boolean,
-    segment?: number,
-    segments?: number,
-    select?: string,
-    set?: object,
-    stats?: object,
-    substitutions?: object,
-    throw?: boolean,
-    transform?: (model: AnyModel, op: string, name: string, value: any, properties: OneProperties) => any,
-    transaction?: object,
-    type?: string,
-    tunnel?: object,
-    where?: string,
-};
+    add?: object
+    batch?: object
+    capacity?: string
+    consistent?: boolean
+    context?: object
+    count?: boolean
+    delete?: object
+    execute?: boolean
+    exists?: boolean | null
+    fields?: string[]
+    follow?: boolean
+    hidden?: boolean
+    index?: string
+    limit?: number
+    log?: boolean
+    many?: boolean
+    maxPages?: number
+    next?: object
+    //  DEPRECATED
+    noerror?: boolean
+    parse?: boolean
+    partial?: boolean
+    postFormat?: (model: AnyModel, cmd: {}) => {}
+    prev?: object
+    push?: object
+    remove?: string[]
+    reprocess?: boolean
+    return?: string | boolean
+    reverse?: boolean
+    segment?: number
+    segments?: number
+    select?: string
+    set?: object
+    stats?: object
+    substitutions?: object
+    timestamps?: boolean
+    throw?: boolean
+    transform?: (model: AnyModel, op: string, name: string, value: any, properties: OneProperties) => any
+    transaction?: object
+    type?: string
+    tunnel?: object
+    warn?: Boolean
+    where?: string
+    profile?: string
+}
 
 /*
     Properties for most APIs. Essentially untyped.
  */
 export type OneProperties = {
     [key: string]: any
-};
+}
 
 export class Paged<T> extends Array<T> {
-    count?: number;
-    next?: object;
-    prev?: object;
+    count?: number
+    next?: object
+    prev?: object
 }
 
 export type AnyModel = {
-    constructor(table: any, name: string, options?: ModelConstructorOptions): AnyModel;
-    create(properties: OneProperties, params?: OneParams): Promise<AnyEntity>;
-    find(properties?: OneProperties, params?: OneParams): Promise<Paged<AnyEntity>>;
-    get(properties: OneProperties, params?: OneParams): Promise<AnyEntity | undefined>;
-    load(properties: OneProperties, params?: OneParams): Promise<AnyEntity | undefined>;
-    init(properties?: OneProperties, params?: OneParams): AnyEntity;
-    remove(properties: OneProperties, params?: OneParams): Promise<AnyEntity | Array<AnyEntity> | undefined>;
-    scan(properties?: OneProperties, params?: OneParams): Promise<Paged<AnyEntity>>;
-    update(properties: OneProperties, params?: OneParams): Promise<AnyEntity>;
-    upsert(properties: OneProperties, params?: OneParams): Promise<AnyEntity>;
-};
+    constructor(table: any, name: string, options?: ModelConstructorOptions): AnyModel
+    create(properties: OneProperties, params?: OneParams): Promise<AnyEntity>
+    find(properties?: OneProperties, params?: OneParams): Promise<Paged<AnyEntity>>
+    get(properties: OneProperties, params?: OneParams): Promise<AnyEntity | undefined>
+    load(properties: OneProperties, params?: OneParams): Promise<AnyEntity | undefined>
+    init(properties?: OneProperties, params?: OneParams): AnyEntity
+    remove(properties: OneProperties, params?: OneParams): Promise<AnyEntity | Array<AnyEntity> | undefined>
+    scan(properties?: OneProperties, params?: OneParams): Promise<Paged<AnyEntity>>
+    update(properties: OneProperties, params?: OneParams): Promise<AnyEntity>
+    upsert(properties: OneProperties, params?: OneParams): Promise<AnyEntity>
+}
 
 type ExtractModel<M> = M extends Entity<infer X> ? X : never
-type GetKeys<T> = T extends T ? keyof T: never;
+type GetKeys<T> = T extends T ? keyof T : never
 
 /*
     Create the type for create properties.
@@ -302,30 +328,30 @@ type GetKeys<T> = T extends T ? keyof T: never;
 
     type EntityParametersForCreate<M extends OneModel> = Required<M> & Optional<M>
 */
-type EntityParametersForCreate<T extends OneModel> =
-    Omit<
-        Omit<
-            Omit<
-                Omit<
-                    Required<T>,
-                    GetKeys<Defaulted<T>>
-                >,
-                GetKeys<Generated<T>>
-            >, GetKeys<ValueTemplates<T>>
-        >, GetKeys<TimestampValue<T>>
-    > & Optional<T> & Partial<Generated<T>> & Partial<Defaulted<T>> & Partial<ValueTemplates<T>> & Partial<TimestampValue<T>>
+type EntityParametersForCreate<T extends OneModel> = Omit<
+    Omit<Omit<Omit<Required<T>, GetKeys<Defaulted<T>>>, GetKeys<Generated<T>>>, GetKeys<ValueTemplates<T>>>,
+    GetKeys<TimestampValue<T>>
+> &
+    Optional<T> &
+    Partial<Generated<T>> &
+    Partial<Defaulted<T>> &
+    Partial<ValueTemplates<T>> &
+    Partial<TimestampValue<T>>
 
 type EntityParametersForUpdate<T extends OneModel> = Partial<Required<T> & OptionalOrNull<T>>
 
+type TransactionalOneParams = OneParams & {transaction: object}
+
 export class Model<T> {
-    constructor(table: any, name: string, options?: ModelConstructorOptions);
-    create(properties: EntityParametersForCreate<ExtractModel<T>>, params?: OneParams): Promise<T>;
-    find(properties?: EntityParametersForFind<T>, params?: OneParams): Promise<Paged<T>>;
-    get(properties: EntityParameters<T>, params?: OneParams): Promise<T | undefined>;
-    load(properties: EntityParameters<T>, params?: OneParams): Promise<T | undefined>;
-    init(properties?: EntityParameters<T>, params?: OneParams): T;
-    remove(properties: EntityParameters<T>, params?: OneParams): Promise<T | Array<T> | undefined>;
-    scan(properties?: EntityParameters<T>, params?: OneParams): Promise<Paged<T>>;
-    update(properties: EntityParametersForUpdate<ExtractModel<T>>, params?: OneParams): Promise<T>;
-    upsert(properties: EntityParameters<T>, params?: OneParams): Promise<T>;
+    constructor(table: any, name: string, options?: ModelConstructorOptions)
+    create(properties: EntityParametersForCreate<ExtractModel<T>>, params?: OneParams): Promise<T>
+    find(properties?: EntityParametersForFind<T>, params?: OneParams): Promise<Paged<T>>
+    get(properties: EntityParameters<T>, params?: OneParams): Promise<T | undefined>
+    load(properties: EntityParameters<T>, params?: OneParams): Promise<T | undefined>
+    init(properties?: EntityParameters<T>, params?: OneParams): T
+    remove(properties: EntityParameters<T>, params?: OneParams): Promise<T | Array<T> | undefined>
+    scan(properties?: EntityParameters<T>, params?: OneParams): Promise<Paged<T>>
+    update(properties: EntityParametersForUpdate<ExtractModel<T>>, params?: OneParams): Promise<T>
+    upsert(properties: EntityParameters<T>, params?: OneParams): Promise<T>
+    check(properties: EntityParameters<T>, params: TransactionalOneParams): void
 }
diff --git a/node_modules/dynamodb-onetable/dist/cjs/Model.js b/node_modules/dynamodb-onetable/dist/cjs/Model.js
index 8a94cbb..69a6778 100644
--- a/node_modules/dynamodb-onetable/dist/cjs/Model.js
+++ b/node_modules/dynamodb-onetable/dist/cjs/Model.js
@@ -1,13 +1,4 @@
 "use strict";
-var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
-    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
-    return new (P || (P = Promise))(function (resolve, reject) {
-        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
-        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
-        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
-        step((generator = generator.apply(thisArg, _arguments || [])).next());
-    });
-};
 Object.defineProperty(exports, "__esModule", { value: true });
 exports.Model = void 0;
 /*
@@ -15,6 +6,7 @@ exports.Model = void 0;
 
     A model represents a DynamoDB single-table entity.
 */
+const buffer_1 = require("buffer");
 const Expression_js_1 = require("./Expression.js");
 const Error_js_1 = require("./Error.js");
 /*
@@ -26,7 +18,7 @@ const ReadWrite = {
     find: 'read',
     put: 'write',
     scan: 'read',
-    update: 'write'
+    update: 'write',
 };
 const TransformParseResponseAs = {
     delete: 'get',
@@ -34,10 +26,10 @@ const TransformParseResponseAs = {
     find: 'find',
     put: 'get',
     scan: 'scan',
-    update: 'get'
+    update: 'get',
 };
 const KeysOnly = { delete: true, get: true };
-const TransactOps = { delete: 'Delete', get: 'Get', put: 'Put', update: 'Update' };
+const TransactOps = { delete: 'Delete', get: 'Get', put: 'Put', update: 'Update', check: 'ConditionCheck' };
 const BatchOps = { delete: 'DeleteRequest', put: 'PutRequest', update: 'PutRequest' };
 const ValidTypes = ['array', 'arraybuffer', 'binary', 'boolean', 'buffer', 'date', 'number', 'object', 'set', 'string'];
 const SanityPages = 1000;
@@ -66,16 +58,12 @@ class Model {
         this.sort = null;
         //  Cache table properties
         this.createdField = table.createdField;
-        this.generic = options.generic;
         this.nested = false;
         this.nulls = table.nulls;
         this.tableName = table.name;
         this.typeField = options.typeField || table.typeField;
         this.generic = options.generic != null ? options.generic : table.generic;
-        this.timestamps = options.timestamps;
-        if (this.timestamps == null) {
-            this.timestamps = table.timestamps;
-        }
+        this.timestamps = options.timestamps != null ? options.timestamps : table.timestamps;
         this.updatedField = table.updatedField;
         this.block = { fields: {}, deps: [] };
         /*
@@ -98,10 +86,10 @@ class Model {
     /*
         Prepare a model based on the schema and compute the attribute mapping.
      */
-    prepModel(schemaFields, block, prefix = '') {
+    prepModel(schemaFields, block, parent) {
         let { fields } = block;
         schemaFields = this.table.assign({}, schemaFields);
-        if (!prefix) {
+        if (!parent) {
             //  Top level only
             if (!schemaFields[this.typeField]) {
                 schemaFields[this.typeField] = { type: String, hidden: true };
@@ -122,20 +110,34 @@ class Model {
         let mapTargets = {};
         let map = {};
         for (let [name, field] of Object.entries(schemaFields)) {
-            let pathname = prefix ? `${prefix}.${name}` : name;
             if (!field.type) {
                 field.type = 'string';
-                this.table.log.error(`Missing type field for ${pathname}`, { field });
-                // throw new OneTableArgError(`Missing field type for ${pathname}`)
+                this.table.log.error(`Missing type field for ${field.name}`, { field });
             }
-            field.pathname = pathname;
             field.name = name;
             fields[name] = field;
-            field.isoDates = field.isoDates != null ? field.isoDates : table.isoDates;
-            //  DEPRECATE 2.3
+            field.isoDates = field.isoDates != null ? field.isoDates : table.isoDates || false;
+            if (field.partial == null) {
+                field.partial = parent && parent.partial != null ? parent.partial : this.table.partial;
+            }
             if (field.uuid) {
-                console.warn('The "uuid" schema property is deprecated. Please use "generate": "uuid or ulid" instead');
-                field.generate = field.generate || field.uuid;
+                throw new Error_js_1.OneTableArgError('The "uuid" schema property is deprecated. Please use "generate": "uuid or ulid" instead');
+            }
+            if (field.encode) {
+                let schema = this.schema.definition;
+                if (typeof field.encode == 'string' && this.table.separator) {
+                    let def = schema.models[this.name][field.encode];
+                    if (def?.value) {
+                        let parts = def.value.match(/\${(.*?)}/g);
+                        let index = parts.indexOf('${' + field.name + '}');
+                        if (index >= 0) {
+                            field.encode = [field.encode, this.table.separator, index];
+                        }
+                    }
+                    if (typeof field.encode == 'string') {
+                        throw new Error_js_1.OneTableArgError(`Cannot resolve encoded reference for ${this.name}.${field.name}`);
+                    }
+                }
             }
             field.type = this.checkType(field);
             /*
@@ -151,7 +153,7 @@ class Model {
                     }
                     field.attribute = map[name] = [att, sub];
                     if (mapTargets[att].indexOf(sub) >= 0) {
-                        throw new Error_js_1.OneTableArgError(`Multiple attributes in ${this.pathname} mapped to the target ${to}`);
+                        throw new Error_js_1.OneTableArgError(`Multiple attributes in ${field.name} mapped to the target ${to}`);
                     }
                     mapTargets[att].push(sub);
                 }
@@ -173,10 +175,10 @@ class Model {
                 Handle index requirements
             */
             let index = this.indexProperties[field.attribute[0]];
-            if (index && !prefix) {
+            if (index && !parent) {
                 field.isIndexed = true;
                 if (field.attribute.length > 1) {
-                    throw new Error_js_1.OneTableArgError(`Cannot map property "${pathname}" to a compound attribute "${this.name}.${pathname}"`);
+                    throw new Error_js_1.OneTableArgError(`Cannot map property "${field.name}" to a compound attribute"`);
                 }
                 if (index == 'primary') {
                     field.required = true;
@@ -189,31 +191,35 @@ class Model {
                     }
                 }
             }
+            if (parent && field.partial === undefined && parent.partial !== undefined) {
+                field.partial = parent.partial;
+            }
             if (field.value) {
                 //  Value template properties are hidden by default
                 if (field.hidden == null) {
-                    field.hidden = table.hidden != null ? table.hidden : true;
+                    field.hidden = true;
                 }
             }
             /*
                 Handle nested schema (recursive)
             */
+            if (field.items && field.type == 'array') {
+                field.schema = field.items.schema;
+                field.isArray = true;
+            }
             if (field.schema) {
-                if (field.type == 'array') {
-                    throw new Error_js_1.OneTableArgError(`Array types do not (yet) support nested schemas for field "${field.name}" in model "${this.name}"`);
-                }
-                if (field.type == 'object') {
+                if (field.type == 'object' || field.type == 'array') {
                     field.block = { deps: [], fields: {} };
-                    this.prepModel(field.schema, field.block, pathname);
+                    this.prepModel(field.schema, field.block, field);
                     //  FUTURE - better to apply this to the field block
                     this.nested = true;
                 }
                 else {
-                    throw new Error_js_1.OneTableArgError(`Nested scheme not supported "${field.type}" types for field "${field.name}" in model "${this.name}"`);
+                    throw new Error_js_1.OneTableArgError(`Nested scheme does not supported "${field.type}" types for field "${field.name}" in model "${this.name}"`);
                 }
             }
         }
-        if (Object.values(fields).find(f => f.unique && f.attribute != this.hash && f.attribute != this.sort)) {
+        if (Object.values(fields).find((f) => f.unique && f.attribute != this.hash && f.attribute != this.sort)) {
             this.hasUniqueFields = true;
         }
         this.mappings = mapTargets;
@@ -237,13 +243,13 @@ class Model {
     }
     orderFields(block, field) {
         let { deps, fields } = block;
-        if (deps.find(i => i.name == field.pathname)) {
+        if (deps.find((i) => i.name == field.name)) {
             return;
         }
         if (field.value) {
             let vars = this.table.getVars(field.value);
-            for (let pathname of vars) {
-                let name = pathname.split('.').shift();
+            for (let path of vars) {
+                let name = path.split(/[.[]/g).shift().trim(']');
                 let ref = fields[name];
                 if (ref && ref != field) {
                     if (ref.schema) {
@@ -260,6 +266,8 @@ class Model {
     getPropValue(properties, path) {
         let v = properties;
         for (let part of path.split('.')) {
+            if (v == null)
+                return v;
             v = v[part];
         }
         return v;
@@ -268,212 +276,224 @@ class Model {
         Run an operation on DynamodDB. The command has been parsed via Expression.
         Returns [] for find/scan, cmd if !execute, else returns item.
      */
-    run(op, expression) {
-        return __awaiter(this, void 0, void 0, function* () {
-            let { index, properties, params } = expression;
-            //  UNDOCUMENTED AND DEPRECATED
-            if (params.preFormat) {
-                params.preFormat(this, expression);
-            }
-            /*
-                Get a string representation of the API request
-             */
-            let cmd = expression.command();
-            if (!expression.execute) {
-                if (params.log !== false) {
-                    this.table.log[params.log ? 'info' : 'data'](`OneTable command for "${op}" "${this.name} (not executed)"`, {
-                        cmd, op, properties, params,
-                    });
-                }
-                return cmd;
+    async run(op, expression) {
+        let { index, properties, params } = expression;
+        /*
+            Get a string representation of the API request
+         */
+        let cmd = expression.command();
+        if (!expression.execute) {
+            if (params.log !== false) {
+                this.table.log[params.log ? 'info' : 'data'](`OneTable command for "${op}" "${this.name} (not executed)"`, {
+                    cmd,
+                    op,
+                    properties,
+                    params,
+                });
             }
-            /*
-                Transactions save the command in params.transaction and wait for db.transaction() to be called.
-             */
-            let t = params.transaction;
-            if (t) {
-                if (params.batch) {
-                    throw new Error_js_1.OneTableArgError('Cannot have batched transactions');
-                }
-                let top = TransactOps[op];
-                if (top) {
-                    params.expression = expression;
-                    let items = t.TransactItems = t.TransactItems || [];
-                    items.push({ [top]: cmd });
-                    return this.transformReadItem(op, properties, properties, params);
-                }
-                else {
-                    throw new Error_js_1.OneTableArgError(`Unknown transaction operation ${op}`);
-                }
+            return cmd;
+        }
+        /*
+            Transactions save the command in params.transaction and wait for db.transaction() to be called.
+         */
+        let t = params.transaction;
+        if (t) {
+            if (params.batch) {
+                throw new Error_js_1.OneTableArgError('Cannot have batched transactions');
             }
-            /*
-                Batch operations save the command in params.transaction and wait for db.batchGet|batchWrite to be called.
-             */
-            let b = params.batch;
-            if (b) {
+            let top = TransactOps[op];
+            if (top) {
                 params.expression = expression;
-                let ritems = b.RequestItems = b.RequestItems || {};
-                if (op == 'get') {
-                    let list = ritems[this.tableName] = ritems[this.tableName] || { Keys: [] };
-                    list.Keys.push(cmd.Keys);
-                    return this.transformReadItem(op, properties, properties, params);
-                }
-                else {
-                    let list = ritems[this.tableName] = ritems[this.tableName] || [];
-                    let bop = BatchOps[op];
-                    list.push({ [bop]: cmd });
-                    return this.transformReadItem(op, properties, properties, params);
-                }
+                let items = (t.TransactItems = t.TransactItems || []);
+                items.push({ [top]: cmd });
+                return this.transformReadItem(op, properties, properties, params, expression);
             }
-            /*
-                Prep the stats
-            */
-            let stats = params.stats;
-            if (stats && typeof params == 'object') {
-                stats.count = stats.count || 0;
-                stats.scanned = stats.capacity || 0;
-                stats.capacity = stats.capacity || 0;
+            else {
+                throw new Error_js_1.OneTableArgError(`Unknown transaction operation ${op}`);
             }
-            /*
-                Run command. Paginate if required.
-             */
-            let pages = 0, items = [], count = 0;
-            let maxPages = params.maxPages ? params.maxPages : SanityPages;
-            let result;
-            do {
-                result = yield this.table.execute(this.name, op, cmd, properties, params);
-                if (result.LastEvaluatedKey) {
-                    //  Continue next page
-                    cmd.ExclusiveStartKey = result.LastEvaluatedKey;
-                }
-                if (result.Items) {
-                    items = items.concat(result.Items);
-                    if (stats) {
-                        stats.count += result.Count;
-                        stats.scanned += result.ScannedCount;
-                        if (result.ConsumedCapacity) {
-                            stats.capacity += result.ConsumedCapacity.CapacityUnits;
-                        }
-                    }
-                }
-                else if (result.Item) {
-                    items = [result.Item];
-                    break;
-                }
-                else if (result.Attributes) {
-                    items = [result.Attributes];
-                    break;
+        }
+        /*
+            Batch operations save the command in params.transaction and wait for db.batchGet|batchWrite to be called.
+         */
+        let b = params.batch;
+        if (b) {
+            params.expression = expression;
+            let ritems = (b.RequestItems = b.RequestItems || {});
+            if (op == 'get') {
+                let list = (ritems[this.tableName] = ritems[this.tableName] || { Keys: [] });
+                list.Keys.push(cmd.Keys);
+                return this.transformReadItem(op, properties, properties, params, expression);
+            }
+            else {
+                let list = (ritems[this.tableName] = ritems[this.tableName] || []);
+                let bop = BatchOps[op];
+                list.push({ [bop]: cmd });
+                return this.transformReadItem(op, properties, properties, params, expression);
+            }
+        }
+        /*
+            Prep the stats
+        */
+        let stats = params.stats;
+        if (stats && typeof params == 'object') {
+            stats.count = stats.count || 0;
+            stats.scanned = stats.capacity || 0;
+            stats.capacity = stats.capacity || 0;
+        }
+        /*
+            Run command. Paginate if required.
+         */
+        let pages = 0, items = [], count = 0;
+        let maxPages = params.maxPages ? params.maxPages : SanityPages;
+        let result;
+        do {
+            result = await this.table.execute(this.name, op, cmd, properties, params);
+            if (result.LastEvaluatedKey) {
+                //  Continue next page
+                cmd.ExclusiveStartKey = result.LastEvaluatedKey;
+            }
+            if (result.Items) {
+                items = items.concat(result.Items);
+            }
+            else if (result.Item) {
+                items = [result.Item];
+                break;
+            }
+            else if (result.Attributes) {
+                items = [result.Attributes];
+                break;
+            }
+            else if (params.count || params.select == 'COUNT') {
+                count += result.Count;
+            }
+            if (stats) {
+                if (result.Count) {
+                    stats.count += result.Count;
                 }
-                else if (params.count || params.select == 'COUNT') {
-                    count += result.Count;
+                if (result.ScannedCount) {
+                    stats.scanned += result.ScannedCount;
                 }
-                if (params.progress) {
-                    params.progress({ items, pages, stats, params, cmd });
+                if (result.ConsumedCapacity) {
+                    stats.capacity += result.ConsumedCapacity.CapacityUnits;
                 }
-                if (items.length) {
-                    if (cmd.Limit) {
-                        cmd.Limit -= result.Count;
-                        if (cmd.Limit <= 0) {
-                            break;
-                        }
+            }
+            if (params.progress) {
+                params.progress({ items, pages, stats, params, cmd });
+            }
+            if (items.length) {
+                if (cmd.Limit) {
+                    cmd.Limit -= result.Count;
+                    if (cmd.Limit <= 0) {
+                        break;
                     }
                 }
-            } while (result.LastEvaluatedKey && (maxPages == null || ++pages < maxPages));
-            let prev;
-            if ((op == 'find' || op == 'scan') && items.length) {
-                if (items.length) {
-                    /*
-                        Determine next / previous cursors. Note: data items not yet reversed if scanning backwards.
-                        Can use LastEvaluatedKey for the direction of scanning. Calculate the other end from the returned items.
-                        Next/prev will be swapped when the items are reversed below
-                    */
-                    let { hash, sort } = (params.index && params.index != 'primary') ? index : this.indexes.primary;
-                    let cursor = { [hash]: items[0][hash], [sort]: items[0][sort] };
-                    if (cursor[hash] == null || cursor[sort] == null) {
-                        cursor = null;
-                    }
-                    // next = result.LastEvaluatedKey
-                    if (params.next || params.prev) {
-                        prev = cursor;
+            }
+        } while (result.LastEvaluatedKey && (maxPages == null || ++pages < maxPages));
+        let prev;
+        if ((op == 'find' || op == 'scan') && items.length) {
+            if (items.length) {
+                /*
+                    Determine next / previous cursors. Note: data items not yet reversed if scanning backwards.
+                    Can use LastEvaluatedKey for the direction of scanning. Calculate the other end from the returned items.
+                    Next/prev will be swapped when the items are reversed below
+                */
+                let { hash, sort } = params.index && params.index != 'primary' ? index : this.indexes.primary;
+                let cursor = { [hash]: items[0][hash], [sort]: items[0][sort] };
+                if (cursor[hash] == null || cursor[sort] == null) {
+                    cursor = null;
+                }
+                if (params.next || params.prev) {
+                    prev = cursor;
+                    if (cursor && params.index != 'primary') {
+                        let { hash, sort } = this.indexes.primary;
+                        prev[hash] = items[0][hash];
+                        if (sort != null) {
+                            prev[sort] = items[0][sort];
+                        }
                     }
                 }
             }
-            /*
-                Process the response
-            */
-            if (params.parse) {
-                items = this.parseResponse(op, expression, items);
+        }
+        /*
+            Process the response
+        */
+        if (params.parse) {
+            items = this.parseResponse(op, expression, items);
+        }
+        /*
+            Handle pagination next/prev
+        */
+        if (op == 'find' || op == 'scan') {
+            if (result.LastEvaluatedKey) {
+                items.next = this.table.unmarshall(result.LastEvaluatedKey, params);
+                Object.defineProperty(items, 'next', { enumerable: false });
             }
-            /*
-                Handle pagination next/prev
-            */
-            if (op == 'find' || op == 'scan') {
-                if (result.LastEvaluatedKey) {
-                    items.next = this.table.unmarshall(result.LastEvaluatedKey, params);
-                    Object.defineProperty(items, 'next', { enumerable: false });
-                }
-                if (params.count || params.select == 'COUNT') {
-                    items.count = count;
-                    Object.defineProperty(items, 'count', { enumerable: false });
-                }
-                if (prev) {
-                    items.prev = this.table.unmarshall(prev, params);
-                    Object.defineProperty(items, 'prev', { enumerable: false });
-                }
-                if (params.prev && params.next == null && op != 'scan') {
-                    //  DynamoDB scan ignores ScanIndexForward
-                    items = items.reverse();
-                    let tmp = items.prev;
-                    items.prev = items.next;
-                    items.next = tmp;
-                }
+            if (params.count || params.select == 'COUNT') {
+                items.count = count;
+                Object.defineProperty(items, 'count', { enumerable: false });
             }
-            /*
-                Log unless the user provides params.log: false.
-                The logger will typically filter data/trace.
-            */
-            if (params.log !== false) {
-                this.table.log[params.log ? 'info' : 'data'](`OneTable result for "${op}" "${this.name}"`, {
-                    cmd, items, op, properties, params,
-                });
+            if (prev) {
+                items.prev = this.table.unmarshall(prev, params);
+                Object.defineProperty(items, 'prev', { enumerable: false });
             }
-            /*
-                Handle transparent follow. Get/Update/Find the actual item using the keys
-                returned from the request on the GSI.
-            */
-            if (params.follow || (index.follow && params.follow !== false)) {
-                if (op == 'get') {
-                    return yield this.get(items[0]);
-                }
-                if (op == 'update') {
-                    properties = Object.assign({}, properties, items[0]);
-                    return yield this.update(properties);
-                }
-                if (op == 'find') {
-                    let results = [], promises = [];
-                    params = Object.assign({}, params);
-                    delete params.follow;
-                    delete params.index;
-                    delete params.fallback;
-                    for (let item of items) {
-                        promises.push(this.get(item, params));
-                        if (promises.length > FollowThreads) {
-                            results = results.concat(yield Promise.all(promises));
-                            promises = [];
-                        }
-                    }
-                    if (promises.length) {
-                        results = results.concat(yield Promise.all(promises));
+            if (params.prev && params.next == null && op != 'scan') {
+                //  DynamoDB scan ignores ScanIndexForward
+                items = items.reverse();
+                let tmp = items.prev;
+                items.prev = items.next;
+                items.next = tmp;
+            }
+        }
+        /*
+            Log unless the user provides params.log: false.
+            The logger will typically filter data/trace.
+        */
+        if (params.log !== false) {
+            this.table.log[params.log ? 'info' : 'data'](`OneTable result for "${op}" "${this.name}"`, {
+                cmd,
+                items,
+                op,
+                properties,
+                params,
+            });
+        }
+        /*
+            Handle transparent follow. Get/Update/Find the actual item using the keys
+            returned from the request on the GSI.
+        */
+        if (params.follow || (index.follow && params.follow !== false)) {
+            if (op == 'get') {
+                return await this.get(items[0]);
+            }
+            if (op == 'update') {
+                properties = Object.assign({}, properties, items[0]);
+                return await this.update(properties);
+            }
+            if (op == 'find') {
+                let results = [], promises = [];
+                params = Object.assign({}, params);
+                delete params.follow;
+                delete params.index;
+                delete params.fallback;
+                for (let item of items) {
+                    promises.push(this.get(item, params));
+                    if (promises.length > FollowThreads) {
+                        results = results.concat(await Promise.all(promises));
+                        promises = [];
                     }
-                    results.next = items.next;
-                    results.prev = items.prev;
-                    Object.defineProperty(results, 'next', { enumerable: false });
-                    Object.defineProperty(results, 'prev', { enumerable: false });
-                    return results;
                 }
+                if (promises.length) {
+                    results = results.concat(await Promise.all(promises));
+                }
+                results.next = items.next;
+                results.prev = items.prev;
+                results.count = items.count;
+                Object.defineProperty(results, 'next', { enumerable: false });
+                Object.defineProperty(results, 'prev', { enumerable: false });
+                return results;
             }
-            return (op == 'find' || op == 'scan') ? items : items[0];
-        });
+        }
+        return op == 'find' || op == 'scan' ? items : items[0];
     }
     /*
         Parse the response into Javascript objects and transform for the high level API.
@@ -500,7 +520,7 @@ class Model {
                     //  Special "unique" model for unique fields. Don't return in result.
                     continue;
                 }
-                items[index] = model.transformReadItem(op, item, properties, params);
+                items[index] = model.transformReadItem(op, item, properties, params, expression);
             }
         }
         return items;
@@ -508,374 +528,416 @@ class Model {
     /*
         Create/Put a new item. Will overwrite existing items if exists: null.
     */
-    create(properties, params = {}) {
-        return __awaiter(this, void 0, void 0, function* () {
-            ({ properties, params } = this.checkArgs(properties, params, { parse: true, high: true, exists: false }));
-            let result;
-            if (this.hasUniqueFields) {
-                result = yield this.createUnique(properties, params);
-            }
-            else {
-                result = yield this.putItem(properties, params);
-            }
-            return result;
-        });
+    async create(properties, params = {}) {
+        ;
+        ({ properties, params } = this.checkArgs(properties, params, { parse: true, high: true, exists: false }));
+        let result;
+        if (this.hasUniqueFields) {
+            result = await this.createUnique(properties, params);
+        }
+        else {
+            result = await this.putItem(properties, params);
+        }
+        return result;
     }
     /*
         Create an item with unique attributes. Use a transaction to create a unique item for each unique attribute.
      */
-    createUnique(properties, params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            if (params.batch) {
-                throw new Error_js_1.OneTableArgError('Cannot use batch with unique properties which require transactions');
-            }
-            let transactHere = params.transaction ? false : true;
-            let transaction = params.transaction = params.transaction || {};
-            let { hash, sort } = this.indexes.primary;
-            let fields = this.block.fields;
-            fields = Object.values(fields).filter(f => f.unique && f.attribute != hash && f.attribute != sort);
+    async createUnique(properties, params) {
+        if (params.batch) {
+            throw new Error_js_1.OneTableArgError('Cannot use batch with unique properties which require transactions');
+        }
+        let transactHere = params.transaction ? false : true;
+        let transaction = (params.transaction = params.transaction || {});
+        let { hash, sort } = this.indexes.primary;
+        let fields = this.block.fields;
+        fields = Object.values(fields).filter((f) => f.unique && f.attribute != hash && f.attribute != sort);
+        let timestamp = (transaction.timestamp = transaction.timestamp || new Date());
+        if (params.timestamps !== false) {
             if (this.timestamps === true || this.timestamps == 'create') {
-                properties[this.createdField] = new Date();
+                properties[this.createdField] = timestamp;
             }
             if (this.timestamps === true || this.timestamps == 'update') {
-                properties[this.updatedField] = new Date();
-            }
-            params.prepared = properties = this.prepareProperties('put', properties, params);
-            for (let field of fields) {
-                if (properties[field.name] !== undefined) {
-                    let scope = '';
-                    if (field.scope) {
-                        scope = this.runTemplate(null, null, field, properties, params, field.scope) + '#';
+                properties[this.updatedField] = timestamp;
+            }
+        }
+        params.prepared = properties = this.prepareProperties('put', properties, params);
+        let ttlField = fields.find(f => f.ttl);
+        for (let field of fields) {
+            if (properties[field.name] !== undefined) {
+                let scope = '';
+                if (field.scope) {
+                    scope = this.runTemplate(null, null, field, properties, params, field.scope) + '#';
+                    if (scope == undefined) {
+                        throw new Error_js_1.OneTableError('Missing properties to resolve unique scope', {
+                            properties,
+                            field,
+                            scope: field.scope,
+                            code: 'UniqueError',
+                        });
                     }
-                    let pk = `_unique#${scope}${this.name}#${field.attribute}#${properties[field.name]}`;
-                    let sk = '_unique#';
-                    yield this.schema.uniqueModel.create({ [this.hash]: pk, [this.sort]: sk }, { transaction, exists: false, return: 'NONE' });
                 }
+                let pk = `_unique#${scope}${this.name}#${field.attribute}#${properties[field.name]}`;
+                let sk = '_unique#';
+                let uproperties = { [this.hash]: pk, [this.sort]: sk };
+                if (ttlField) {
+                    /*
+                        Add a TTL expiry property to the unique record
+                     */
+                    let value = properties[ttlField.name];
+                    uproperties[ttlField.name] = new Date(new Date(value).getTime() * 1000);
+                }
+                await this.schema.uniqueModel.create(uproperties, { transaction, exists: false, return: 'NONE' });
             }
-            let item = yield this.putItem(properties, params);
-            if (!transactHere) {
-                return item;
+        }
+        let item = await this.putItem(properties, params);
+        if (!transactHere) {
+            return item;
+        }
+        let expression = params.expression;
+        try {
+            await this.table.transact('write', params.transaction, params);
+        }
+        catch (err) {
+            if (err instanceof Error_js_1.OneTableError &&
+                err.code === 'TransactionCanceledException' &&
+                err.context.err.message.indexOf('ConditionalCheckFailed') !== -1) {
+                let names = fields.map((f) => f.name).join(', ');
+                throw new Error_js_1.OneTableError(`Cannot create unique attributes "${names}" for "${this.name}". An item of the same name already exists.`, { properties, transaction, code: 'UniqueError' });
             }
-            let expression = params.expression;
-            try {
-                yield this.table.transact('write', params.transaction, params);
+            throw err;
+        }
+        let items = this.parseResponse('put', expression);
+        return items[0];
+    }
+    async check(properties, params) {
+        ;
+        ({ properties, params } = this.checkArgs(properties, params, { parse: true, high: true }));
+        properties = this.prepareProperties('get', properties, params);
+        const expression = new Expression_js_1.Expression(this, 'check', properties, params);
+        this.run('check', expression);
+    }
+    async find(properties = {}, params = {}) {
+        ;
+        ({ properties, params } = this.checkArgs(properties, params, { parse: true, high: true }));
+        return await this.queryItems(properties, params);
+    }
+    async get(properties = {}, params = {}) {
+        ;
+        ({ properties, params } = this.checkArgs(properties, params, { parse: true, high: true }));
+        properties = this.prepareProperties('get', properties, params);
+        if (params.fallback) {
+            if (params.batch) {
+                throw new Error_js_1.OneTableError('Need complete keys for batched get operation', {
+                    properties,
+                    code: 'NonUniqueError',
+                });
             }
-            catch (err) {
-                if (err instanceof Error_js_1.OneTableError && err.code === 'TransactionCanceledException' && err.context.err.message.indexOf('ConditionalCheckFailed') !== -1) {
-                    let names = fields.map(f => f.name).join(', ');
-                    throw new Error_js_1.OneTableError(`Cannot create unique attributes "${names}" for "${this.name}". An item of the same name already exists.`, { properties, transaction, code: 'UniqueError' });
-                }
-                throw err;
+            //  Fallback via find when using non-primary indexes
+            params.limit = 2;
+            let items = await this.find(properties, params);
+            if (items.length > 1) {
+                throw new Error_js_1.OneTableError('Get without sort key returns more than one result', {
+                    properties,
+                    code: 'NonUniqueError',
+                });
             }
-            let items = this.parseResponse('put', expression);
             return items[0];
-        });
-    }
-    find(properties = {}, params = {}) {
-        return __awaiter(this, void 0, void 0, function* () {
-            ({ properties, params } = this.checkArgs(properties, params, { parse: true, high: true }));
-            return yield this.queryItems(properties, params);
-        });
-    }
-    get(properties = {}, params = {}) {
-        return __awaiter(this, void 0, void 0, function* () {
-            ({ properties, params } = this.checkArgs(properties, params, { parse: true, high: true }));
-            properties = this.prepareProperties('get', properties, params);
-            if (params.fallback) {
-                //  Fallback via find when using non-primary indexes
-                params.limit = 2;
-                let items = yield this.find(properties, params);
-                if (items.length > 1) {
-                    throw new Error_js_1.OneTableError('Get without sort key returns more than one result', { properties, code: 'NonUniqueError' });
-                }
-                return items[0];
-            }
-            //  FUTURE refactor to use getItem
-            let expression = new Expression_js_1.Expression(this, 'get', properties, params);
-            return yield this.run('get', expression);
-        });
+        }
+        //  FUTURE refactor to use getItem
+        let expression = new Expression_js_1.Expression(this, 'get', properties, params);
+        return await this.run('get', expression);
     }
-    load(properties = {}, params = {}) {
-        return __awaiter(this, void 0, void 0, function* () {
-            ({ properties, params } = this.checkArgs(properties, params));
-            properties = this.prepareProperties('get', properties, params);
-            let expression = new Expression_js_1.Expression(this, 'get', properties, params);
-            return yield this.table.batchLoad(expression);
-        });
+    async load(properties = {}, params = {}) {
+        ;
+        ({ properties, params } = this.checkArgs(properties, params));
+        properties = this.prepareProperties('get', properties, params);
+        let expression = new Expression_js_1.Expression(this, 'get', properties, params);
+        return await this.table.batchLoad(expression);
     }
     init(properties = {}, params = {}) {
+        ;
         ({ properties, params } = this.checkArgs(properties, params, { parse: true, high: true }));
         return this.initItem(properties, params);
     }
-    remove(properties, params = {}) {
-        return __awaiter(this, void 0, void 0, function* () {
-            ({ properties, params } = this.checkArgs(properties, params, { parse: true, exists: null, high: true }));
-            properties = this.prepareProperties('delete', properties, params);
-            if (params.fallback) {
-                return yield this.removeByFind(properties, params);
-            }
-            let expression = new Expression_js_1.Expression(this, 'delete', properties, params);
-            if (this.hasUniqueFields) {
-                return yield this.removeUnique(properties, params);
-            }
-            else {
-                return yield this.run('delete', expression);
-            }
-        });
+    async remove(properties, params = {}) {
+        ;
+        ({ properties, params } = this.checkArgs(properties, params, { parse: true, exists: null, high: true }));
+        properties = this.prepareProperties('delete', properties, params);
+        if (params.fallback || params.many) {
+            return await this.removeByFind(properties, params);
+        }
+        let expression = new Expression_js_1.Expression(this, 'delete', properties, params);
+        if (this.hasUniqueFields) {
+            return await this.removeUnique(properties, params);
+        }
+        else {
+            return await this.run('delete', expression);
+        }
     }
     /*
         Remove multiple objects after doing a full find/query
      */
-    removeByFind(properties, params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            if (params.retry) {
-                throw new Error_js_1.OneTableArgError('Remove cannot retry', { properties });
-            }
-            params.parse = true;
-            let findParams = Object.assign({}, params);
-            delete findParams.transaction;
-            let items = yield this.find(properties, findParams);
-            if (items.length > 1 && !params.many) {
-                throw new Error_js_1.OneTableError(`Removing multiple items from "${this.name}". Use many:true to enable.`, {
-                    properties,
-                    code: 'NonUniqueError',
-                });
+    async removeByFind(properties, params) {
+        if (params.retry) {
+            throw new Error_js_1.OneTableArgError('Remove cannot retry', { properties });
+        }
+        params.parse = true;
+        let findParams = Object.assign({}, params);
+        delete findParams.transaction;
+        let items = await this.find(properties, findParams);
+        if (items.length > 1 && !params.many) {
+            throw new Error_js_1.OneTableError(`Removing multiple items from "${this.name}". Use many:true to enable.`, {
+                properties,
+                code: 'NonUniqueError',
+            });
+        }
+        let response = [];
+        for (let item of items) {
+            let removed;
+            if (this.hasUniqueFields) {
+                removed = await this.removeUnique(item, { retry: true, transaction: params.transaction });
             }
-            let response = [];
-            for (let item of items) {
-                let removed;
-                if (this.hasUniqueFields) {
-                    removed = yield this.removeUnique(item, { retry: true, transaction: params.transaction });
-                }
-                else {
-                    removed = yield this.remove(item, { retry: true, return: params.return, transaction: params.transaction });
-                }
-                response.push(removed);
+            else {
+                removed = await this.remove(item, { retry: true, return: params.return, transaction: params.transaction });
             }
-            return response;
-        });
+            response.push(removed);
+        }
+        return response;
     }
     /*
         Remove an item with unique properties. Use transactions to remove unique items.
     */
-    removeUnique(properties, params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            let transactHere = params.transaction ? false : true;
-            let transaction = params.transaction = params.transaction || {};
-            let { hash, sort } = this.indexes.primary;
-            let fields = Object.values(this.block.fields).filter(f => f.unique && f.attribute != hash && f.attribute != sort);
-            params.prepared = properties = this.prepareProperties('delete', properties, params);
-            let keys = {
-                [hash]: properties[hash]
-            };
-            if (sort) {
-                keys[sort] = properties[sort];
-            }
-            /*
-                Get the prior item so we know the previous unique property values so they can be removed.
-                This must be run here, even if part of a transaction.
-            */
-            let prior = yield this.get(keys, { hidden: true });
-            if (prior) {
-                prior = this.prepareProperties('update', prior);
-            }
-            else if (params.exists === undefined || params.exists == true) {
-                throw new Error_js_1.OneTableError('Cannot find existing item to remove', { properties, code: 'NotFoundError' });
-            }
-            for (let field of fields) {
-                let sk = `_unique#`;
-                let scope = '';
-                if (field.scope) {
-                    scope = this.runTemplate(null, null, field, properties, params, field.scope) + '#';
-                }
-                // If we had a prior record, remove unique values that existed
-                if (prior && prior[field.name]) {
-                    let pk = `_unique#${scope}${this.name}#${field.attribute}#${prior[field.name]}`;
-                    yield this.schema.uniqueModel.remove({ [this.hash]: pk, [this.sort]: sk }, { transaction, exists: params.exists });
-                }
-                else if (!prior && properties[field.name] !== undefined) {
-                    // if we did not have a prior record and the field is defined, try to remove it
-                    let pk = `_unique#${scope}${this.name}#${field.attribute}#${properties[field.name]}`;
-                    yield this.schema.uniqueModel.remove({ [this.hash]: pk, [this.sort]: sk }, {
-                        transaction,
-                        exists: params.exists
+    async removeUnique(properties, params) {
+        let transactHere = params.transaction ? false : true;
+        let transaction = (params.transaction = params.transaction || {});
+        let { hash, sort } = this.indexes.primary;
+        let fields = Object.values(this.block.fields).filter((f) => f.unique && f.attribute != hash && f.attribute != sort);
+        params.prepared = properties = this.prepareProperties('delete', properties, params);
+        let keys = {
+            [hash]: properties[hash],
+        };
+        if (sort) {
+            keys[sort] = properties[sort];
+        }
+        /*
+            Get the prior item so we know the previous unique property values so they can be removed.
+            This must be run here, even if part of a transaction.
+        */
+        let prior = await this.get(keys, { hidden: true });
+        if (prior) {
+            prior = this.prepareProperties('update', prior);
+        }
+        else if (params.exists === undefined || params.exists == true) {
+            throw new Error_js_1.OneTableError('Cannot find existing item to remove', { properties, code: 'NotFoundError' });
+        }
+        for (let field of fields) {
+            let sk = `_unique#`;
+            let scope = '';
+            if (field.scope) {
+                scope = this.runTemplate(null, null, field, properties, params, field.scope) + '#';
+                if (scope == undefined) {
+                    throw new Error_js_1.OneTableError('Missing properties to resolve unique scope', {
+                        properties,
+                        field,
+                        params,
+                        scope: field.scope,
+                        code: 'UniqueError',
                     });
                 }
             }
-            let removed = yield this.deleteItem(properties, params);
-            // Only execute transaction if we are not in a transaction
-            if (transactHere) {
-                removed = yield this.table.transact('write', transaction, params);
+            // If we had a prior record, remove unique values that existed
+            if (prior && prior[field.name]) {
+                let pk = `_unique#${scope}${this.name}#${field.attribute}#${prior[field.name]}`;
+                await this.schema.uniqueModel.remove({ [this.hash]: pk, [this.sort]: sk }, { transaction, exists: params.exists });
             }
-            return removed;
-        });
+            else if (!prior && properties[field.name] !== undefined) {
+                // if we did not have a prior record and the field is defined, try to remove it
+                let pk = `_unique#${scope}${this.name}#${field.attribute}#${properties[field.name]}`;
+                await this.schema.uniqueModel.remove({ [this.hash]: pk, [this.sort]: sk }, {
+                    transaction,
+                    exists: params.exists,
+                });
+            }
+        }
+        let removed = await this.deleteItem(properties, params);
+        // Only execute transaction if we are not in a transaction
+        if (transactHere) {
+            removed = await this.table.transact('write', transaction, params);
+        }
+        return removed;
     }
-    scan(properties = {}, params = {}) {
-        return __awaiter(this, void 0, void 0, function* () {
-            ({ properties, params } = this.checkArgs(properties, params, { parse: true, high: true }));
-            return yield this.scanItems(properties, params);
-        });
+    async scan(properties = {}, params = {}) {
+        ;
+        ({ properties, params } = this.checkArgs(properties, params, { parse: true, high: true }));
+        return await this.scanItems(properties, params);
     }
-    update(properties, params = {}) {
-        return __awaiter(this, void 0, void 0, function* () {
-            ({ properties, params } = this.checkArgs(properties, params, { exists: true, parse: true, high: true }));
-            if (this.hasUniqueFields) {
-                let hasUniqueProperties = Object.entries(properties).find((pair) => {
-                    return this.block.fields[pair[0]] && this.block.fields[pair[0]].unique;
-                });
-                if (hasUniqueProperties) {
-                    return yield this.updateUnique(properties, params);
-                }
+    async update(properties, params = {}) {
+        ;
+        ({ properties, params } = this.checkArgs(properties, params, { exists: true, parse: true, high: true }));
+        if (this.hasUniqueFields) {
+            let hasUniqueProperties = Object.entries(properties).find((pair) => {
+                return this.block.fields[pair[0]] && this.block.fields[pair[0]].unique;
+            });
+            if (hasUniqueProperties) {
+                return await this.updateUnique(properties, params);
             }
-            return yield this.updateItem(properties, params);
-        });
+        }
+        return await this.updateItem(properties, params);
     }
-    upsert(properties, params = {}) {
-        return __awaiter(this, void 0, void 0, function* () {
-            params.exists = null;
-            return yield this.update(properties, params);
-        });
+    async upsert(properties, params = {}) {
+        params.exists = null;
+        return await this.update(properties, params);
     }
     /*
-        Update an item with unique attributes and actually updating a unique property.
+        Update an item with unique attributes.
         Use a transaction to update a unique item for each unique attribute.
      */
-    updateUnique(properties, params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            if (params.batch) {
-                throw new Error_js_1.OneTableArgError('Cannot use batch with unique properties which require transactions');
-            }
-            let transactHere = params.transaction ? false : true;
-            let transaction = params.transaction = params.transaction || {};
-            let index = this.indexes.primary;
-            let { hash, sort } = index;
-            params.prepared = properties = this.prepareProperties('update', properties, params);
-            let keys = {
-                [index.hash]: properties[index.hash]
-            };
-            if (index.sort) {
-                keys[index.sort] = properties[index.sort];
-            }
-            /*
-                Get the prior item so we know the previous unique property values so they can be removed.
-                This must be run here, even if part of a transaction.
-            */
-            let prior = yield this.get(keys, { hidden: true });
-            if (prior) {
-                prior = this.prepareProperties('update', prior);
-            }
-            else if (params.exists === undefined || params.exists == true) {
-                throw new Error_js_1.OneTableError('Cannot find existing item to update', { properties, code: 'NotFoundError' });
+    async updateUnique(properties, params) {
+        if (params.batch) {
+            throw new Error_js_1.OneTableArgError('Cannot use batch with unique properties which require transactions');
+        }
+        let transactHere = params.transaction ? false : true;
+        let transaction = (params.transaction = params.transaction || {});
+        let index = this.indexes.primary;
+        let { hash, sort } = index;
+        params.prepared = properties = this.prepareProperties('update', properties, params);
+        let keys = {
+            [index.hash]: properties[index.hash],
+        };
+        if (index.sort) {
+            keys[index.sort] = properties[index.sort];
+        }
+        /*
+            Get the prior item so we know the previous unique property values so they can be removed.
+            This must be run here, even if part of a transaction.
+        */
+        let prior = await this.get(keys, { hidden: true });
+        if (prior) {
+            prior = this.prepareProperties('update', prior);
+        }
+        else if (params.exists === undefined || params.exists == true) {
+            throw new Error_js_1.OneTableError('Cannot find existing item to update', { properties, code: 'NotFoundError' });
+        }
+        /*
+            Create all required unique properties. Remove prior unique properties if they have changed.
+        */
+        let fields = Object.values(this.block.fields).filter((f) => f.unique && f.attribute != hash && f.attribute != sort);
+        let ttlField = fields.find(f => f.ttl);
+        for (let field of fields) {
+            let toBeRemoved = params.remove && params.remove.includes(field.name);
+            let isUnchanged = prior && properties[field.name] === prior[field.name];
+            if (isUnchanged) {
+                continue;
             }
-            /*
-                Create all required unique properties. Remove prior unique properties if they have changed.
-            */
-            let fields = Object.values(this.block.fields).filter(f => f.unique && f.attribute != hash && f.attribute != sort);
-            for (let field of fields) {
-                let toBeRemoved = (params.remove && params.remove.includes(field.name));
-                let isUnchanged = (prior && properties[field.name] === prior[field.name]);
-                if (isUnchanged) {
-                    continue;
-                }
-                let scope = '';
-                if (field.scope) {
-                    scope = this.runTemplate(null, null, field, properties, params, field.scope) + '#';
-                }
-                let pk = `_unique#${scope}${this.name}#${field.attribute}#${properties[field.name]}`;
-                let sk = `_unique#`;
-                // If we had a prior value AND value is changing or being removed, remove old value
-                if (prior && prior[field.name] && (properties[field.name] !== undefined || toBeRemoved)) {
-                    /*
-                        Remove prior unique properties if they have changed and create new unique property.
-                    */
-                    let priorPk = `_unique#${scope}${this.name}#${field.attribute}#${prior[field.name]}`;
-                    if (pk == priorPk) {
-                        //  Hasn't changed
-                        continue;
-                    }
-                    yield this.schema.uniqueModel.remove({ [this.hash]: priorPk, [this.sort]: sk }, {
-                        transaction,
-                        exists: null,
-                        execute: params.execute,
-                        log: params.log,
+            let scope = '';
+            if (field.scope) {
+                scope = this.runTemplate(null, null, field, properties, params, field.scope) + '#';
+                if (scope == undefined) {
+                    throw new Error_js_1.OneTableError('Missing properties to resolve unique scope', {
+                        properties,
+                        field,
+                        scope: field.scope,
+                        code: 'UniqueError',
                     });
                 }
-                // If value is changing, add new unique value
-                if (properties[field.name] !== undefined) {
-                    yield this.schema.uniqueModel.create({ [this.hash]: pk, [this.sort]: sk }, {
-                        transaction,
-                        exists: false,
-                        return: 'NONE',
-                        log: params.log,
-                        execute: params.execute
-                    });
-                }
-            }
-            let item = yield this.updateItem(properties, params);
-            if (!transactHere) {
-                return item;
-            }
-            /*
-                Perform all operations in a transaction so update will only be applied if the unique properties can be created.
-            */
-            try {
-                yield this.table.transact('write', params.transaction, params);
             }
-            catch (err) {
-                if (err instanceof Error_js_1.OneTableError && err.code === 'TransactionCanceledException' && err.context.err.message.indexOf('ConditionalCheckFailed') !== -1) {
-                    let names = fields.map(f => f.name).join(', ');
-                    throw new Error_js_1.OneTableError(`Cannot update unique attributes "${names}" for "${this.name}". An item of the same name already exists.`, { properties, transaction, code: 'UniqueError' });
+            let pk = `_unique#${scope}${this.name}#${field.attribute}#${properties[field.name]}`;
+            let sk = `_unique#`;
+            // If we had a prior value AND value is changing or being removed, remove old value
+            if (prior && prior[field.name] && (properties[field.name] !== undefined || toBeRemoved)) {
+                /*
+                    Remove prior unique properties if they have changed and create new unique property.
+                */
+                let priorPk = `_unique#${scope}${this.name}#${field.attribute}#${prior[field.name]}`;
+                if (pk == priorPk) {
+                    //  Hasn't changed
+                    continue;
                 }
-                throw err;
-            }
-            if (params.return == 'none' || params.return === false) {
-                return;
+                await this.schema.uniqueModel.remove({ [this.hash]: priorPk, [this.sort]: sk }, {
+                    transaction,
+                    exists: null,
+                    execute: params.execute,
+                    log: params.log,
+                });
             }
-            if (params.return == 'get') {
-                return yield this.get(keys, {
-                    hidden: params.hidden,
+            // If value is changing, add new unique value
+            if (properties[field.name] !== undefined) {
+                let uproperties = { [this.hash]: pk, [this.sort]: sk };
+                if (ttlField) {
+                    /*
+                        Add a TTL expiry property to the unique record
+                     */
+                    let value = properties[ttlField.name];
+                    uproperties[ttlField.name] = new Date(new Date(value).getTime() * 1000);
+                }
+                await this.schema.uniqueModel.create(uproperties, {
+                    transaction,
+                    exists: false,
+                    return: 'NONE',
                     log: params.log,
-                    parse: params.parse,
                     execute: params.execute,
                 });
             }
-            if (params.return) {
-                throw new Error_js_1.OneTableArgError('Update cannot return an updated item that contain unique attributes');
-            }
-            else {
-                /*
-                if (this.table.warn !== false) {
-                    console.warn(`Update with unique items uses transactions and cannot return the updated item.` +
-                                 `Use params {return: 'none'} to squelch this warning. ` +
-                                 `Use {return: 'get'} to do a non-transactional get of the item after the update. `)
-                } */
-                return properties;
+        }
+        let item = await this.updateItem(properties, params);
+        if (!transactHere) {
+            return item;
+        }
+        /*
+            Perform all operations in a transaction so update will only be applied if the unique properties can be created.
+        */
+        try {
+            await this.table.transact('write', params.transaction, params);
+        }
+        catch (err) {
+            if (err instanceof Error_js_1.OneTableError &&
+                err.code === 'TransactionCanceledException' &&
+                err.context.err.message.indexOf('ConditionalCheckFailed') !== -1) {
+                let names = fields.map((f) => f.name).join(', ');
+                throw new Error_js_1.OneTableError(`Cannot update unique attributes "${names}" for "${this.name}". An item of the same name already exists.`, { properties, transaction, code: 'UniqueError' });
             }
-        });
+            throw err;
+        }
+        if (params.return == 'none' || params.return == 'NONE' || params.return === false) {
+            return;
+        }
+        if (params.return == 'get') {
+            return await this.get(keys, {
+                hidden: params.hidden,
+                log: params.log,
+                parse: params.parse,
+                execute: params.execute,
+            });
+        }
+        if (this.table.warn) {
+            console.warn(`Update with unique items uses transactions and cannot return the updated item.` +
+                `Use params {return: 'none'} to squelch this warning. ` +
+                `Use {return: 'get'} to do a non-transactional get of the item after the update. `);
+        }
     }
     //  Low level API
     /* private */
-    deleteItem(properties, params = {}) {
-        return __awaiter(this, void 0, void 0, function* () {
-            ({ properties, params } = this.checkArgs(properties, params));
-            if (!params.prepared) {
-                properties = this.prepareProperties('delete', properties, params);
-            }
-            let expression = new Expression_js_1.Expression(this, 'delete', properties, params);
-            return yield this.run('delete', expression);
-        });
+    async deleteItem(properties, params = {}) {
+        ;
+        ({ properties, params } = this.checkArgs(properties, params));
+        if (!params.prepared) {
+            properties = this.prepareProperties('delete', properties, params);
+        }
+        let expression = new Expression_js_1.Expression(this, 'delete', properties, params);
+        return await this.run('delete', expression);
     }
     /* private */
-    getItem(properties, params = {}) {
-        return __awaiter(this, void 0, void 0, function* () {
-            ({ properties, params } = this.checkArgs(properties, params));
-            properties = this.prepareProperties('get', properties, params);
-            let expression = new Expression_js_1.Expression(this, 'get', properties, params);
-            return yield this.run('get', expression);
-        });
+    async getItem(properties, params = {}) {
+        ;
+        ({ properties, params } = this.checkArgs(properties, params));
+        properties = this.prepareProperties('get', properties, params);
+        let expression = new Expression_js_1.Expression(this, 'get', properties, params);
+        return await this.run('get', expression);
     }
     /* private */
     initItem(properties, params = {}) {
+        ;
         ({ properties, params } = this.checkArgs(properties, params));
         let fields = this.block.fields;
         this.setDefaults('init', fields, properties, params);
@@ -885,108 +947,115 @@ class Model {
                 properties[key] = null;
             }
         }
-        this.runTemplates('put', this.indexes.primary, this.block.deps, properties, params);
+        this.runTemplates('put', '', this.indexes.primary, this.block.deps, properties, params);
         return properties;
     }
     /* private */
-    putItem(properties, params = {}) {
-        return __awaiter(this, void 0, void 0, function* () {
-            ({ properties, params } = this.checkArgs(properties, params));
-            if (!params.prepared) {
+    async putItem(properties, params = {}) {
+        ;
+        ({ properties, params } = this.checkArgs(properties, params));
+        if (!params.prepared) {
+            if (params.timestamps !== false) {
+                let timestamp = params.transaction
+                    ? (params.transaction.timestamp = params.transaction.timestamp || new Date())
+                    : new Date();
                 if (this.timestamps === true || this.timestamps == 'create') {
-                    properties[this.createdField] = new Date();
+                    properties[this.createdField] = timestamp;
                 }
                 if (this.timestamps === true || this.timestamps == 'update') {
-                    properties[this.updatedField] = new Date();
+                    properties[this.updatedField] = timestamp;
                 }
-                properties = this.prepareProperties('put', properties, params);
             }
-            let expression = new Expression_js_1.Expression(this, 'put', properties, params);
-            return yield this.run('put', expression);
-        });
+            properties = this.prepareProperties('put', properties, params);
+        }
+        let expression = new Expression_js_1.Expression(this, 'put', properties, params);
+        return await this.run('put', expression);
     }
     /* private */
-    queryItems(properties = {}, params = {}) {
-        return __awaiter(this, void 0, void 0, function* () {
-            ({ properties, params } = this.checkArgs(properties, params));
-            properties = this.prepareProperties('find', properties, params);
-            let expression = new Expression_js_1.Expression(this, 'find', properties, params);
-            return yield this.run('find', expression);
-        });
+    async queryItems(properties = {}, params = {}) {
+        ;
+        ({ properties, params } = this.checkArgs(properties, params));
+        properties = this.prepareProperties('find', properties, params);
+        let expression = new Expression_js_1.Expression(this, 'find', properties, params);
+        return await this.run('find', expression);
     }
     //  Note: scanItems will return all model types
     /* private */
-    scanItems(properties = {}, params = {}) {
-        return __awaiter(this, void 0, void 0, function* () {
-            ({ properties, params } = this.checkArgs(properties, params));
-            properties = this.prepareProperties('scan', properties, params);
-            let expression = new Expression_js_1.Expression(this, 'scan', properties, params);
-            return yield this.run('scan', expression);
-        });
+    async scanItems(properties = {}, params = {}) {
+        ;
+        ({ properties, params } = this.checkArgs(properties, params));
+        properties = this.prepareProperties('scan', properties, params);
+        let expression = new Expression_js_1.Expression(this, 'scan', properties, params);
+        return await this.run('scan', expression);
     }
     /* private */
-    updateItem(properties, params = {}) {
-        return __awaiter(this, void 0, void 0, function* () {
-            ({ properties, params } = this.checkArgs(properties, params));
-            if (this.timestamps === true || this.timestamps == 'update') {
-                let now = new Date();
-                properties[this.updatedField] = now;
+    async updateItem(properties, params = {}) {
+        ;
+        ({ properties, params } = this.checkArgs(properties, params));
+        if (this.timestamps === true || this.timestamps == 'update') {
+            if (params.timestamps !== false) {
+                let timestamp = params.transaction
+                    ? (params.transaction.timestamp = params.transaction.timestamp || new Date())
+                    : new Date();
+                properties[this.updatedField] = timestamp;
                 if (params.exists == null) {
                     let field = this.block.fields[this.createdField] || this.table;
-                    let when = (field.isoDates) ? now.toISOString() : now.getTime();
+                    let when = field.isoDates ? timestamp.toISOString() : timestamp.getTime();
                     params.set = params.set || {};
                     params.set[this.createdField] = `if_not_exists(\${${this.createdField}}, {${when}})`;
                 }
             }
-            properties = this.prepareProperties('update', properties, params);
-            let expression = new Expression_js_1.Expression(this, 'update', properties, params);
-            return yield this.run('update', expression);
-        });
+        }
+        properties = this.prepareProperties('update', properties, params);
+        let expression = new Expression_js_1.Expression(this, 'update', properties, params);
+        return await this.run('update', expression);
     }
     /* private */
-    fetch(models, properties = {}, params = {}) {
-        return __awaiter(this, void 0, void 0, function* () {
-            ({ properties, params } = this.checkArgs(properties, params));
-            if (models.length == 0) {
-                return {};
-            }
-            let where = [];
-            for (let model of models) {
-                where.push(`\${${this.typeField}} = {${model}}`);
-            }
-            if (params.where) {
-                params.where = `(${params.where}) and (${where.join(' or ')})`;
-            }
-            else {
-                params.where = where.join(' or ');
-            }
-            params.parse = true;
-            params.hidden = true;
-            let items = yield this.queryItems(properties, params);
-            return this.table.groupByType(items);
-        });
+    async fetch(models, properties = {}, params = {}) {
+        ;
+        ({ properties, params } = this.checkArgs(properties, params));
+        if (models.length == 0) {
+            return {};
+        }
+        let where = [];
+        for (let model of models) {
+            where.push(`\${${this.typeField}} = {${model}}`);
+        }
+        if (params.where) {
+            params.where = `(${params.where}) and (${where.join(' or ')})`;
+        }
+        else {
+            params.where = where.join(' or ');
+        }
+        params.parse = true;
+        params.hidden = true;
+        let items = await this.queryItems(properties, params);
+        return this.table.groupByType(items);
     }
     /*
         Map Dynamo types to Javascript types after reading data
      */
-    transformReadItem(op, raw, properties, params) {
+    transformReadItem(op, raw, properties, params, expression) {
         if (!raw) {
             return raw;
         }
-        return this.transformReadBlock(op, raw, properties, params, this.block.fields);
+        return this.transformReadBlock(op, raw, properties, params, this.block.fields, expression);
     }
-    transformReadBlock(op, raw, properties, params, fields) {
+    transformReadBlock(op, raw, properties, params, fields, expression) {
         let rec = {};
         for (let [name, field] of Object.entries(fields)) {
             //  Skip hidden params. Follow needs hidden params to do the follow.
-            if (field.hidden && params.hidden !== true && params.follow !== true) {
-                continue;
+            if (field.hidden && params.follow !== true) {
+                if (params.hidden === false || (params.hidden == null && this.table.hidden === false)) {
+                    continue;
+                }
             }
             let att, sub;
             if (op == 'put') {
                 att = field.name;
             }
             else {
+                ;
                 [att, sub] = field.attribute;
             }
             let value = raw[att];
@@ -995,35 +1064,44 @@ class Model {
                     let [att, sep, index] = field.encode;
                     value = (raw[att] || '').split(sep)[index];
                 }
-                if (value === undefined) {
-                    continue;
-                }
             }
-            if (sub) {
+            if (sub && value) {
                 value = value[sub];
             }
             if (field.crypt && params.decrypt !== false) {
                 value = this.decrypt(value);
             }
             if (field.default !== undefined && value === undefined) {
-                if (typeof field.default == 'function') {
-                    // console.warn('WARNING: default functions are DEPRECATED and will be removed soon.')
-                    value = field.default(this, field.name, properties);
-                }
-                else {
-                    value = field.default;
+                if (!params.fields || params.fields.indexOf(name) >= 0) {
+                    rec[name] = field.default;
                 }
             }
             else if (value === undefined) {
                 if (field.required) {
-                    this.table.log.error(`Required field "${name}" in model "${this.name}" not defined in table item`, {
-                        model: this.name, raw, params, field
-                    });
+                    /*
+                        Transactions transform the properties to return something, but
+                        does not have all the properties and required fields may be missing).
+                        Also find operation with fields selections may not include required fields.
+                     */
+                    if (!params.transaction && !params.batch && !params.fields && !field.encode && !expression?.index?.project) {
+                        if (params.warn || this.table.warn) {
+                            this.table.log.error(`Required field "${name}" in model "${this.name}" not defined in table item`, { model: this.name, raw, params, field });
+                        }
+                    }
                 }
-                continue;
             }
-            else if (field.schema && typeof value == 'object') {
-                rec[name] = this.transformReadBlock(op, raw[name], properties[name] || {}, params, field.block.fields);
+            else if (field.schema && value !== null && typeof value == 'object') {
+                if (field.items && Array.isArray(value)) {
+                    rec[name] = [];
+                    let i = 0;
+                    for (let rvalue of raw[att]) {
+                        rec[name][i] = this.transformReadBlock(op, rvalue, properties[name] || [], params, field.block.fields, expression);
+                        i++;
+                    }
+                }
+                else {
+                    rec[name] = this.transformReadBlock(op, raw[att], properties[name] || {}, params, field.block.fields, expression);
+                }
             }
             else {
                 rec[name] = this.transformReadAttribute(field, name, value, params, properties);
@@ -1037,7 +1115,10 @@ class Model {
                 }
             }
         }
-        if (params.hidden == true && rec[this.typeField] === undefined && !this.generic && this.block.fields == fields) {
+        if (params.hidden == true &&
+            rec[this.typeField] === undefined &&
+            !this.generic &&
+            this.block.fields == fields) {
             rec[this.typeField] = this.name;
         }
         if (this.table.params.transform) {
@@ -1061,7 +1142,7 @@ class Model {
             }
         }
         if (field.type == 'buffer' || field.type == 'arraybuffer' || field.type == 'binary') {
-            return Buffer.from(value, 'base64');
+            return buffer_1.Buffer.from(value, 'base64');
         }
         return value;
     }
@@ -1078,14 +1159,19 @@ class Model {
         }
         //  DEPRECATE
         this.tunnelProperties(properties, params);
-        let rec = this.collectProperties(op, this.block, index, properties, params);
+        if (params.filter) {
+            this.convertFilter(properties, params, index);
+        }
+        let rec = this.collectProperties(op, '', this.block, index, properties, params);
         if (params.fallback) {
             return properties;
         }
         if (op != 'scan' && this.getHash(rec, this.block.fields, index, params) == null) {
             this.table.log.error(`Empty hash key`, { properties, params, op, rec, index, model: this.name });
             throw new Error_js_1.OneTableError(`Empty hash key. Check hash key and any value template variable references.`, {
-                properties, rec, code: 'MissingError',
+                properties,
+                rec,
+                code: 'MissingError',
             });
         }
         if (this.table.params.transform && ReadWrite[op] == 'write') {
@@ -1093,6 +1179,56 @@ class Model {
         }
         return rec;
     }
+    /*
+        Convert a full text params.filter into a smart params.where
+        NOTE: this is prototype code and definitely not perfect! Use at own risk.
+     */
+    convertFilter(properties, params, index) {
+        let filter = params.filter.toString();
+        let fields = this.block.fields;
+        let where;
+        //  TODO support > >= < <= ..., AND or ...
+        let [name, value] = filter.split('=');
+        if (value) {
+            name = name.trim();
+            value = value.trim();
+            let field = fields[name];
+            if (field) {
+                name = field.map ? field.map : name;
+                if (field.encode) {
+                    properties[name] = value;
+                }
+                else {
+                    where = `\${${name}} = {"${value}"}`;
+                }
+            }
+            else {
+                where = `\${${name}} = {"${value}"}`;
+            }
+        }
+        else {
+            value = name;
+            where = [];
+            for (let [name, field] of Object.entries(fields)) {
+                let primary = this.indexes.primary;
+                if (primary.hash == name || primary.sort == name || index.hash == name || index.sort == name) {
+                    continue;
+                }
+                if (field.encode) {
+                    continue;
+                }
+                name = field.map ? field.map : name;
+                where.push(`(contains(\${${name}}, {"${filter}"}))`);
+            }
+            if (where) {
+                where = where.join(' or ');
+            }
+        }
+        params.where = where;
+        params.maxPages = params.maxPages || 25;
+        //  Remove limit otherwise the search will only search "limit" items at a time
+        delete params.limit;
+    }
     //  Handle fallback for get/delete as GSIs only support find and scan
     needsFallback(op, index, params) {
         if (index != this.indexes.primary && op != 'find' && op != 'scan') {
@@ -1111,7 +1247,7 @@ class Model {
         if (generic) {
             return rec[index.hash];
         }
-        let field = Object.values(fields).find(f => f.attribute[0] == index.hash);
+        let field = Object.values(fields).find((f) => f.attribute[0] == index.hash);
         if (!field) {
             return null;
         }
@@ -1135,10 +1271,12 @@ class Model {
     }
     /*
         Collect the required attribute from the properties and context.
-        This handles tunneled properties, blends context properties, resolves default values, handles Nulls and empty strings,
-        and invokes validations. Nested schemas are handled here.
+        This handles tunneled properties, blends context properties, resolves default values,
+        handles Nulls and empty strings, and invokes validations. Nested schemas are handled here.
+
+        NOTE: pathname is only needed for DEPRECATED and undocumented callbacks.
     */
-    collectProperties(op, block, index, properties, params, context, rec = {}) {
+    collectProperties(op, pathname, block, index, properties, params, context, rec = {}) {
         let fields = block.fields;
         if (!context) {
             context = params.context || this.table.context;
@@ -1147,41 +1285,69 @@ class Model {
             First process nested schemas recursively
         */
         if (this.nested && !KeysOnly[op]) {
-            //  Process nested schema recursively
-            for (let field of Object.values(fields)) {
-                if (field.schema) {
-                    let name = field.name;
-                    let value = properties[name];
-                    if (op == 'put') {
-                        value = value || field.default;
-                        if (value === undefined && field.required) {
-                            value = field.type == 'array' ? [] : {};
-                        }
-                    }
-                    if (value !== undefined) {
-                        rec[name] = this.collectProperties(op, field.block, index, value, params, context[name] || {});
-                    }
-                }
-            }
+            this.collectNested(op, pathname, fields, index, properties, params, context, rec);
         }
         /*
             Then process the non-schema properties at this level (non-recursive)
         */
         this.addContext(op, fields, index, properties, params, context);
         this.setDefaults(op, fields, properties, params);
-        this.runTemplates(op, index, block.deps, properties, params);
-        this.convertNulls(op, fields, properties, params);
+        this.runTemplates(op, pathname, index, block.deps, properties, params);
+        this.convertNulls(op, pathname, fields, properties, params);
         this.validateProperties(op, fields, properties, params);
         this.selectProperties(op, block, index, properties, params, rec);
         this.transformProperties(op, fields, properties, params, rec);
         return rec;
     }
+    /*
+        Process nested schema recursively
+    */
+    collectNested(op, pathname, fields, index, properties, params, context, rec) {
+        for (let field of Object.values(fields)) {
+            let schema = field.schema || field?.items?.schema;
+            if (schema) {
+                let name = field.name;
+                let value = properties[name];
+                if (op == 'put' && value === undefined) {
+                    value = field.required ? (field.type == 'array' ? [] : {}) : field.default;
+                }
+                let ctx = context[name] || {};
+                let partial = this.getPartial(field, params);
+                if (value === null && field.nulls === true) {
+                    rec[name] = null;
+                }
+                else if (value !== undefined) {
+                    if (field.items && Array.isArray(value)) {
+                        rec[name] = [];
+                        let i = 0;
+                        for (let rvalue of value) {
+                            let path = pathname ? `${pathname}.${name}[${i}]` : `${name}[${i}]`;
+                            let obj = this.collectProperties(op, path, field.block, index, rvalue, params, ctx);
+                            //  Don't update properties if empty and partial and no default
+                            if (!partial || Object.keys(obj).length > 0 || field.default !== undefined) {
+                                rec[name][i++] = obj;
+                            }
+                        }
+                    }
+                    else {
+                        let path = pathname ? `${pathname}.${field.name}` : field.name;
+                        let obj = this.collectProperties(op, path, field.block, index, value, params, ctx);
+                        if (!partial || Object.keys(obj).length > 0 || field.default !== undefined) {
+                            rec[name] = obj;
+                        }
+                    }
+                }
+            }
+        }
+    }
     /*
         DEPRECATE - not needed anymore
     */
     tunnelProperties(properties, params) {
         if (params.tunnel) {
-            console.warn('WARNING: tunnel properties should not be required for typescript and will be removed soon.');
+            if (this.table.warn) {
+                console.warn('WARNING: tunnel properties should not be required for typescript and will be removed soon.');
+            }
             for (let [kind, settings] of Object.entries(params.tunnel)) {
                 for (let [key, value] of Object.entries(settings)) {
                     properties[key] = { [kind]: value };
@@ -1331,6 +1497,9 @@ class Model {
                     if (generate === true) {
                         value = this.table.generate();
                     }
+                    else if (typeof generate === 'function') {
+                        value = generate();
+                    }
                     else if (generate == 'uuid') {
                         value = this.table.uuid();
                     }
@@ -1354,65 +1523,72 @@ class Model {
     }
     /*
         Remove null properties from the table unless Table.nulls == true
+        TODO - null conversion would be better done in Expression then pathnames would not be needed.
+        NOTE: pathname is only needed for DEPRECATED callbacks.
     */
-    convertNulls(op, fields, properties, params) {
+    convertNulls(op, pathname, fields, properties, params) {
         for (let [name, value] of Object.entries(properties)) {
             let field = fields[name];
             if (!field || field.schema)
                 continue;
             if (value === null && field.nulls !== true) {
-                if (field.required && (
                 //  create with null/undefined, or update with null property
-                (op == 'put' && properties[field.name] == null) ||
-                    (op == 'update' && properties[field.name] === null))) {
+                if (field.required &&
+                    ((op == 'put' && properties[field.name] == null) ||
+                        (op == 'update' && properties[field.name] === null))) {
                     //  Validation will catch this
                     continue;
                 }
+                delete properties[name];
+                if (this.getPartial(field, params) === false && pathname.match(/[[.]/)) {
+                    /*
+                        Partial disabled for a nested object
+                        Don't create remove entry as the entire object is being created/updated
+                     */
+                    continue;
+                }
                 if (params.remove && !Array.isArray(params.remove)) {
                     params.remove = [params.remove];
                 }
                 else {
                     params.remove = params.remove || [];
                 }
-                params.remove.push(field.pathname);
-                delete properties[name];
+                let path = pathname ? `${pathname}.${field.name}` : field.name;
+                params.remove.push(path);
             }
             else if (typeof value == 'object' && (field.type == 'object' || field.type == 'array')) {
-                properties[name] = this.removeNulls(field, value);
+                //  LEGACY: Remove nested empty strings because DynamoDB cannot handle these nested in objects or arrays
+                if (this.table.params.legacyEmpties === true) {
+                    properties[name] = this.handleEmpties(field, value);
+                }
             }
         }
     }
     /*
         Process value templates and property values that are functions
      */
-    runTemplates(op, index, deps, properties, params) {
+    runTemplates(op, pathname, index, deps, properties, params) {
         for (let field of deps) {
             if (field.schema)
                 continue;
             let name = field.name;
-            if (field.isIndexed && (op != 'put' && op != 'update') &&
-                field.attribute[0] != index.hash && field.attribute[0] != index.sort) {
+            if (field.isIndexed &&
+                op != 'put' &&
+                op != 'update' &&
+                field.attribute[0] != index.hash &&
+                field.attribute[0] != index.sort) {
                 //  Ignore indexes not being used for this call
                 continue;
             }
+            let path = pathname ? `${pathname}.${field.name}` : field.name;
             if (field.value === true && typeof this.table.params.value == 'function') {
-                properties[name] = this.table.params.value(this, field.pathname, properties, params);
-            }
-            else if (typeof properties[name] == 'function') {
-                //  Undocumented and not supported for typescript
-                properties[name] = properties[name](field.pathname, properties);
+                properties[name] = this.table.params.value(this, path, properties, params);
             }
             else if (properties[name] === undefined) {
                 if (field.value) {
-                    if (typeof field.value == 'function') {
-                        // console.warn('WARNING: value functions are DEPRECATED and will be removed soon.')
-                        properties[name] = field.value(field.pathname, properties);
-                    }
-                    else {
-                        let value = this.runTemplate(op, index, field, properties, params, field.value);
-                        if (value != null) {
-                            properties[name] = value;
-                        }
+                    let value = this.runTemplate(op, index, field, properties, params, field.value);
+                    if (value != null) {
+                        properties[name] = value;
                     }
                 }
             }
@@ -1446,7 +1622,7 @@ class Model {
                 v = match;
             }
             if (typeof v == 'object' && v.toString() == '[object Object]') {
-                throw new Error_js_1.OneTableError(`Value for "${field.pathname}" is not a primitive value`, { code: 'TypeError' });
+                throw new Error_js_1.OneTableError(`Value for "${field.name}" is not a primitive value`, { code: 'TypeError' });
             }
             return v;
         });
@@ -1454,13 +1630,15 @@ class Model {
             Consider unresolved template variables. If field is the sort key and doing find,
             then use sort key prefix and begins_with, (provide no where clause).
          */
-        if (value.indexOf('${') >= 0 && index) {
-            if (field.attribute[0] == index.sort) {
-                if (op == 'find') {
-                    //  Strip from first ${ onward and retain fixed prefix portion
-                    value = value.replace(/\${.*/g, '');
-                    if (value) {
-                        return { begins: value };
+        if (value.indexOf('${') >= 0) {
+            if (index) {
+                if (field.attribute[0] == index.sort) {
+                    if (op == 'find') {
+                        //  Strip from first ${ onward and retain fixed prefix portion
+                        value = value.replace(/\${.*/g, '');
+                        if (value) {
+                            return { begins: value };
+                        }
                     }
                 }
             }
@@ -1500,20 +1678,23 @@ class Model {
         }
         for (let field of Object.values(fields)) {
             //  If required and create, must be defined. If required and update, must not be null.
-            if (field.required && !field.schema && ((op == 'put' && properties[field.name] == null) || (op == 'update' && properties[field.name] === null))) {
+            if (field.required &&
+                !field.schema &&
+                ((op == 'put' && properties[field.name] == null) || (op == 'update' && properties[field.name] === null))) {
                 validation[field.name] = `Value not defined for required field "${field.name}"`;
             }
         }
         if (Object.keys(validation).length > 0) {
-            let error = new Error_js_1.OneTableError(`Validation Error in "${this.name}" for "${Object.keys(validation).join(', ')}"`, { validation, code: 'ValidationError' });
-            throw error;
+            throw new Error_js_1.OneTableError(`Validation Error in "${this.name}" for "${Object.keys(validation).join(', ')}"`, {
+                validation,
+                code: 'ValidationError',
+                properties,
+            });
         }
     }
     validateProperty(field, value, details, params) {
         let fieldName = field.name;
-        //  DEPRECATE
         if (typeof params.validate == 'function') {
-            // console.warn('WARNING: params.validate functions are DEPRECATED and will be removed soon.')
             let error;
             ({ error, value } = params.validate(this, field, value));
             if (error) {
@@ -1559,10 +1740,11 @@ class Model {
     }
     transformProperties(op, fields, properties, params, rec) {
         for (let [name, field] of Object.entries(fields)) {
+            //  Nested schemas handled via collectProperties
             if (field.schema)
                 continue;
             let value = rec[name];
-            if (value !== undefined && !field.schema) {
+            if (value !== undefined) {
                 rec[name] = this.transformWriteAttribute(op, field, value, properties, params);
             }
         }
@@ -1589,7 +1771,9 @@ class Model {
         else if (type == 'number') {
             let num = Number(value);
             if (isNaN(num)) {
-                throw new Error_js_1.OneTableError(`Invalid value "${value}" provided for field "${field.name}"`, { code: 'ValidationError' });
+                throw new Error_js_1.OneTableError(`Invalid value "${value}" provided for field "${field.name}"`, {
+                    code: 'ValidationError',
+                });
             }
             value = num;
         }
@@ -1605,27 +1789,31 @@ class Model {
             }
         }
         else if (type == 'buffer' || type == 'arraybuffer' || type == 'binary') {
-            if (value instanceof Buffer || value instanceof ArrayBuffer || value instanceof DataView) {
+            if (value instanceof buffer_1.Buffer || value instanceof ArrayBuffer || value instanceof DataView) {
                 value = value.toString('base64');
             }
         }
         else if (type == 'array') {
-            //  Heursistics to accept legacy string values for array types. Note: TS would catch this also.
-            if (value != null && !Array.isArray(value)) {
-                if (value == '') {
-                    value = [];
+            if (value != null) {
+                if (Array.isArray(value)) {
+                    value = this.transformNestedWriteFields(field, value);
                 }
                 else {
-                    //  FUTURE: should be moved to validations
-                    throw new Error_js_1.OneTableArgError(`Invalid data type for Array field "${field.name}" in "${this.name}"`);
-                    // value = [value]
+                    //  Heursistics to accept legacy string values for array types. Note: TS would catch this also.
+                    if (value == '') {
+                        value = [];
+                    }
+                    else {
+                        //  FUTURE: should be moved to validations
+                        throw new Error_js_1.OneTableArgError(`Invalid data type for Array field "${field.name}" in "${this.name}"`);
+                    }
                 }
             }
         }
         else if (type == 'set' && Array.isArray(value)) {
             value = this.transformWriteSet(type, value);
         }
-        else if (type == 'object' && (value != null && typeof value == 'object')) {
+        else if (type == 'object' && value != null && typeof value == 'object') {
             value = this.transformNestedWriteFields(field, value);
         }
         if (field.crypt && value != null) {
@@ -1639,7 +1827,7 @@ class Model {
             if (value instanceof Date) {
                 obj[key] = this.transformWriteDate(field, value);
             }
-            else if (value instanceof Buffer || value instanceof ArrayBuffer || value instanceof DataView) {
+            else if (value instanceof buffer_1.Buffer || value instanceof ArrayBuffer || value instanceof DataView) {
                 value = value.toString('base64');
             }
             else if (Array.isArray(value) && (field.type == Set || type == Set)) {
@@ -1662,13 +1850,13 @@ class Model {
         if (type == Set || type == 'Set' || type == 'set') {
             let v = value.values().next().value;
             if (typeof v == 'string') {
-                value = value.map(v => v.toString());
+                value = value.map((v) => v.toString());
             }
             else if (typeof v == 'number') {
-                value = value.map(v => Number(v));
+                value = value.map((v) => Number(v));
             }
-            else if (v instanceof Buffer || v instanceof ArrayBuffer || v instanceof DataView) {
-                value = value.map(v => v.toString('base64'));
+            else if (v instanceof buffer_1.Buffer || v instanceof ArrayBuffer || v instanceof DataView) {
+                value = value.map((v) => v.toString('base64'));
             }
         }
         else {
@@ -1680,25 +1868,26 @@ class Model {
         Handle dates. Supports epoch and ISO date transformations.
     */
     transformWriteDate(field, value) {
+        let isoDates = field.isoDates || this.table.isoDates;
         if (field.ttl) {
             //  Convert dates to DynamoDB TTL
             if (value instanceof Date) {
                 value = value.getTime();
             }
             else if (typeof value == 'string') {
-                value = (new Date(Date.parse(value))).getTime();
+                value = new Date(Date.parse(value)).getTime();
             }
             value = Math.ceil(value / 1000);
         }
-        else if (field.isoDates) {
+        else if (isoDates) {
             if (value instanceof Date) {
                 value = value.toISOString();
             }
             else if (typeof value == 'string') {
-                value = (new Date(Date.parse(value))).toISOString();
+                value = new Date(Date.parse(value)).toISOString();
             }
             else if (typeof value == 'number') {
-                value = (new Date(value)).toISOString();
+                value = new Date(value).toISOString();
             }
         }
         else {
@@ -1707,7 +1896,7 @@ class Model {
                 value = value.getTime();
             }
             else if (typeof value == 'string') {
-                value = (new Date(Date.parse(value))).getTime();
+                value = new Date(Date.parse(value)).getTime();
             }
         }
         return value;
@@ -1757,15 +1946,14 @@ class Model {
         return { properties, params };
     }
     /*
-        Handle nulls and empty strings properly according to nulls preference.
+        Handle nulls and empty strings properly according to nulls preference in plain objects and arrays.
         NOTE: DynamoDB can handle empty strings as top level non-key string attributes, but not nested in lists or maps. Ugh!
     */
-    removeNulls(field, obj) {
+    handleEmpties(field, obj) {
         let result;
-        /*
-            Loop over plain objects and arrays only
-        */
-        if (obj !== null && typeof obj == 'object' && (obj.constructor.name == 'Object' || obj.constructor.name == 'Array')) {
+        if (obj !== null &&
+            typeof obj == 'object' &&
+            (obj.constructor.name == 'Object' || obj.constructor.name == 'Array')) {
             result = Array.isArray(obj) ? [] : {};
             for (let [key, value] of Object.entries(obj)) {
                 if (value === '') {
@@ -1777,7 +1965,7 @@ class Model {
                     continue;
                 }
                 else if (typeof value == 'object') {
-                    result[key] = this.removeNulls(field, value);
+                    result[key] = this.handleEmpties(field, value);
                 }
                 else {
                     result[key] = value;
@@ -1789,5 +1977,16 @@ class Model {
         }
         return result;
     }
+    /*
+        Return if a field supports partial updates of its children.
+        Only relevant for fields with nested schema
+     */
+    getPartial(field, params) {
+        let partial = params.partial;
+        if (partial === undefined) {
+            partial = field.partial;
+        }
+        return partial ? true : false;
+    }
 }
 exports.Model = Model;
diff --git a/node_modules/dynamodb-onetable/dist/cjs/Schema.d.ts b/node_modules/dynamodb-onetable/dist/cjs/Schema.d.ts
index a2fcb54..abd767d 100644
--- a/node_modules/dynamodb-onetable/dist/cjs/Schema.d.ts
+++ b/node_modules/dynamodb-onetable/dist/cjs/Schema.d.ts
@@ -2,6 +2,7 @@ export class Schema {
     constructor(table: any, schema: any);
     table: any;
     keyTypes: {};
+    process: {};
     params: any;
     getCurrentSchema(): any;
     setSchemaInner(schema: any): any;
@@ -46,6 +47,9 @@ export class Schema {
             type: string;
             required: boolean;
         };
+        process: {
+            type: string;
+        };
         version: {
             type: string;
             required: boolean;
@@ -73,10 +77,15 @@ export class Schema {
             type: string;
             required: boolean;
         };
+        status: {
+            type: string;
+        };
     };
     addModel(name: any, fields: any): void;
     listModels(): string[];
-    getModel(name: any): any;
+    getModel(name: any, options?: {
+        nothrow: boolean;
+    }): any;
     removeModel(name: any): void;
     getKeys(refresh?: boolean): Promise<any>;
     setDefaultParams(params: any): any;
@@ -88,4 +97,4 @@ export class Schema {
     removeSchema(schema: any): Promise<void>;
     saveSchema(schema: any): Promise<any>;
 }
-import { Model } from "./Model.js";
+import { Model } from './Model.js';
diff --git a/node_modules/dynamodb-onetable/dist/cjs/Schema.js b/node_modules/dynamodb-onetable/dist/cjs/Schema.js
index 8eeb34a..ef46e66 100644
--- a/node_modules/dynamodb-onetable/dist/cjs/Schema.js
+++ b/node_modules/dynamodb-onetable/dist/cjs/Schema.js
@@ -2,15 +2,6 @@
 /*
     Schema.js - Utility class to manage schemas
  */
-var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
-    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
-    return new (P || (P = Promise))(function (resolve, reject) {
-        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
-        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
-        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
-        step((generator = generator.apply(thisArg, _arguments || [])).next());
-    });
-};
 Object.defineProperty(exports, "__esModule", { value: true });
 exports.Schema = void 0;
 const Model_js_1 = require("./Model.js");
@@ -26,6 +17,7 @@ class Schema {
     constructor(table, schema) {
         this.table = table;
         this.keyTypes = {};
+        this.process = {};
         table.schema = this;
         Object.defineProperty(this, 'table', { enumerable: false });
         this.params = table.getSchemaParams();
@@ -34,7 +26,9 @@ class Schema {
     getCurrentSchema() {
         if (this.definition) {
             let schema = this.table.assign({}, this.definition, { params: this.params });
-            return this.transformSchemaForWrite(schema);
+            schema = this.transformSchemaForWrite(schema);
+            schema.process = Object.assign({}, this.process);
+            return schema;
         }
         return null;
     }
@@ -51,31 +45,28 @@ class Schema {
             }
             this.indexes = indexes;
             //  Must set before creating models
-            if (params) {
-                this.table.setSchemaParams(params);
-            }
+            this.table.setSchemaParams(params);
             for (let [name, model] of Object.entries(models)) {
                 if (name == SchemaModel || name == MigrationModel)
                     continue;
                 this.models[name] = new Model_js_1.Model(this.table, name, { fields: model });
             }
             this.createStandardModels();
+            this.process = schema.process;
         }
         return this.indexes;
     }
     /*
         Set the schema to use. If undefined, get the table keys.
     */
-    setSchema(schema) {
-        return __awaiter(this, void 0, void 0, function* () {
-            if (schema) {
-                this.setSchemaInner(schema);
-            }
-            else {
-                yield this.getKeys();
-            }
-            return this.indexes;
-        });
+    async setSchema(schema) {
+        if (schema) {
+            this.setSchemaInner(schema);
+        }
+        else {
+            await this.getKeys();
+        }
+        return this.indexes;
     }
     //  Start of a function to better validate schemas. More to do.
     validateSchema(schema) {
@@ -100,10 +91,6 @@ class Schema {
                     if (index.sort == null) {
                         throw new Error_js_1.OneTableArgError('LSIs must define a sort attribute');
                     }
-                    /*
-                    if (index.project) {
-                        throw new OneTableArgError('Unexpected project definition for LSI')
-                    } */
                     index.hash = primary.hash;
                     lsi++;
                 }
@@ -135,9 +122,7 @@ class Schema {
         let { indexes, table } = this;
         let primary = indexes.primary;
         let type = this.keyTypes[primary.hash] || 'string';
-        let fields = {
-            [primary.hash]: { type }
-        };
+        let fields = { [primary.hash]: { type } };
         if (primary.sort) {
             let type = this.keyTypes[primary.sort] || 'string';
             fields[primary.sort] = { type };
@@ -162,7 +147,7 @@ class Schema {
     createSchemaModel() {
         let { indexes, table } = this;
         let primary = indexes.primary;
-        let fields = this.schemaModelFields = {
+        let fields = (this.schemaModelFields = {
             [primary.hash]: { type: 'string', required: true, value: `${SchemaKey}` },
             format: { type: 'string', required: true },
             indexes: { type: 'object', required: true },
@@ -170,8 +155,9 @@ class Schema {
             models: { type: 'object', required: true },
             params: { type: 'object', required: true },
             queries: { type: 'object', required: true },
+            process: { type: 'object' },
             version: { type: 'string', required: true },
-        };
+        });
         if (primary.sort) {
             fields[primary.sort] = { type: 'string', required: true, value: `${SchemaKey}:\${name}` };
         }
@@ -180,15 +166,16 @@ class Schema {
     createMigrationModel() {
         let { indexes } = this;
         let primary = indexes.primary;
-        let fields = this.migrationModelFields = {
+        let fields = (this.migrationModelFields = {
             [primary.hash]: { type: 'string', value: `${MigrationKey}` },
             date: { type: 'date', required: true },
             description: { type: 'string', required: true },
             path: { type: 'string', required: true },
             version: { type: 'string', required: true },
-        };
+            status: { type: 'string' },
+        });
         if (primary.sort) {
-            fields[primary.sort] = { type: 'string', value: `${MigrationKey}:\${version}` };
+            fields[primary.sort] = { type: 'string', value: `${MigrationKey}:\${version}:\${date}` };
         }
         this.models[MigrationModel] = new Model_js_1.Model(this.table, MigrationModel, { fields, indexes });
     }
@@ -201,8 +188,11 @@ class Schema {
     /*
         Thows exception if model cannot be found
      */
-    getModel(name) {
+    getModel(name, options = { nothrow: false }) {
         if (!name) {
+            if (options.nothrow) {
+                return null;
+            }
             throw new Error('Undefined model name');
         }
         let model = this.models[name.toString()];
@@ -210,6 +200,9 @@ class Schema {
             if (name == UniqueModel) {
                 return this.uniqueModel;
             }
+            if (options.nothrow) {
+                return null;
+            }
             throw new Error(`Cannot find model ${name}`);
         }
         return model;
@@ -221,34 +214,32 @@ class Schema {
         }
         delete this.models[name.toString()];
     }
-    getKeys(refresh = false) {
-        return __awaiter(this, void 0, void 0, function* () {
-            if (this.indexes && !refresh) {
-                return this.indexes;
-            }
-            let info = yield this.table.describeTable();
-            for (let def of info.Table.AttributeDefinitions) {
-                this.keyTypes[def.AttributeName] = (def.AttributeType == 'N') ? 'number' : 'string';
-            }
-            let indexes = { primary: {} };
-            for (let key of info.Table.KeySchema) {
-                let type = key.KeyType.toLowerCase() == 'hash' ? 'hash' : 'sort';
-                indexes.primary[type] = key.AttributeName;
-            }
-            if (info.Table.GlobalSecondaryIndexes) {
-                for (let index of info.Table.GlobalSecondaryIndexes) {
-                    let keys = indexes[index.IndexName] = {};
-                    for (let key of index.KeySchema) {
-                        let type = key.KeyType.toLowerCase() == 'hash' ? 'hash' : 'sort';
-                        keys[type] = key.AttributeName;
-                    }
-                    indexes[index.IndexName] = keys;
+    async getKeys(refresh = false) {
+        if (this.indexes && !refresh) {
+            return this.indexes;
+        }
+        let info = await this.table.describeTable();
+        for (let def of info.Table.AttributeDefinitions) {
+            this.keyTypes[def.AttributeName] = def.AttributeType == 'N' ? 'number' : 'string';
+        }
+        let indexes = { primary: {} };
+        for (let key of info.Table.KeySchema) {
+            let type = key.KeyType.toLowerCase() == 'hash' ? 'hash' : 'sort';
+            indexes.primary[type] = key.AttributeName;
+        }
+        if (info.Table.GlobalSecondaryIndexes) {
+            for (let index of info.Table.GlobalSecondaryIndexes) {
+                let keys = (indexes[index.IndexName] = {});
+                for (let key of index.KeySchema) {
+                    let type = key.KeyType.toLowerCase() == 'hash' ? 'hash' : 'sort';
+                    keys[type] = key.AttributeName;
                 }
+                indexes[index.IndexName] = keys;
             }
-            this.indexes = indexes;
-            this.createStandardModels();
-            return indexes;
-        });
+        }
+        this.indexes = indexes;
+        this.createStandardModels();
+        return indexes;
     }
     setDefaultParams(params) {
         if (params.typeField == null) {
@@ -260,11 +251,14 @@ class Schema {
         if (params.nulls == null) {
             params.nulls = false;
         }
+        if (params.separator == null) {
+            params.separator = '#';
+        }
         if (params.timestamps == null) {
             params.timestamps = false;
         }
-        if (params.hidden == null) {
-            params.hidden = false;
+        if (params.warn == null) {
+            params.warn = false;
         }
         return params;
     }
@@ -284,7 +278,10 @@ class Schema {
         if (field.validate && field.validate instanceof RegExp) {
             field.validate = `/${field.validate.source}/${field.validate.flags}`;
         }
-        let type = (typeof field.type == 'function') ? field.type.name : field.type;
+        if (field.encode) {
+            field.encode = field.encode.map((e) => (e instanceof RegExp ? `/${e.source}/${e.flags}` : e));
+        }
+        let type = typeof field.type == 'function' ? field.type.name : field.type;
         field.type = type.toLowerCase();
         //  DEPRECATE
         if (field.uuid) {
@@ -336,82 +333,74 @@ class Schema {
     /*
         Read the current schema saved in the table
     */
-    readSchema() {
-        return __awaiter(this, void 0, void 0, function* () {
-            let indexes = this.indexes || (yield this.getKeys());
-            let primary = indexes.primary;
-            let params = {
-                [primary.hash]: SchemaKey
-            };
-            if (primary.sort) {
-                params[primary.sort] = `${SchemaKey}:Current`;
-            }
-            let schema = yield this.table.getItem(params, { hidden: true, parse: true });
-            return this.transformSchemaAfterRead(schema);
-        });
+    async readSchema() {
+        let indexes = this.indexes || (await this.getKeys());
+        let primary = indexes.primary;
+        let params = {
+            [primary.hash]: SchemaKey,
+        };
+        if (primary.sort) {
+            params[primary.sort] = `${SchemaKey}:Current`;
+        }
+        let schema = await this.table.getItem(params, { hidden: true, parse: true });
+        return this.transformSchemaAfterRead(schema);
     }
-    readSchemas() {
-        return __awaiter(this, void 0, void 0, function* () {
-            let indexes = this.indexes || (yield this.getKeys());
-            let primary = indexes.primary;
-            let params = {
-                [primary.hash]: `${SchemaKey}`
-            };
-            let schemas = yield this.table.queryItems(params, { hidden: true, parse: true });
-            for (let [index, schema] of Object.entries(schemas)) {
-                schemas[index] = this.transformSchemaAfterRead(schema);
-            }
-            return schemas;
-        });
+    async readSchemas() {
+        let indexes = this.indexes || (await this.getKeys());
+        let primary = indexes.primary;
+        let params = {
+            [primary.hash]: `${SchemaKey}`,
+        };
+        let schemas = await this.table.queryItems(params, { hidden: true, parse: true });
+        for (let [index, schema] of Object.entries(schemas)) {
+            schemas[index] = this.transformSchemaAfterRead(schema);
+        }
+        return schemas;
     }
-    removeSchema(schema) {
-        return __awaiter(this, void 0, void 0, function* () {
-            if (!this.indexes) {
-                yield this.getKeys();
-            }
-            let model = this.getModel(SchemaModel);
-            yield model.remove(schema);
-        });
+    async removeSchema(schema) {
+        if (!this.indexes) {
+            await this.getKeys();
+        }
+        let model = this.getModel(SchemaModel);
+        await model.remove(schema);
     }
     /*
         Update the schema model saved in the database _Schema model.
         NOTE: this does not update the current schema used by the Table instance.
     */
-    saveSchema(schema) {
-        return __awaiter(this, void 0, void 0, function* () {
-            if (!this.indexes) {
-                yield this.getKeys();
-            }
-            if (schema) {
-                schema = this.table.assign({}, schema);
-                if (!schema.params) {
-                    schema.params = this.params;
-                }
-                if (!schema.models) {
-                    schema.models = {};
-                }
-                if (!schema.indexes) {
-                    schema.indexes = this.indexes || (yield this.getKeys());
-                }
-                if (!schema.queries) {
-                    schema.queries = {};
-                }
-                schema = this.transformSchemaForWrite(schema);
+    async saveSchema(schema) {
+        if (!this.indexes) {
+            await this.getKeys();
+        }
+        if (schema) {
+            schema = this.table.assign({}, schema);
+            if (!schema.params) {
+                schema.params = this.params;
             }
-            else {
-                schema = this.getCurrentSchema();
+            if (!schema.models) {
+                schema.models = {};
             }
-            if (!schema) {
-                throw new Error('No schema to save');
+            if (!schema.indexes) {
+                schema.indexes = this.indexes || (await this.getKeys());
             }
-            if (!schema.name) {
-                schema.name = 'Current';
+            if (!schema.queries) {
+                schema.queries = {};
             }
-            schema.version = schema.version || '0.0.1';
-            schema.format = SchemaFormat;
-            let model = this.getModel(SchemaModel);
-            return yield model.update(schema, { exists: null });
-        });
+            schema = this.transformSchemaForWrite(schema);
+        }
+        else {
+            schema = this.getCurrentSchema();
+        }
+        if (!schema) {
+            throw new Error('No schema to save');
+        }
+        if (!schema.name) {
+            schema.name = 'Current';
+        }
+        schema.version = schema.version || '0.0.1';
+        schema.format = SchemaFormat;
+        let model = this.getModel(SchemaModel);
+        return await model.create(schema, { exists: null });
     }
 }
 exports.Schema = Schema;
diff --git a/node_modules/dynamodb-onetable/dist/cjs/Table.d.ts b/node_modules/dynamodb-onetable/dist/cjs/Table.d.ts
index 42a95e3..19f113e 100644
--- a/node_modules/dynamodb-onetable/dist/cjs/Table.d.ts
+++ b/node_modules/dynamodb-onetable/dist/cjs/Table.d.ts
@@ -3,116 +3,156 @@
 */
 
 import {
-    AnyEntity, AnyModel, Model, OneIndex, OneParams, OneProperties, OneModel, OneSchema, Paged, Entity
-} from "./Model";
+    AnyEntity,
+    AnyModel,
+    Model,
+    OneIndex,
+    OneParams,
+    OneProperties,
+    OneModel,
+    OneSchema,
+    Paged,
+    Entity,
+} from './Model.js'
+import {Metrics} from './Metrics.js'
+import {DynamoDBRecord} from 'aws-lambda'
 
 export type EntityGroup = {
     [key: string]: AnyEntity[]
-};
+}
+
+export type StreamEntityGroup = {
+    [key: string]: {
+        type: 'INSERT' | 'MODIFY' | 'REMOVE'
+        new?: AnyEntity
+        old?: AnyEntity
+    }[]
+}
 
 type TableConstructorParams<Schema extends OneSchema> = {
-    client?: {},                    //  Instance of DocumentClient or Dynamo.
-    crypto?: {},                    //  Crypto configuration.
-    generate?: (() => string),      //  Function to generate IDs for field schema that requires.
-    generic?: boolean,              //  Create a generic (low-level) raw model. Default false.
-    logger?: boolean | ((tag: string, message: string, context: {}) => void),      // Logging callback
+    client?: {} //  Instance of DocumentClient or Dynamo.
+    crypto?: {} //  Crypto configuration.
+    generate?: () => string //  Function to generate IDs for field schema that requires.
+    generic?: boolean //  Create a generic (low-level) raw model. Default false.
+    logger?: boolean | ((tag: string, message: string, context: {}) => void) // Logging callback
     //  Intercept table reads and writes
-    intercept?: (model: AnyModel, op: string, rec: {}, params: OneParams, raw?: {}) => void,
-    metrics?: boolean | object,     //  Enable CloudWatch metrics.
-    name?: string,                  //  Table name.
-    schema?: Schema,                //  Table models schema.
-    senselogs?: {},                 //  SenseLogs instance for logging
+    intercept?: (model: AnyModel, op: string, rec: {}, params: OneParams, raw?: {}) => void
+    metrics?: boolean | object //  Enable metrics.
+    name?: string //  Table name.
+    schema?: Schema //  Table models schema.
+    senselogs?: {} //  SenseLogs instance for logging
     //  Transform record for read / write.
-    transform?: (model: AnyModel, op: string, item: AnyEntity, properties: OneProperties, params?: OneParams, raw?: {}) => AnyEntity,
+    transform?: (
+        model: AnyModel,
+        op: string,
+        item: AnyEntity,
+        properties: OneProperties,
+        params?: OneParams,
+        raw?: {}
+    ) => AnyEntity
     //  Validate properties before writing
-    validate?: (model: AnyModel, properties: OneProperties, params?: OneParams) => {},
+    validate?: (model: AnyModel, properties: OneProperties, params?: OneParams) => {}
     //  Compute a value for a value template
-    value?: (model: AnyModel, fieldName: string, properties: OneProperties, params?: OneParams) => string,
+    value?: (model: AnyModel, fieldName: string, properties: OneProperties, params?: OneParams) => string
 
     // https://www.npmjs.com/package/dataloader DataLoader constructor
     dataloader?: new (batchLoadFn: any, options?: any) => any
 
-    partial?: boolean,              //  Allow partial updates of nested schemas. Default false.
-    warn?: boolean,                 //  Issue warnings
-    hidden?: boolean,               //  Hide key attributes in Javascript properties. Default false.
+    partial?: boolean //  Allow partial updates of nested schemas. Default true.
+    warn?: boolean //  Issue warnings
+    hidden?: boolean //  Hide key and value template attributes in Javascript properties. Default true.
 
     //  DEPRECATED 2.3 - Should now be specified via the schema.params
-    createdField?: string,          //  Name of "created" timestamp attribute.
-    isoDates?: boolean,             //  Set to true to store dates as Javascript ISO Date strings.
-    nulls?: boolean,                //  Store nulls in database attributes. Default false.
-    timestamps?: boolean,           //  Make "created" and "updated" timestamps. Default true.
-    typeField?: string,             //  Name of model type attribute. Default "_type".
-    updatedField?: string,          //  Name of "updated" timestamp attribute.
+    createdField?: string //  Name of "created" timestamp attribute.
+    isoDates?: boolean //  Set to true to store dates as Javascript ISO Date strings.
+    nulls?: boolean //  Store nulls in database attributes. Default false.
+    timestamps?: boolean //  Make "created" and "updated" timestamps. Default true.
+    typeField?: string //  Name of model type attribute. Default "_type".
+    updatedField?: string //  Name of "updated" timestamp attribute.
 
     //  DEPRECATED 2.3 - Defer to generate
-    uuid?: (() => string) | string, //  Function to create a UUID if field schema requires it.
-};
+    uuid?: (() => string) | string //  Function to create a UUID if field schema requires it.
+}
 
-type ModelNames<Schema extends OneSchema> = keyof Schema["models"];
+type ModelNames<Schema extends OneSchema> = keyof Schema['models']
 type ExtractModel<M> = M extends Entity<infer X> ? X : never
 
 export class Table<Schema extends OneSchema = any> {
-    name: string;
-    constructor(params: TableConstructorParams<Schema>);
-
-    addContext(context?: {}): Table<Schema>;
-    addModel(name: string, fields: OneModel): void;
-
-    batchGet(batch: any, params?: OneParams): Promise<{}[]>;
-    batchWrite(batch: any, params?: OneParams): Promise<{}>;
-    clearContext(): Table<Schema>;
-    getTableDefinition(params?: {}): {};
-    createTable(params?: {}): Promise<{}>;
-    deleteTable(confirmation: string): Promise<{}>;
-    describeTable(): Promise<{}>;
-    exists(): Promise<Boolean>;
-    getContext(): {};
-    generate(): string;
-    getLog(): any;
-    getKeys(): Promise<OneIndex>;
-    getModel<T>(name: T extends ModelNames<Schema> ? T : ModelNames<Schema>): T extends string ? Model<Entity<Schema["models"][T]>> : Model<Entity<ExtractModel<T>>>;
-    getCurrentSchema(): {};
-    groupByType(items: AnyEntity[], params?: OneParams): EntityGroup;
-    listModels(): AnyModel[];
-    listTables(): string[];
-    readSchema(): Promise<OneSchema>;
-    readSchemas(): Promise<OneSchema[]>;
-    removeModel(name: string): void;
-    removeSchema(schema: OneSchema): Promise<void>;
-    saveSchema(schema?: OneSchema): Promise<OneSchema>;
-    setClient(client: {}): void;
-    setContext(context?: {}, merge?: boolean): Table<Schema>;
-    setGenerate(fn: () => string): void;
-    setLog(log: any): void;
-    setParams(params: OneParams): void;
-    setSchema(schema?: OneSchema): Promise<void>;
-    transact(op: string, transaction: any, params?: OneParams): Promise<void>;
-    uid(size: number): string;
-    ulid(): string;
-    updateTable(params?: {}): Promise<{}>;
-    uuid(): string;
-
-    deleteItem(properties: OneProperties, params?: OneParams): Promise<void>;
-    getItem(properties: OneProperties, params?: OneParams): Promise<AnyEntity | undefined>;
-    putItem(properties: OneProperties, params?: OneParams): Promise<AnyEntity>;
-    queryItems(properties: OneProperties, params?: OneParams): Promise<Paged<AnyEntity>>;
-    scanItems(properties?: OneProperties, params?: OneParams): Promise<Paged<AnyEntity>>;
-    updateItem(properties: OneProperties, params?: OneParams): Promise<AnyEntity>;
-
-    child(context: {}): Table<Schema>;
-
-    create(modelName: string, properties: OneProperties, params?: OneParams): Promise<AnyEntity>;
-    find(modelName: string, properties?: OneProperties, params?: OneParams): Promise<Paged<AnyEntity>>;
-    get(modelName: string, properties: OneProperties, params?: OneParams): Promise<AnyEntity | undefined>;
-    load(modelName: string, properties: OneProperties, params?: OneParams): Promise<AnyEntity | undefined>;
-    init(modelName: string, properties?: OneProperties, params?: OneParams): AnyEntity;
-    remove(modelName: string, properties: OneProperties, params?: OneParams): Promise<void>;
-    scan(modelName: string, properties?: OneProperties, params?: OneParams): Promise<Paged<AnyEntity>>;
-    update(modelName: string, properties: OneProperties, params?: OneParams): Promise<AnyEntity>;
-    upsert(modelName: string, properties: OneProperties, params?: OneParams): Promise<AnyEntity>;
-
-    fetch(models: string[], properties?: OneProperties, params?: OneParams): Promise<EntityGroup>;
-
-    marshall(item: AnyEntity | AnyEntity[], params?: OneParams) : AnyEntity;
-    unmarshall(item: AnyEntity | AnyEntity[], params?: OneParams) : AnyEntity;
+    name: string
+    metrics: Metrics
+    constructor(params: TableConstructorParams<Schema>)
+
+    addContext(context?: {}): Table<Schema>
+    addModel(name: string, fields: OneModel): void
+
+    batchGet<T = {}>(batch: any, params?: OneParams): Promise<T[]>
+    // batchGet(batch: any, params?: OneParams): Promise<{}[]>
+    batchWrite(batch: any, params?: OneParams): Promise<{}>
+    clearContext(): Table<Schema>
+    getTableDefinition(params?: {}): {}
+    createTable(params?: {}): Promise<{}>
+    deleteTable(confirmation: string): Promise<{}>
+    describeTable(): Promise<{}>
+    exists(): Promise<Boolean>
+    flushMetrics(): Promise<void>
+    getContext(): {}
+    generate(): string
+    getLog(): any
+    getKeys(): Promise<OneIndex>
+    getModel<T>(
+        name: T extends ModelNames<Schema> ? T : ModelNames<Schema>,
+        options?: {nothrow?: boolean}
+    ): T extends string ? Model<Entity<Schema['models'][T]>> : Model<Entity<ExtractModel<T>>>
+
+    /* Proposed
+        getModel<T extends ModelNames<Schema>>(name: T, options?: {nothrow?: boolean}): Model<Entity<Schema['models'][T]>>
+    */
+
+    getCurrentSchema(): OneSchema | null
+    groupByType(items: AnyEntity[], params?: OneParams): EntityGroup
+    listModels(): AnyModel[]
+    listTables(): string[]
+    readSchema(): Promise<OneSchema>
+    readSchemas(): Promise<OneSchema[]>
+    removeModel(name: string): void
+    removeSchema(schema: OneSchema): Promise<void>
+    saveSchema(schema?: OneSchema): Promise<OneSchema>
+    setClient(client: {}): void
+    setContext(context?: {}, merge?: boolean): Table<Schema>
+    setGenerate(fn: () => string): void
+    setLog(log: any): void
+    setParams(params: OneParams): void
+    setSchema(schema?: OneSchema): Promise<void>
+    transact(op: string, transaction: any, params?: OneParams): Promise<void>
+    uid(size: number): string
+    ulid(): string
+    updateTable(params?: {}): Promise<{}>
+    uuid(): string
+
+    deleteItem(properties: OneProperties, params?: OneParams): Promise<void>
+    getItem(properties: OneProperties, params?: OneParams): Promise<AnyEntity | undefined>
+    putItem(properties: OneProperties, params?: OneParams): Promise<AnyEntity>
+    queryItems(properties: OneProperties, params?: OneParams): Promise<Paged<AnyEntity>>
+    scanItems(properties?: OneProperties, params?: OneParams): Promise<Paged<AnyEntity>>
+    updateItem(properties: OneProperties, params?: OneParams): Promise<AnyEntity>
+
+    child(context: {}): Table<Schema>
+
+    create(modelName: string, properties: OneProperties, params?: OneParams): Promise<AnyEntity>
+    find(modelName: string, properties?: OneProperties, params?: OneParams): Promise<Paged<AnyEntity>>
+    get(modelName: string, properties: OneProperties, params?: OneParams): Promise<AnyEntity | undefined>
+    load(modelName: string, properties: OneProperties, params?: OneParams): Promise<AnyEntity | undefined>
+    init(modelName: string, properties?: OneProperties, params?: OneParams): AnyEntity
+    remove(modelName: string, properties: OneProperties, params?: OneParams): Promise<void>
+    scan(modelName: string, properties?: OneProperties, params?: OneParams): Promise<Paged<AnyEntity>>
+    update(modelName: string, properties: OneProperties, params?: OneParams): Promise<AnyEntity>
+    upsert(modelName: string, properties: OneProperties, params?: OneParams): Promise<AnyEntity>
+
+    fetch(models: string[], properties?: OneProperties, params?: OneParams): Promise<EntityGroup>
+
+    marshall(item: AnyEntity | AnyEntity[], params?: OneParams): AnyEntity
+    unmarshall(item: AnyEntity | AnyEntity[], params?: OneParams): AnyEntity
+    stream(records: DynamoDBRecord[], params?: OneParams): StreamEntityGroup
+
+    static terminate(): Promise<void>
 }
diff --git a/node_modules/dynamodb-onetable/dist/cjs/Table.js b/node_modules/dynamodb-onetable/dist/cjs/Table.js
index 03169b5..3969d51 100644
--- a/node_modules/dynamodb-onetable/dist/cjs/Table.js
+++ b/node_modules/dynamodb-onetable/dist/cjs/Table.js
@@ -4,24 +4,16 @@
 
     A OneTable Table represents a single (connected) DynamoDB table
  */
-var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
-    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
-    return new (P || (P = Promise))(function (resolve, reject) {
-        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
-        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
-        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
-        step((generator = generator.apply(thisArg, _arguments || [])).next());
-    });
-};
 var __importDefault = (this && this.__importDefault) || function (mod) {
     return (mod && mod.__esModule) ? mod : { "default": mod };
 };
 Object.defineProperty(exports, "__esModule", { value: true });
 exports.Table = void 0;
+const process_1 = __importDefault(require("process"));
+const buffer_1 = require("buffer");
 const crypto_1 = __importDefault(require("crypto"));
-const UUID_js_1 = __importDefault(require("./UUID.js"));
-const ULID_js_1 = __importDefault(require("./ULID.js"));
-const UID_js_1 = __importDefault(require("./UID.js"));
+const UID_js_1 = require("./UID.js");
+const Dynamo_js_1 = __importDefault(require("./Dynamo.js"));
 const Expression_js_1 = require("./Expression.js");
 const Schema_js_1 = require("./Schema.js");
 const Metrics_js_1 = require("./Metrics.js");
@@ -61,8 +53,21 @@ const DynamoOps = {
     transactGet: 'transactGet',
     transactWrite: 'transactWrite',
 };
+/*
+    The generic model is used for the low-level API and batch operations
+ */
 const GenericModel = '_Generic';
 const maxBatchSize = 25;
+/*
+    On exit, flush buffered metrics. This requires any Lambda layer to receive this signal.
+    Without lambda layers, users can call flushMetrics() from time to time.
+ */
+process_1.default.on('SIGTERM', 
+/* istanbul ignore next */
+async () => {
+    /* istanbul ignore next */
+    await Table.terminate();
+});
 /*
     Represent a single DynamoDB table
  */
@@ -79,143 +84,118 @@ class Table {
         }
         if (params.crypto) {
             this.initCrypto(params.crypto);
-            this.crypto = Object.assign(params.crypto);
-            for (let [name, crypto] of Object.entries(this.crypto)) {
-                crypto.secret = crypto_1.default.createHash('sha256').update(crypto.password, 'utf8').digest();
-                this.crypto[name] = crypto;
-                this.crypto[name].name = name;
-            }
         }
         this.setParams(params);
+        //  Set schema param defaults
+        this.typeField = '_type';
+        this.createdField = 'created';
+        this.isoDates = false;
+        this.nulls = false;
+        this.separator = '#';
+        this.timestamps = false;
+        this.updatedField = 'updated';
+        this.warn = false;
         this.schema = new Schema_js_1.Schema(this, params.schema);
+        if (params.metrics) {
+            this.metrics = new Metrics_js_1.Metrics(this, params.metrics);
+        }
         if (params.dataloader) {
-            this.dataloader = new params.dataloader(cmds => this.batchLoaderFunction(cmds), { maxBatchSize });
+            this.dataloader = new params.dataloader((cmds) => this.batchLoaderFunction(cmds), { maxBatchSize });
         }
     }
     setClient(client) {
+        if (client.send && !client.V3) {
+            //  V3 SDK and not yet wrapped by Dynamo
+            client = new Dynamo_js_1.default({ client });
+        }
         this.client = client;
         this.V3 = client.V3;
         this.service = this.V3 ? this.client : this.client.service;
     }
     setParams(params) {
-        //  DEPRECATED - these should be supplied by the schema.params
-        if (params.createdField != null || this.isoDates != null || this.nulls != null ||
-            this.timestamps != null || this.typeField != null || this.updatedField != null) {
-            console.warn('OneTable: Using deprecated Table constructor parameters. Define in the schema.params instead.');
-            //  FUTURE 2.3
-            //  throw new OneTableArgError('Using deprecated Table constructor parameters. Define in the schema.params instead.')
-        }
-        //  DEPRECATE - these should be specified via the Schema params
-        this.createdField = params.createdField || 'created';
-        this.isoDates = params.isoDates || false;
-        this.nulls = params.nulls || false;
-        this.timestamps = params.timestamps != null ? params.timestamps : false;
-        this.typeField = params.typeField || '_type';
-        this.updatedField = params.updatedField || 'updated';
+        if (params.createdField != null ||
+            this.isoDates != null ||
+            this.nulls != null ||
+            this.separator != null ||
+            this.timestamps != null ||
+            this.typeField != null ||
+            this.updatedField != null) {
+            throw new Error_js_1.OneTableArgError('Using deprecated Table constructor parameters. Define in the Schema.params instead.');
+        }
         if (params.uuid) {
             console.warn('OneTable: Using deprecated Table constructor "uuid" parameter. Use a "generate" function instead or ' +
                 'Set schema models to use "generate: uuid|ulid" explicitly.');
             params.generate = params.generate | params.uuid;
         }
-        //  MOB - warn if unset. Revert default to true in future
         if (params.partial == null) {
             console.warn('OneTable: Must set Table constructor "partial" param to true or false. ' +
-                'This param permits updating partial nested schemas. Currently defaults to false, ' +
-                'but in a future version will default to true. ' +
-                'Set to false to future proof or set to true for the new behavior.');
-            //  FUTURE 2.5 - change default to true
-            params.partial = false;
+                'This param permits updating partial nested schemas. Defaults to true.');
+            params.partial = true;
         }
-        this.hidden = params.hidden != null ? params.hidden : true;
+        //  Return hidden fields by default. Default is false.
+        this.hidden = params.hidden != null ? params.hidden : false;
         this.partial = params.partial;
-        this.warn = params.warn || true;
+        this.warn = params.warn || false;
         if (typeof params.generate == 'function') {
             this.generate = params.generate || this.uuid;
         }
         else if (params.generate) {
-            //  FUTURE throw exception
-            console.warn('OneTable: Generate can only be a function');
-            if (params.generate == 'uuid') {
-                this.generate = this.uuid;
-            }
-            else if (params.generate == 'ulid') {
-                this.generate = this.ulid;
-            }
-            else {
-                this.generate = this.uuid;
-            }
+            throw new Error_js_1.OneTableArgError('OneTable: Generate can only be a function');
         }
         this.name = params.name;
-        if (params.metrics) {
-            this.metrics = new Metrics_js_1.Metrics(this, params.metrics, this.metrics);
-        }
         if (params.monitor) {
             this.monitor = params.monitor;
         }
         this.params = params;
     }
-    setSchemaParams(params) {
+    setSchemaParams(params = {}) {
         this.createdField = params.createdField || 'created';
         this.isoDates = params.isoDates || false;
         this.nulls = params.nulls || false;
+        this.separator = params.separator != null ? params.separator : '#';
         this.timestamps = params.timestamps != null ? params.timestamps : false;
         this.typeField = params.typeField || '_type';
         this.updatedField = params.updatedField || 'updated';
+        this.warn = params.warn || false;
         if (params.hidden != null) {
-            console.warn(`Schema hidden params should be specified via the Table constructor params`);
+            this.log.warn(`Schema hidden params should be specified via the Table constructor params`, { '@stack': true });
         }
-        //  DEPRECATE
-        this.hidden = params.hidden != null ? params.hidden : true;
     }
     getSchemaParams() {
         return {
             createdField: this.createdField,
-            hidden: this.hidden,
             isoDates: this.isoDates,
             nulls: this.nulls,
+            separator: this.separator,
             timestamps: this.timestamps,
             typeField: this.typeField,
             updatedField: this.updatedField,
         };
     }
-    setSchema(schema) {
-        return __awaiter(this, void 0, void 0, function* () {
-            return yield this.schema.setSchema(schema);
-        });
+    async setSchema(schema) {
+        return await this.schema.setSchema(schema);
     }
     getCurrentSchema() {
         return this.schema.getCurrentSchema();
     }
-    getKeys() {
-        return __awaiter(this, void 0, void 0, function* () {
-            return yield this.schema.getKeys();
-        });
+    async getKeys() {
+        return await this.schema.getKeys();
     }
-    getPrimaryKeys() {
-        return __awaiter(this, void 0, void 0, function* () {
-            let keys = yield this.schema.getKeys();
-            return keys.primary;
-        });
+    async getPrimaryKeys() {
+        let keys = await this.schema.getKeys();
+        return keys.primary;
     }
-    readSchema() {
-        return __awaiter(this, void 0, void 0, function* () {
-            return this.schema.readSchema();
-        });
+    async readSchema() {
+        return this.schema.readSchema();
     }
-    readSchemas() {
-        return __awaiter(this, void 0, void 0, function* () {
-            return this.schema.readSchemas();
-        });
+    async readSchemas() {
+        return this.schema.readSchemas();
     }
-    removeSchema(schema) {
-        return __awaiter(this, void 0, void 0, function* () {
-            return this.schema.removeSchema(schema);
-        });
+    async removeSchema(schema) {
+        return this.schema.removeSchema(schema);
     }
-    saveSchema(schema) {
-        return __awaiter(this, void 0, void 0, function* () {
-            return this.schema.saveSchema(schema);
-        });
+    async saveSchema(schema) {
+        return this.schema.saveSchema(schema);
     }
     /*
         Output the AWS table definition as a JSON structure to use in external tools such as CloudFormation
@@ -262,7 +242,7 @@ class Table {
                 let project, projection;
                 if (Array.isArray(index.project)) {
                     projection = 'INCLUDE';
-                    project = index.project.filter(a => a != indexes.primary.hash && a != indexes.primary.sort);
+                    project = index.project.filter((a) => a != indexes.primary.hash && a != indexes.primary.sort);
                 }
                 else if (index.project == 'keys') {
                     projection = 'KEYS_ONLY';
@@ -275,7 +255,7 @@ class Table {
                     KeySchema: keys,
                     Projection: {
                         ProjectionType: projection,
-                    }
+                    },
                 };
                 if (project) {
                     projDef.Projection.NonKeyAttributes = project;
@@ -314,54 +294,52 @@ class Table {
         Create a DynamoDB table. Uses the current schema index definition.
         Alternatively, params may contain standard DynamoDB createTable parameters.
     */
-    createTable(params = {}) {
-        return __awaiter(this, void 0, void 0, function* () {
-            const def = this.getTableDefinition(params);
-            let result;
-            this.log.trace(`OneTable createTable for "${this.name}"`, { def });
+    async createTable(params = {}) {
+        const def = this.getTableDefinition(params);
+        let result;
+        this.log.trace(`OneTable createTable for "${this.name}"`, { def });
+        if (this.V3) {
+            result = await this.service.createTable(def);
+        }
+        else {
+            result = await this.service.createTable(def).promise();
+        }
+        /*
+            Wait for table to become active. Must do if setting a TTL attribute
+        */
+        if (params.TimeToLiveSpecification) {
+            params.wait = 5 * 60;
+        }
+        if (params.wait) {
+            let deadline = new Date(Date.now() + params.wait * 1000);
+            let info;
+            do {
+                info = await this.describeTable();
+                if (info.Table.TableStatus == 'ACTIVE') {
+                    break;
+                }
+                if (deadline < Date.now()) {
+                    throw new Error('Table has not become active');
+                }
+                await this.delay(1000);
+            } while (Date.now() < deadline);
+        }
+        /*
+            Define a TTL attribute
+        */
+        if (params.TimeToLiveSpecification) {
+            let def = {
+                TableName: this.name,
+                TimeToLiveSpecification: params.TimeToLiveSpecification,
+            };
             if (this.V3) {
-                result = yield this.service.createTable(def);
+                await this.service.updateTimeToLive(def);
             }
             else {
-                result = yield this.service.createTable(def).promise();
-            }
-            /*
-                Wait for table to become active. Must do if setting a TTL attribute
-            */
-            if (params.TimeToLiveSpecification) {
-                params.wait = 5 * 60;
-            }
-            if (params.wait) {
-                let deadline = new Date(Date.now() + params.wait * 1000);
-                let info;
-                do {
-                    info = yield this.describeTable();
-                    if (info.Table.TableStatus == 'ACTIVE') {
-                        break;
-                    }
-                    if (deadline < Date.now()) {
-                        throw new Error('Table has not become active');
-                    }
-                    yield this.delay(1000);
-                } while (Date.now() < deadline);
-            }
-            /*
-                Define a TTL attribute
-            */
-            if (params.TimeToLiveSpecification) {
-                let def = {
-                    TableName: this.name,
-                    TimeToLiveSpecification: params.TimeToLiveSpecification,
-                };
-                if (this.V3) {
-                    yield this.service.updateTimeToLive(def);
-                }
-                else {
-                    yield this.service.updateTimeToLive(def).promise();
-                }
+                await this.service.updateTimeToLive(def).promise();
             }
-            return result;
-        });
+        }
+        return result;
     }
     getAttributeType(name) {
         for (let model of Object.values(this.schema.models)) {
@@ -375,152 +353,142 @@ class Table {
     /*
         Delete the DynamoDB table forever. Be careful.
     */
-    deleteTable(confirmation) {
-        return __awaiter(this, void 0, void 0, function* () {
-            if (confirmation == ConfirmRemoveTable) {
-                this.log.trace(`OneTable deleteTable for "${this.name}"`);
-                if (this.V3) {
-                    yield this.service.deleteTable({ TableName: this.name });
-                }
-                else {
-                    yield this.service.deleteTable({ TableName: this.name }).promise();
-                }
+    async deleteTable(confirmation) {
+        if (confirmation == ConfirmRemoveTable) {
+            this.log.trace(`OneTable deleteTable for "${this.name}"`);
+            if (this.V3) {
+                await this.service.deleteTable({ TableName: this.name });
             }
             else {
-                throw new Error_js_1.OneTableArgError(`Missing required confirmation "${ConfirmRemoveTable}"`);
+                await this.service.deleteTable({ TableName: this.name }).promise();
             }
-        });
+        }
+        else {
+            throw new Error_js_1.OneTableArgError(`Missing required confirmation "${ConfirmRemoveTable}"`);
+        }
     }
-    updateTable(params = {}) {
-        return __awaiter(this, void 0, void 0, function* () {
-            let def = {
-                AttributeDefinitions: [],
-                GlobalSecondaryIndexUpdates: [],
-                TableName: this.name,
-            };
-            let { create, provisioned } = params;
-            if (provisioned) {
-                if (!provisioned.ReadCapacityUnits && !provisioned.WriteCapacityUnits) {
-                    def.BillingMode = 'PAY_PER_REQUEST';
-                }
-                else {
-                    if (!create) {
-                        def.ProvisionedThroughput = provisioned;
-                    }
-                    def.BillingMode = 'PROVISIONED';
+    async updateTable(params = {}) {
+        let def = {
+            AttributeDefinitions: [],
+            GlobalSecondaryIndexUpdates: [],
+            TableName: this.name,
+        };
+        let { create, provisioned } = params;
+        if (provisioned) {
+            if (!provisioned.ReadCapacityUnits && !provisioned.WriteCapacityUnits) {
+                def.BillingMode = 'PAY_PER_REQUEST';
+            }
+            else {
+                if (!create) {
+                    def.ProvisionedThroughput = provisioned;
                 }
+                def.BillingMode = 'PROVISIONED';
             }
-            let indexes = this.schema.indexes;
-            if (!indexes) {
-                throw new Error_js_1.OneTableArgError('Cannot update table without schema indexes');
+        }
+        let indexes = this.schema.indexes;
+        if (!indexes) {
+            throw new Error_js_1.OneTableArgError('Cannot update table without schema indexes');
+        }
+        if (create) {
+            if (create.hash == null || create.hash == indexes.primary.hash || create.type == 'local') {
+                throw new Error_js_1.OneTableArgError('Cannot update table to create an LSI');
             }
-            if (create) {
-                if (create.hash == null || create.hash == indexes.primary.hash || create.type == 'local') {
-                    throw new Error_js_1.OneTableArgError('Cannot update table to create an LSI');
-                }
-                let keys = [];
-                let projection, project;
-                if (Array.isArray(create.project)) {
-                    projection = 'INCLUDE';
-                    project = create.project.filter(a => a != create.hash && a != create.sort);
-                }
-                else if (create.project == 'keys') {
-                    projection = 'KEYS_ONLY';
-                }
-                else {
-                    projection = 'ALL';
-                }
-                let projDef = {
-                    IndexName: create.name,
-                    KeySchema: keys,
-                    Projection: {
-                        ProjectionType: projection,
-                    }
-                };
-                if (project) {
-                    projDef.Projection.NonKeyAttributes = project;
-                }
-                keys.push({ AttributeName: create.hash, KeyType: 'HASH' });
-                def.AttributeDefinitions.push({ AttributeName: create.hash, AttributeType: 'S' });
-                if (create.sort) {
-                    def.AttributeDefinitions.push({ AttributeName: create.sort, AttributeType: 'S' });
-                    keys.push({ AttributeName: create.sort, KeyType: 'RANGE' });
-                }
-                if (provisioned) {
-                    projDef.ProvisionedThroughput = provisioned;
-                }
-                def.GlobalSecondaryIndexUpdates.push({ Create: projDef });
+            let keys = [];
+            let projection, project;
+            if (Array.isArray(create.project)) {
+                projection = 'INCLUDE';
+                project = create.project.filter((a) => a != create.hash && a != create.sort);
             }
-            else if (params.remove) {
-                def.GlobalSecondaryIndexUpdates.push({ Delete: { IndexName: params.remove.name } });
+            else if (create.project == 'keys') {
+                projection = 'KEYS_ONLY';
             }
-            else if (params.update) {
-                let update = { Update: { IndexName: params.update.name } };
-                if (provisioned) {
-                    update.Update.ProvisionedThroughput = provisioned;
-                }
-                def.GlobalSecondaryIndexUpdates.push(update);
+            else {
+                projection = 'ALL';
+            }
+            let projDef = {
+                IndexName: create.name,
+                KeySchema: keys,
+                Projection: {
+                    ProjectionType: projection,
+                },
+            };
+            if (project) {
+                projDef.Projection.NonKeyAttributes = project;
             }
-            if (def.GlobalSecondaryIndexUpdates.length == 0) {
-                delete def.GlobalSecondaryIndexUpdates;
+            keys.push({ AttributeName: create.hash, KeyType: 'HASH' });
+            def.AttributeDefinitions.push({ AttributeName: create.hash, AttributeType: 'S' });
+            if (create.sort) {
+                def.AttributeDefinitions.push({ AttributeName: create.sort, AttributeType: 'S' });
+                keys.push({ AttributeName: create.sort, KeyType: 'RANGE' });
             }
-            if (params.TimeToLiveSpecification) {
-                let def = {
-                    TableName: params.TableName,
-                    TimeToLiveSpecification: params.TimeToLiveSpecification,
-                };
-                if (this.V3) {
-                    yield this.service.updateTimeToLive(def);
-                }
-                else {
-                    yield this.service.updateTimeToLive(def).promise();
-                }
+            if (provisioned) {
+                projDef.ProvisionedThroughput = provisioned;
+            }
+            def.GlobalSecondaryIndexUpdates.push({ Create: projDef });
+        }
+        else if (params.remove) {
+            def.GlobalSecondaryIndexUpdates.push({ Delete: { IndexName: params.remove.name } });
+        }
+        else if (params.update) {
+            let update = { Update: { IndexName: params.update.name } };
+            if (provisioned) {
+                update.Update.ProvisionedThroughput = provisioned;
             }
-            this.log.trace(`OneTable updateTable for "${this.name}"`, { def });
+            def.GlobalSecondaryIndexUpdates.push(update);
+        }
+        if (def.GlobalSecondaryIndexUpdates.length == 0) {
+            delete def.GlobalSecondaryIndexUpdates;
+        }
+        if (params.TimeToLiveSpecification) {
+            let def = {
+                TableName: params.TableName,
+                TimeToLiveSpecification: params.TimeToLiveSpecification,
+            };
             if (this.V3) {
-                return yield this.service.updateTable(def);
+                await this.service.updateTimeToLive(def);
             }
             else {
-                return yield this.service.updateTable(def).promise();
+                await this.service.updateTimeToLive(def).promise();
             }
-        });
+        }
+        this.log.trace(`OneTable updateTable for "${this.name}"`, { def });
+        if (this.V3) {
+            return await this.service.updateTable(def);
+        }
+        else {
+            return await this.service.updateTable(def).promise();
+        }
     }
     /*
         Return the raw AWS table description
     */
-    describeTable() {
-        return __awaiter(this, void 0, void 0, function* () {
-            if (this.V3) {
-                return yield this.service.describeTable({ TableName: this.name });
-            }
-            else {
-                return yield this.service.describeTable({ TableName: this.name }).promise();
-            }
-        });
+    async describeTable() {
+        if (this.V3) {
+            return await this.service.describeTable({ TableName: this.name });
+        }
+        else {
+            return await this.service.describeTable({ TableName: this.name }).promise();
+        }
     }
     /*
         Return true if the underlying DynamoDB table represented by this OneTable instance is present.
     */
-    exists() {
-        return __awaiter(this, void 0, void 0, function* () {
-            let results = yield this.listTables();
-            return results && results.find(t => t == this.name) != null ? true : false;
-        });
+    async exists() {
+        let results = await this.listTables();
+        return results && results.find((t) => t == this.name) != null ? true : false;
     }
     /*
         Return a list of tables in the AWS region described by the Table instance
     */
-    listTables() {
-        return __awaiter(this, void 0, void 0, function* () {
-            let results;
-            if (this.V3) {
-                results = yield this.service.listTables({});
-            }
-            else {
-                results = yield this.service.listTables({}).promise();
-            }
-            return results.TableNames;
-        });
+    async listTables() {
+        let results;
+        if (this.V3) {
+            results = await this.service.listTables({});
+        }
+        else {
+            results = await this.service.listTables({}).promise();
+        }
+        return results.TableNames;
     }
     listModels() {
         return this.schema.listModels();
@@ -533,12 +501,15 @@ class Table {
     }
     setLog(log) {
         this.log = log;
+        if (this.metrics) {
+            this.metrics.setLog(log);
+        }
     }
     /*
         Thows exception if model cannot be found
      */
-    getModel(name) {
-        return this.schema.getModel(name);
+    getModel(name, options = { nothrow: false }) {
+        return this.schema.getModel(name, options);
     }
     removeModel(name) {
         return this.schema.removeModel(name);
@@ -571,295 +542,263 @@ class Table {
         The high level API is similar to the Model API except the model name is provided as the first parameter.
         This API is useful for factories
     */
-    create(modelName, properties, params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            let model = this.getModel(modelName);
-            return yield model.create(properties, params);
-        });
+    async create(modelName, properties, params) {
+        let model = this.getModel(modelName);
+        return await model.create(properties, params);
     }
-    find(modelName, properties, params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            let model = this.getModel(modelName);
-            return yield model.find(properties, params);
-        });
+    async find(modelName, properties, params) {
+        let model = this.getModel(modelName);
+        return await model.find(properties, params);
     }
-    get(modelName, properties, params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            let model = this.getModel(modelName);
-            return yield model.get(properties, params);
-        });
+    async get(modelName, properties, params) {
+        let model = this.getModel(modelName);
+        return await model.get(properties, params);
     }
-    load(modelName, properties, params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            let model = this.getModel(modelName);
-            return yield model.load(properties, params);
-        });
+    async load(modelName, properties, params) {
+        let model = this.getModel(modelName);
+        return await model.load(properties, params);
     }
     init(modelName, properties, params) {
         let model = this.getModel(modelName);
         return model.init(properties, params);
     }
-    remove(modelName, properties, params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            let model = this.getModel(modelName);
-            return yield model.remove(properties, params);
-        });
-    }
-    scan(modelName, properties, params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            let model = this.getModel(modelName);
-            return yield model.scan(properties, params);
-        });
-    }
-    update(modelName, properties, params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            let model = this.getModel(modelName);
-            return yield model.update(properties, params);
-        });
+    async remove(modelName, properties, params) {
+        let model = this.getModel(modelName);
+        return await model.remove(properties, params);
     }
-    upsert(modelName, properties, params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            params.exists = null;
-            return this.update(modelName, properties, params);
-        });
+    async scan(modelName, properties, params) {
+        let model = this.getModel(modelName);
+        return await model.scan(properties, params);
     }
-    execute(model, op, cmd, properties = {}, params = {}) {
-        return __awaiter(this, void 0, void 0, function* () {
-            let mark = new Date();
-            let trace = { model, cmd, op, properties };
-            let result;
-            try {
-                let client = params.client || this.client;
-                if (params.stats || this.metrics || this.monitor) {
-                    cmd.ReturnConsumedCapacity = params.capacity || 'INDEXES';
-                    cmd.ReturnItemCollectionMetrics = 'SIZE';
-                }
-                this.log[params.log ? 'info' : 'trace'](`OneTable "${op}" "${model}"`, { trace });
-                if (this.V3) {
-                    result = yield client[op](cmd);
-                }
-                else {
-                    result = yield client[DocumentClientMethods[op]](cmd).promise();
-                }
+    async update(modelName, properties, params) {
+        let model = this.getModel(modelName);
+        return await model.update(properties, params);
+    }
+    async upsert(modelName, properties, params = {}) {
+        params.exists = null;
+        return this.update(modelName, properties, params);
+    }
+    async execute(model, op, cmd, properties = {}, params = {}) {
+        let mark = new Date();
+        let trace = { model, cmd, op, properties };
+        let result;
+        try {
+            let client = params.client || this.client;
+            if (params.stats || this.metrics || this.monitor) {
+                cmd.ReturnConsumedCapacity = params.capacity || 'INDEXES';
+                cmd.ReturnItemCollectionMetrics = 'SIZE';
+            }
+            this.log[params.log ? 'info' : 'trace'](`OneTable "${op}" "${model}"`, { trace });
+            if (this.V3) {
+                result = await client[op](cmd);
             }
-            catch (err) {
-                //  V3 stores the error in 'name' (Ugh!)
-                let code = err.code || err.name;
-                if (params.throw === false) {
-                    result = {};
-                }
-                else if (code == 'ConditionalCheckFailedException' && op == 'put') {
-                    this.log.info(`Conditional check failed "${op}" on "${model}"`, { err, trace });
-                    throw new Error_js_1.OneTableError(`Conditional create failed for "${model}"`, {
-                        code, err, trace,
-                    });
-                }
-                else if (code == 'ProvisionedThroughputExceededException') {
-                    throw new Error_js_1.OneTableError('Provisioning Throughput Exception', {
-                        code, err, trace,
-                    });
-                }
-                else if (code == 'TransactionCanceledException') {
-                    throw new Error_js_1.OneTableError('Transaction Cancelled', {
-                        code, err, trace,
-                    });
-                }
-                else {
-                    result = result || {};
-                    result.Error = 1;
-                    if (params.log != false) {
-                        this.log.error(`OneTable exception in "${op}" on "${model}"`, { err, trace });
-                    }
-                    throw new Error_js_1.OneTableError(`OneTable execute failed "${op}" for "${model}. ${err.message}`, {
-                        code, err, trace,
-                    });
-                }
+            else {
+                result = await client[DocumentClientMethods[op]](cmd).promise();
             }
-            finally {
-                if (result) {
-                    if (this.metrics) {
-                        this.metrics.add(model, op, result, params, mark);
-                    }
-                    if (this.monitor) {
-                        yield this.monitor(model, op, result, params, mark);
-                    }
+        }
+        catch (err) {
+            //  V3 stores the error in 'name' (Ugh!)
+            let code = err.code || err.name;
+            if (params.throw === false) {
+                result = {};
+            }
+            else if (code == 'ConditionalCheckFailedException' && op == 'put') {
+                this.log.info(`Conditional check failed "${op}" on "${model}"`, { err, trace });
+                throw new Error_js_1.OneTableError(`Conditional create failed for "${model}"`, {
+                    code,
+                    err,
+                    trace,
+                });
+            }
+            else if (code == 'ProvisionedThroughputExceededException') {
+                throw new Error_js_1.OneTableError('Provisioning Throughput Exception', {
+                    code,
+                    err,
+                    trace,
+                });
+            }
+            else if (code == 'TransactionCanceledException') {
+                throw new Error_js_1.OneTableError('Transaction Cancelled', {
+                    code,
+                    err,
+                    trace,
+                });
+            }
+            else {
+                result = result || {};
+                result.Error = 1;
+                if (params.log != false) {
+                    this.log.error(`OneTable exception in "${op}" on "${model} ${err.message}"`, { err, trace });
                 }
+                throw new Error_js_1.OneTableError(`OneTable execute failed "${op}" for "${model}", ${err.message}`, {
+                    code,
+                    err,
+                    trace,
+                });
             }
-            if (typeof params.info == 'object') {
-                params.info.operation = DynamoOps[op];
-                params.info.args = cmd;
-                params.info.properties = properties;
+        }
+        finally {
+            if (result) {
+                if (this.metrics) {
+                    await this.metrics.add(model, op, result, params, mark);
+                }
+                if (this.monitor) {
+                    await this.monitor(model, op, result, params, mark);
+                }
             }
-            return result;
-        });
+        }
+        if (typeof params.info == 'object') {
+            params.info.operation = DynamoOps[op];
+            params.info.args = cmd;
+            params.info.properties = properties;
+        }
+        return result;
     }
     /*
         The low level API does not use models. It permits the reading / writing of any attribute.
     */
-    batchGet(batch, params = {}) {
-        return __awaiter(this, void 0, void 0, function* () {
-            if (Object.getOwnPropertyNames(batch).length == 0) {
-                return [];
-            }
-            let def = batch.RequestItems[this.name];
-            if (params.fields) {
-                if (params.fields.indexOf(this.typeField) < 0) {
-                    params.fields.push(this.typeField);
-                }
-                let expression = new Expression_js_1.Expression(this.schema.genericModel, 'batchGet', {}, params);
-                let cmd = expression.command();
-                def.ProjectionExpression = cmd.ProjectionExpression;
-                def.ExpressionAttributeNames = cmd.ExpressionAttributeNames;
-            }
-            def.ConsistentRead = params.consistent ? true : false;
-            // let result = await this.execute(GenericModel, 'batchGet', batch, {}, params)
-            let result, retries = 0, more;
-            result = params.parse ? [] : { Responses: {} };
-            do {
-                more = false;
-                let data = yield this.execute(GenericModel, 'batchGet', batch, {}, params);
-                if (data) {
-                    let responses = data.Responses;
-                    if (responses) {
-                        for (let [key, items] of Object.entries(responses)) {
-                            for (let item of items) {
-                                if (params.parse) {
-                                    item = this.unmarshall(item, params);
-                                    let type = item[this.typeField] || '_unknown';
-                                    let model = this.schema.models[type];
-                                    if (model && model != this.schema.uniqueModel) {
-                                        result.push(model.transformReadItem('get', item, {}, params));
-                                    }
-                                }
-                                else {
-                                    let set = result.Responses[key] = result.Responses[key] || [];
-                                    set.push(item);
+    async batchGet(batch, params = {}) {
+        if (Object.getOwnPropertyNames(batch).length == 0) {
+            return [];
+        }
+        let def = batch.RequestItems[this.name];
+        if (params.fields) {
+            if (params.fields.indexOf(this.typeField) < 0) {
+                params.fields.push(this.typeField);
+            }
+            let expression = new Expression_js_1.Expression(this.schema.genericModel, 'batchGet', {}, params);
+            let cmd = expression.command();
+            def.ProjectionExpression = cmd.ProjectionExpression;
+            def.ExpressionAttributeNames = cmd.ExpressionAttributeNames;
+        }
+        def.ConsistentRead = params.consistent ? true : false;
+        let result, retries = 0, more;
+        result = params.parse ? [] : { Responses: {} };
+        do {
+            more = false;
+            let data = await this.execute(GenericModel, 'batchGet', batch, {}, params);
+            if (data) {
+                let responses = data.Responses;
+                if (responses) {
+                    for (let [key, items] of Object.entries(responses)) {
+                        for (let item of items) {
+                            if (params.parse) {
+                                item = this.unmarshall(item, params);
+                                let type = item[this.typeField] || '_unknown';
+                                let model = this.schema.models[type];
+                                if (model && model != this.schema.uniqueModel) {
+                                    result.push(model.transformReadItem('get', item, {}, params));
                                 }
                             }
+                            else {
+                                let set = (result.Responses[key] = result.Responses[key] || []);
+                                set.push(item);
+                            }
                         }
                     }
-                    let unprocessed = data.UnprocessedItems;
-                    if (unprocessed && Object.keys(unprocessed).length) {
-                        batch.RequestItems = unprocessed;
-                        if (params.reprocess === false) {
-                            return false;
-                        }
-                        if (retries > 11) {
-                            throw new Error(unprocessed);
-                        }
-                        yield this.delay(10 * (Math.pow(2, retries++)));
-                        more = true;
-                    }
                 }
-            } while (more);
-            return result;
-        });
-    }
-    /*
-        AWS BatchWrite may throw an exception if no items can be processed.
-        Otherwise it will retry (up to 11 times) and return partial results in UnprocessedItems.
-        Those will be handled here if possible.
-    */
-    batchWrite(batch, params = {}) {
-        return __awaiter(this, void 0, void 0, function* () {
-            if (Object.getOwnPropertyNames(batch).length == 0) {
-                return {};
-            }
-            let retries = 0, more;
-            do {
-                more = false;
-                let response = yield this.execute(GenericModel, 'batchWrite', batch, {}, params);
-                let data = response.data;
-                if (data && data.UnprocessedItems && Object.keys(data.UnprocessedItems).length) {
-                    batch.RequestItems = data.UnprocessedItems;
+                let unprocessed = data.UnprocessedItems;
+                if (unprocessed && Object.keys(unprocessed).length) {
+                    batch.RequestItems = unprocessed;
                     if (params.reprocess === false) {
                         return false;
                     }
                     if (retries > 11) {
-                        throw new Error(response.UnprocessedItems);
+                        throw new Error(unprocessed);
                     }
-                    yield this.delay(10 * (Math.pow(2, retries++)));
+                    await this.delay(10 * 2 ** retries++);
                     more = true;
                 }
-            } while (more);
-            return true;
-        });
+            }
+        } while (more);
+        return result;
     }
-    batchLoad(expression) {
-        return __awaiter(this, void 0, void 0, function* () {
-            if (this.dataloader) {
-                return yield this.dataloader.load(expression);
+    /*
+        AWS BatchWrite may throw an exception if no items can be processed.
+        Otherwise it will retry (up to 11 times) and return partial results in UnprocessedItems.
+        Those will be handled here if possible.
+    */
+    async batchWrite(batch, params = {}) {
+        if (Object.getOwnPropertyNames(batch).length === 0) {
+            return {};
+        }
+        let retries = 0, more;
+        do {
+            more = false;
+            let response = await this.execute(GenericModel, 'batchWrite', batch, {}, params);
+            if (response && response.UnprocessedItems && Object.keys(response.UnprocessedItems).length) {
+                batch.RequestItems = response.UnprocessedItems;
+                if (params.reprocess === false) {
+                    return false;
+                }
+                if (retries > 11) {
+                    throw new Error(response.UnprocessedItems);
+                }
+                await this.delay(10 * 2 ** retries++);
+                more = true;
             }
-            throw new Error('params.dataloader DataLoader constructor is required to use load feature');
-        });
+        } while (more);
+        return true;
     }
-    deleteItem(properties, params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            return yield this.schema.genericModel.deleteItem(properties, params);
-        });
+    async batchLoad(expression) {
+        if (this.dataloader) {
+            return await this.dataloader.load(expression);
+        }
+        throw new Error('params.dataloader DataLoader constructor is required to use load feature');
     }
-    getItem(properties, params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            return yield this.schema.genericModel.getItem(properties, params);
-        });
+    async deleteItem(properties, params) {
+        return await this.schema.genericModel.deleteItem(properties, params);
     }
-    putItem(properties, params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            return yield this.schema.genericModel.putItem(properties, params);
-        });
+    async getItem(properties, params) {
+        return await this.schema.genericModel.getItem(properties, params);
     }
-    queryItems(properties, params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            return yield this.schema.genericModel.queryItems(properties, params);
-        });
+    async putItem(properties, params) {
+        return await this.schema.genericModel.putItem(properties, params);
     }
-    scanItems(properties, params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            return yield this.schema.genericModel.scanItems(properties, params);
-        });
+    async queryItems(properties, params) {
+        return await this.schema.genericModel.queryItems(properties, params);
     }
-    updateItem(properties, params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            return yield this.schema.genericModel.updateItem(properties, params);
-        });
+    async scanItems(properties, params) {
+        return await this.schema.genericModel.scanItems(properties, params);
     }
-    fetch(models, properties, params) {
-        return __awaiter(this, void 0, void 0, function* () {
-            return yield this.schema.genericModel.fetch(models, properties, params);
-        });
+    async updateItem(properties, params) {
+        return await this.schema.genericModel.updateItem(properties, params);
+    }
+    async fetch(models, properties, params) {
+        return await this.schema.genericModel.fetch(models, properties, params);
     }
     /*
         Invoke a prepared transaction. Note: transactGet does not work on non-primary indexes.
      */
-    transact(op, transaction, params = {}) {
-        return __awaiter(this, void 0, void 0, function* () {
-            if (params.execute === false) {
-                if (params.log !== false) {
-                    this.log[params.log ? 'info' : 'data'](`OneTable transaction for "${op}" (not executed)`, {
-                        transaction, op, params,
-                    });
-                }
-                return transaction;
-            }
-            let result = yield this.execute(GenericModel, op == 'write' ? 'transactWrite' : 'transactGet', transaction, {}, params);
-            if (op == 'get') {
-                if (params.parse) {
-                    let items = [];
-                    for (let r of result.Responses) {
-                        if (r.Item) {
-                            let item = this.unmarshall(r.Item, params);
-                            let type = item[this.typeField] || '_unknown';
-                            let model = this.schema.models[type];
-                            if (model && model != this.schema.uniqueModel) {
-                                items.push(model.transformReadItem('get', item, {}, params));
-                            }
+    async transact(op, transaction, params = {}) {
+        if (params.execute === false) {
+            if (params.log !== false) {
+                this.log[params.log ? 'info' : 'data'](`OneTable transaction for "${op}" (not executed)`, {
+                    transaction,
+                    op,
+                    params,
+                });
+            }
+            return transaction;
+        }
+        let result = await this.execute(GenericModel, op == 'write' ? 'transactWrite' : 'transactGet', transaction, {}, params);
+        if (op == 'get') {
+            if (params.parse) {
+                let items = [];
+                for (let r of result.Responses) {
+                    if (r.Item) {
+                        let item = this.unmarshall(r.Item, params);
+                        let type = item[this.typeField] || '_unknown';
+                        let model = this.schema.models[type];
+                        if (model && model != this.schema.uniqueModel) {
+                            items.push(model.transformReadItem('get', item, {}, params));
                         }
                     }
-                    result = items;
                 }
+                result = items;
             }
-            return result;
-        });
+        }
+        return result;
     }
     /*
         Convert items into a map of items by model type
@@ -868,7 +807,7 @@ class Table {
         let result = {};
         for (let item of items) {
             let type = item[this.typeField] || '_unknown';
-            let list = result[type] = result[type] || [];
+            let list = (result[type] = result[type] || []);
             let model = this.schema.models[type];
             let preparedItem;
             if (typeof params.hidden === 'boolean' && !params.hidden) {
@@ -895,65 +834,63 @@ class Table {
         @param expressions
         @returns {Promise<*>}
      */
-    batchLoaderFunction(expressions) {
-        return __awaiter(this, void 0, void 0, function* () {
-            const commands = expressions.map(each => each.command());
-            const groupedByTableName = commands.reduce((groupedBy, item) => {
-                const tableName = item.TableName;
-                if (!groupedBy[tableName])
-                    groupedBy[tableName] = [];
-                groupedBy[tableName].push(item);
-                return groupedBy;
-            }, {});
-            // convert each of the get requests into a single RequestItem with unique Keys
-            const requestItems = Object.keys(groupedByTableName).reduce((requestItems, tableName) => {
-                // batch get does not support duplicate Keys, so we need to make them unique
-                // it's complex because we have the unmarshalled values on the Keys when it's V3
-                const allKeys = groupedByTableName[tableName].map(each => each.Key);
-                const uniqueKeys = allKeys.filter((key1, index1, self) => {
-                    const index2 = self.findIndex(key2 => {
-                        return Object.keys(key2).every(prop => {
-                            if (this.V3) {
-                                const type = Object.keys(key1[prop])[0]; // { S: "XX" } => type is S
-                                return key2[prop][type] === key1[prop][type];
-                            }
-                            return key2[prop] === key1[prop];
-                        });
-                    });
-                    return index2 === index1;
-                });
-                requestItems[tableName] = { Keys: uniqueKeys };
-                return requestItems;
-            }, {});
-            const results = yield this.batchGet({ RequestItems: requestItems });
-            // return the exact mapping (on same order as input) of each get command request to the result from database
-            // to do that we need to find in the Responses object the item that was request and return it in the same position
-            return commands.map((command, index) => {
-                const { model, params } = expressions[index];
-                // each key is { pk: { S: "XX" } } when V3 or { pk: "XX" } when V2
-                // on map function, key will be pk and unmarshalled will be { S: "XX" }, OR "XXX"
-                const criteria = Object.entries(command.Key).map(([key, unmarshalled]) => {
-                    if (this.V3) {
-                        const type = Object.keys(unmarshalled)[0]; // the type will be S
-                        return [[key, type], unmarshalled[type]]; // return [[pk, S], "XX"]
-                    }
-                    return [[key], unmarshalled];
-                });
-                // finds the matching object in the unmarshalled Responses array with criteria Key above
-                const findByKeyUnmarshalled = (items = []) => items.find(item => {
-                    return criteria.every(([[prop, type], value]) => {
-                        if (type)
-                            return item[prop][type] === value; // if it has a type it means it is V3
-                        return item[prop] === value;
+    async batchLoaderFunction(expressions) {
+        const commands = expressions.map((each) => each.command());
+        const groupedByTableName = commands.reduce((groupedBy, item) => {
+            const tableName = item.TableName;
+            if (!groupedBy[tableName])
+                groupedBy[tableName] = [];
+            groupedBy[tableName].push(item);
+            return groupedBy;
+        }, {});
+        // convert each of the get requests into a single RequestItem with unique Keys
+        const requestItems = Object.keys(groupedByTableName).reduce((requestItems, tableName) => {
+            // batch get does not support duplicate Keys, so we need to make them unique
+            // it's complex because we have the unmarshalled values on the Keys when it's V3
+            const allKeys = groupedByTableName[tableName].map((each) => each.Key);
+            const uniqueKeys = allKeys.filter((key1, index1, self) => {
+                const index2 = self.findIndex((key2) => {
+                    return Object.keys(key2).every((prop) => {
+                        if (this.V3) {
+                            const type = Object.keys(key1[prop])[0]; // { S: "XX" } => type is S
+                            return key2[prop][type] === key1[prop][type];
+                        }
+                        return key2[prop] === key1[prop];
                     });
                 });
-                const items = results.Responses[command.TableName];
-                const item = findByKeyUnmarshalled(items);
-                if (item) {
-                    const unmarshalled = this.unmarshall(item, params);
-                    return model.transformReadItem('get', unmarshalled, {}, params);
+                return index2 === index1;
+            });
+            requestItems[tableName] = { Keys: uniqueKeys };
+            return requestItems;
+        }, {});
+        const results = await this.batchGet({ RequestItems: requestItems });
+        // return the exact mapping (on same order as input) of each get command request to the result from database
+        // to do that we need to find in the Responses object the item that was request and return it in the same position
+        return commands.map((command, index) => {
+            const { model, params } = expressions[index];
+            // each key is { pk: { S: "XX" } } when V3 or { pk: "XX" } when V2
+            // on map function, key will be pk and unmarshalled will be { S: "XX" }, OR "XXX"
+            const criteria = Object.entries(command.Key).map(([key, unmarshalled]) => {
+                if (this.V3) {
+                    const type = Object.keys(unmarshalled)[0]; // the type will be S
+                    return [[key, type], unmarshalled[type]]; // return [[pk, S], "XX"]
                 }
+                return [[key], unmarshalled];
             });
+            // finds the matching object in the unmarshalled Responses array with criteria Key above
+            const findByKeyUnmarshalled = (items = []) => items.find((item) => {
+                return criteria.every(([[prop, type], value]) => {
+                    if (type)
+                        return item[prop][type] === value; // if it has a type it means it is V3
+                    return item[prop] === value;
+                });
+            });
+            const items = results.Responses[command.TableName];
+            const item = findByKeyUnmarshalled(items);
+            if (item) {
+                const unmarshalled = this.unmarshall(item, params);
+                return model.transformReadItem('get', unmarshalled, {}, params);
+            }
         });
     }
     /*
@@ -961,17 +898,17 @@ class Table {
         Consider ULIDs which are crypto sortable.
     */
     uuid() {
-        return (0, UUID_js_1.default)();
+        return (0, UID_js_1.UUID)();
     }
     // Simple time-based, sortable unique ID.
     ulid() {
-        return new ULID_js_1.default().toString();
+        return new UID_js_1.ULID().toString();
     }
     /*
         Crypto-grade ID of given length. If >= 10 in length, suitably unique for most use-cases.
      */
-    uid(size) {
-        return (0, UID_js_1.default)(size);
+    uid(size = 10) {
+        return (0, UID_js_1.UID)(size);
     }
     setGenerate(fn) {
         this.generate = fn;
@@ -1011,7 +948,7 @@ class Table {
             let iv = crypto_1.default.randomBytes(IV_LENGTH);
             let crypt = crypto_1.default.createCipheriv(crypto.cipher, crypto.secret, iv);
             let crypted = crypt.update(text, inCode, outCode) + crypt.final(outCode);
-            let tag = (crypto.cipher.indexOf('-gcm') > 0) ? crypt.getAuthTag().toString(outCode) : '';
+            let tag = crypto.cipher.indexOf('-gcm') > 0 ? crypt.getAuthTag().toString(outCode) : '';
             text = `${crypto.name}:${tag}:${iv.toString('hex')}:${crypted}`;
         }
         return text;
@@ -1029,9 +966,9 @@ class Table {
             if (!crypto) {
                 throw new Error_js_1.OneTableArgError(`Database crypto not defined for ${name}`);
             }
-            iv = Buffer.from(iv, 'hex');
+            iv = buffer_1.Buffer.from(iv, 'hex');
             let crypt = crypto_1.default.createDecipheriv(crypto.cipher, crypto.secret, iv);
-            crypt.setAuthTag(Buffer.from(tag, inCode));
+            crypt.setAuthTag(buffer_1.Buffer.from(tag, inCode));
             text = crypt.update(data, inCode, outCode) + crypt.final(outCode);
         }
         return text;
@@ -1103,17 +1040,66 @@ class Table {
     }
     unmarshallv2(item) {
         for (let [key, value] of Object.entries(item)) {
-            if (value != null && typeof value == 'object' && value.wrapperName == 'Set' && Array.isArray(value.values)) {
+            if (value != null &&
+                typeof value == 'object' &&
+                value.wrapperName == 'Set' &&
+                Array.isArray(value.values)) {
                 let list = value.values;
                 if (value.type == 'Binary') {
                     //  Match AWS SDK V3 behavior
-                    list = list.map(v => new Uint8Array(v));
+                    list = list.map((v) => new Uint8Array(v));
                 }
                 item[key] = new Set(list);
             }
         }
         return item;
     }
+    unmarshallStreamImage(image, params) {
+        let client = params.client ? params.client : this.client;
+        let options = client.params.unmarshall;
+        return client.unmarshall(image, options);
+    }
+    /*
+        Handle DynamoDb Stream Records
+     */
+    stream(records, params = {}) {
+        const tableModels = this.listModels();
+        const result = {};
+        for (const record of records) {
+            if (!record.dynamodb.NewImage && !record.dynamodb.OldImage) {
+                continue;
+            }
+            const model = { type: record.eventName };
+            let typeNew;
+            let typeOld;
+            // Unmarshall and transform the New Image if it exists
+            if (record.dynamodb.NewImage) {
+                const jsonNew = this.unmarshallStreamImage(record.dynamodb.NewImage, params);
+                typeNew = jsonNew[this.typeField];
+                // If type not found then don't do anything
+                if (typeNew && tableModels.includes(typeNew)) {
+                    model.new = this.schema.models[typeNew].transformReadItem('get', jsonNew, {}, params);
+                }
+            }
+            // Unmarshall and transform the Old Image if it exists
+            if (record.dynamodb.OldImage) {
+                const jsonOld = this.unmarshallStreamImage(record.dynamodb.OldImage, params);
+                typeOld = jsonOld[this.typeField];
+                // If type not found then don't do anything
+                if (typeOld && tableModels.includes(typeOld)) {
+                    // If there was a new image of a different type then skip
+                    if (typeNew && typeNew !== typeOld) {
+                        continue;
+                    }
+                    model.old = this.schema.models[typeOld].transformReadItem('get', jsonOld, {}, params);
+                }
+            }
+            const type = typeNew || typeOld;
+            let list = (result[type] = result[type] || []);
+            list.push(model);
+        }
+        return result;
+    }
     /*
         Recursive Object.assign. Will clone dates, regexp, simple objects and arrays.
         Other class instances and primitives are copied not cloned.
@@ -1164,13 +1150,17 @@ class Table {
         }
         return dest;
     }
-    delay(time) {
-        return __awaiter(this, void 0, void 0, function* () {
-            return new Promise(function (resolve) {
-                setTimeout(() => resolve(true), time);
-            });
+    async delay(time) {
+        return new Promise(function (resolve) {
+            setTimeout(() => resolve(true), time);
         });
     }
+    async flushMetrics() {
+        await this.metrics.flush();
+    }
+    static async terminate() {
+        await Metrics_js_1.Metrics.terminate();
+    }
 }
 exports.Table = Table;
 /*
@@ -1223,7 +1213,9 @@ class Log {
                     try {
                         buf.push(`    ${key}: ${JSON.stringify(value, null, 4)}`);
                     }
-                    catch (err) { /* continue */ }
+                    catch (err) {
+                        /* continue */
+                    }
                 }
                 buf.push('}');
                 console.log(level, message, buf.join('\n'));
diff --git a/node_modules/dynamodb-onetable/dist/cjs/UID.d.ts b/node_modules/dynamodb-onetable/dist/cjs/UID.d.ts
index bd8e6c9..3066603 100644
--- a/node_modules/dynamodb-onetable/dist/cjs/UID.d.ts
+++ b/node_modules/dynamodb-onetable/dist/cjs/UID.d.ts
@@ -1 +1,10 @@
-export default function UID(size: any): string;
+export function UID(size: number): string
+export class ULID {
+    constructor(when?: string | number | Date)
+    when: Date
+    toString(): string
+    decode(ulid: string | ULID): number
+    getRandom(): string
+    getTime(now: Date): string
+}
+export function UUID(): string
\ No newline at end of file
diff --git a/node_modules/dynamodb-onetable/dist/cjs/UID.js b/node_modules/dynamodb-onetable/dist/cjs/UID.js
index 4bf5894..b92326f 100644
--- a/node_modules/dynamodb-onetable/dist/cjs/UID.js
+++ b/node_modules/dynamodb-onetable/dist/cjs/UID.js
@@ -1,26 +1,97 @@
 "use strict";
-/*
-    UID - Unique Crypto-grade ID of a given length.
-
-    If >= 10 in length, suitably unique for most use-cases.
-    Converted to use safe letters -- base 32 excluding I, L, O and U.
-    Note: Not a ULID and not sortable.
-*/
 var __importDefault = (this && this.__importDefault) || function (mod) {
     return (mod && mod.__esModule) ? mod : { "default": mod };
 };
 Object.defineProperty(exports, "__esModule", { value: true });
+exports.ULID = void 0;
+exports.UID = UID;
+exports.UUID = UUID;
+/*
+    UID - UUIDs and ULIDs of crypto and non-crypto varieties
+*/
 const crypto_1 = __importDefault(require("crypto"));
+//  Crockford's base 32 excluding I, L, O and U
 //  Repeat Z to make encoding faster for rand == 0xFF
 const Letters = '0123456789ABCDEFGHJKMNPQRSTVWXYZZ';
 const LettersLen = Letters.length - 1;
+const RandomLength = 16;
+const TimeLen = 10;
+/*
+    If >= 10 in length, suitably unique for most use-cases.
+    Converted to use safe letters -- base 32 excluding I, L, O and U.
+    Note: Not a ULID and not sortable.
+ */
 function UID(size) {
     let bytes = [];
     let buffer = crypto_1.default.randomBytes(size);
     for (let i = 0; i < size; i++) {
         //  Letters is one longer than LettersLen
-        bytes[i] = Letters[Math.floor(buffer.readUInt8(i) / 0xFF * LettersLen)];
+        bytes[i] = Letters[Math.floor((buffer.readUInt8(i) / 0xff) * LettersLen)];
     }
     return bytes.join('');
 }
-exports.default = UID;
+/*
+    Simple non-crypto UUID
+*/
+function UUID() {
+    return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function (c) {
+        let r = (Math.random() * 16) | 0, v = c == 'x' ? r : (r & 0x3) | 0x8;
+        return v.toString(16);
+    });
+}
+/*
+    ULID.js -- Universal Unique Lexicographically Sortable Identifier
+    https://github.com/ulid/spec
+ */
+class ULID {
+    constructor(when) {
+        if (when instanceof Date) {
+            this.when = new Date(when);
+        }
+        else if (typeof when == 'string' || typeof when == 'number') {
+            this.when = new Date(when);
+        }
+        else {
+            this.when = new Date();
+        }
+    }
+    toString() {
+        return this.getTime(this.when) + this.getRandom(RandomLength);
+    }
+    //  Decode the time portion of the ULID and return a number
+    decode(ulid) {
+        ulid = ulid.toString();
+        if (ulid.length !== TimeLen + RandomLength) {
+            throw new Error('Invalid ULID');
+        }
+        let letters = ulid.substr(0, TimeLen).split('').reverse();
+        return letters.reduce((accum, c, index) => {
+            let i = Letters.indexOf(c);
+            if (i < 0) {
+                throw new Error(`Invalid ULID char ${c}`);
+            }
+            accum += index * Math.pow(LettersLen, i);
+            return accum;
+        }, 0);
+    }
+    getRandom(size) {
+        let bytes = [];
+        let buffer = crypto_1.default.randomBytes(size);
+        for (let i = 0; i < size; i++) {
+            //  Letters is one longer than LettersLen
+            bytes[i] = Letters[Math.floor((buffer.readUInt8(i) / 0xff) * LettersLen)];
+        }
+        return bytes.join('');
+    }
+    getTime(now) {
+        now = now.getTime();
+        let bytes = [];
+        for (let i = 0; i < TimeLen; i++) {
+            let mod = now % LettersLen;
+            bytes[i] = Letters.charAt(mod);
+            now = (now - mod) / LettersLen;
+        }
+        return bytes.reverse().join('');
+    }
+}
+exports.ULID = ULID;
diff --git a/node_modules/dynamodb-onetable/dist/cjs/ULID.d.ts b/node_modules/dynamodb-onetable/dist/cjs/ULID.d.ts
deleted file mode 100644
index 66ef0d0..0000000
--- a/node_modules/dynamodb-onetable/dist/cjs/ULID.d.ts
+++ /dev/null
@@ -1,8 +0,0 @@
-export default class ULID {
-    constructor(when?: string | number | Date);
-    when: Date;
-    toString(): string;
-    decode(ulid: string | ULID): number;
-    getRandom(): string;
-    getTime(now: Date): string;
-}
diff --git a/node_modules/dynamodb-onetable/dist/cjs/ULID.js b/node_modules/dynamodb-onetable/dist/cjs/ULID.js
deleted file mode 100644
index c8fe377..0000000
--- a/node_modules/dynamodb-onetable/dist/cjs/ULID.js
+++ /dev/null
@@ -1,68 +0,0 @@
-"use strict";
-var __importDefault = (this && this.__importDefault) || function (mod) {
-    return (mod && mod.__esModule) ? mod : { "default": mod };
-};
-Object.defineProperty(exports, "__esModule", { value: true });
-/*
-    ULID.js -- Universal Unique Lexicographically Sortable Identifier
-    https://github.com/ulid/spec
- */
-const crypto_1 = __importDefault(require("crypto"));
-//  Crockford's base 32 excluding I, L, O and U
-//  Repeat Z to make encoding faster for rand == 0xFF
-const Letters = '0123456789ABCDEFGHJKMNPQRSTVWXYZZ';
-const LettersLen = Letters.length - 1;
-const RandomLength = 16;
-const TimeLen = 10;
-class ULID {
-    constructor(when) {
-        if (when instanceof Date) {
-            this.when = new Date(when);
-        }
-        else if (typeof when == 'string' || typeof when == 'number') {
-            this.when = new Date(when);
-        }
-        else {
-            this.when = new Date();
-        }
-    }
-    toString() {
-        return this.getTime(this.when) + this.getRandom(RandomLength);
-    }
-    //  Decode the time portion of the ULID and return a number
-    decode(ulid) {
-        ulid = ulid.toString();
-        if (ulid.length !== (TimeLen + RandomLength)) {
-            throw new Error('Invalid ULID');
-        }
-        let letters = ulid.substr(0, TimeLen).split('').reverse();
-        return letters.reduce((accum, c, index) => {
-            let i = Letters.indexOf(c);
-            if (i < 0) {
-                throw new Error(`Invalid ULID char ${c}`);
-            }
-            accum += index * Math.pow(LettersLen, i);
-            return accum;
-        }, 0);
-    }
-    getRandom(size) {
-        let bytes = [];
-        let buffer = crypto_1.default.randomBytes(size);
-        for (let i = 0; i < size; i++) {
-            //  Letters is one longer than LettersLen
-            bytes[i] = Letters[Math.floor(buffer.readUInt8(i) / 0xFF * LettersLen)];
-        }
-        return bytes.join('');
-    }
-    getTime(now) {
-        now = now.getTime();
-        let bytes = [];
-        for (let i = 0; i < TimeLen; i++) {
-            let mod = now % LettersLen;
-            bytes[i] = Letters.charAt(mod);
-            now = (now - mod) / LettersLen;
-        }
-        return bytes.reverse().join('');
-    }
-}
-exports.default = ULID;
diff --git a/node_modules/dynamodb-onetable/dist/cjs/UUID.d.ts b/node_modules/dynamodb-onetable/dist/cjs/UUID.d.ts
deleted file mode 100644
index 5f9bec4..0000000
--- a/node_modules/dynamodb-onetable/dist/cjs/UUID.d.ts
+++ /dev/null
@@ -1 +0,0 @@
-export default function UUID(): string;
diff --git a/node_modules/dynamodb-onetable/dist/cjs/UUID.js b/node_modules/dynamodb-onetable/dist/cjs/UUID.js
deleted file mode 100644
index a4e25d7..0000000
--- a/node_modules/dynamodb-onetable/dist/cjs/UUID.js
+++ /dev/null
@@ -1,13 +0,0 @@
-"use strict";
-Object.defineProperty(exports, "__esModule", { value: true });
-/*
-    Simple non-crypto UUID. See node-uuid if you require crypto UUIDs.
-    Consider ULIDs which are crypto sortable.
-*/
-function UUID() {
-    return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function (c) {
-        let r = Math.random() * 16 | 0, v = c == 'x' ? r : (r & 0x3 | 0x8);
-        return v.toString(16);
-    });
-}
-exports.default = UUID;
diff --git a/node_modules/dynamodb-onetable/dist/cjs/index.d.ts b/node_modules/dynamodb-onetable/dist/cjs/index.d.ts
index ac08a83..60d44a7 100644
--- a/node_modules/dynamodb-onetable/dist/cjs/index.d.ts
+++ b/node_modules/dynamodb-onetable/dist/cjs/index.d.ts
@@ -14,15 +14,14 @@ import {
     OneProperties,
     OneSchema,
     OneType,
-    Paged
-} from './Model'
+    Paged,
+} from './Model.js'
 
-import { Table } from './Table'
-import { Expression } from './Expression'
-import { OneTableError, OneTableArgError } from './Error'
+import {Table} from './Table.js'
+import {Expression} from './Expression.js'
+import {OneTableError, OneTableArgError} from './Error.js'
 
-import ULID from './ULID.js'
-import UUID from './UUID.js'
+import {UID, ULID, UUID} from './UID.js'
 
 export {
     AnyEntity,
@@ -40,6 +39,7 @@ export {
     OneType,
     Paged,
     Table,
+    UID,
     ULID,
     UUID,
 }
diff --git a/node_modules/dynamodb-onetable/dist/cjs/index.js b/node_modules/dynamodb-onetable/dist/cjs/index.js
index ce268cc..06c7da4 100644
--- a/node_modules/dynamodb-onetable/dist/cjs/index.js
+++ b/node_modules/dynamodb-onetable/dist/cjs/index.js
@@ -2,11 +2,8 @@
 /*
     dynamodb-onetable - DynamoDB wrapper for single table patterns
 */
-var __importDefault = (this && this.__importDefault) || function (mod) {
-    return (mod && mod.__esModule) ? mod : { "default": mod };
-};
 Object.defineProperty(exports, "__esModule", { value: true });
-exports.UUID = exports.ULID = exports.Table = exports.OneTableError = exports.OneTableArgError = exports.Model = exports.Expression = void 0;
+exports.UUID = exports.ULID = exports.UID = exports.Table = exports.OneTableError = exports.OneTableArgError = exports.Model = exports.Expression = void 0;
 const Expression_js_1 = require("./Expression.js");
 Object.defineProperty(exports, "Expression", { enumerable: true, get: function () { return Expression_js_1.Expression; } });
 const Model_js_1 = require("./Model.js");
@@ -16,7 +13,7 @@ Object.defineProperty(exports, "Table", { enumerable: true, get: function () { r
 const Error_js_1 = require("./Error.js");
 Object.defineProperty(exports, "OneTableError", { enumerable: true, get: function () { return Error_js_1.OneTableError; } });
 Object.defineProperty(exports, "OneTableArgError", { enumerable: true, get: function () { return Error_js_1.OneTableArgError; } });
-const ULID_js_1 = __importDefault(require("./ULID.js"));
-exports.ULID = ULID_js_1.default;
-const UUID_js_1 = __importDefault(require("./UUID.js"));
-exports.UUID = UUID_js_1.default;
+const UID_js_1 = require("./UID.js");
+Object.defineProperty(exports, "UID", { enumerable: true, get: function () { return UID_js_1.UID; } });
+Object.defineProperty(exports, "ULID", { enumerable: true, get: function () { return UID_js_1.ULID; } });
+Object.defineProperty(exports, "UUID", { enumerable: true, get: function () { return UID_js_1.UUID; } });
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/coverage/lcov-report/block-navigation.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/coverage/lcov-report/block-navigation.d.ts
new file mode 100644
index 0000000..a45a494
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/coverage/lcov-report/block-navigation.d.ts
@@ -0,0 +1 @@
+declare function jumpToCode(event: any): void;
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/coverage/lcov-report/block-navigation.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/coverage/lcov-report/block-navigation.js
new file mode 100644
index 0000000..0a8690c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/coverage/lcov-report/block-navigation.js
@@ -0,0 +1,69 @@
+/* eslint-disable */
+var jumpToCode = (function init() {
+    // Classes of code we would like to highlight in the file view
+    var missingCoverageClasses = ['.cbranch-no', '.cstat-no', '.fstat-no'];
+    // Elements to highlight in the file listing view
+    var fileListingElements = ['td.pct.low'];
+    // We don't want to select elements that are direct descendants of another match
+    var notSelector = ':not(' + missingCoverageClasses.join('):not(') + ') > '; // becomes `:not(a):not(b) > `
+    // Selecter that finds elements on the page to which we can jump
+    var selector = fileListingElements.join(', ') +
+        ', ' +
+        notSelector +
+        missingCoverageClasses.join(', ' + notSelector); // becomes `:not(a):not(b) > a, :not(a):not(b) > b`
+    // The NodeList of matching elements
+    var missingCoverageElements = document.querySelectorAll(selector);
+    var currentIndex;
+    function toggleClass(index) {
+        missingCoverageElements
+            .item(currentIndex)
+            .classList.remove('highlighted');
+        missingCoverageElements.item(index).classList.add('highlighted');
+    }
+    function makeCurrent(index) {
+        toggleClass(index);
+        currentIndex = index;
+        missingCoverageElements.item(index).scrollIntoView({
+            behavior: 'smooth',
+            block: 'center',
+            inline: 'center'
+        });
+    }
+    function goToPrevious() {
+        var nextIndex = 0;
+        if (typeof currentIndex !== 'number' || currentIndex === 0) {
+            nextIndex = missingCoverageElements.length - 1;
+        }
+        else if (missingCoverageElements.length > 1) {
+            nextIndex = currentIndex - 1;
+        }
+        makeCurrent(nextIndex);
+    }
+    function goToNext() {
+        var nextIndex = 0;
+        if (typeof currentIndex === 'number' &&
+            currentIndex < missingCoverageElements.length - 1) {
+            nextIndex = currentIndex + 1;
+        }
+        makeCurrent(nextIndex);
+    }
+    return function jump(event) {
+        if (document.getElementById('fileSearch') === document.activeElement &&
+            document.activeElement != null) {
+            // if we're currently focused on the search input, we don't want to navigate
+            return;
+        }
+        switch (event.which) {
+            case 78: // n
+            case 74: // j
+                goToNext();
+                break;
+            case 66: // b
+            case 75: // k
+            case 80: // p
+                goToPrevious();
+                break;
+        }
+    };
+})();
+window.addEventListener('keydown', jumpToCode);
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/coverage/lcov-report/prettify.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/coverage/lcov-report/prettify.d.ts
new file mode 100644
index 0000000..e69de29
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/coverage/lcov-report/prettify.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/coverage/lcov-report/prettify.js
new file mode 100644
index 0000000..a3666c8
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/coverage/lcov-report/prettify.js
@@ -0,0 +1,476 @@
+/* eslint-disable */
+window.PR_SHOULD_USE_CONTINUATION = true;
+(function () { var h = ["break,continue,do,else,for,if,return,while"]; var u = [h, "auto,case,char,const,default,double,enum,extern,float,goto,int,long,register,short,signed,sizeof,static,struct,switch,typedef,union,unsigned,void,volatile"]; var p = [u, "catch,class,delete,false,import,new,operator,private,protected,public,this,throw,true,try,typeof"]; var l = [p, "alignof,align_union,asm,axiom,bool,concept,concept_map,const_cast,constexpr,decltype,dynamic_cast,explicit,export,friend,inline,late_check,mutable,namespace,nullptr,reinterpret_cast,static_assert,static_cast,template,typeid,typename,using,virtual,where"]; var x = [p, "abstract,boolean,byte,extends,final,finally,implements,import,instanceof,null,native,package,strictfp,super,synchronized,throws,transient"]; var R = [x, "as,base,by,checked,decimal,delegate,descending,dynamic,event,fixed,foreach,from,group,implicit,in,interface,internal,into,is,lock,object,out,override,orderby,params,partial,readonly,ref,sbyte,sealed,stackalloc,string,select,uint,ulong,unchecked,unsafe,ushort,var"]; var r = "all,and,by,catch,class,else,extends,false,finally,for,if,in,is,isnt,loop,new,no,not,null,of,off,on,or,return,super,then,true,try,unless,until,when,while,yes"; var w = [p, "debugger,eval,export,function,get,null,set,undefined,var,with,Infinity,NaN"]; var s = "caller,delete,die,do,dump,elsif,eval,exit,foreach,for,goto,if,import,last,local,my,next,no,our,print,package,redo,require,sub,undef,unless,until,use,wantarray,while,BEGIN,END"; var I = [h, "and,as,assert,class,def,del,elif,except,exec,finally,from,global,import,in,is,lambda,nonlocal,not,or,pass,print,raise,try,with,yield,False,True,None"]; var f = [h, "alias,and,begin,case,class,def,defined,elsif,end,ensure,false,in,module,next,nil,not,or,redo,rescue,retry,self,super,then,true,undef,unless,until,when,yield,BEGIN,END"]; var H = [h, "case,done,elif,esac,eval,fi,function,in,local,set,then,until"]; var A = [l, R, w, s + I, f, H]; var e = /^(DIR|FILE|vector|(de|priority_)?queue|list|stack|(const_)?iterator|(multi)?(set|map)|bitset|u?(int|float)\d*)/; var C = "str"; var z = "kwd"; var j = "com"; var O = "typ"; var G = "lit"; var L = "pun"; var F = "pln"; var m = "tag"; var E = "dec"; var J = "src"; var P = "atn"; var n = "atv"; var N = "nocode"; var M = "(?:^^\\.?|[+-]|\\!|\\!=|\\!==|\\#|\\%|\\%=|&|&&|&&=|&=|\\(|\\*|\\*=|\\+=|\\,|\\-=|\\->|\\/|\\/=|:|::|\\;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\@|\\[|\\^|\\^=|\\^\\^|\\^\\^=|\\{|\\||\\|=|\\|\\||\\|\\|=|\\~|break|case|continue|delete|do|else|finally|instanceof|return|throw|try|typeof)\\s*"; function k(Z) { var ad = 0; var S = false; var ac = false; for (var V = 0, U = Z.length; V < U; ++V) {
+    var ae = Z[V];
+    if (ae.ignoreCase) {
+        ac = true;
+    }
+    else {
+        if (/[a-z]/i.test(ae.source.replace(/\\u[0-9a-f]{4}|\\x[0-9a-f]{2}|\\[^ux]/gi, ""))) {
+            S = true;
+            ac = false;
+            break;
+        }
+    }
+} var Y = { b: 8, t: 9, n: 10, v: 11, f: 12, r: 13 }; function ab(ah) { var ag = ah.charCodeAt(0); if (ag !== 92) {
+    return ag;
+} var af = ah.charAt(1); ag = Y[af]; if (ag) {
+    return ag;
+}
+else {
+    if ("0" <= af && af <= "7") {
+        return parseInt(ah.substring(1), 8);
+    }
+    else {
+        if (af === "u" || af === "x") {
+            return parseInt(ah.substring(2), 16);
+        }
+        else {
+            return ah.charCodeAt(1);
+        }
+    }
+} } function T(af) { if (af < 32) {
+    return (af < 16 ? "\\x0" : "\\x") + af.toString(16);
+} var ag = String.fromCharCode(af); if (ag === "\\" || ag === "-" || ag === "[" || ag === "]") {
+    ag = "\\" + ag;
+} return ag; } function X(am) { var aq = am.substring(1, am.length - 1).match(new RegExp("\\\\u[0-9A-Fa-f]{4}|\\\\x[0-9A-Fa-f]{2}|\\\\[0-3][0-7]{0,2}|\\\\[0-7]{1,2}|\\\\[\\s\\S]|-|[^-\\\\]", "g")); var ak = []; var af = []; var ao = aq[0] === "^"; for (var ar = ao ? 1 : 0, aj = aq.length; ar < aj; ++ar) {
+    var ah = aq[ar];
+    if (/\\[bdsw]/i.test(ah)) {
+        ak.push(ah);
+    }
+    else {
+        var ag = ab(ah);
+        var al;
+        if (ar + 2 < aj && "-" === aq[ar + 1]) {
+            al = ab(aq[ar + 2]);
+            ar += 2;
+        }
+        else {
+            al = ag;
+        }
+        af.push([ag, al]);
+        if (!(al < 65 || ag > 122)) {
+            if (!(al < 65 || ag > 90)) {
+                af.push([Math.max(65, ag) | 32, Math.min(al, 90) | 32]);
+            }
+            if (!(al < 97 || ag > 122)) {
+                af.push([Math.max(97, ag) & ~32, Math.min(al, 122) & ~32]);
+            }
+        }
+    }
+} af.sort(function (av, au) { return (av[0] - au[0]) || (au[1] - av[1]); }); var ai = []; var ap = [NaN, NaN]; for (var ar = 0; ar < af.length; ++ar) {
+    var at = af[ar];
+    if (at[0] <= ap[1] + 1) {
+        ap[1] = Math.max(ap[1], at[1]);
+    }
+    else {
+        ai.push(ap = at);
+    }
+} var an = ["["]; if (ao) {
+    an.push("^");
+} an.push.apply(an, ak); for (var ar = 0; ar < ai.length; ++ar) {
+    var at = ai[ar];
+    an.push(T(at[0]));
+    if (at[1] > at[0]) {
+        if (at[1] + 1 > at[0]) {
+            an.push("-");
+        }
+        an.push(T(at[1]));
+    }
+} an.push("]"); return an.join(""); } function W(al) { var aj = al.source.match(new RegExp("(?:\\[(?:[^\\x5C\\x5D]|\\\\[\\s\\S])*\\]|\\\\u[A-Fa-f0-9]{4}|\\\\x[A-Fa-f0-9]{2}|\\\\[0-9]+|\\\\[^ux0-9]|\\(\\?[:!=]|[\\(\\)\\^]|[^\\x5B\\x5C\\(\\)\\^]+)", "g")); var ah = aj.length; var an = []; for (var ak = 0, am = 0; ak < ah; ++ak) {
+    var ag = aj[ak];
+    if (ag === "(") {
+        ++am;
+    }
+    else {
+        if ("\\" === ag.charAt(0)) {
+            var af = +ag.substring(1);
+            if (af && af <= am) {
+                an[af] = -1;
+            }
+        }
+    }
+} for (var ak = 1; ak < an.length; ++ak) {
+    if (-1 === an[ak]) {
+        an[ak] = ++ad;
+    }
+} for (var ak = 0, am = 0; ak < ah; ++ak) {
+    var ag = aj[ak];
+    if (ag === "(") {
+        ++am;
+        if (an[am] === undefined) {
+            aj[ak] = "(?:";
+        }
+    }
+    else {
+        if ("\\" === ag.charAt(0)) {
+            var af = +ag.substring(1);
+            if (af && af <= am) {
+                aj[ak] = "\\" + an[am];
+            }
+        }
+    }
+} for (var ak = 0, am = 0; ak < ah; ++ak) {
+    if ("^" === aj[ak] && "^" !== aj[ak + 1]) {
+        aj[ak] = "";
+    }
+} if (al.ignoreCase && S) {
+    for (var ak = 0; ak < ah; ++ak) {
+        var ag = aj[ak];
+        var ai = ag.charAt(0);
+        if (ag.length >= 2 && ai === "[") {
+            aj[ak] = X(ag);
+        }
+        else {
+            if (ai !== "\\") {
+                aj[ak] = ag.replace(/[a-zA-Z]/g, function (ao) { var ap = ao.charCodeAt(0); return "[" + String.fromCharCode(ap & ~32, ap | 32) + "]"; });
+            }
+        }
+    }
+} return aj.join(""); } var aa = []; for (var V = 0, U = Z.length; V < U; ++V) {
+    var ae = Z[V];
+    if (ae.global || ae.multiline) {
+        throw new Error("" + ae);
+    }
+    aa.push("(?:" + W(ae) + ")");
+} return new RegExp(aa.join("|"), ac ? "gi" : "g"); } function a(V) { var U = /(?:^|\s)nocode(?:\s|$)/; var X = []; var T = 0; var Z = []; var W = 0; var S; if (V.currentStyle) {
+    S = V.currentStyle.whiteSpace;
+}
+else {
+    if (window.getComputedStyle) {
+        S = document.defaultView.getComputedStyle(V, null).getPropertyValue("white-space");
+    }
+} var Y = S && "pre" === S.substring(0, 3); function aa(ab) { switch (ab.nodeType) {
+    case 1:
+        if (U.test(ab.className)) {
+            return;
+        }
+        for (var ae = ab.firstChild; ae; ae = ae.nextSibling) {
+            aa(ae);
+        }
+        var ad = ab.nodeName;
+        if ("BR" === ad || "LI" === ad) {
+            X[W] = "\n";
+            Z[W << 1] = T++;
+            Z[(W++ << 1) | 1] = ab;
+        }
+        break;
+    case 3:
+    case 4:
+        var ac = ab.nodeValue;
+        if (ac.length) {
+            if (!Y) {
+                ac = ac.replace(/[ \t\r\n]+/g, " ");
+            }
+            else {
+                ac = ac.replace(/\r\n?/g, "\n");
+            }
+            X[W] = ac;
+            Z[W << 1] = T;
+            T += ac.length;
+            Z[(W++ << 1) | 1] = ab;
+        }
+        break;
+} } aa(V); return { sourceCode: X.join("").replace(/\n$/, ""), spans: Z }; } function B(S, U, W, T) { if (!U) {
+    return;
+} var V = { sourceCode: U, basePos: S }; W(V); T.push.apply(T, V.decorations); } var v = /\S/; function o(S) { var V = undefined; for (var U = S.firstChild; U; U = U.nextSibling) {
+    var T = U.nodeType;
+    V = (T === 1) ? (V ? S : U) : (T === 3) ? (v.test(U.nodeValue) ? S : V) : V;
+} return V === S ? undefined : V; } function g(U, T) { var S = {}; var V; (function () { var ad = U.concat(T); var ah = []; var ag = {}; for (var ab = 0, Z = ad.length; ab < Z; ++ab) {
+    var Y = ad[ab];
+    var ac = Y[3];
+    if (ac) {
+        for (var ae = ac.length; --ae >= 0;) {
+            S[ac.charAt(ae)] = Y;
+        }
+    }
+    var af = Y[1];
+    var aa = "" + af;
+    if (!ag.hasOwnProperty(aa)) {
+        ah.push(af);
+        ag[aa] = null;
+    }
+} ah.push(/[\0-\uffff]/); V = k(ah); })(); var X = T.length; var W = function (ah) { var Z = ah.sourceCode, Y = ah.basePos; var ad = [Y, F]; var af = 0; var an = Z.match(V) || []; var aj = {}; for (var ae = 0, aq = an.length; ae < aq; ++ae) {
+    var ag = an[ae];
+    var ap = aj[ag];
+    var ai = void 0;
+    var am;
+    if (typeof ap === "string") {
+        am = false;
+    }
+    else {
+        var aa = S[ag.charAt(0)];
+        if (aa) {
+            ai = ag.match(aa[1]);
+            ap = aa[0];
+        }
+        else {
+            for (var ao = 0; ao < X; ++ao) {
+                aa = T[ao];
+                ai = ag.match(aa[1]);
+                if (ai) {
+                    ap = aa[0];
+                    break;
+                }
+            }
+            if (!ai) {
+                ap = F;
+            }
+        }
+        am = ap.length >= 5 && "lang-" === ap.substring(0, 5);
+        if (am && !(ai && typeof ai[1] === "string")) {
+            am = false;
+            ap = J;
+        }
+        if (!am) {
+            aj[ag] = ap;
+        }
+    }
+    var ab = af;
+    af += ag.length;
+    if (!am) {
+        ad.push(Y + ab, ap);
+    }
+    else {
+        var al = ai[1];
+        var ak = ag.indexOf(al);
+        var ac = ak + al.length;
+        if (ai[2]) {
+            ac = ag.length - ai[2].length;
+            ak = ac - al.length;
+        }
+        var ar = ap.substring(5);
+        B(Y + ab, ag.substring(0, ak), W, ad);
+        B(Y + ab + ak, al, q(ar, al), ad);
+        B(Y + ab + ac, ag.substring(ac), W, ad);
+    }
+} ah.decorations = ad; }; return W; } function i(T) { var W = [], S = []; if (T.tripleQuotedStrings) {
+    W.push([C, /^(?:\'\'\'(?:[^\'\\]|\\[\s\S]|\'{1,2}(?=[^\']))*(?:\'\'\'|$)|\"\"\"(?:[^\"\\]|\\[\s\S]|\"{1,2}(?=[^\"]))*(?:\"\"\"|$)|\'(?:[^\\\']|\\[\s\S])*(?:\'|$)|\"(?:[^\\\"]|\\[\s\S])*(?:\"|$))/, null, "'\""]);
+}
+else {
+    if (T.multiLineStrings) {
+        W.push([C, /^(?:\'(?:[^\\\']|\\[\s\S])*(?:\'|$)|\"(?:[^\\\"]|\\[\s\S])*(?:\"|$)|\`(?:[^\\\`]|\\[\s\S])*(?:\`|$))/, null, "'\"`"]);
+    }
+    else {
+        W.push([C, /^(?:\'(?:[^\\\'\r\n]|\\.)*(?:\'|$)|\"(?:[^\\\"\r\n]|\\.)*(?:\"|$))/, null, "\"'"]);
+    }
+} if (T.verbatimStrings) {
+    S.push([C, /^@\"(?:[^\"]|\"\")*(?:\"|$)/, null]);
+} var Y = T.hashComments; if (Y) {
+    if (T.cStyleComments) {
+        if (Y > 1) {
+            W.push([j, /^#(?:##(?:[^#]|#(?!##))*(?:###|$)|.*)/, null, "#"]);
+        }
+        else {
+            W.push([j, /^#(?:(?:define|elif|else|endif|error|ifdef|include|ifndef|line|pragma|undef|warning)\b|[^\r\n]*)/, null, "#"]);
+        }
+        S.push([C, /^<(?:(?:(?:\.\.\/)*|\/?)(?:[\w-]+(?:\/[\w-]+)+)?[\w-]+\.h|[a-z]\w*)>/, null]);
+    }
+    else {
+        W.push([j, /^#[^\r\n]*/, null, "#"]);
+    }
+} if (T.cStyleComments) {
+    S.push([j, /^\/\/[^\r\n]*/, null]);
+    S.push([j, /^\/\*[\s\S]*?(?:\*\/|$)/, null]);
+} if (T.regexLiterals) {
+    var X = ("/(?=[^/*])(?:[^/\\x5B\\x5C]|\\x5C[\\s\\S]|\\x5B(?:[^\\x5C\\x5D]|\\x5C[\\s\\S])*(?:\\x5D|$))+/");
+    S.push(["lang-regex", new RegExp("^" + M + "(" + X + ")")]);
+} var V = T.types; if (V) {
+    S.push([O, V]);
+} var U = ("" + T.keywords).replace(/^ | $/g, ""); if (U.length) {
+    S.push([z, new RegExp("^(?:" + U.replace(/[\s,]+/g, "|") + ")\\b"), null]);
+} W.push([F, /^\s+/, null, " \r\n\t\xA0"]); S.push([G, /^@[a-z_$][a-z_$@0-9]*/i, null], [O, /^(?:[@_]?[A-Z]+[a-z][A-Za-z_$@0-9]*|\w+_t\b)/, null], [F, /^[a-z_$][a-z_$@0-9]*/i, null], [G, new RegExp("^(?:0x[a-f0-9]+|(?:\\d(?:_\\d+)*\\d*(?:\\.\\d*)?|\\.\\d\\+)(?:e[+\\-]?\\d+)?)[a-z]*", "i"), null, "0123456789"], [F, /^\\[\s\S]?/, null], [L, /^.[^\s\w\.$@\'\"\`\/\#\\]*/, null]); return g(W, S); } var K = i({ keywords: A, hashComments: true, cStyleComments: true, multiLineStrings: true, regexLiterals: true }); function Q(V, ag) { var U = /(?:^|\s)nocode(?:\s|$)/; var ab = /\r\n?|\n/; var ac = V.ownerDocument; var S; if (V.currentStyle) {
+    S = V.currentStyle.whiteSpace;
+}
+else {
+    if (window.getComputedStyle) {
+        S = ac.defaultView.getComputedStyle(V, null).getPropertyValue("white-space");
+    }
+} var Z = S && "pre" === S.substring(0, 3); var af = ac.createElement("LI"); while (V.firstChild) {
+    af.appendChild(V.firstChild);
+} var W = [af]; function ae(al) { switch (al.nodeType) {
+    case 1:
+        if (U.test(al.className)) {
+            break;
+        }
+        if ("BR" === al.nodeName) {
+            ad(al);
+            if (al.parentNode) {
+                al.parentNode.removeChild(al);
+            }
+        }
+        else {
+            for (var an = al.firstChild; an; an = an.nextSibling) {
+                ae(an);
+            }
+        }
+        break;
+    case 3:
+    case 4:
+        if (Z) {
+            var am = al.nodeValue;
+            var aj = am.match(ab);
+            if (aj) {
+                var ai = am.substring(0, aj.index);
+                al.nodeValue = ai;
+                var ah = am.substring(aj.index + aj[0].length);
+                if (ah) {
+                    var ak = al.parentNode;
+                    ak.insertBefore(ac.createTextNode(ah), al.nextSibling);
+                }
+                ad(al);
+                if (!ai) {
+                    al.parentNode.removeChild(al);
+                }
+            }
+        }
+        break;
+} } function ad(ak) { while (!ak.nextSibling) {
+    ak = ak.parentNode;
+    if (!ak) {
+        return;
+    }
+} function ai(al, ar) { var aq = ar ? al.cloneNode(false) : al; var ao = al.parentNode; if (ao) {
+    var ap = ai(ao, 1);
+    var an = al.nextSibling;
+    ap.appendChild(aq);
+    for (var am = an; am; am = an) {
+        an = am.nextSibling;
+        ap.appendChild(am);
+    }
+} return aq; } var ah = ai(ak.nextSibling, 0); for (var aj; (aj = ah.parentNode) && aj.nodeType === 1;) {
+    ah = aj;
+} W.push(ah); } for (var Y = 0; Y < W.length; ++Y) {
+    ae(W[Y]);
+} if (ag === (ag | 0)) {
+    W[0].setAttribute("value", ag);
+} var aa = ac.createElement("OL"); aa.className = "linenums"; var X = Math.max(0, ((ag - 1)) | 0) || 0; for (var Y = 0, T = W.length; Y < T; ++Y) {
+    af = W[Y];
+    af.className = "L" + ((Y + X) % 10);
+    if (!af.firstChild) {
+        af.appendChild(ac.createTextNode("\xA0"));
+    }
+    aa.appendChild(af);
+} V.appendChild(aa); } function D(ac) { var aj = /\bMSIE\b/.test(navigator.userAgent); var am = /\n/g; var al = ac.sourceCode; var an = al.length; var V = 0; var aa = ac.spans; var T = aa.length; var ah = 0; var X = ac.decorations; var Y = X.length; var Z = 0; X[Y] = an; var ar, aq; for (aq = ar = 0; aq < Y;) {
+    if (X[aq] !== X[aq + 2]) {
+        X[ar++] = X[aq++];
+        X[ar++] = X[aq++];
+    }
+    else {
+        aq += 2;
+    }
+} Y = ar; for (aq = ar = 0; aq < Y;) {
+    var at = X[aq];
+    var ab = X[aq + 1];
+    var W = aq + 2;
+    while (W + 2 <= Y && X[W + 1] === ab) {
+        W += 2;
+    }
+    X[ar++] = at;
+    X[ar++] = ab;
+    aq = W;
+} Y = X.length = ar; var ae = null; while (ah < T) {
+    var af = aa[ah];
+    var S = aa[ah + 2] || an;
+    var ag = X[Z];
+    var ap = X[Z + 2] || an;
+    var W = Math.min(S, ap);
+    var ak = aa[ah + 1];
+    var U;
+    if (ak.nodeType !== 1 && (U = al.substring(V, W))) {
+        if (aj) {
+            U = U.replace(am, "\r");
+        }
+        ak.nodeValue = U;
+        var ai = ak.ownerDocument;
+        var ao = ai.createElement("SPAN");
+        ao.className = X[Z + 1];
+        var ad = ak.parentNode;
+        ad.replaceChild(ao, ak);
+        ao.appendChild(ak);
+        if (V < S) {
+            aa[ah + 1] = ak = ai.createTextNode(al.substring(W, S));
+            ad.insertBefore(ak, ao.nextSibling);
+        }
+    }
+    V = W;
+    if (V >= S) {
+        ah += 2;
+    }
+    if (V >= ap) {
+        Z += 2;
+    }
+} } var t = {}; function c(U, V) { for (var S = V.length; --S >= 0;) {
+    var T = V[S];
+    if (!t.hasOwnProperty(T)) {
+        t[T] = U;
+    }
+    else {
+        if (window.console) {
+            console.warn("cannot override language handler %s", T);
+        }
+    }
+} } function q(T, S) { if (!(T && t.hasOwnProperty(T))) {
+    T = /^\s*</.test(S) ? "default-markup" : "default-code";
+} return t[T]; } c(K, ["default-code"]); c(g([], [[F, /^[^<?]+/], [E, /^<!\w[^>]*(?:>|$)/], [j, /^<\!--[\s\S]*?(?:-\->|$)/], ["lang-", /^<\?([\s\S]+?)(?:\?>|$)/], ["lang-", /^<%([\s\S]+?)(?:%>|$)/], [L, /^(?:<[%?]|[%?]>)/], ["lang-", /^<xmp\b[^>]*>([\s\S]+?)<\/xmp\b[^>]*>/i], ["lang-js", /^<script\b[^>]*>([\s\S]*?)(<\/script\b[^>]*>)/i], ["lang-css", /^<style\b[^>]*>([\s\S]*?)(<\/style\b[^>]*>)/i], ["lang-in.tag", /^(<\/?[a-z][^<>]*>)/i]]), ["default-markup", "htm", "html", "mxml", "xhtml", "xml", "xsl"]); c(g([[F, /^[\s]+/, null, " \t\r\n"], [n, /^(?:\"[^\"]*\"?|\'[^\']*\'?)/, null, "\"'"]], [[m, /^^<\/?[a-z](?:[\w.:-]*\w)?|\/?>$/i], [P, /^(?!style[\s=]|on)[a-z](?:[\w:-]*\w)?/i], ["lang-uq.val", /^=\s*([^>\'\"\s]*(?:[^>\'\"\s\/]|\/(?=\s)))/], [L, /^[=<>\/]+/], ["lang-js", /^on\w+\s*=\s*\"([^\"]+)\"/i], ["lang-js", /^on\w+\s*=\s*\'([^\']+)\'/i], ["lang-js", /^on\w+\s*=\s*([^\"\'>\s]+)/i], ["lang-css", /^style\s*=\s*\"([^\"]+)\"/i], ["lang-css", /^style\s*=\s*\'([^\']+)\'/i], ["lang-css", /^style\s*=\s*([^\"\'>\s]+)/i]]), ["in.tag"]); c(g([], [[n, /^[\s\S]+/]]), ["uq.val"]); c(i({ keywords: l, hashComments: true, cStyleComments: true, types: e }), ["c", "cc", "cpp", "cxx", "cyc", "m"]); c(i({ keywords: "null,true,false" }), ["json"]); c(i({ keywords: R, hashComments: true, cStyleComments: true, verbatimStrings: true, types: e }), ["cs"]); c(i({ keywords: x, cStyleComments: true }), ["java"]); c(i({ keywords: H, hashComments: true, multiLineStrings: true }), ["bsh", "csh", "sh"]); c(i({ keywords: I, hashComments: true, multiLineStrings: true, tripleQuotedStrings: true }), ["cv", "py"]); c(i({ keywords: s, hashComments: true, multiLineStrings: true, regexLiterals: true }), ["perl", "pl", "pm"]); c(i({ keywords: f, hashComments: true, multiLineStrings: true, regexLiterals: true }), ["rb"]); c(i({ keywords: w, cStyleComments: true, regexLiterals: true }), ["js"]); c(i({ keywords: r, hashComments: 3, cStyleComments: true, multilineStrings: true, tripleQuotedStrings: true, regexLiterals: true }), ["coffee"]); c(g([], [[C, /^[\s\S]+/]]), ["regex"]); function d(V) { var U = V.langExtension; try {
+    var S = a(V.sourceNode);
+    var T = S.sourceCode;
+    V.sourceCode = T;
+    V.spans = S.spans;
+    V.basePos = 0;
+    q(U, T)(V);
+    D(V);
+}
+catch (W) {
+    if ("console" in window) {
+        console.log(W && W.stack ? W.stack : W);
+    }
+} } function y(W, V, U) { var S = document.createElement("PRE"); S.innerHTML = W; if (U) {
+    Q(S, U);
+} var T = { langExtension: V, numberLines: U, sourceNode: S }; d(T); return S.innerHTML; } function b(ad) { function Y(af) { return document.getElementsByTagName(af); } var ac = [Y("pre"), Y("code"), Y("xmp")]; var T = []; for (var aa = 0; aa < ac.length; ++aa) {
+    for (var Z = 0, V = ac[aa].length; Z < V; ++Z) {
+        T.push(ac[aa][Z]);
+    }
+} ac = null; var W = Date; if (!W.now) {
+    W = { now: function () { return +(new Date); } };
+} var X = 0; var S; var ab = /\blang(?:uage)?-([\w.]+)(?!\S)/; var ae = /\bprettyprint\b/; function U() { var ag = (window.PR_SHOULD_USE_CONTINUATION ? W.now() + 250 : Infinity); for (; X < T.length && W.now() < ag; X++) {
+    var aj = T[X];
+    var ai = aj.className;
+    if (ai.indexOf("prettyprint") >= 0) {
+        var ah = ai.match(ab);
+        var am;
+        if (!ah && (am = o(aj)) && "CODE" === am.tagName) {
+            ah = am.className.match(ab);
+        }
+        if (ah) {
+            ah = ah[1];
+        }
+        var al = false;
+        for (var ak = aj.parentNode; ak; ak = ak.parentNode) {
+            if ((ak.tagName === "pre" || ak.tagName === "code" || ak.tagName === "xmp") && ak.className && ak.className.indexOf("prettyprint") >= 0) {
+                al = true;
+                break;
+            }
+        }
+        if (!al) {
+            var af = aj.className.match(/\blinenums\b(?::(\d+))?/);
+            af = af ? af[1] && af[1].length ? +af[1] : true : false;
+            if (af) {
+                Q(aj, af);
+            }
+            S = { langExtension: ah, sourceNode: aj, numberLines: af };
+            d(S);
+        }
+    }
+} if (X < T.length) {
+    setTimeout(U, 250);
+}
+else {
+    if (ad) {
+        ad();
+    }
+} } U(); } window.prettyPrintOne = y; window.prettyPrint = b; window.PR = { createSimpleLexer: g, registerLangHandler: c, sourceDecorator: i, PR_ATTRIB_NAME: P, PR_ATTRIB_VALUE: n, PR_COMMENT: j, PR_DECLARATION: E, PR_KEYWORD: z, PR_LITERAL: G, PR_NOCODE: N, PR_PLAIN: F, PR_PUNCTUATION: L, PR_SOURCE: J, PR_STRING: C, PR_TAG: m, PR_TYPE: O }; })();
+PR.registerLangHandler(PR.createSimpleLexer([], [[PR.PR_DECLARATION, /^<!\w[^>]*(?:>|$)/], [PR.PR_COMMENT, /^<\!--[\s\S]*?(?:-\->|$)/], [PR.PR_PUNCTUATION, /^(?:<[%?]|[%?]>)/], ["lang-", /^<\?([\s\S]+?)(?:\?>|$)/], ["lang-", /^<%([\s\S]+?)(?:%>|$)/], ["lang-", /^<xmp\b[^>]*>([\s\S]+?)<\/xmp\b[^>]*>/i], ["lang-handlebars", /^<script\b[^>]*type\s*=\s*['"]?text\/x-handlebars-template['"]?\b[^>]*>([\s\S]*?)(<\/script\b[^>]*>)/i], ["lang-js", /^<script\b[^>]*>([\s\S]*?)(<\/script\b[^>]*>)/i], ["lang-css", /^<style\b[^>]*>([\s\S]*?)(<\/style\b[^>]*>)/i], ["lang-in.tag", /^(<\/?[a-z][^<>]*>)/i], [PR.PR_DECLARATION, /^{{[#^>/]?\s*[\w.][^}]*}}/], [PR.PR_DECLARATION, /^{{&?\s*[\w.][^}]*}}/], [PR.PR_DECLARATION, /^{{{>?\s*[\w.][^}]*}}}/], [PR.PR_COMMENT, /^{{![^}]*}}/]]), ["handlebars", "hbs"]);
+PR.registerLangHandler(PR.createSimpleLexer([[PR.PR_PLAIN, /^[ \t\r\n\f]+/, null, " \t\r\n\f"]], [[PR.PR_STRING, /^\"(?:[^\n\r\f\\\"]|\\(?:\r\n?|\n|\f)|\\[\s\S])*\"/, null], [PR.PR_STRING, /^\'(?:[^\n\r\f\\\']|\\(?:\r\n?|\n|\f)|\\[\s\S])*\'/, null], ["lang-css-str", /^url\(([^\)\"\']*)\)/i], [PR.PR_KEYWORD, /^(?:url|rgb|\!important|@import|@page|@media|@charset|inherit)(?=[^\-\w]|$)/i, null], ["lang-css-kw", /^(-?(?:[_a-z]|(?:\\[0-9a-f]+ ?))(?:[_a-z0-9\-]|\\(?:\\[0-9a-f]+ ?))*)\s*:/i], [PR.PR_COMMENT, /^\/\*[^*]*\*+(?:[^\/*][^*]*\*+)*\//], [PR.PR_COMMENT, /^(?:<!--|-->)/], [PR.PR_LITERAL, /^(?:\d+|\d*\.\d+)(?:%|[a-z]+)?/i], [PR.PR_LITERAL, /^#(?:[0-9a-f]{3}){1,2}/i], [PR.PR_PLAIN, /^-?(?:[_a-z]|(?:\\[\da-f]+ ?))(?:[_a-z\d\-]|\\(?:\\[\da-f]+ ?))*/i], [PR.PR_PUNCTUATION, /^[^\s\w\'\"]+/]]), ["css"]);
+PR.registerLangHandler(PR.createSimpleLexer([], [[PR.PR_KEYWORD, /^-?(?:[_a-z]|(?:\\[\da-f]+ ?))(?:[_a-z\d\-]|\\(?:\\[\da-f]+ ?))*/i]]), ["css-kw"]);
+PR.registerLangHandler(PR.createSimpleLexer([], [[PR.PR_STRING, /^[^\)\"\']+/]]), ["css-str"]);
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/coverage/lcov-report/sorter.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/coverage/lcov-report/sorter.d.ts
new file mode 100644
index 0000000..a49797a
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/coverage/lcov-report/sorter.d.ts
@@ -0,0 +1 @@
+declare function addSorting(): void;
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/coverage/lcov-report/sorter.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/coverage/lcov-report/sorter.js
new file mode 100644
index 0000000..c6f2213
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/coverage/lcov-report/sorter.js
@@ -0,0 +1,162 @@
+/* eslint-disable */
+var addSorting = (function () {
+    'use strict';
+    var cols, currentSort = {
+        index: 0,
+        desc: false
+    };
+    // returns the summary table element
+    function getTable() {
+        return document.querySelector('.coverage-summary');
+    }
+    // returns the thead element of the summary table
+    function getTableHeader() {
+        return getTable().querySelector('thead tr');
+    }
+    // returns the tbody element of the summary table
+    function getTableBody() {
+        return getTable().querySelector('tbody');
+    }
+    // returns the th element for nth column
+    function getNthColumn(n) {
+        return getTableHeader().querySelectorAll('th')[n];
+    }
+    function onFilterInput() {
+        const searchValue = document.getElementById('fileSearch').value;
+        const rows = document.getElementsByTagName('tbody')[0].children;
+        for (let i = 0; i < rows.length; i++) {
+            const row = rows[i];
+            if (row.textContent
+                .toLowerCase()
+                .includes(searchValue.toLowerCase())) {
+                row.style.display = '';
+            }
+            else {
+                row.style.display = 'none';
+            }
+        }
+    }
+    // loads the search box
+    function addSearchBox() {
+        var template = document.getElementById('filterTemplate');
+        var templateClone = template.content.cloneNode(true);
+        templateClone.getElementById('fileSearch').oninput = onFilterInput;
+        template.parentElement.appendChild(templateClone);
+    }
+    // loads all columns
+    function loadColumns() {
+        var colNodes = getTableHeader().querySelectorAll('th'), colNode, cols = [], col, i;
+        for (i = 0; i < colNodes.length; i += 1) {
+            colNode = colNodes[i];
+            col = {
+                key: colNode.getAttribute('data-col'),
+                sortable: !colNode.getAttribute('data-nosort'),
+                type: colNode.getAttribute('data-type') || 'string'
+            };
+            cols.push(col);
+            if (col.sortable) {
+                col.defaultDescSort = col.type === 'number';
+                colNode.innerHTML =
+                    colNode.innerHTML + '<span class="sorter"></span>';
+            }
+        }
+        return cols;
+    }
+    // attaches a data attribute to every tr element with an object
+    // of data values keyed by column name
+    function loadRowData(tableRow) {
+        var tableCols = tableRow.querySelectorAll('td'), colNode, col, data = {}, i, val;
+        for (i = 0; i < tableCols.length; i += 1) {
+            colNode = tableCols[i];
+            col = cols[i];
+            val = colNode.getAttribute('data-value');
+            if (col.type === 'number') {
+                val = Number(val);
+            }
+            data[col.key] = val;
+        }
+        return data;
+    }
+    // loads all row data
+    function loadData() {
+        var rows = getTableBody().querySelectorAll('tr'), i;
+        for (i = 0; i < rows.length; i += 1) {
+            rows[i].data = loadRowData(rows[i]);
+        }
+    }
+    // sorts the table using the data for the ith column
+    function sortByIndex(index, desc) {
+        var key = cols[index].key, sorter = function (a, b) {
+            a = a.data[key];
+            b = b.data[key];
+            return a < b ? -1 : a > b ? 1 : 0;
+        }, finalSorter = sorter, tableBody = document.querySelector('.coverage-summary tbody'), rowNodes = tableBody.querySelectorAll('tr'), rows = [], i;
+        if (desc) {
+            finalSorter = function (a, b) {
+                return -1 * sorter(a, b);
+            };
+        }
+        for (i = 0; i < rowNodes.length; i += 1) {
+            rows.push(rowNodes[i]);
+            tableBody.removeChild(rowNodes[i]);
+        }
+        rows.sort(finalSorter);
+        for (i = 0; i < rows.length; i += 1) {
+            tableBody.appendChild(rows[i]);
+        }
+    }
+    // removes sort indicators for current column being sorted
+    function removeSortIndicators() {
+        var col = getNthColumn(currentSort.index), cls = col.className;
+        cls = cls.replace(/ sorted$/, '').replace(/ sorted-desc$/, '');
+        col.className = cls;
+    }
+    // adds sort indicators for current column being sorted
+    function addSortIndicators() {
+        getNthColumn(currentSort.index).className += currentSort.desc
+            ? ' sorted-desc'
+            : ' sorted';
+    }
+    // adds event listeners for all sorter widgets
+    function enableUI() {
+        var i, el, ithSorter = function ithSorter(i) {
+            var col = cols[i];
+            return function () {
+                var desc = col.defaultDescSort;
+                if (currentSort.index === i) {
+                    desc = !currentSort.desc;
+                }
+                sortByIndex(i, desc);
+                removeSortIndicators();
+                currentSort.index = i;
+                currentSort.desc = desc;
+                addSortIndicators();
+            };
+        };
+        for (i = 0; i < cols.length; i += 1) {
+            if (cols[i].sortable) {
+                // add the click event handler on the th so users
+                // dont have to click on those tiny arrows
+                el = getNthColumn(i).querySelector('.sorter').parentElement;
+                if (el.addEventListener) {
+                    el.addEventListener('click', ithSorter(i));
+                }
+                else {
+                    el.attachEvent('onclick', ithSorter(i));
+                }
+            }
+        }
+    }
+    // adds sorting functionality to the UI
+    return function () {
+        if (!getTable()) {
+            return;
+        }
+        cols = loadColumns();
+        loadData();
+        addSearchBox();
+        addSortIndicators();
+        enableUI();
+    };
+})();
+window.addEventListener('load', addSorting);
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/dist/cjs/index.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/dist/cjs/index.d.ts
new file mode 100644
index 0000000..bcb27f3
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/dist/cjs/index.d.ts
@@ -0,0 +1,174 @@
+export const __esModule: boolean;
+export const DefaultSpans: {
+    period: number;
+    samples: number;
+}[];
+export class CustomMetrics {
+    static terminate(): Promise<void>;
+    static flushAll(): Promise<void>;
+    static freeInstanceByKey(key: any): void;
+    static saveInstance(tags: any, metrics: any): void;
+    constructor(options?: {});
+    consistent: any;
+    buffers: any;
+    prefix: any;
+    log: Log;
+    buffer: any;
+    expires: any;
+    primaryKey: any;
+    sortKey: any;
+    type: any;
+    client: any;
+    table: any;
+    options: {};
+    owner: any;
+    spans: any;
+    ttl: any;
+    source: any;
+    pResolution: any;
+    emit(namespace: any, metricName: any, value: any, dimensionsList?: {}[], options?: {}): Promise<any>;
+    emitDimensions(namespace: any, metricName: any, point: any, dimensionsList: any, options: any): Promise<any>;
+    bufferMetric(namespace: any, metricName: any, point: any, dimensions: any, options: any): Promise<any>;
+    emitDimensionedMetric(namespace: any, metricName: any, point: any, dimensions: any, options?: {}): Promise<any>;
+    upgrade(namespace: any, metricName: any, dimensionsList?: {}[], options?: {}): Promise<any>;
+    upgradeMetric(old: any): any;
+    flush(): Promise<void>;
+    flushElt(elt: any, timestamp: any): Promise<void>;
+    getBufferKey(namespace: any, metricName: any, dimensions: any): string;
+    query(namespace: any, metricName: any, dimensions: any, period: any, statistic: any, options?: {}): Promise<{
+        dimensions: {};
+        metric: any;
+        namespace: any;
+        owner: any;
+        period: any;
+        points: {
+            value: number;
+            timestamp: any;
+            count: number;
+        }[];
+        samples: any;
+    } | {
+        dimensions: {};
+        metric: any;
+        namespace: any;
+        period: any;
+        points: {
+            value: any;
+            count: any;
+            timestamp: number;
+        }[];
+        owner: any;
+        samples: any;
+    } | {
+        dimensions: any;
+        id: any;
+        metric: any;
+        namespace: any;
+        period: any;
+        points: any[];
+        owner: any;
+        samples: number;
+    }>;
+    accumulateMetric(metric: any, span: any, statistic: any, owner: any, start: any, period: any): {
+        dimensions: {};
+        metric: any;
+        namespace: any;
+        owner: any;
+        period: any;
+        points: {
+            value: number;
+            timestamp: any;
+            count: number;
+        }[];
+        samples: any;
+    };
+    calculateSeries(metric: any, span: any, statistic: any, owner: any, start: any, period: any): {
+        dimensions: {};
+        metric: any;
+        namespace: any;
+        period: any;
+        points: {
+            value: any;
+            count: any;
+            timestamp: number;
+        }[];
+        owner: any;
+        samples: any;
+    };
+    makeDimensionString(dimensions: any): string;
+    makeDimensionObject(dimensions: any): {};
+    addValue(metric: any, timestamp: any, point: any, si: any, querySpanIndex?: any): void;
+    setPoint(span: any, index: any, add: any): void;
+    getMetricList(namespace?: any, metric?: any, options?: {
+        limit: number;
+    }): Promise<{
+        namespaces: string[];
+    }>;
+    initMetric(owner: any, namespace: any, name: any, dimensions: any, timestamp: any): {
+        dimensions: any;
+        metric: any;
+        namespace: any;
+        owner: any;
+        spans: any[];
+        version: number;
+    };
+    getMetric(owner: any, namespace: any, metric: any, dimensions: any, log: any): Promise<{
+        dimensions: any;
+        expires: any;
+        metric: any;
+        namespace: any;
+        owner: any;
+        seq: any;
+        spans: any;
+    }>;
+    findMetrics(owner: any, namespace: any, metric: any, limit: any, startKey: any): Promise<{
+        items: {
+            dimensions: any;
+            expires: any;
+            metric: any;
+            namespace: any;
+            owner: any;
+            seq: any;
+            spans: any;
+        }[];
+        next: Record<string, any>;
+        command: client_dynamodb_1.QueryCommand;
+    }>;
+    putMetric(item: any, options: any): Promise<boolean>;
+    mapItemFromDB(data: any): {
+        dimensions: any;
+        expires: any;
+        metric: any;
+        namespace: any;
+        owner: any;
+        seq: any;
+        spans: any;
+    };
+    mapItemToDB(item: any): {
+        [x: number]: any;
+        spans: any;
+        seq: any;
+        _source: any;
+    };
+    roundTime(span: any, timestamp: any): number;
+    assert(c: any): void;
+    info(message: any, context?: {}): void;
+    error(message: any, context?: {}): void;
+    trace(message: any, context?: {}): void;
+    round(n: any): number;
+    jitter(msecs: any): number;
+    delay(time: any): Promise<any>;
+}
+declare class Log {
+    constructor(dest: any);
+    senselogs: any;
+    logger: (chan: any, message: any, context: any) => void;
+    verbose: boolean;
+    error(message: any, context: any): void;
+    info(message: any, context: any): void;
+    trace(message: any, context: any): void;
+    process(chan: any, message: any, context: any): void;
+    defaultLogger(chan: any, message: any, context: any): void;
+}
+import client_dynamodb_1 = require("@aws-sdk/client-dynamodb");
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/dist/cjs/index.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/dist/cjs/index.js
new file mode 100644
index 0000000..7e8b515
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/dist/cjs/index.js
@@ -0,0 +1,982 @@
+"use strict";
+var __importDefault = (this && this.__importDefault) || function (mod) {
+    return (mod && mod.__esModule) ? mod : { "default": mod };
+};
+Object.defineProperty(exports, "__esModule", { value: true });
+exports.CustomMetrics = exports.DefaultSpans = void 0;
+const process_1 = __importDefault(require("process"));
+const client_dynamodb_1 = require("@aws-sdk/client-dynamodb");
+const util_dynamodb_1 = require("@aws-sdk/util-dynamodb");
+const Version = 1;
+const Assert = true;
+const Buffering = true;
+const DefaultResolution = 0;
+const MaxSeq = Number.MAX_SAFE_INTEGER;
+const MaxRetries = 10;
+const MetricListLimit = 10000;
+exports.DefaultSpans = [
+    { period: 5 * 60, samples: 10 },
+    { period: 60 * 60, samples: 12 },
+    { period: 24 * 60 * 60, samples: 12 },
+    { period: 7 * 24 * 60 * 60, samples: 14 },
+    { period: 28 * 24 * 60 * 60, samples: 14 },
+    { period: 365 * 24 * 60 * 60, samples: 12 },
+];
+var Instances = {};
+process_1.default.on('SIGTERM', async () => {
+    await CustomMetrics.terminate();
+});
+class CustomMetrics {
+    constructor(options = {}) {
+        this.consistent = false;
+        this.buffers = null;
+        this.prefix = 'metric';
+        this.log = new Log(options.log);
+        if (options.ttl && typeof options.ttl != 'number') {
+            throw new Error('Bad type for "ttl" option');
+        }
+        if (options.spans && (!Array.isArray(options.spans) || options.spans.length == 0)) {
+            throw new Error('The "spans" option must be an non-empty array');
+        }
+        if (options.source && typeof options.source != 'string') {
+            throw new Error('Non-string "source" option');
+        }
+        if (options.pResolution != undefined && (options.pResolution < 0 || options.pResolution > 1000)) {
+            throw new Error('Invalid "pResolution" option. Must be between 0 and 1000. Default is 0');
+        }
+        if (options.consistent != null && typeof options.consistent != 'boolean') {
+            throw new Error('Bad type for "consistent" option');
+        }
+        if (options.prefix) {
+            this.prefix = options.prefix;
+        }
+        if (options.buffer) {
+            if (typeof options.buffer != 'object') {
+                throw new Error('Bad type for "buffer" option');
+            }
+            this.buffer = options.buffer;
+        }
+        this.expires = options.expires || 'expires';
+        this.primaryKey = options.primaryKey || 'pk';
+        this.sortKey = options.sortKey || 'sk';
+        this.type = options.type || { _type: 'Metric' };
+        if (options.client) {
+            this.client = options.client;
+        }
+        else {
+            let params = {};
+            if (options.creds) {
+                params.credentials = options.creds;
+                params.region = params.credentials.region;
+            }
+            if (options.region) {
+                params.region = options.region;
+            }
+            this.client = new client_dynamodb_1.DynamoDBClient(params);
+        }
+        if (!options.table) {
+            throw new Error('Missing DynamoDB table name property');
+        }
+        this.table = options.table;
+        this.options = options;
+        this.owner = options.owner || 'default';
+        this.spans = options.spans || exports.DefaultSpans;
+        this.ttl = options.ttl || this.spans[this.spans.length - 1].period;
+        if (options.consistent != null) {
+            this.consistent = options.consistent;
+        }
+        if (options.source) {
+            this.source = options.source;
+        }
+        this.pResolution = options.pResolution || DefaultResolution;
+    }
+    async emit(namespace, metricName, value, dimensionsList = [{}], options = {}) {
+        if (value == undefined || value == null) {
+            throw new Error('Invalid metric value');
+        }
+        if (dimensionsList.length == 0) {
+            dimensionsList = [{}];
+        }
+        value = Number(value);
+        if (isNaN(value)) {
+            throw new Error(`Value to emit is not valid`);
+        }
+        if (!namespace || !metricName) {
+            throw new Error('Missing emit namespace / metric argument');
+        }
+        if (!Array.isArray(dimensionsList)) {
+            throw new Error('Dimensions must be an array');
+        }
+        if (dimensionsList.length == 0) {
+            dimensionsList = [{}];
+        }
+        let point;
+        point = { count: 1, sum: value };
+        return await this.emitDimensions(namespace, metricName, point, dimensionsList, options);
+    }
+    async emitDimensions(namespace, metricName, point, dimensionsList, options) {
+        let result;
+        for (let dim of dimensionsList) {
+            let dimensions = this.makeDimensionString(dim);
+            let buffer = options.buffer || this.buffer;
+            if (buffer && (buffer.elapsed || buffer.force || buffer.sum || buffer.count) && Buffering) {
+                result = await this.bufferMetric(namespace, metricName, point, dimensions, options);
+            }
+            else {
+                result = await this.emitDimensionedMetric(namespace, metricName, point, dimensions, options);
+            }
+        }
+        return result;
+    }
+    async bufferMetric(namespace, metricName, point, dimensions, options) {
+        let buffer = options.buffer || this.buffer;
+        let key = this.getBufferKey(namespace, metricName, dimensions);
+        let buffers = (this.buffers = this.buffers || {});
+        let timestamp = Math.floor((options.timestamp || Date.now()) / 1000);
+        let elapsed = buffer.elapsed || this.spans[0].period / this.spans[0].samples;
+        let elt = (buffers[key] = buffers[key] || {
+            count: 0,
+            sum: 0,
+            timestamp: timestamp + elapsed,
+            elapsed: elapsed,
+            namespace: namespace,
+            metric: metricName,
+            dimensions,
+            spans: [{ points: [{ count: 0, sum: 0 }] }],
+        });
+        let current = elt.spans[0].points.at(-1);
+        if (current) {
+            current.count += point.count;
+            current.sum += point.sum;
+        }
+        elt.count += point.count;
+        elt.sum += point.sum;
+        if (buffer.force ||
+            (buffer.sum && elt.sum >= buffer.sum) ||
+            (buffer.count && elt.count >= buffer.count) ||
+            timestamp >= elt.timestamp) {
+            options = Object.assign({}, options, { timestamp: timestamp * 1000 });
+            let metric = await this.emitDimensionedMetric(namespace, metricName, elt, dimensions, options);
+            elt.count = elt.sum = 0;
+            elt.spans = metric.spans;
+            elt.timestamp = timestamp + (buffer.elapsed || this.spans[0].period / this.spans[0].samples);
+            return metric;
+        }
+        CustomMetrics.saveInstance({ key }, this);
+        return {
+            spans: elt.spans,
+            metric: metricName,
+            namespace: namespace,
+            owner: options.owner || this.owner,
+            version: Version,
+        };
+    }
+    async emitDimensionedMetric(namespace, metricName, point, dimensions, options = {}) {
+        let timestamp = Math.floor((options.timestamp || Date.now()) / 1000);
+        let ttl = options.ttl != undefined ? options.ttl : this.ttl;
+        let retries = MaxRetries;
+        let metric;
+        let backoff = 10;
+        let chan = options.log == true ? 'info' : 'trace';
+        do {
+            let owner = options.owner || this.owner;
+            metric = await this.getMetric(owner, namespace, metricName, dimensions, options.log);
+            if (metric) {
+                if (options.upgrade) {
+                    metric = this.upgradeMetric(metric);
+                }
+            }
+            else {
+                metric = this.initMetric(owner, namespace, metricName, dimensions, timestamp);
+            }
+            if (point.timestamp) {
+                let si = metric.spans.findIndex((s) => s.end - s.period <= point.timestamp || s.end <= point.timestamp);
+                if (si >= 0) {
+                    this.addValue(metric, point.timestamp, point, si);
+                }
+                else {
+                }
+            }
+            else {
+                this.addValue(metric, timestamp, point, 0);
+            }
+            if (this.source) {
+                metric._source = this.source;
+            }
+            if (ttl) {
+                metric.expires = timestamp + ttl;
+            }
+            if (await this.putMetric(metric, options)) {
+                break;
+            }
+            if (retries == 0) {
+                this.log.error(`Metric update has too many retries`, { namespace, metricName, dimensions });
+                break;
+            }
+            this.log[chan](`Retry ${MaxRetries - retries} metric update ${metric.namespace} ${metric.metric} ${metric.dimensions}`, {
+                retries,
+                metric,
+            });
+            backoff = backoff * 2;
+            this.log[chan](`Retry backoff ${backoff} ${this.jitter(backoff)}`);
+            await this.delay(this.jitter(backoff));
+        } while (retries-- > 0);
+        return metric;
+    }
+    async upgrade(namespace, metricName, dimensionsList = [{}], options = {}) {
+        let owner = options.owner || this.owner;
+        if (dimensionsList.length == 0) {
+            dimensionsList = [{}];
+        }
+        let metric;
+        for (let dim of dimensionsList) {
+            let dimensions = this.makeDimensionString(dim);
+            let old = await this.getMetric(owner, namespace, metricName, dimensions, options.log);
+            metric = this.upgradeMetric(old);
+            await this.putMetric(metric, options);
+        }
+        return metric;
+    }
+    upgradeMetric(old) {
+        let required = false;
+        if (this.spans.length == old.spans.length) {
+            for (let [index, span] of Object.entries(old.spans)) {
+                if (span.period != this.spans[index].period || span.samples != this.spans[index].samples) {
+                    required = true;
+                }
+            }
+            if (!required) {
+                return old;
+            }
+        }
+        let timestamp = Math.min(...old.spans.map((span) => span.end - span.period)) || Math.floor(Date.now() / 1000);
+        let metric = this.initMetric(old.owner, old.namespace, old.metric, old.dimensions, timestamp);
+        for (let span of old.spans) {
+            let interval = span.period / span.samples;
+            let timestamp = span.end - span.points.length * interval;
+            let si = metric.spans.findIndex((s) => s.end - s.period <= timestamp || s.end <= timestamp);
+            for (let point of span.points) {
+                this.addValue(metric, timestamp, point, si);
+                timestamp += interval;
+            }
+        }
+        return metric;
+    }
+    static async terminate() {
+        await CustomMetrics.flushAll();
+    }
+    static async flushAll() {
+        for (let [key, instance] of Object.entries(Instances)) {
+            await instance.flush();
+            CustomMetrics.freeInstanceByKey(key);
+        }
+        Instances = {};
+    }
+    async flush() {
+        if (!this.buffers)
+            return;
+        let now = Date.now() / 1000;
+        for (let elt of Object.values(this.buffers)) {
+            await this.flushElt(elt, now);
+        }
+    }
+    async flushElt(elt, timestamp) {
+        elt.timestamp = Math.min(timestamp, elt.timestamp);
+        let metric = await this.emitDimensionedMetric(elt.namespace, elt.metric, elt, elt.dimensions, {
+            timestamp: elt.timestamp * 1000,
+        });
+        elt.count = elt.sum = 0;
+        elt.spans = metric.spans;
+        elt.timestamp = timestamp + (elt.elapsed || this.spans[0].period / this.spans[0].samples);
+    }
+    getBufferKey(namespace, metricName, dimensions) {
+        return `${namespace}|${metricName}|${JSON.stringify(dimensions)}`;
+    }
+    async query(namespace, metricName, dimensions, period, statistic, options = {}) {
+        let owner = options.owner || this.owner;
+        let dimString = this.makeDimensionString(dimensions);
+        if (period > this.spans.at(-1).period) {
+            period = this.spans.at(-1).period;
+        }
+        let timestamp = Math.floor((options.timestamp || Date.now()) / 1000);
+        if (this.buffers) {
+            let key = this.getBufferKey(namespace, metricName, dimString);
+            if (this.buffers[key]) {
+                await this.flushElt(this.buffers[key], timestamp);
+            }
+        }
+        let metric = await this.getMetric(owner, namespace, metricName, dimString, options.log);
+        if (!metric) {
+            return { dimensions, id: options.id, metric: metricName, namespace, period, points: [], owner, samples: 0 };
+        }
+        let start;
+        let si;
+        if (options.start) {
+            start = options.start / 1000;
+            si = metric.spans.findIndex((s) => period <= s.period && s.end - s.period <= start && start <= s.end);
+        }
+        else {
+            let span = metric.spans[0];
+            let interval = span.period / span.samples;
+            let t = this.roundTime(span, timestamp + 1);
+            if (span.end - interval <= t && t <= span.end) {
+                start = t - period;
+            }
+            else {
+                start = timestamp - period;
+            }
+            si = metric.spans.findIndex((s) => period <= s.period);
+        }
+        if (si < 0) {
+            si = metric.spans.length - 1;
+        }
+        let span = metric.spans[si];
+        start = this.roundTime(span, start);
+        this.addValue(metric, timestamp, { count: 0, sum: 0 }, 0, si);
+        let result;
+        if (options.accumulate) {
+            result = this.accumulateMetric(metric, span, statistic, owner, start, period);
+        }
+        else {
+            result = this.calculateSeries(metric, span, statistic, owner, start, period);
+        }
+        result.id = options.id;
+        this.log[options.log == true ? 'info' : 'trace'](`Query metrics ${namespace}, ${metricName}`, {
+            dimensions,
+            period,
+            statistic,
+            options,
+            result,
+        });
+        return result;
+    }
+    accumulateMetric(metric, span, statistic, owner, start, period) {
+        let value = 0, count = 0, pvalues = [];
+        if (statistic == 'max') {
+            value = Number.NEGATIVE_INFINITY;
+        }
+        else if (statistic == 'min') {
+            value = Infinity;
+        }
+        else if (statistic == 'sum') {
+            value = 0;
+            count = 0;
+        }
+        else if (statistic == 'count') {
+            value = 0;
+            count = 0;
+        }
+        else if (statistic == 'current') {
+            value = 0;
+            count = 0;
+        }
+        else if (statistic.match(/^p[0-9]+/)) {
+            pvalues = [];
+        }
+        else {
+            value = 0;
+            count = 0;
+        }
+        let points = span.points;
+        let interval = span.period / span.samples;
+        let t = span.end - span.points.length * interval;
+        for (let i = 0; i < points.length; i++) {
+            let point = points[i];
+            if (start <= t && t < start + period) {
+                if (statistic == 'max') {
+                    if (point.max != undefined) {
+                        value = Math.max(value, point.max);
+                    }
+                    else {
+                        value = Math.max(value, point.sum / (point.count || 1));
+                    }
+                }
+                else if (statistic == 'min') {
+                    if (point.min != undefined) {
+                        value = Math.min(value, point.min);
+                    }
+                    else {
+                        value = Math.min(value, point.sum / (point.count || 1));
+                    }
+                }
+                else if (statistic == 'sum') {
+                    value += point.sum;
+                }
+                else if (statistic == 'current') {
+                    value = point.sum / (point.count || 1);
+                }
+                else if (statistic == 'count') {
+                    value += point.count;
+                }
+                else if (statistic.match(/^p[0-9]+/)) {
+                    pvalues = pvalues.concat(point.pvalues);
+                }
+                else {
+                    value += point.sum;
+                }
+                count += point.count;
+            }
+            t += interval;
+        }
+        if (statistic.match(/^p[0-9]+/)) {
+            let p = parseInt(statistic.slice(1));
+            pvalues.sort((a, b) => a - b);
+            let nth = Math.min(Math.round((pvalues.length * p) / 100 + 1), pvalues.length - 1);
+            value = pvalues[nth];
+        }
+        else if (statistic == 'avg') {
+            value /= Math.max(count, 1);
+        }
+        return {
+            dimensions: this.makeDimensionObject(metric.dimensions),
+            metric: metric.metric,
+            namespace: metric.namespace,
+            owner: owner,
+            period: span.period,
+            points: [{ value, timestamp: start + period, count }],
+            samples: span.samples,
+        };
+    }
+    calculateSeries(metric, span, statistic, owner, start, period) {
+        let points = [];
+        let interval = span.period / span.samples;
+        let t;
+        let firstPoint = span.end - span.points.length * interval;
+        let count = Math.floor((firstPoint - start) / interval);
+        for (t = start; t < firstPoint && points.length < span.samples; t += interval) {
+            points.push({ value: 0, count: 0, timestamp: t * 1000 });
+        }
+        t = firstPoint;
+        for (let point of span.points) {
+            if (start <= t && t < start + period) {
+                let value = undefined;
+                if (point.count > 0) {
+                    if (statistic == 'max') {
+                        if (point.max != undefined) {
+                            if (value == undefined) {
+                                value = point.max;
+                            }
+                            else {
+                                value = Math.max(value, point.max);
+                            }
+                        }
+                    }
+                    else if (statistic == 'min') {
+                        if (point.min != undefined) {
+                            if (value == undefined) {
+                                value = point.min;
+                            }
+                            else {
+                                value = Math.min(value, point.min);
+                            }
+                        }
+                    }
+                    else if (statistic == 'sum') {
+                        value = point.sum;
+                    }
+                    else if (statistic == 'count') {
+                        value = point.count;
+                    }
+                    else if (statistic.match(/^p[0-9]+/)) {
+                        let p = parseInt(statistic.slice(1));
+                        let pvalues = point.pvalues;
+                        pvalues.sort((a, b) => a - b);
+                        let nth = Math.min(Math.round((pvalues.length * p) / 100 + 1), pvalues.length - 1);
+                        value = pvalues[nth];
+                    }
+                    else {
+                        value = point.sum / point.count;
+                    }
+                }
+                else {
+                    value = 0;
+                }
+                points.push({ value, count: point.count, timestamp: (t + interval) * 1000 });
+            }
+            t += interval;
+        }
+        count = Math.ceil(period / interval);
+        while (points.length < count) {
+            points.push({ value: 0, count: 0, timestamp: t * 1000 });
+            t += interval;
+        }
+        return {
+            dimensions: this.makeDimensionObject(metric.dimensions),
+            metric: metric.metric,
+            namespace: metric.namespace,
+            period: span.period,
+            points: points,
+            owner: owner,
+            samples: span.samples,
+        };
+    }
+    makeDimensionString(dimensions) {
+        let result = [];
+        let entries = Object.entries(dimensions).sort((a, b) => a[0].localeCompare(b[0]));
+        for (let [name, value] of entries) {
+            result.push(`${name}=${value}`);
+        }
+        return result.join(',');
+    }
+    makeDimensionObject(dimensions) {
+        let result = {};
+        for (let dimension of dimensions.split(',')) {
+            if (dimension) {
+                let [key, value] = dimension.split('=');
+                result[key] = value;
+            }
+        }
+        return result;
+    }
+    addValue(metric, timestamp, point, si, querySpanIndex = undefined) {
+        this.assert(metric);
+        this.assert(timestamp);
+        this.assert(0 <= si && si < metric.spans.length);
+        let span = metric.spans[si];
+        let interval = span.period / span.samples;
+        let points = span.points || [];
+        let queryRecurse = si < querySpanIndex && si + 1 < metric.spans.length;
+        while (points.length > span.samples) {
+            points.shift();
+        }
+        let first = span.end - points.length * interval;
+        let shift = 0;
+        if (points.length) {
+            if (queryRecurse) {
+                shift = points.length;
+            }
+            else if (timestamp >= first) {
+                shift = Math.floor((timestamp - first) / interval) - span.samples;
+                if (!queryRecurse && point.count && timestamp >= span.end) {
+                    shift += 1;
+                }
+            }
+            shift = Math.max(0, Math.min(shift, points.length));
+            this.assert(0 <= shift && shift <= points.length);
+            for (let i = 0; i < shift; i++) {
+                let p = points.shift();
+                if (p.count && si + 1 < metric.spans.length) {
+                    this.addValue(metric, first, p, si + 1, querySpanIndex);
+                }
+                first += interval;
+            }
+        }
+        if (queryRecurse) {
+            this.addValue(metric, timestamp, point, si + 1, querySpanIndex);
+            return;
+        }
+        if (point.count) {
+            let index;
+            if (points.length == 0) {
+                points.push({ count: 0, sum: 0 });
+                span.end = this.roundTime(span, timestamp + 1);
+                first = span.end - interval;
+                index = 0;
+            }
+            else {
+                if (timestamp < span.end - span.period) {
+                    return;
+                }
+                while (timestamp < first) {
+                    points.unshift({ count: 0, sum: 0 });
+                    first -= interval;
+                }
+                while (timestamp >= span.end) {
+                    points.push({ count: 0, sum: 0 });
+                    span.end += interval;
+                }
+                index = Math.floor((timestamp - first) / interval);
+            }
+            this.assert(points.length <= span.samples);
+            if (!(0 <= index && index < points.length)) {
+                this.assert(0 <= index && index < points.length);
+                if (index > 0) {
+                    index = points.length - 1;
+                }
+            }
+            this.setPoint(span, index, point);
+        }
+    }
+    setPoint(span, index, add) {
+        let points = span.points;
+        this.assert(0 <= index && index < points.length);
+        let point = points[index];
+        if (!point) {
+            this.log.error(`Metric null point`, { span, index, add });
+            return;
+        }
+        if (add.count) {
+            let value = add.sum / add.count;
+            if (point.min == undefined) {
+                point.min = value;
+            }
+            else {
+                point.min = Math.min(value, point.min);
+            }
+            if (point.max == undefined) {
+                point.max = value;
+            }
+            else {
+                point.max = Math.max(value, point.max);
+            }
+        }
+        if (this.pResolution) {
+            point.pvalues = point.pvalues || [];
+            if (add.pvalues) {
+                point.pvalues.push(...add.pvalues);
+            }
+            else {
+                point.pvalues.push(add.sum / add.count);
+            }
+            point.pvalues.splice(0, point.pvalues.length - this.pResolution);
+        }
+        point.sum += add.sum;
+        point.count += add.count;
+    }
+    async getMetricList(namespace = undefined, metric = undefined, options = { limit: MetricListLimit }) {
+        let map = {};
+        let owner = options.owner || this.owner;
+        let next = options.next;
+        let limit = options.limit || MetricListLimit;
+        let chan = options.log == true ? 'info' : 'trace';
+        let items, command;
+        let count = 0;
+        do {
+            ;
+            ({ command, items, next } = await this.findMetrics(owner, namespace, metric, limit, next));
+            this.log[chan](`Find metrics ${namespace}, ${metric}`, { command, items });
+            if (items.length) {
+                for (let item of items) {
+                    let ns = (map[item.namespace] = map[item.namespace] || {});
+                    let met = (ns[item.metric] = ns[item.metric] || []);
+                    met.push(item.dimensions);
+                }
+                count += items.length;
+            }
+        } while (next && count < limit);
+        let result = { namespaces: Object.keys(map) };
+        if (namespace && map[namespace]) {
+            result.metrics = Object.keys(map[namespace]);
+            if (metric) {
+                let dimensions = map[namespace][metric];
+                if (dimensions) {
+                    result.dimensions = [];
+                    dimensions = dimensions.sort().filter((v, index, self) => self.indexOf(v) === index);
+                    for (let dimension of dimensions) {
+                        result.dimensions.push(this.makeDimensionObject(dimension));
+                    }
+                }
+            }
+        }
+        return result;
+    }
+    initMetric(owner, namespace, name, dimensions, timestamp) {
+        let metric = {
+            dimensions,
+            metric: name,
+            namespace,
+            owner,
+            spans: [],
+            version: Version,
+        };
+        for (let sdef of this.spans) {
+            let span = {
+                samples: sdef.samples,
+                period: sdef.period,
+                end: timestamp,
+                points: [],
+            };
+            span.end = this.roundTime(span, timestamp + 1);
+            metric.spans.push(span);
+        }
+        return metric;
+    }
+    async getMetric(owner, namespace, metric, dimensions, log) {
+        let command = new client_dynamodb_1.GetItemCommand({
+            TableName: this.table,
+            Key: {
+                [this.primaryKey]: { S: `${this.prefix}#${Version}#${owner}` },
+                [this.sortKey]: { S: `${this.prefix}#${namespace}#${metric}#${dimensions}` },
+            },
+            ConsistentRead: this.consistent,
+        });
+        let data = await this.client.send(command);
+        let result = null;
+        if (data && data.Item) {
+            let item = (0, util_dynamodb_1.unmarshall)(data.Item);
+            result = this.mapItemFromDB(item);
+        }
+        if (log == true) {
+            let chan = log == true ? 'info' : 'trace';
+            this.log[chan](`GetMetric ${namespace}, ${metric} ${dimensions}`, { cmd: command, result });
+        }
+        return result;
+    }
+    async findMetrics(owner, namespace, metric, limit, startKey) {
+        let key = [namespace];
+        if (metric) {
+            key.push(metric);
+        }
+        let start = startKey ? (0, util_dynamodb_1.marshall)(startKey) : undefined;
+        let command = new client_dynamodb_1.QueryCommand({
+            TableName: this.table,
+            ExpressionAttributeNames: {
+                '#_0': this.primaryKey,
+                '#_1': this.sortKey,
+            },
+            ExpressionAttributeValues: {
+                ':_0': { S: `${this.prefix}#${Version}#${owner}` },
+                ':_1': { S: `${this.prefix}#${key.join('#')}` },
+            },
+            KeyConditionExpression: '#_0 = :_0 and begins_with(#_1, :_1)',
+            ConsistentRead: this.consistent,
+            Limit: limit,
+            ScanIndexForward: true,
+            ExclusiveStartKey: start,
+            ProjectionExpression: `${this.primaryKey}, ${this.sortKey}`,
+        });
+        let result = await this.client.send(command);
+        let items = [];
+        if (result.Items) {
+            for (let i = 0; i < result.Items.length; i++) {
+                let item = (0, util_dynamodb_1.unmarshall)(result.Items[i]);
+                items.push(this.mapItemFromDB(item));
+            }
+        }
+        let next = undefined;
+        if (result.LastEvaluatedKey) {
+            next = (0, util_dynamodb_1.unmarshall)(result.LastEvaluatedKey);
+        }
+        return { items, next, command };
+    }
+    async putMetric(item, options) {
+        let ConditionExpression, ExpressionAttributeValues;
+        let seq;
+        if (item.seq != undefined) {
+            seq = item.seq = item.seq || 0;
+            if (item.seq++ >= MaxSeq) {
+                item.seq = 0;
+            }
+            ConditionExpression = `seq = :_0`;
+            ExpressionAttributeValues = { ':_0': { N: seq.toString() } };
+        }
+        else {
+            item.seq = 0;
+        }
+        let mapped = this.mapItemToDB(item);
+        let params = {
+            TableName: this.table,
+            ReturnValues: 'NONE',
+            Item: (0, util_dynamodb_1.marshall)(mapped, { removeUndefinedValues: true }),
+            ConditionExpression,
+            ExpressionAttributeValues,
+        };
+        let command = new client_dynamodb_1.PutItemCommand(params);
+        let chan = options.log == true ? 'info' : 'trace';
+        this.log[chan](`Put metric ${item.namespace}, ${item.metric}`, {
+            dimensions: item.dimensions,
+            command,
+            params,
+            item,
+        });
+        try {
+            await this.client.send(command);
+            return true;
+        }
+        catch (err) {
+            ;
+            (function (err, log) {
+                let code = err.code || err.name;
+                if (code == 'ConditionalCheckFailedException') {
+                    log.trace(`Update collision`, { err });
+                }
+                else if (code == 'ProvisionedThroughputExceededException') {
+                    log.info(`Provisioned throughput exceeded: ${err.message}`, { err, cmd: command, item });
+                }
+                else {
+                    log.error(`Emit exception code ${err.name} ${err.code} message ${err.message}`, {
+                        err,
+                        cmd: command,
+                        item,
+                    });
+                    throw err;
+                }
+                return false;
+            })(err, this.log);
+        }
+    }
+    mapItemFromDB(data) {
+        let pk = data[this.primaryKey];
+        let sk = data[this.sortKey];
+        let owner = pk.split('#').pop();
+        let [, namespace, metric, dimensions] = sk.split('#');
+        let spans;
+        if (data.spans) {
+            spans = data.spans.map((s) => {
+                return {
+                    end: s.se,
+                    period: s.sp,
+                    samples: s.ss,
+                    points: s.pt.map((p) => {
+                        let point = { count: Number(p.c), sum: Number(p.s) };
+                        if (p.x != null) {
+                            point.max = Number(p.x);
+                        }
+                        if (p.m != null) {
+                            point.min = Number(p.m);
+                        }
+                        if (p.v) {
+                            point.pvalues = p.v;
+                        }
+                        return point;
+                    }),
+                };
+            });
+        }
+        let expires = data[this.expires];
+        let seq = data.seq;
+        return { dimensions, expires, metric, namespace, owner, seq, spans };
+    }
+    mapItemToDB(item) {
+        let result = {
+            [this.primaryKey]: `${this.prefix}#${Version}#${item.owner}`,
+            [this.sortKey]: `${this.prefix}#${item.namespace}#${item.metric}#${item.dimensions}`,
+            [this.expires]: item.expires,
+            spans: item.spans.map((i) => {
+                return {
+                    se: i.end,
+                    sp: i.period,
+                    ss: i.samples,
+                    pt: i.points.map((point) => {
+                        let p = { c: point.count, s: this.round(point.sum) };
+                        if (point.max != null) {
+                            p.x = this.round(point.max);
+                        }
+                        if (point.min != null) {
+                            p.m = this.round(point.min);
+                        }
+                        if (point.pvalues) {
+                            p.v = point.pvalues;
+                        }
+                        return p;
+                    }),
+                };
+            }),
+            seq: item.seq,
+            _source: item._source,
+        };
+        if (this.type) {
+            let [key, model] = Object.entries(this.type)[0];
+            result[key] = model;
+        }
+        return result;
+    }
+    static freeInstanceByKey(key) {
+        delete Instances[key];
+    }
+    static saveInstance(tags, metrics) {
+        let key = JSON.stringify(tags);
+        Instances[key] = metrics;
+    }
+    roundTime(span, timestamp) {
+        let interval = span.period / span.samples;
+        return Math.ceil(timestamp / interval) * interval;
+    }
+    assert(c) {
+        if (!c && Assert) {
+            let msg = { stack: '' };
+            if (typeof Error.captureStackTrace === 'function') {
+                Error.captureStackTrace(msg);
+            }
+            else {
+                msg.stack = new Error('Assert').stack;
+            }
+            this.log.error(`Assertion failed`, { stack: msg.stack });
+        }
+    }
+    info(message, context = {}) {
+        console.log('INFO: ' + message, context);
+    }
+    error(message, context = {}) {
+        console.log('ERROR: ' + message, context);
+    }
+    trace(message, context = {}) {
+        console.log('TRACE: ' + message, context);
+    }
+    round(n) {
+        if (isNaN(n) || n == null) {
+            return 0;
+        }
+        let places = 16 - n.toFixed(0).length;
+        return Number(n.toFixed(places)) - 0;
+    }
+    jitter(msecs) {
+        return Math.min(10 * 1000, Math.floor(msecs / 2 + msecs * Math.random()));
+    }
+    async delay(time) {
+        return new Promise(function (resolve, reject) {
+            setTimeout(() => resolve(true), time);
+        });
+    }
+}
+exports.CustomMetrics = CustomMetrics;
+class Log {
+    constructor(dest) {
+        this.senselogs = null;
+        this.logger = null;
+        this.verbose = false;
+        if (dest === true) {
+            this.logger = this.defaultLogger;
+        }
+        else if (dest == 'verbose') {
+            this.logger = this.defaultLogger;
+            this.verbose = true;
+        }
+        else if (dest && typeof dest.info == 'function') {
+            this.senselogs = dest;
+        }
+    }
+    error(message, context) {
+        this.process('error', message, context);
+    }
+    info(message, context) {
+        this.process('info', message, context);
+    }
+    trace(message, context) {
+        this.process('trace', message, context);
+    }
+    process(chan, message, context) {
+        if (this.logger) {
+            this.logger(chan, message, context);
+        }
+        else if (this.senselogs) {
+            this.senselogs[chan](message, context);
+        }
+    }
+    defaultLogger(chan, message, context) {
+        if (chan == 'trace' && !this.verbose) {
+            return;
+        }
+        let tag = chan.toUpperCase();
+        if (context) {
+            try {
+                console.log(tag, message, JSON.stringify(context, null, 4));
+            }
+            catch (err) {
+                let buf = ['{'];
+                for (let [key, value] of Object.entries(context)) {
+                    try {
+                        buf.push(`    ${key}: ${JSON.stringify(value, null, 4)}`);
+                    }
+                    catch (err) {
+                    }
+                }
+                buf.push('}');
+                console.log(tag, message, buf.join('\n'));
+            }
+        }
+        else {
+            console.log(tag, message);
+        }
+    }
+}
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/dist/mjs/index.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/dist/mjs/index.d.ts
new file mode 100644
index 0000000..10b2449
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/dist/mjs/index.d.ts
@@ -0,0 +1,173 @@
+export const DefaultSpans: {
+    period: number;
+    samples: number;
+}[];
+export class CustomMetrics {
+    static terminate(): Promise<void>;
+    static flushAll(): Promise<void>;
+    static freeInstanceByKey(key: any): void;
+    static saveInstance(tags: any, metrics: any): void;
+    constructor(options?: {});
+    consistent: boolean;
+    buffer: any;
+    buffers: any;
+    client: any;
+    expires: any;
+    log: Log;
+    options: {};
+    owner: any;
+    prefix: string;
+    primaryKey: any;
+    sortKey: any;
+    pResolution: any;
+    source: any;
+    spans: any;
+    table: any;
+    type: any;
+    ttl: any;
+    emit(namespace: any, metricName: any, value: any, dimensionsList?: {}[], options?: {}): Promise<any>;
+    emitDimensions(namespace: any, metricName: any, point: any, dimensionsList: any, options: any): Promise<any>;
+    bufferMetric(namespace: any, metricName: any, point: any, dimensions: any, options: any): Promise<any>;
+    emitDimensionedMetric(namespace: any, metricName: any, point: any, dimensions: any, options?: {}): Promise<any>;
+    upgrade(namespace: any, metricName: any, dimensionsList?: {}[], options?: {}): Promise<any>;
+    upgradeMetric(old: any): any;
+    flush(): Promise<void>;
+    flushElt(elt: any, timestamp: any): Promise<void>;
+    getBufferKey(namespace: any, metricName: any, dimensions: any): string;
+    query(namespace: any, metricName: any, dimensions: any, period: any, statistic: any, options?: {}): Promise<{
+        dimensions: {};
+        metric: any;
+        namespace: any;
+        owner: any;
+        period: any;
+        points: {
+            value: number;
+            timestamp: any;
+            count: number;
+        }[];
+        samples: any;
+    } | {
+        dimensions: {};
+        metric: any;
+        namespace: any;
+        period: any;
+        points: {
+            value: any;
+            count: any;
+            timestamp: number;
+        }[];
+        owner: any;
+        samples: any;
+    } | {
+        dimensions: any;
+        id: any;
+        metric: any;
+        namespace: any;
+        period: any;
+        points: any[];
+        owner: any;
+        samples: number;
+    }>;
+    accumulateMetric(metric: any, span: any, statistic: any, owner: any, start: any, period: any): {
+        dimensions: {};
+        metric: any;
+        namespace: any;
+        owner: any;
+        period: any;
+        points: {
+            value: number;
+            timestamp: any;
+            count: number;
+        }[];
+        samples: any;
+    };
+    calculateSeries(metric: any, span: any, statistic: any, owner: any, start: any, period: any): {
+        dimensions: {};
+        metric: any;
+        namespace: any;
+        period: any;
+        points: {
+            value: any;
+            count: any;
+            timestamp: number;
+        }[];
+        owner: any;
+        samples: any;
+    };
+    makeDimensionString(dimensions: any): string;
+    makeDimensionObject(dimensions: any): {};
+    addValue(metric: any, timestamp: any, point: any, si: any, querySpanIndex?: any): void;
+    setPoint(span: any, index: any, add: any): void;
+    getMetricList(namespace?: any, metric?: any, options?: {
+        limit: number;
+    }): Promise<{
+        namespaces: string[];
+    }>;
+    initMetric(owner: any, namespace: any, name: any, dimensions: any, timestamp: any): {
+        dimensions: any;
+        metric: any;
+        namespace: any;
+        owner: any;
+        spans: any[];
+        version: number;
+    };
+    getMetric(owner: any, namespace: any, metric: any, dimensions: any, log: any): Promise<{
+        dimensions: any;
+        expires: any;
+        metric: any;
+        namespace: any;
+        owner: any;
+        seq: any;
+        spans: any;
+    }>;
+    findMetrics(owner: any, namespace: any, metric: any, limit: any, startKey: any): Promise<{
+        items: {
+            dimensions: any;
+            expires: any;
+            metric: any;
+            namespace: any;
+            owner: any;
+            seq: any;
+            spans: any;
+        }[];
+        next: Record<string, any>;
+        command: QueryCommand;
+    }>;
+    putMetric(item: any, options: any): Promise<boolean>;
+    mapItemFromDB(data: any): {
+        dimensions: any;
+        expires: any;
+        metric: any;
+        namespace: any;
+        owner: any;
+        seq: any;
+        spans: any;
+    };
+    mapItemToDB(item: any): {
+        [x: number]: any;
+        spans: any;
+        seq: any;
+        _source: any;
+    };
+    roundTime(span: any, timestamp: any): number;
+    assert(c: any): void;
+    info(message: any, context?: {}): void;
+    error(message: any, context?: {}): void;
+    trace(message: any, context?: {}): void;
+    round(n: any): number;
+    jitter(msecs: any): number;
+    delay(time: any): Promise<any>;
+}
+declare class Log {
+    constructor(dest: any);
+    senselogs: any;
+    logger: any;
+    verbose: boolean;
+    error(message: any, context: any): void;
+    info(message: any, context: any): void;
+    trace(message: any, context: any): void;
+    process(chan: any, message: any, context: any): void;
+    defaultLogger(chan: any, message: any, context: any): void;
+}
+import { QueryCommand } from '@aws-sdk/client-dynamodb';
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/dist/mjs/index.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/dist/mjs/index.js
new file mode 100644
index 0000000..018353a
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/dist/mjs/index.js
@@ -0,0 +1,996 @@
+"use strict";
+var __importDefault = (this && this.__importDefault) || function (mod) {
+    return (mod && mod.__esModule) ? mod : { "default": mod };
+};
+Object.defineProperty(exports, "__esModule", { value: true });
+exports.CustomMetrics = exports.DefaultSpans = void 0;
+const process_1 = __importDefault(require("process"));
+const client_dynamodb_1 = require("@aws-sdk/client-dynamodb");
+const util_dynamodb_1 = require("@aws-sdk/util-dynamodb");
+const Version = 1;
+const Assert = true;
+const Buffering = true;
+const DefaultResolution = 0;
+const MaxSeq = Number.MAX_SAFE_INTEGER;
+const MaxRetries = 10;
+const MetricListLimit = 10000;
+exports.DefaultSpans = [
+    { period: 5 * 60, samples: 10 },
+    { period: 60 * 60, samples: 12 },
+    { period: 24 * 60 * 60, samples: 12 },
+    { period: 7 * 24 * 60 * 60, samples: 14 },
+    { period: 28 * 24 * 60 * 60, samples: 14 },
+    { period: 365 * 24 * 60 * 60, samples: 12 },
+];
+var Instances = {};
+process_1.default.on('SIGTERM', async () => {
+    await CustomMetrics.terminate();
+});
+class CustomMetrics {
+    consistent = false;
+    buffer;
+    buffers = null;
+    client;
+    expires;
+    log;
+    options;
+    owner;
+    prefix = 'metric';
+    primaryKey;
+    sortKey;
+    pResolution;
+    source;
+    spans;
+    table;
+    type;
+    ttl;
+    constructor(options = {}) {
+        this.log = new Log(options.log);
+        if (options.ttl && typeof options.ttl != 'number') {
+            throw new Error('Bad type for "ttl" option');
+        }
+        if (options.spans && (!Array.isArray(options.spans) || options.spans.length == 0)) {
+            throw new Error('The "spans" option must be an non-empty array');
+        }
+        if (options.source && typeof options.source != 'string') {
+            throw new Error('Non-string "source" option');
+        }
+        if (options.pResolution != undefined && (options.pResolution < 0 || options.pResolution > 1000)) {
+            throw new Error('Invalid "pResolution" option. Must be between 0 and 1000. Default is 0');
+        }
+        if (options.consistent != null && typeof options.consistent != 'boolean') {
+            throw new Error('Bad type for "consistent" option');
+        }
+        if (options.prefix) {
+            this.prefix = options.prefix;
+        }
+        if (options.buffer) {
+            if (typeof options.buffer != 'object') {
+                throw new Error('Bad type for "buffer" option');
+            }
+            this.buffer = options.buffer;
+        }
+        this.expires = options.expires || 'expires';
+        this.primaryKey = options.primaryKey || 'pk';
+        this.sortKey = options.sortKey || 'sk';
+        this.type = options.type || { _type: 'Metric' };
+        if (options.client) {
+            this.client = options.client;
+        }
+        else {
+            let params = {};
+            if (options.creds) {
+                params.credentials = options.creds;
+                params.region = params.credentials.region;
+            }
+            if (options.region) {
+                params.region = options.region;
+            }
+            this.client = new client_dynamodb_1.DynamoDBClient(params);
+        }
+        if (!options.table) {
+            throw new Error('Missing DynamoDB table name property');
+        }
+        this.table = options.table;
+        this.options = options;
+        this.owner = options.owner || 'default';
+        this.spans = options.spans || exports.DefaultSpans;
+        this.ttl = options.ttl || this.spans[this.spans.length - 1].period;
+        if (options.consistent != null) {
+            this.consistent = options.consistent;
+        }
+        if (options.source) {
+            this.source = options.source;
+        }
+        this.pResolution = options.pResolution || DefaultResolution;
+    }
+    async emit(namespace, metricName, value, dimensionsList = [{}], options = {}) {
+        if (value == undefined || value == null) {
+            throw new Error('Invalid metric value');
+        }
+        if (dimensionsList.length == 0) {
+            dimensionsList = [{}];
+        }
+        value = Number(value);
+        if (isNaN(value)) {
+            throw new Error(`Value to emit is not valid`);
+        }
+        if (!namespace || !metricName) {
+            throw new Error('Missing emit namespace / metric argument');
+        }
+        if (!Array.isArray(dimensionsList)) {
+            throw new Error('Dimensions must be an array');
+        }
+        if (dimensionsList.length == 0) {
+            dimensionsList = [{}];
+        }
+        let point;
+        point = { count: 1, sum: value };
+        return await this.emitDimensions(namespace, metricName, point, dimensionsList, options);
+    }
+    async emitDimensions(namespace, metricName, point, dimensionsList, options) {
+        let result;
+        for (let dim of dimensionsList) {
+            let dimensions = this.makeDimensionString(dim);
+            let buffer = options.buffer || this.buffer;
+            if (buffer && (buffer.elapsed || buffer.force || buffer.sum || buffer.count) && Buffering) {
+                result = await this.bufferMetric(namespace, metricName, point, dimensions, options);
+            }
+            else {
+                result = await this.emitDimensionedMetric(namespace, metricName, point, dimensions, options);
+            }
+        }
+        return result;
+    }
+    async bufferMetric(namespace, metricName, point, dimensions, options) {
+        let buffer = options.buffer || this.buffer;
+        let key = this.getBufferKey(namespace, metricName, dimensions);
+        let buffers = (this.buffers = this.buffers || {});
+        let timestamp = Math.floor((options.timestamp || Date.now()) / 1000);
+        let elapsed = buffer.elapsed || this.spans[0].period / this.spans[0].samples;
+        let elt = (buffers[key] = buffers[key] || {
+            count: 0,
+            sum: 0,
+            timestamp: timestamp + elapsed,
+            elapsed: elapsed,
+            namespace: namespace,
+            metric: metricName,
+            dimensions,
+            spans: [{ points: [{ count: 0, sum: 0 }] }],
+        });
+        let current = elt.spans[0].points.at(-1);
+        if (current) {
+            current.count += point.count;
+            current.sum += point.sum;
+        }
+        elt.count += point.count;
+        elt.sum += point.sum;
+        if (buffer.force ||
+            (buffer.sum && elt.sum >= buffer.sum) ||
+            (buffer.count && elt.count >= buffer.count) ||
+            timestamp >= elt.timestamp) {
+            options = Object.assign({}, options, { timestamp: timestamp * 1000 });
+            let metric = await this.emitDimensionedMetric(namespace, metricName, elt, dimensions, options);
+            elt.count = elt.sum = 0;
+            elt.spans = metric.spans;
+            elt.timestamp = timestamp + (buffer.elapsed || this.spans[0].period / this.spans[0].samples);
+            return metric;
+        }
+        CustomMetrics.saveInstance({ key }, this);
+        return {
+            spans: elt.spans,
+            metric: metricName,
+            namespace: namespace,
+            owner: options.owner || this.owner,
+            version: Version,
+        };
+    }
+    async emitDimensionedMetric(namespace, metricName, point, dimensions, options = {}) {
+        let timestamp = Math.floor((options.timestamp || Date.now()) / 1000);
+        let ttl = options.ttl != undefined ? options.ttl : this.ttl;
+        let retries = MaxRetries;
+        let metric;
+        let backoff = 10;
+        let chan = options.log == true ? 'info' : 'trace';
+        do {
+            let owner = options.owner || this.owner;
+            metric = await this.getMetric(owner, namespace, metricName, dimensions, options.log);
+            if (metric) {
+                if (options.upgrade) {
+                    metric = this.upgradeMetric(metric);
+                }
+            }
+            else {
+                metric = this.initMetric(owner, namespace, metricName, dimensions, timestamp);
+            }
+            if (point.timestamp) {
+                let si = metric.spans.findIndex((s) => s.end - s.period <= point.timestamp || s.end <= point.timestamp);
+                if (si >= 0) {
+                    this.addValue(metric, point.timestamp, point, si);
+                }
+                else {
+                }
+            }
+            else {
+                this.addValue(metric, timestamp, point, 0);
+            }
+            if (this.source) {
+                metric._source = this.source;
+            }
+            if (ttl) {
+                metric.expires = timestamp + ttl;
+            }
+            if (await this.putMetric(metric, options)) {
+                break;
+            }
+            if (retries == 0) {
+                this.log.error(`Metric update has too many retries`, { namespace, metricName, dimensions });
+                break;
+            }
+            this.log[chan](`Retry ${MaxRetries - retries} metric update ${metric.namespace} ${metric.metric} ${metric.dimensions}`, {
+                retries,
+                metric,
+            });
+            backoff = backoff * 2;
+            this.log[chan](`Retry backoff ${backoff} ${this.jitter(backoff)}`);
+            await this.delay(this.jitter(backoff));
+        } while (retries-- > 0);
+        return metric;
+    }
+    async upgrade(namespace, metricName, dimensionsList = [{}], options = {}) {
+        let owner = options.owner || this.owner;
+        if (dimensionsList.length == 0) {
+            dimensionsList = [{}];
+        }
+        let metric;
+        for (let dim of dimensionsList) {
+            let dimensions = this.makeDimensionString(dim);
+            let old = await this.getMetric(owner, namespace, metricName, dimensions, options.log);
+            metric = this.upgradeMetric(old);
+            await this.putMetric(metric, options);
+        }
+        return metric;
+    }
+    upgradeMetric(old) {
+        let required = false;
+        if (this.spans.length == old.spans.length) {
+            for (let [index, span] of Object.entries(old.spans)) {
+                if (span.period != this.spans[index].period || span.samples != this.spans[index].samples) {
+                    required = true;
+                }
+            }
+            if (!required) {
+                return old;
+            }
+        }
+        let timestamp = Math.min(...old.spans.map((span) => span.end - span.period)) || Math.floor(Date.now() / 1000);
+        let metric = this.initMetric(old.owner, old.namespace, old.metric, old.dimensions, timestamp);
+        for (let span of old.spans) {
+            let interval = span.period / span.samples;
+            let timestamp = span.end - span.points.length * interval;
+            let si = metric.spans.findIndex((s) => s.end - s.period <= timestamp || s.end <= timestamp);
+            for (let point of span.points) {
+                this.addValue(metric, timestamp, point, si);
+                timestamp += interval;
+            }
+        }
+        return metric;
+    }
+    static async terminate() {
+        await CustomMetrics.flushAll();
+    }
+    static async flushAll() {
+        for (let [key, instance] of Object.entries(Instances)) {
+            await instance.flush();
+            CustomMetrics.freeInstanceByKey(key);
+        }
+        Instances = {};
+    }
+    async flush() {
+        if (!this.buffers)
+            return;
+        let now = Date.now() / 1000;
+        for (let elt of Object.values(this.buffers)) {
+            await this.flushElt(elt, now);
+        }
+    }
+    async flushElt(elt, timestamp) {
+        elt.timestamp = Math.min(timestamp, elt.timestamp);
+        let metric = await this.emitDimensionedMetric(elt.namespace, elt.metric, elt, elt.dimensions, {
+            timestamp: elt.timestamp * 1000,
+        });
+        elt.count = elt.sum = 0;
+        elt.spans = metric.spans;
+        elt.timestamp = timestamp + (elt.elapsed || this.spans[0].period / this.spans[0].samples);
+    }
+    getBufferKey(namespace, metricName, dimensions) {
+        return `${namespace}|${metricName}|${JSON.stringify(dimensions)}`;
+    }
+    async query(namespace, metricName, dimensions, period, statistic, options = {}) {
+        let owner = options.owner || this.owner;
+        let dimString = this.makeDimensionString(dimensions);
+        if (period > this.spans.at(-1).period) {
+            period = this.spans.at(-1).period;
+        }
+        let timestamp = Math.floor((options.timestamp || Date.now()) / 1000);
+        if (this.buffers) {
+            let key = this.getBufferKey(namespace, metricName, dimString);
+            if (this.buffers[key]) {
+                await this.flushElt(this.buffers[key], timestamp);
+            }
+        }
+        let metric = await this.getMetric(owner, namespace, metricName, dimString, options.log);
+        if (!metric) {
+            return { dimensions, id: options.id, metric: metricName, namespace, period, points: [], owner, samples: 0 };
+        }
+        let start;
+        let si;
+        if (options.start) {
+            start = options.start / 1000;
+            si = metric.spans.findIndex((s) => period <= s.period && s.end - s.period <= start && start <= s.end);
+        }
+        else {
+            let span = metric.spans[0];
+            let interval = span.period / span.samples;
+            let t = this.roundTime(span, timestamp + 1);
+            if (span.end - interval <= t && t <= span.end) {
+                start = t - period;
+            }
+            else {
+                start = timestamp - period;
+            }
+            si = metric.spans.findIndex((s) => period <= s.period);
+        }
+        if (si < 0) {
+            si = metric.spans.length - 1;
+        }
+        let span = metric.spans[si];
+        start = this.roundTime(span, start);
+        this.addValue(metric, timestamp, { count: 0, sum: 0 }, 0, si);
+        let result;
+        if (options.accumulate) {
+            result = this.accumulateMetric(metric, span, statistic, owner, start, period);
+        }
+        else {
+            result = this.calculateSeries(metric, span, statistic, owner, start, period);
+        }
+        result.id = options.id;
+        this.log[options.log == true ? 'info' : 'trace'](`Query metrics ${namespace}, ${metricName}`, {
+            dimensions,
+            period,
+            statistic,
+            options,
+            result,
+        });
+        return result;
+    }
+    accumulateMetric(metric, span, statistic, owner, start, period) {
+        let value = 0, count = 0, pvalues = [];
+        if (statistic == 'max') {
+            value = Number.NEGATIVE_INFINITY;
+        }
+        else if (statistic == 'min') {
+            value = Infinity;
+        }
+        else if (statistic == 'sum') {
+            value = 0;
+            count = 0;
+        }
+        else if (statistic == 'count') {
+            value = 0;
+            count = 0;
+        }
+        else if (statistic == 'current') {
+            value = 0;
+            count = 0;
+        }
+        else if (statistic.match(/^p[0-9]+/)) {
+            pvalues = [];
+        }
+        else {
+            value = 0;
+            count = 0;
+        }
+        let points = span.points;
+        let interval = span.period / span.samples;
+        let t = span.end - span.points.length * interval;
+        for (let i = 0; i < points.length; i++) {
+            let point = points[i];
+            if (start <= t && t < start + period) {
+                if (statistic == 'max') {
+                    if (point.max != undefined) {
+                        value = Math.max(value, point.max);
+                    }
+                    else {
+                        value = Math.max(value, point.sum / (point.count || 1));
+                    }
+                }
+                else if (statistic == 'min') {
+                    if (point.min != undefined) {
+                        value = Math.min(value, point.min);
+                    }
+                    else {
+                        value = Math.min(value, point.sum / (point.count || 1));
+                    }
+                }
+                else if (statistic == 'sum') {
+                    value += point.sum;
+                }
+                else if (statistic == 'current') {
+                    value = point.sum / (point.count || 1);
+                }
+                else if (statistic == 'count') {
+                    value += point.count;
+                }
+                else if (statistic.match(/^p[0-9]+/)) {
+                    pvalues = pvalues.concat(point.pvalues);
+                }
+                else {
+                    value += point.sum;
+                }
+                count += point.count;
+            }
+            t += interval;
+        }
+        if (statistic.match(/^p[0-9]+/)) {
+            let p = parseInt(statistic.slice(1));
+            pvalues.sort((a, b) => a - b);
+            let nth = Math.min(Math.round((pvalues.length * p) / 100 + 1), pvalues.length - 1);
+            value = pvalues[nth];
+        }
+        else if (statistic == 'avg') {
+            value /= Math.max(count, 1);
+        }
+        return {
+            dimensions: this.makeDimensionObject(metric.dimensions),
+            metric: metric.metric,
+            namespace: metric.namespace,
+            owner: owner,
+            period: span.period,
+            points: [{ value, timestamp: start + period, count }],
+            samples: span.samples,
+        };
+    }
+    calculateSeries(metric, span, statistic, owner, start, period) {
+        let points = [];
+        let interval = span.period / span.samples;
+        let t;
+        let firstPoint = span.end - span.points.length * interval;
+        let count = Math.floor((firstPoint - start) / interval);
+        for (t = start; t < firstPoint && points.length < span.samples; t += interval) {
+            points.push({ value: 0, count: 0, timestamp: t * 1000 });
+        }
+        t = firstPoint;
+        for (let point of span.points) {
+            if (start <= t && t < start + period) {
+                let value = undefined;
+                if (point.count > 0) {
+                    if (statistic == 'max') {
+                        if (point.max != undefined) {
+                            if (value == undefined) {
+                                value = point.max;
+                            }
+                            else {
+                                value = Math.max(value, point.max);
+                            }
+                        }
+                    }
+                    else if (statistic == 'min') {
+                        if (point.min != undefined) {
+                            if (value == undefined) {
+                                value = point.min;
+                            }
+                            else {
+                                value = Math.min(value, point.min);
+                            }
+                        }
+                    }
+                    else if (statistic == 'sum') {
+                        value = point.sum;
+                    }
+                    else if (statistic == 'count') {
+                        value = point.count;
+                    }
+                    else if (statistic.match(/^p[0-9]+/)) {
+                        let p = parseInt(statistic.slice(1));
+                        let pvalues = point.pvalues;
+                        pvalues.sort((a, b) => a - b);
+                        let nth = Math.min(Math.round((pvalues.length * p) / 100 + 1), pvalues.length - 1);
+                        value = pvalues[nth];
+                    }
+                    else {
+                        value = point.sum / point.count;
+                    }
+                }
+                else {
+                    value = 0;
+                }
+                points.push({ value, count: point.count, timestamp: (t + interval) * 1000 });
+            }
+            t += interval;
+        }
+        count = Math.ceil(period / interval);
+        while (points.length < count) {
+            points.push({ value: 0, count: 0, timestamp: t * 1000 });
+            t += interval;
+        }
+        return {
+            dimensions: this.makeDimensionObject(metric.dimensions),
+            metric: metric.metric,
+            namespace: metric.namespace,
+            period: span.period,
+            points: points,
+            owner: owner,
+            samples: span.samples,
+        };
+    }
+    makeDimensionString(dimensions) {
+        let result = [];
+        let entries = Object.entries(dimensions).sort((a, b) => a[0].localeCompare(b[0]));
+        for (let [name, value] of entries) {
+            result.push(`${name}=${value}`);
+        }
+        return result.join(',');
+    }
+    makeDimensionObject(dimensions) {
+        let result = {};
+        for (let dimension of dimensions.split(',')) {
+            if (dimension) {
+                let [key, value] = dimension.split('=');
+                result[key] = value;
+            }
+        }
+        return result;
+    }
+    addValue(metric, timestamp, point, si, querySpanIndex = undefined) {
+        this.assert(metric);
+        this.assert(timestamp);
+        this.assert(0 <= si && si < metric.spans.length);
+        let span = metric.spans[si];
+        let interval = span.period / span.samples;
+        let points = span.points || [];
+        let queryRecurse = si < querySpanIndex && si + 1 < metric.spans.length;
+        while (points.length > span.samples) {
+            points.shift();
+        }
+        let first = span.end - points.length * interval;
+        let shift = 0;
+        if (points.length) {
+            if (queryRecurse) {
+                shift = points.length;
+            }
+            else if (timestamp >= first) {
+                shift = Math.floor((timestamp - first) / interval) - span.samples;
+                if (!queryRecurse && point.count && timestamp >= span.end) {
+                    shift += 1;
+                }
+            }
+            shift = Math.max(0, Math.min(shift, points.length));
+            this.assert(0 <= shift && shift <= points.length);
+            for (let i = 0; i < shift; i++) {
+                let p = points.shift();
+                if (p.count && si + 1 < metric.spans.length) {
+                    this.addValue(metric, first, p, si + 1, querySpanIndex);
+                }
+                first += interval;
+            }
+        }
+        if (queryRecurse) {
+            this.addValue(metric, timestamp, point, si + 1, querySpanIndex);
+            return;
+        }
+        if (point.count) {
+            let index;
+            if (points.length == 0) {
+                points.push({ count: 0, sum: 0 });
+                span.end = this.roundTime(span, timestamp + 1);
+                first = span.end - interval;
+                index = 0;
+            }
+            else {
+                if (timestamp < span.end - span.period) {
+                    return;
+                }
+                while (timestamp < first) {
+                    points.unshift({ count: 0, sum: 0 });
+                    first -= interval;
+                }
+                while (timestamp >= span.end) {
+                    points.push({ count: 0, sum: 0 });
+                    span.end += interval;
+                }
+                index = Math.floor((timestamp - first) / interval);
+            }
+            this.assert(points.length <= span.samples);
+            if (!(0 <= index && index < points.length)) {
+                this.assert(0 <= index && index < points.length);
+                if (index > 0) {
+                    index = points.length - 1;
+                }
+            }
+            this.setPoint(span, index, point);
+        }
+    }
+    setPoint(span, index, add) {
+        let points = span.points;
+        this.assert(0 <= index && index < points.length);
+        let point = points[index];
+        if (!point) {
+            this.log.error(`Metric null point`, { span, index, add });
+            return;
+        }
+        if (add.count) {
+            let value = add.sum / add.count;
+            if (point.min == undefined) {
+                point.min = value;
+            }
+            else {
+                point.min = Math.min(value, point.min);
+            }
+            if (point.max == undefined) {
+                point.max = value;
+            }
+            else {
+                point.max = Math.max(value, point.max);
+            }
+        }
+        if (this.pResolution) {
+            point.pvalues = point.pvalues || [];
+            if (add.pvalues) {
+                point.pvalues.push(...add.pvalues);
+            }
+            else {
+                point.pvalues.push(add.sum / add.count);
+            }
+            point.pvalues.splice(0, point.pvalues.length - this.pResolution);
+        }
+        point.sum += add.sum;
+        point.count += add.count;
+    }
+    async getMetricList(namespace = undefined, metric = undefined, options = { limit: MetricListLimit }) {
+        let map = {};
+        let owner = options.owner || this.owner;
+        let next = options.next;
+        let limit = options.limit || MetricListLimit;
+        let chan = options.log == true ? 'info' : 'trace';
+        let items, command;
+        let count = 0;
+        do {
+            ;
+            ({ command, items, next } = await this.findMetrics(owner, namespace, metric, limit, next));
+            this.log[chan](`Find metrics ${namespace}, ${metric}`, { command, items });
+            if (items.length) {
+                for (let item of items) {
+                    let ns = (map[item.namespace] = map[item.namespace] || {});
+                    let met = (ns[item.metric] = ns[item.metric] || []);
+                    met.push(item.dimensions);
+                }
+                count += items.length;
+            }
+        } while (next && count < limit);
+        let result = { namespaces: Object.keys(map) };
+        if (namespace && map[namespace]) {
+            result.metrics = Object.keys(map[namespace]);
+            if (metric) {
+                let dimensions = map[namespace][metric];
+                if (dimensions) {
+                    result.dimensions = [];
+                    dimensions = dimensions.sort().filter((v, index, self) => self.indexOf(v) === index);
+                    for (let dimension of dimensions) {
+                        result.dimensions.push(this.makeDimensionObject(dimension));
+                    }
+                }
+            }
+        }
+        return result;
+    }
+    initMetric(owner, namespace, name, dimensions, timestamp) {
+        let metric = {
+            dimensions,
+            metric: name,
+            namespace,
+            owner,
+            spans: [],
+            version: Version,
+        };
+        for (let sdef of this.spans) {
+            let span = {
+                samples: sdef.samples,
+                period: sdef.period,
+                end: timestamp,
+                points: [],
+            };
+            span.end = this.roundTime(span, timestamp + 1);
+            metric.spans.push(span);
+        }
+        return metric;
+    }
+    async getMetric(owner, namespace, metric, dimensions, log) {
+        let command = new client_dynamodb_1.GetItemCommand({
+            TableName: this.table,
+            Key: {
+                [this.primaryKey]: { S: `${this.prefix}#${Version}#${owner}` },
+                [this.sortKey]: { S: `${this.prefix}#${namespace}#${metric}#${dimensions}` },
+            },
+            ConsistentRead: this.consistent,
+        });
+        let data = await this.client.send(command);
+        let result = null;
+        if (data && data.Item) {
+            let item = (0, util_dynamodb_1.unmarshall)(data.Item);
+            result = this.mapItemFromDB(item);
+        }
+        if (log == true) {
+            let chan = log == true ? 'info' : 'trace';
+            this.log[chan](`GetMetric ${namespace}, ${metric} ${dimensions}`, { cmd: command, result });
+        }
+        return result;
+    }
+    async findMetrics(owner, namespace, metric, limit, startKey) {
+        let key = [namespace];
+        if (metric) {
+            key.push(metric);
+        }
+        let start = startKey ? (0, util_dynamodb_1.marshall)(startKey) : undefined;
+        let command = new client_dynamodb_1.QueryCommand({
+            TableName: this.table,
+            ExpressionAttributeNames: {
+                '#_0': this.primaryKey,
+                '#_1': this.sortKey,
+            },
+            ExpressionAttributeValues: {
+                ':_0': { S: `${this.prefix}#${Version}#${owner}` },
+                ':_1': { S: `${this.prefix}#${key.join('#')}` },
+            },
+            KeyConditionExpression: '#_0 = :_0 and begins_with(#_1, :_1)',
+            ConsistentRead: this.consistent,
+            Limit: limit,
+            ScanIndexForward: true,
+            ExclusiveStartKey: start,
+            ProjectionExpression: `${this.primaryKey}, ${this.sortKey}`,
+        });
+        let result = await this.client.send(command);
+        let items = [];
+        if (result.Items) {
+            for (let i = 0; i < result.Items.length; i++) {
+                let item = (0, util_dynamodb_1.unmarshall)(result.Items[i]);
+                items.push(this.mapItemFromDB(item));
+            }
+        }
+        let next = undefined;
+        if (result.LastEvaluatedKey) {
+            next = (0, util_dynamodb_1.unmarshall)(result.LastEvaluatedKey);
+        }
+        return { items, next, command };
+    }
+    async putMetric(item, options) {
+        let ConditionExpression, ExpressionAttributeValues;
+        let seq;
+        if (item.seq != undefined) {
+            seq = item.seq = item.seq || 0;
+            if (item.seq++ >= MaxSeq) {
+                item.seq = 0;
+            }
+            ConditionExpression = `seq = :_0`;
+            ExpressionAttributeValues = { ':_0': { N: seq.toString() } };
+        }
+        else {
+            item.seq = 0;
+        }
+        let mapped = this.mapItemToDB(item);
+        let params = {
+            TableName: this.table,
+            ReturnValues: 'NONE',
+            Item: (0, util_dynamodb_1.marshall)(mapped, { removeUndefinedValues: true }),
+            ConditionExpression,
+            ExpressionAttributeValues,
+        };
+        let command = new client_dynamodb_1.PutItemCommand(params);
+        let chan = options.log == true ? 'info' : 'trace';
+        this.log[chan](`Put metric ${item.namespace}, ${item.metric}`, {
+            dimensions: item.dimensions,
+            command,
+            params,
+            item,
+        });
+        try {
+            await this.client.send(command);
+            return true;
+        }
+        catch (err) {
+            ;
+            (function (err, log) {
+                let code = err.code || err.name;
+                if (code == 'ConditionalCheckFailedException') {
+                    log.trace(`Update collision`, { err });
+                }
+                else if (code == 'ProvisionedThroughputExceededException') {
+                    log.info(`Provisioned throughput exceeded: ${err.message}`, { err, cmd: command, item });
+                }
+                else {
+                    log.error(`Emit exception code ${err.name} ${err.code} message ${err.message}`, {
+                        err,
+                        cmd: command,
+                        item,
+                    });
+                    throw err;
+                }
+                return false;
+            })(err, this.log);
+        }
+    }
+    mapItemFromDB(data) {
+        let pk = data[this.primaryKey];
+        let sk = data[this.sortKey];
+        let owner = pk.split('#').pop();
+        let [, namespace, metric, dimensions] = sk.split('#');
+        let spans;
+        if (data.spans) {
+            spans = data.spans.map((s) => {
+                return {
+                    end: s.se,
+                    period: s.sp,
+                    samples: s.ss,
+                    points: s.pt.map((p) => {
+                        let point = { count: Number(p.c), sum: Number(p.s) };
+                        if (p.x != null) {
+                            point.max = Number(p.x);
+                        }
+                        if (p.m != null) {
+                            point.min = Number(p.m);
+                        }
+                        if (p.v) {
+                            point.pvalues = p.v;
+                        }
+                        return point;
+                    }),
+                };
+            });
+        }
+        let expires = data[this.expires];
+        let seq = data.seq;
+        return { dimensions, expires, metric, namespace, owner, seq, spans };
+    }
+    mapItemToDB(item) {
+        let result = {
+            [this.primaryKey]: `${this.prefix}#${Version}#${item.owner}`,
+            [this.sortKey]: `${this.prefix}#${item.namespace}#${item.metric}#${item.dimensions}`,
+            [this.expires]: item.expires,
+            spans: item.spans.map((i) => {
+                return {
+                    se: i.end,
+                    sp: i.period,
+                    ss: i.samples,
+                    pt: i.points.map((point) => {
+                        let p = { c: point.count, s: this.round(point.sum) };
+                        if (point.max != null) {
+                            p.x = this.round(point.max);
+                        }
+                        if (point.min != null) {
+                            p.m = this.round(point.min);
+                        }
+                        if (point.pvalues) {
+                            p.v = point.pvalues;
+                        }
+                        return p;
+                    }),
+                };
+            }),
+            seq: item.seq,
+            _source: item._source,
+        };
+        if (this.type) {
+            let [key, model] = Object.entries(this.type)[0];
+            result[key] = model;
+        }
+        return result;
+    }
+    static freeInstanceByKey(key) {
+        delete Instances[key];
+    }
+    static saveInstance(tags, metrics) {
+        let key = JSON.stringify(tags);
+        Instances[key] = metrics;
+    }
+    roundTime(span, timestamp) {
+        let interval = span.period / span.samples;
+        return Math.ceil(timestamp / interval) * interval;
+    }
+    assert(c) {
+        if (!c && Assert) {
+            let msg = { stack: '' };
+            if (typeof Error.captureStackTrace === 'function') {
+                Error.captureStackTrace(msg);
+            }
+            else {
+                msg.stack = new Error('Assert').stack;
+            }
+            this.log.error(`Assertion failed`, { stack: msg.stack });
+        }
+    }
+    info(message, context = {}) {
+        console.log('INFO: ' + message, context);
+    }
+    error(message, context = {}) {
+        console.log('ERROR: ' + message, context);
+    }
+    trace(message, context = {}) {
+        console.log('TRACE: ' + message, context);
+    }
+    round(n) {
+        if (isNaN(n) || n == null) {
+            return 0;
+        }
+        let places = 16 - n.toFixed(0).length;
+        return Number(n.toFixed(places)) - 0;
+    }
+    jitter(msecs) {
+        return Math.min(10 * 1000, Math.floor(msecs / 2 + msecs * Math.random()));
+    }
+    async delay(time) {
+        return new Promise(function (resolve, reject) {
+            setTimeout(() => resolve(true), time);
+        });
+    }
+}
+exports.CustomMetrics = CustomMetrics;
+class Log {
+    senselogs = null;
+    logger = null;
+    verbose = false;
+    constructor(dest) {
+        if (dest === true) {
+            this.logger = this.defaultLogger;
+        }
+        else if (dest == 'verbose') {
+            this.logger = this.defaultLogger;
+            this.verbose = true;
+        }
+        else if (dest && typeof dest.info == 'function') {
+            this.senselogs = dest;
+        }
+    }
+    error(message, context) {
+        this.process('error', message, context);
+    }
+    info(message, context) {
+        this.process('info', message, context);
+    }
+    trace(message, context) {
+        this.process('trace', message, context);
+    }
+    process(chan, message, context) {
+        if (this.logger) {
+            this.logger(chan, message, context);
+        }
+        else if (this.senselogs) {
+            this.senselogs[chan](message, context);
+        }
+    }
+    defaultLogger(chan, message, context) {
+        if (chan == 'trace' && !this.verbose) {
+            return;
+        }
+        let tag = chan.toUpperCase();
+        if (context) {
+            try {
+                console.log(tag, message, JSON.stringify(context, null, 4));
+            }
+            catch (err) {
+                let buf = ['{'];
+                for (let [key, value] of Object.entries(context)) {
+                    try {
+                        buf.push(`    ${key}: ${JSON.stringify(value, null, 4)}`);
+                    }
+                    catch (err) {
+                    }
+                }
+                buf.push('}');
+                console.log(tag, message, buf.join('\n'));
+            }
+        }
+        else {
+            console.log(tag, message);
+        }
+    }
+}
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/doc/schema.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/doc/schema.d.ts
new file mode 100644
index 0000000..2145db9
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/doc/schema.d.ts
@@ -0,0 +1,132 @@
+declare const Version = 1;
+declare const Schema: {
+    format: string;
+    version: string;
+    indexes: {
+        primary: {
+            hash: string;
+            sort: string;
+        };
+    };
+    models: {
+        readonly Metric: {
+            readonly pk: {
+                readonly type: "string";
+                readonly value: "metric#${version}#${owner}";
+            };
+            readonly sk: {
+                readonly type: "string";
+                readonly value: "metric#${namespace}#${metric}#${dimensions}";
+            };
+            readonly dimensions: {
+                readonly type: "string";
+                readonly required: true;
+                readonly encode: readonly ["sk", "#", "3"];
+            };
+            readonly expires: {
+                readonly type: "date";
+                readonly ttl: true;
+            };
+            readonly metric: {
+                readonly type: "string";
+                readonly required: true;
+                readonly encode: readonly ["sk", "#", "2"];
+            };
+            readonly namespace: {
+                readonly type: "string";
+                readonly required: true;
+                readonly encode: readonly ["sk", "#", "1"];
+            };
+            readonly owner: {
+                readonly type: "string";
+                readonly required: true;
+                readonly encode: readonly ["pk", "#", "2"];
+            };
+            readonly version: {
+                readonly type: "number";
+                readonly default: 1;
+                readonly encode: readonly ["pk", "#", "1"];
+            };
+            readonly id: {
+                readonly type: "string";
+            };
+            readonly spans: {
+                readonly type: "array";
+                readonly required: true;
+                readonly default: readonly [];
+                readonly items: {
+                    readonly type: "object";
+                    readonly default: {};
+                    readonly schema: {
+                        readonly end: {
+                            readonly type: "number";
+                            readonly required: true;
+                            readonly map: "se";
+                        };
+                        readonly period: {
+                            readonly type: "number";
+                            readonly required: true;
+                            readonly map: "sp";
+                        };
+                        readonly samples: {
+                            readonly type: "number";
+                            readonly required: true;
+                            readonly map: "ss";
+                        };
+                        readonly points: {
+                            readonly type: "array";
+                            readonly required: true;
+                            readonly map: "pt";
+                            readonly default: readonly [];
+                            readonly items: {
+                                readonly type: "object";
+                                readonly schema: {
+                                    readonly count: {
+                                        readonly type: "number";
+                                        readonly required: true;
+                                        readonly map: "c";
+                                    };
+                                    readonly max: {
+                                        readonly type: "number";
+                                        readonly map: "x";
+                                    };
+                                    readonly min: {
+                                        readonly type: "number";
+                                        readonly map: "m";
+                                    };
+                                    readonly sum: {
+                                        readonly type: "number";
+                                        readonly required: true;
+                                        readonly map: "s";
+                                    };
+                                    readonly pvalues: {
+                                        readonly type: "array";
+                                        readonly map: "v";
+                                    };
+                                    readonly timestamp: {
+                                        readonly type: "number";
+                                        readonly map: "e";
+                                    };
+                                };
+                            };
+                        };
+                    };
+                };
+            };
+            readonly seq: {
+                readonly type: "number";
+                readonly default: 0;
+            };
+            readonly _source: {
+                readonly type: "string";
+            };
+        };
+    };
+    params: {
+        isoDates: boolean;
+        nulls: boolean;
+        timestamps: boolean;
+        typeField: string;
+    };
+};
+export { Schema, Version };
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/doc/schema.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/doc/schema.js
new file mode 100644
index 0000000..5baa10e
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/doc/schema.js
@@ -0,0 +1,68 @@
+"use strict";
+Object.defineProperty(exports, "__esModule", { value: true });
+exports.Version = exports.Schema = void 0;
+/*
+    schema.ts -- CustomMetrics Schema
+ */
+const Version = 1;
+exports.Version = Version;
+const Schema = {
+    format: 'onetable:1.1.0',
+    version: '0.0.1',
+    indexes: { primary: { hash: 'pk', sort: 'sk' } },
+    models: {
+        Metric: {
+            pk: { type: 'string', value: 'metric#${version}#${owner}' },
+            sk: { type: 'string', value: 'metric#${namespace}#${metric}#${dimensions}' },
+            dimensions: { type: 'string', required: true, encode: ['sk', '#', '3'] },
+            expires: { type: 'date', ttl: true },
+            metric: { type: 'string', required: true, encode: ['sk', '#', '2'] },
+            namespace: { type: 'string', required: true, encode: ['sk', '#', '1'] },
+            owner: { type: 'string', required: true, encode: ['pk', '#', '2'] },
+            version: { type: 'number', default: Version, encode: ['pk', '#', '1'] },
+            id: { type: 'string' }, // Never stored. Preserved on query
+            spans: {
+                type: 'array',
+                required: true,
+                default: [],
+                items: {
+                    type: 'object',
+                    default: {},
+                    schema: {
+                        // When the points will be full.
+                        end: { type: 'number', required: true, map: 'se' },
+                        period: { type: 'number', required: true, map: 'sp' },
+                        samples: { type: 'number', required: true, map: 'ss' },
+                        points: {
+                            type: 'array',
+                            required: true,
+                            map: 'pt',
+                            default: [],
+                            items: {
+                                type: 'object',
+                                schema: {
+                                    count: { type: 'number', required: true, map: 'c' },
+                                    max: { type: 'number', map: 'x' },
+                                    min: { type: 'number', map: 'm' },
+                                    sum: { type: 'number', required: true, map: 's' },
+                                    //  Never stored
+                                    pvalues: { type: 'array', map: 'v' },
+                                    timestamp: { type: 'number', map: 'e', },
+                                },
+                            },
+                        },
+                    },
+                },
+            },
+            seq: { type: 'number', default: 0 },
+            _source: { type: 'string' }, // When set, bypass DynamoDB steams change detection
+        }
+    },
+    params: {
+        isoDates: false,
+        nulls: false,
+        timestamps: false,
+        typeField: '_type',
+    },
+};
+exports.Schema = Schema;
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/jest.config.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/jest.config.d.ts
new file mode 100644
index 0000000..a987825
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/jest.config.d.ts
@@ -0,0 +1,14 @@
+export let coveragePathIgnorePatterns: string[];
+export let coverageDirectory: string;
+export namespace globals {
+    let __DYNAMODB__: any;
+}
+export let roots: string[];
+export let testMatch: string[];
+export let globalSetup: string;
+export let globalTeardown: string;
+export let testEnvironment: string;
+export let transform: {
+    '^.+\\.(js|ts)$': string;
+};
+export let verbose: any;
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/jest.config.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/jest.config.js
new file mode 100644
index 0000000..068ad4b
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/jest.config.js
@@ -0,0 +1,34 @@
+/*
+   Jest configuration
+ */
+module.exports = {
+    "coveragePathIgnorePatterns": [
+        "node_modules",
+        "test/utils"
+    ],
+    coverageDirectory: "coverage",
+    globals: {
+        __DYNAMODB__: null,
+    },
+    roots: [
+        "<rootDir>/src",
+        "<rootDir>/test"
+    ],
+    testMatch: [
+        "**/*.[jt]s",
+        "!**/src/*.[jt]s",
+        "!**/setup.[jt]s",
+        "!**/init.[jt]s",
+        "!**/teardown.[jt]s",
+        "!**/helpers.[jt]s",
+        "!**/schemas/*",
+    ],
+    globalSetup: '<rootDir>/test/utils/setup.ts',
+    globalTeardown: '<rootDir>/test/utils/teardown.ts',
+    testEnvironment: "node",
+    transform: {
+        '^.+\\.(js|ts)$': 'ts-jest'
+    },
+    verbose: undefined
+    // setupFiles: ['<rootDir>/test/utils/helpers.ts'],
+};
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/src/index.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/src/index.d.ts
new file mode 100644
index 0000000..a72dd56
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/src/index.d.ts
@@ -0,0 +1,193 @@
+import { DynamoDBClient, QueryCommand } from '@aws-sdk/client-dynamodb';
+export type SpanDef = {
+    period: number;
+    samples: number;
+};
+export declare const DefaultSpans: SpanDef[];
+export type Metric = {
+    dimensions: string;
+    expires?: number;
+    id?: string;
+    metric: string;
+    namespace: string;
+    owner?: string;
+    version?: number;
+    spans: Span[];
+    seq?: number;
+    _source?: string;
+};
+export type Point = {
+    count: number;
+    max?: number;
+    min?: number;
+    pvalues?: number[];
+    sum: number;
+    timestamp?: number;
+};
+export type Span = {
+    end: number;
+    period: number;
+    samples: number;
+    points: Point[];
+};
+export type MetricDimensions = {
+    [key: string]: unknown;
+};
+export type MetricDimensionsList = MetricDimensions[];
+export type MetricList = {
+    namespaces: string[];
+    metrics?: string[];
+    dimensions?: MetricDimensions[];
+};
+export type MetricQueryPoint = {
+    count: number;
+    timestamp?: number;
+    value?: number;
+};
+export type MetricQueryResult = {
+    dimensions: MetricDimensions;
+    id?: string;
+    metric: string;
+    namespace: string;
+    owner: string;
+    period: number;
+    points: MetricQueryPoint[];
+    samples: number;
+};
+export type MetricOptions = {
+    buffer?: MetricBufferOptions;
+    client?: DynamoDBClient;
+    consistent?: boolean;
+    creds?: object;
+    expires?: string;
+    log?: true | 'verbose' | any;
+    owner?: string;
+    prefix?: string;
+    pResolution?: number;
+    primaryKey?: string;
+    region?: string;
+    sortKey?: string;
+    source?: string;
+    spans?: SpanDef[];
+    table?: string;
+    ttl?: number;
+    type?: {
+        [key: string]: string;
+    };
+};
+export type MetricBufferOptions = {
+    sum?: number;
+    count?: number;
+    elapsed?: number;
+    force?: boolean;
+};
+export type MetricEmitOptions = {
+    buffer?: MetricBufferOptions;
+    log?: boolean;
+    owner?: string;
+    timestamp?: number;
+    ttl?: number;
+    upgrade?: boolean;
+};
+export type MetricListOptions = {
+    log?: boolean;
+    limit?: number;
+    owner?: string;
+    next?: object;
+    timestamp?: number;
+};
+export type MetricQueryOptions = {
+    accumulate?: boolean;
+    id?: string;
+    log?: boolean;
+    owner?: string;
+    start?: number;
+    timestamp?: number;
+};
+type BufferElt = {
+    count: number;
+    dimensions: string;
+    metric: string;
+    namespace: string;
+    spans: Span[];
+    sum: number;
+    timestamp: number;
+    elapsed: number;
+};
+export declare class CustomMetrics {
+    private consistent;
+    private buffer;
+    private buffers;
+    private client;
+    private expires;
+    private log;
+    private options;
+    private owner;
+    private prefix;
+    private primaryKey;
+    private sortKey;
+    private pResolution;
+    private source;
+    private spans;
+    private table;
+    private type;
+    private ttl;
+    constructor(options?: MetricOptions);
+    emit(namespace: string, metricName: string, value: number, dimensionsList?: MetricDimensionsList, options?: MetricEmitOptions): Promise<Metric>;
+    private emitDimensions;
+    bufferMetric(namespace: string, metricName: string, point: Point, dimensions: string, options: MetricEmitOptions): Promise<Metric>;
+    private emitDimensionedMetric;
+    upgrade(namespace: string, metricName: string, dimensionsList?: MetricDimensionsList, options?: MetricEmitOptions): Promise<Metric>;
+    upgradeMetric(old: Metric): Metric;
+    static terminate(): Promise<void>;
+    static flushAll(): Promise<void>;
+    flush(options?: MetricQueryOptions): Promise<void>;
+    flushElt(elt: BufferElt, now: number): Promise<void>;
+    getBufferKey(namespace: string, metricName: string, dimensions: string): string;
+    query(namespace: string, metricName: string, dimensions: MetricDimensions, period: number, statistic: string, options?: MetricQueryOptions): Promise<MetricQueryResult>;
+    queryMetrics(namespace: string, metric: string | undefined, period: number, statistic: string, options?: MetricListOptions): Promise<MetricQueryResult[]>;
+    processMetric(metric: Metric, now: number, period: number, statistic: string, options: MetricQueryOptions): MetricQueryResult;
+    private accumulateMetric;
+    private calculateSeries;
+    private makeDimensionString;
+    private makeDimensionObject;
+    private addValue;
+    private setPoint;
+    getMetricList(namespace?: string, metric?: string, options?: MetricListOptions): Promise<MetricList>;
+    private initMetric;
+    getMetric(owner: string, namespace: string, metric: string, dimensions: string, log: boolean): Promise<Metric>;
+    findMetrics(owner: string, namespace: string, metric: string | undefined, limit: number, startKey: object, fields?: string): Promise<{
+        items: Metric[];
+        next: object;
+        command: QueryCommand;
+    }>;
+    putMetric(item: Metric, options: MetricEmitOptions): Promise<boolean>;
+    mapItemFromDB(data: any): Metric;
+    mapItemToDB(item: Metric): {
+        [x: string]: string | number | {
+            se: number;
+            sp: number;
+            ss: number;
+            pt: any[];
+        }[];
+        spans: {
+            se: number;
+            sp: number;
+            ss: number;
+            pt: any[];
+        }[];
+        seq: number;
+        _source: string;
+    };
+    static freeInstanceByKey(key: string): void;
+    static saveInstance(tags: object, metrics: CustomMetrics): void;
+    private alignTime;
+    private assert;
+    private info;
+    private error;
+    private trace;
+    round(n: number): number;
+    jitter(msecs: number): number;
+    delay(time: number): Promise<boolean>;
+}
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/src/index.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/src/index.js
new file mode 100644
index 0000000..6735924
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/src/index.js
@@ -0,0 +1,1229 @@
+"use strict";
+var __importDefault = (this && this.__importDefault) || function (mod) {
+    return (mod && mod.__esModule) ? mod : { "default": mod };
+};
+Object.defineProperty(exports, "__esModule", { value: true });
+exports.CustomMetrics = exports.DefaultSpans = void 0;
+/*
+    CustomMetrics - Simple, configurable, economical metrics for AWS
+
+    See the README for the Metric schema details.
+ */
+const process_1 = __importDefault(require("process"));
+const client_dynamodb_1 = require("@aws-sdk/client-dynamodb");
+const util_dynamodb_1 = require("@aws-sdk/util-dynamodb");
+const Version = 1;
+//MOB disable
+const Assert = true; // Enable asserts
+const Buffering = true; // Enable buffered metrics
+const DefaultResolution = 0; // Default number of p-values to store
+const MaxSeq = Number.MAX_SAFE_INTEGER; // Maximum sequence number for collision detection
+const MaxRetries = 10; // Max retries when emitting a metric and encountering collisions
+const MetricListLimit = 10000; // Sanity limit for getting a list of metrics
+/*
+    Default spans are configurable by the constructor
+ */
+exports.DefaultSpans = [
+    { period: 5 * 60, samples: 10 }, //  300, 5 mins, interval: 30 secs
+    { period: 60 * 60, samples: 12 }, //  3600, 1 hr, interval: 5 mins
+    { period: 24 * 60 * 60, samples: 12 }, // 86400, 24 hrs, interval: 2 hrs
+    { period: 7 * 24 * 60 * 60, samples: 14 }, // 604,800, 7 days, interval: 1/2 day
+    { period: 28 * 24 * 60 * 60, samples: 14 }, // 2,419,200, 28 days, interval: 2 days
+    { period: 365 * 24 * 60 * 60, samples: 12 }, // 31,536,000, 1 year, interval: 1 month
+];
+var Instances = {};
+/*
+    On exit, flush any buffered metrics. This requires any Lambda Layer to receive this signal
+ */
+process_1.default.on('SIGTERM', 
+/* istanbul ignore next */
+async () => {
+    /* istanbul ignore next */
+    await CustomMetrics.terminate();
+});
+class CustomMetrics {
+    consistent = false;
+    buffer;
+    buffers = null;
+    client;
+    expires;
+    log;
+    options;
+    owner;
+    prefix = 'metric';
+    primaryKey;
+    sortKey;
+    pResolution;
+    source;
+    spans;
+    table;
+    type;
+    ttl;
+    constructor(options = {}) {
+        this.log = new Log(options.log);
+        if (options.ttl && typeof options.ttl != 'number') {
+            throw new Error('Bad type for "ttl" option');
+        }
+        if (options.spans && (!Array.isArray(options.spans) || options.spans.length == 0)) {
+            throw new Error('The "spans" option must be an non-empty array');
+        }
+        if (options.source && typeof options.source != 'string') {
+            throw new Error('Non-string "source" option');
+        }
+        if (options.pResolution != undefined && (options.pResolution < 0 || options.pResolution > 1000)) {
+            throw new Error('Invalid "pResolution" option. Must be between 0 and 1000. Default is 0');
+        }
+        if (options.consistent != null && typeof options.consistent != 'boolean') {
+            throw new Error('Bad type for "consistent" option');
+        }
+        if (options.prefix) {
+            this.prefix = options.prefix;
+        }
+        if (options.buffer) {
+            if (typeof options.buffer != 'object') {
+                throw new Error('Bad type for "buffer" option');
+            }
+            this.buffer = options.buffer;
+        }
+        this.expires = options.expires || 'expires';
+        this.primaryKey = options.primaryKey || 'pk';
+        this.sortKey = options.sortKey || 'sk';
+        this.type = options.type || { _type: 'Metric' };
+        /* istanbul ignore else */
+        if (options.client) {
+            this.client = options.client;
+        }
+        else {
+            let params = {};
+            if (options.creds) {
+                params.credentials = options.creds;
+                //  Allow region in credentials
+                params.region = params.credentials.region;
+            }
+            if (options.region) {
+                params.region = options.region;
+            }
+            this.client = new client_dynamodb_1.DynamoDBClient(params);
+        }
+        if (!options.table) {
+            throw new Error('Missing DynamoDB table name property');
+        }
+        /* istanbul ignore next */
+        this.table = options.table;
+        this.options = options;
+        this.owner = options.owner || 'default';
+        this.spans = options.spans || exports.DefaultSpans;
+        this.ttl = options.ttl || this.spans[this.spans.length - 1].period;
+        if (options.consistent != null) {
+            this.consistent = options.consistent;
+        }
+        if (options.source) {
+            this.source = options.source;
+        }
+        this.pResolution = options.pResolution || DefaultResolution;
+    }
+    async emit(namespace, metricName, value, dimensionsList = [{}], options = {}) {
+        if (value == undefined || value == null) {
+            throw new Error('Invalid metric value');
+        }
+        if (dimensionsList.length == 0) {
+            dimensionsList = [{}];
+        }
+        value = Number(value);
+        if (isNaN(value)) {
+            throw new Error(`Value to emit is not valid`);
+        }
+        if (!namespace || !metricName) {
+            throw new Error('Missing emit namespace / metric argument');
+        }
+        /* istanbul ignore next */
+        if (!Array.isArray(dimensionsList)) {
+            throw new Error('Dimensions must be an array');
+        }
+        if (dimensionsList.length == 0) {
+            dimensionsList = [{}];
+        }
+        let point;
+        point = { count: 1, sum: value };
+        return await this.emitDimensions(namespace, metricName, point, dimensionsList, options);
+    }
+    async emitDimensions(namespace, metricName, point, dimensionsList, options) {
+        let result;
+        for (let dim of dimensionsList) {
+            let dimensions = this.makeDimensionString(dim);
+            let buffer = options.buffer || this.buffer;
+            if (buffer && (buffer.elapsed || buffer.force || buffer.sum || buffer.count) && Buffering) {
+                result = await this.bufferMetric(namespace, metricName, point, dimensions, options);
+            }
+            else {
+                result = await this.emitDimensionedMetric(namespace, metricName, point, dimensions, options);
+            }
+        }
+        return result;
+    }
+    /*
+        Buffer a metric for specific dimensions
+        Point values are uniquely buffered in elements indexed by a (namespace, metric, dimensions) key.
+        Buffered values are flushed when a sum, count or timespan parameter is exceeded.
+        The accumulated buffered values are returned as a metric result until the buffered values are
+        flushed. These values will be only the buffered values for this Lambda.
+        When the metric is flushed, the full persisted metric is returned with all spans.
+        This means returned metrics will typically be just accumulated buffered values and won't reflect
+        other lambdas until flushed. If you need consistent return values -- use query().
+     */
+    async bufferMetric(namespace, metricName, point, dimensions, options) {
+        let buffer = options.buffer || this.buffer;
+        let key = this.getBufferKey(namespace, metricName, dimensions);
+        let buffers = (this.buffers = this.buffers || {});
+        let now = Math.floor((options.timestamp || Date.now()) / 1000);
+        let elapsed = buffer.elapsed || this.spans[0].period / this.spans[0].samples;
+        let elt = (buffers[key] = buffers[key] || {
+            count: 0,
+            sum: 0,
+            timestamp: now + elapsed,
+            elapsed: elapsed,
+            namespace: namespace,
+            metric: metricName,
+            dimensions,
+            spans: [{ points: [{ count: 0, sum: 0 }] }],
+        });
+        /*
+            Add point value to the lowest span and to the elt (to manage when to persist)
+         */
+        let current = elt.spans[0].points.at(-1);
+        if (current) {
+            current.count += point.count;
+            current.sum += point.sum;
+        }
+        elt.count += point.count;
+        elt.sum += point.sum;
+        if (buffer.force ||
+            (buffer.sum && elt.sum >= buffer.sum) ||
+            (buffer.count && elt.count >= buffer.count) ||
+            now >= elt.timestamp) {
+            options = Object.assign({}, options, { timestamp: now * 1000 });
+            let metric = await this.emitDimensionedMetric(namespace, metricName, elt, dimensions, options);
+            //  Reset tallies and save higher spans to return for future buffered metrics
+            elt.count = elt.sum = 0;
+            elt.spans = metric.spans;
+            elt.timestamp = now + (buffer.elapsed || this.spans[0].period / this.spans[0].samples);
+            return metric;
+        }
+        CustomMetrics.saveInstance({ key }, this);
+        return {
+            spans: elt.spans,
+            metric: metricName,
+            namespace: namespace,
+            owner: options.owner || this.owner,
+            version: Version,
+        };
+    }
+    /*
+        Emit a metric for specific dimensions
+     */
+    async emitDimensionedMetric(namespace, metricName, point, dimensions, options = {}) {
+        /*
+            Update the metric. May need retries if colliding with other updaters.
+         */
+        let now = Math.floor((options.timestamp || Date.now()) / 1000);
+        let ttl = options.ttl != undefined ? options.ttl : this.ttl;
+        let retries = MaxRetries;
+        let metric;
+        let backoff = 10;
+        /* istanbul ignore next */
+        let chan = options.log == true ? 'info' : 'trace';
+        do {
+            let owner = options.owner || this.owner;
+            metric = await this.getMetric(owner, namespace, metricName, dimensions, options.log);
+            if (metric) {
+                if (options.upgrade) {
+                    metric = this.upgradeMetric(metric);
+                }
+            }
+            else {
+                metric = this.initMetric(owner, namespace, metricName, dimensions, now);
+            }
+            if (point.timestamp) {
+                /*
+                    Buffered points only.
+                    Pick the first span for which the point is after the earliest span start or after the end of the span
+                 */
+                let si = metric.spans.findIndex((s) => s.end - s.period <= point.timestamp || s.end <= point.timestamp);
+                /* istanbul ignore else */
+                if (si >= 0) {
+                    this.addValue(metric, point.timestamp, point, si);
+                }
+                else {
+                    //  Silently discard
+                }
+            }
+            else {
+                this.addValue(metric, now, point, 0);
+            }
+            /* istanbul ignore next */
+            if (this.source) {
+                metric._source = this.source;
+            }
+            /*
+                Set the expiration TTL. Defaults to the longest span.
+                Users may define a shorter TTL to prune metrics for inactive items.
+            */
+            if (ttl) {
+                //  MOB - is this a date, seconds or msec
+                metric.expires = now + ttl;
+            }
+            if (await this.putMetric(metric, options)) {
+                break;
+            }
+            /* istanbul ignore next */
+            if (retries == 0) {
+                this.log.error(`Metric update has too many retries`, { namespace, metricName, dimensions });
+                break;
+            }
+            /* istanbul ignore next */
+            this.log[chan](`Retry ${MaxRetries - retries} metric update ${metric.namespace} ${metric.metric} ${metric.dimensions}`, {
+                retries,
+                metric,
+            });
+            //  Exponential backoff
+            /* istanbul ignore next */
+            backoff = backoff * 2;
+            /* istanbul ignore next */
+            this.log[chan](`Retry backoff ${backoff} ${this.jitter(backoff)}`);
+            /* istanbul ignore next */
+            await this.delay(this.jitter(backoff));
+        } while (retries-- > 0);
+        return metric;
+    }
+    /*
+        Upgrade a metric with new spans. Only the specified dimensions are upgraded.
+     */
+    async upgrade(namespace, metricName, dimensionsList = [{}], options = {}) {
+        let owner = options.owner || this.owner;
+        if (dimensionsList.length == 0) {
+            dimensionsList = [{}];
+        }
+        let metric;
+        for (let dim of dimensionsList) {
+            let dimensions = this.makeDimensionString(dim);
+            let old = await this.getMetric(owner, namespace, metricName, dimensions, options.log);
+            metric = this.upgradeMetric(old);
+            await this.putMetric(metric, options);
+        }
+        return metric;
+    }
+    /*
+        Upgrade a metric and return the upgraded result
+        Optimized for when an upgrade is not required.
+     */
+    upgradeMetric(old) {
+        let required = false;
+        /*
+            Check if upgrade required
+         */
+        if (this.spans.length == old.spans.length) {
+            for (let [index, span] of Object.entries(old.spans)) {
+                if (span.period != this.spans[index].period || span.samples != this.spans[index].samples) {
+                    required = true;
+                }
+            }
+            if (!required) {
+                return old;
+            }
+        }
+        /*
+            This initializes a new metric with the new spans and apportion the old data points to
+            the new metric at the point's timestamp. Pick the earliest timestamp from the old metric.
+         */
+        let now = Math.min(...old.spans.map((span) => span.end - span.period)) || Math.floor(Date.now() / 1000);
+        let metric = this.initMetric(old.owner, old.namespace, old.metric, old.dimensions, now);
+        for (let span of old.spans) {
+            let interval = span.period / span.samples;
+            let firstPoint = span.end - span.points.length * interval;
+            /*
+                Pick the first span for which the point is after the earliest span start or after the end of the span
+            */
+            let si = metric.spans.findIndex((s) => s.end - s.period <= firstPoint || s.end <= firstPoint);
+            let t = firstPoint;
+            for (let point of span.points) {
+                this.addValue(metric, t, point, si);
+                t += interval;
+            }
+        }
+        return metric;
+    }
+    /*
+        Flush metrics for all instances on Lambda termination
+     */
+    static async terminate() {
+        await CustomMetrics.flushAll();
+    }
+    static async flushAll() {
+        for (let [key, instance] of Object.entries(Instances)) {
+            await instance.flush();
+            CustomMetrics.freeInstanceByKey(key);
+        }
+        Instances = {};
+    }
+    async flush(options = {}) {
+        if (!this.buffers)
+            return;
+        let now = Math.floor((options.timestamp || Date.now()) / 1000);
+        for (let elt of Object.values(this.buffers)) {
+            await this.flushElt(elt, now);
+        }
+    }
+    async flushElt(elt, now) {
+        //  Choose timestamp if before the buffer expires, otherwise choose the buffer expiry time
+        elt.timestamp = Math.min(now, elt.timestamp);
+        let metric = await this.emitDimensionedMetric(elt.namespace, elt.metric, elt, elt.dimensions, {
+            timestamp: elt.timestamp * 1000,
+        });
+        elt.count = elt.sum = 0;
+        elt.spans = metric.spans;
+        elt.timestamp = now + (elt.elapsed || this.spans[0].period / this.spans[0].samples);
+    }
+    getBufferKey(namespace, metricName, dimensions) {
+        return `${namespace}|${metricName}|${JSON.stringify(dimensions)}`;
+    }
+    /*
+        Query metrics. Return an array of metrics
+     */
+    async query(namespace, metricName, dimensions, period, statistic, options = {}) {
+        let owner = options.owner || this.owner;
+        let dimString = this.makeDimensionString(dimensions);
+        if (period > this.spans.at(-1).period) {
+            period = this.spans.at(-1).period;
+        }
+        let now = Math.floor((options.timestamp || Date.now()) / 1000);
+        /*
+           Flush buffered metrics for this instance. Will not see buffered metrics in other instances
+           until they are flushed.
+         */
+        if (this.buffers) {
+            let key = this.getBufferKey(namespace, metricName, dimString);
+            if (this.buffers[key]) {
+                await this.flushElt(this.buffers[key], now);
+            }
+        }
+        let metric = await this.getMetric(owner, namespace, metricName, dimString, options.log);
+        if (!metric) {
+            return { dimensions, id: options.id, metric: metricName, namespace, period, points: [], owner, samples: 0 };
+        }
+        let result = this.processMetric(metric, now, period, statistic, options);
+        /* istanbul ignore next */
+        this.log[options.log == true ? 'info' : 'trace'](`Query metrics ${namespace}, ${metricName}`, {
+            dimensions,
+            period,
+            statistic,
+            options,
+            result,
+        });
+        return result;
+    }
+    async queryMetrics(namespace, metric, period, statistic, options = {}) {
+        let owner = options.owner || this.owner;
+        let next = options.next;
+        let limit = options.limit || MetricListLimit;
+        /* istanbul ignore next */
+        let chan = options.log == true ? 'info' : 'trace';
+        let items, command;
+        let count = 0;
+        do {
+            /* istanbul ignore next */
+            ;
+            ({ command, items, next } = await this.findMetrics(owner, namespace, metric, limit, next, 'spans'));
+            this.log[chan](`Find metrics ${namespace}, ${metric}`, { command, items });
+            if (items.length) {
+                count += items.length;
+            }
+        } while (next && count < limit);
+        let now = Math.floor((options.timestamp || Date.now()) / 1000);
+        let results = [];
+        for (let metric of items) {
+            let result = this.processMetric(metric, now, period, statistic, { accumulate: true, timestamp: now });
+            results.push(result);
+        }
+        return results;
+    }
+    /*
+       Process a metric for query() or queryMetrics() and extract the desired series or accumlated value
+     */
+    processMetric(metric, now, period, statistic, options) {
+        let end;
+        let si;
+        let owner = options.owner || this.owner;
+        if (options.start) {
+            /*
+                Find span for the request start: period < span[i+1].period
+            */
+            let start = options.start / 1000;
+            si = metric.spans.findIndex((s) => period <= s.period && s.end - s.period <= start && start < s.end);
+            end = start + period;
+        }
+        else {
+            let span = metric.spans[0];
+            let interval = span.period / span.samples;
+            /*
+                Special case: if now is within the most recent span interval, then set "start" to include this interval.
+            */
+            if (span.end - interval <= now && now < span.end) {
+                end = span.end;
+            }
+            else {
+                end = now;
+            }
+            si = metric.spans.findIndex((s) => period <= s.period);
+        }
+        if (si < 0) {
+            si = metric.spans.length - 1;
+        }
+        /*
+            Aggregate data for all spans up to the desired span. Do this because spans are updated lazily on emit.
+         */
+        this.addValue(metric, now, { count: 0, sum: 0 }, 0, si);
+        let span = metric.spans[si];
+        let result;
+        if (options.accumulate) {
+            result = this.accumulateMetric(metric, span, statistic, owner, end, period);
+        }
+        else {
+            result = this.calculateSeries(metric, span, statistic, owner, end, period);
+        }
+        result.id = options.id;
+        return result;
+    }
+    /*
+        Accumulate the metric data points into a single value.
+        This is useful for gauges and widgets that need a single data value for the metric.
+        According to the desired statistic, this calculates the avg, count, max, min, sum, and pvalues.
+     */
+    accumulateMetric(metric, span, statistic, owner, end, period) {
+        let start = this.alignTime(span, end - period);
+        let value = 0, count = 0, pvalues = [];
+        if (statistic == 'max') {
+            value = Number.NEGATIVE_INFINITY;
+        }
+        else if (statistic == 'min') {
+            value = Infinity;
+        }
+        else if (statistic == 'sum') {
+            value = 0;
+            count = 0;
+        }
+        else if (statistic == 'count') {
+            value = 0;
+            count = 0;
+        }
+        else if (statistic == 'current') {
+            value = 0;
+            count = 0;
+        }
+        else if (statistic.match(/^p[0-9]+/)) {
+            pvalues = [];
+        } /* avg */
+        else {
+            value = 0;
+            count = 0;
+        }
+        let points = span.points;
+        let interval = span.period / span.samples;
+        let t = span.end - span.points.length * interval;
+        for (let i = 0; i < points.length; i++) {
+            let point = points[i];
+            if (start <= t && t < start + period) {
+                if (statistic == 'max') {
+                    if (point.max != undefined) {
+                        value = Math.max(value, point.max);
+                    }
+                    else {
+                        //  For use to accumulate AWS metrics that don't keep min/max in points
+                        value = Math.max(value, point.sum / (point.count || 1));
+                    }
+                }
+                else if (statistic == 'min') {
+                    if (point.min != undefined) {
+                        value = Math.min(value, point.min);
+                    }
+                    else {
+                        //  For use to accumulate AWS metrics that don't keep min/max in points
+                        value = Math.min(value, point.sum / (point.count || 1));
+                    }
+                }
+                else if (statistic == 'sum') {
+                    value += point.sum;
+                }
+                else if (statistic == 'current') {
+                    value = point.sum / (point.count || 1);
+                }
+                else if (statistic == 'count') {
+                    value += point.count;
+                }
+                else if (statistic.match(/^p[0-9]+/)) {
+                    pvalues = pvalues.concat(point.pvalues);
+                } /* avg */
+                else {
+                    value += point.sum;
+                }
+                count += point.count;
+            }
+            t += interval;
+        }
+        if (statistic.match(/^p[0-9]+/)) {
+            let p = parseInt(statistic.slice(1));
+            pvalues.sort((a, b) => a - b);
+            let nth = Math.min(Math.round((pvalues.length * p) / 100 + 1), pvalues.length - 1);
+            value = pvalues[nth];
+        }
+        else if (statistic == 'avg') {
+            value /= Math.max(count, 1);
+        }
+        return {
+            dimensions: this.makeDimensionObject(metric.dimensions),
+            metric: metric.metric,
+            namespace: metric.namespace,
+            owner: owner,
+            period: span.period,
+            points: [{ value, timestamp: start + period, count }],
+            samples: span.samples,
+        };
+    }
+    /*
+        Process the metric points. This is used for graphs that need all the data points.
+        This calculates the avg, max, min, sum, count, pvalues and per-point timestamps.
+        This always returns a full series of points even if there is no data.
+     */
+    calculateSeries(metric, span, statistic, owner, end, period) {
+        let points = [];
+        let interval = span.period / span.samples;
+        /*
+            Start points aligned with span buckets
+         */
+        let start = this.alignTime(span, end - period);
+        let firstPoint = span.end - span.points.length * interval;
+        let t;
+        for (t = start; t < firstPoint && points.length < span.samples; t += interval) {
+            points.push({ value: 0, count: 0, timestamp: t * 1000 });
+        }
+        t = firstPoint;
+        for (let point of span.points) {
+            //  MOB - end was start + period, now end is closer
+            if (start <= t && t < end) {
+                let value = undefined;
+                /* istanbul ignore else */
+                if (point.count > 0) {
+                    if (statistic == 'max') {
+                        if (point.max != undefined) {
+                            if (value == undefined) {
+                                value = point.max;
+                            }
+                            else {
+                                value = Math.max(value, point.max);
+                            }
+                        }
+                    }
+                    else if (statistic == 'min') {
+                        if (point.min != undefined) {
+                            if (value == undefined) {
+                                value = point.min;
+                            }
+                            else {
+                                value = Math.min(value, point.min);
+                            }
+                        }
+                    }
+                    else if (statistic == 'sum') {
+                        value = point.sum;
+                    }
+                    else if (statistic == 'count') {
+                        value = point.count;
+                    }
+                    else if (statistic.match(/^p[0-9]+/)) {
+                        let p = parseInt(statistic.slice(1));
+                        let pvalues = point.pvalues;
+                        pvalues.sort((a, b) => a - b);
+                        let nth = Math.min(Math.round((pvalues.length * p) / 100 + 1), pvalues.length - 1);
+                        value = pvalues[nth];
+                    } /* avg | current */
+                    else {
+                        value = point.sum / point.count;
+                    }
+                }
+                else {
+                    value = 0;
+                }
+                /*
+                    The timestamp is set to be the end of the point bucket not the start, and not after the range
+                */
+                let timestamp = Math.min(t + interval, end) * 1000;
+                points.push({ value, count: point.count, timestamp });
+            }
+            t += interval;
+        }
+        let count = Math.min(Math.ceil(period / interval), span.samples);
+        while (points.length < count) {
+            let timestamp = Math.min(t + interval, end) * 1000;
+            points.push({ value: 0, count: 0, timestamp });
+            t += interval;
+        }
+        return {
+            dimensions: this.makeDimensionObject(metric.dimensions),
+            metric: metric.metric,
+            namespace: metric.namespace,
+            period: span.period,
+            points: points,
+            owner: owner,
+            samples: span.samples,
+        };
+    }
+    /*
+        Convert a dimensions object of the form {key: value, ...} to a string with comma separated "key=value,..." with sorted property keys
+     */
+    makeDimensionString(dimensions) {
+        let result = [];
+        //  Sort dimension properties
+        let entries = Object.entries(dimensions).sort((a, b) => a[0].localeCompare(b[0]));
+        for (let [name, value] of entries) {
+            result.push(`${name}=${value}`);
+        }
+        return result.join(',');
+    }
+    /*
+        Convert a dimensions string of the form "key=value,..." to a a dimensions object {key: value, ...}
+    */
+    makeDimensionObject(dimensions) {
+        let result = {};
+        for (let dimension of dimensions.split(',')) {
+            if (dimension) {
+                let [key, value] = dimension.split('=');
+                result[key] = value;
+            }
+        }
+        return result;
+    }
+    /*
+        Add a point value to the metric the span index with the given timestamp.
+        We aggregate aged out points to upper spans as required.
+        For queries, a span nominates the desired span, all lower span values are aggregated up.
+     */
+    addValue(metric, timestamp, point, si, querySpanIndex = undefined) {
+        this.assert(metric);
+        this.assert(timestamp);
+        this.assert(0 <= si && si < metric.spans.length);
+        let span = metric.spans[si];
+        let interval = span.period / span.samples;
+        /* istanbul ignore next */
+        let points = span.points || [];
+        /*
+            Determine if need to recurse and aggregate earlier spans
+         */
+        let queryRecurse = si < querySpanIndex && si + 1 < metric.spans.length;
+        //  Just for safety, should not happen
+        /* istanbul ignore next */
+        while (points.length > span.samples) {
+            points.shift();
+        }
+        let first = span.end - points.length * interval;
+        /*
+            Aggregate points. Calculate how many points have aged, or if querying, how many must be aggregated.
+        */
+        let shift = 0;
+        if (points.length) {
+            /* istanbul ignore next */
+            if (queryRecurse) {
+                //  Querying and not yet on the target period, so aggregate all points
+                shift = points.length;
+            }
+            else if (timestamp >= first) {
+                //  Count of aged data points
+                shift = Math.floor((timestamp - first) / interval) - span.samples;
+                if (!queryRecurse && point.count && timestamp >= span.end) {
+                    //  Add one more to make room for this point being added
+                    shift += 1;
+                }
+            }
+            shift = Math.max(0, Math.min(shift, points.length));
+            this.assert(0 <= shift && shift <= points.length);
+            /*
+                Add points to the next span by shifting aged points and make room.
+             */
+            for (let i = 0; i < shift; i++) {
+                let p = points.shift();
+                if (p.count && si + 1 < metric.spans.length) {
+                    this.addValue(metric, first, p, si + 1, querySpanIndex);
+                }
+                first += interval;
+            }
+        }
+        if (queryRecurse) {
+            //  Querying and not at the terminal period. Must recurse and aggregate all spans up to the target span.
+            this.addValue(metric, timestamp, point, si + 1, querySpanIndex);
+            return;
+        }
+        if (point.count) {
+            let index;
+            if (points.length == 0) {
+                points.push({ count: 0, sum: 0 });
+                /*
+                    This will set the span.end to the next aligned interval that is >timestamp
+                    NOTE: this may mean that span.start is set before now and before recorded time
+                 */
+                span.end = this.alignTime(span, timestamp + 1);
+                first = span.end - interval;
+                index = 0;
+            }
+            else {
+                if (timestamp < span.end - span.period) {
+                    //  Discard if before the earliest possible point for the span
+                    return;
+                }
+                while (timestamp < first) {
+                    points.unshift({ count: 0, sum: 0 });
+                    first -= interval;
+                }
+                while (timestamp >= span.end) {
+                    points.push({ count: 0, sum: 0 });
+                    span.end += interval;
+                }
+                index = Math.floor((timestamp - first) / interval);
+            }
+            this.assert(points.length <= span.samples);
+            if (!(0 <= index && index < points.length)) {
+                this.assert(0 <= index && index < points.length);
+                //  Just in case - should never happen
+                /* istanbul ignore next */
+                if (index > 0) {
+                    index = points.length - 1;
+                }
+            }
+            this.setPoint(span, index, point);
+        }
+    }
+    /*
+        Add value to a span and update count, min, max, pValues and sum
+        The point "index" defines the point[] to update.
+     */
+    setPoint(span, index, add) {
+        let points = span.points;
+        this.assert(0 <= index && index < points.length);
+        let point = points[index];
+        /* istanbul ignore next */
+        if (!point) {
+            this.log.error(`Metric null point`, { span, index, add });
+            return;
+        }
+        if (add.count) {
+            let value = add.sum / add.count;
+            if (point.min == undefined) {
+                point.min = value;
+            }
+            else {
+                point.min = Math.min(value, point.min);
+            }
+            if (point.max == undefined) {
+                point.max = value;
+            }
+            else {
+                point.max = Math.max(value, point.max);
+            }
+        }
+        if (this.pResolution) {
+            point.pvalues = point.pvalues || [];
+            if (add.pvalues) {
+                point.pvalues.push(...add.pvalues);
+            }
+            else {
+                point.pvalues.push(add.sum / add.count);
+            }
+            point.pvalues.splice(0, point.pvalues.length - this.pResolution);
+        }
+        point.sum += add.sum;
+        point.count += add.count;
+    }
+    /*
+        Get list of metrics at a given level. The args: namespace and metrics may be undefined.
+        Return {namespaces, metrics, dimensions} as possible.
+     */
+    async getMetricList(namespace = undefined, metric = undefined, options = { limit: MetricListLimit }) {
+        let map = {};
+        let owner = options.owner || this.owner;
+        let next = options.next;
+        let limit = options.limit || MetricListLimit;
+        /* istanbul ignore next */
+        let chan = options.log == true ? 'info' : 'trace';
+        let items, command;
+        let count = 0;
+        do {
+            /* istanbul ignore next */
+            ;
+            ({ command, items, next } = await this.findMetrics(owner, namespace, metric, limit, next));
+            this.log[chan](`Find metrics ${namespace}, ${metric}`, { command, items });
+            if (items.length) {
+                for (let item of items) {
+                    let ns = (map[item.namespace] = map[item.namespace] || {});
+                    let met = (ns[item.metric] = ns[item.metric] || []);
+                    met.push(item.dimensions);
+                }
+                count += items.length;
+            }
+        } while (next && count < limit);
+        let result = { namespaces: Object.keys(map) };
+        if (namespace && map[namespace]) {
+            result.metrics = Object.keys(map[namespace]);
+            if (metric) {
+                let dimensions = map[namespace][metric];
+                if (dimensions) {
+                    result.dimensions = [];
+                    dimensions = dimensions.sort().filter((v, index, self) => self.indexOf(v) === index);
+                    for (let dimension of dimensions) {
+                        result.dimensions.push(this.makeDimensionObject(dimension));
+                    }
+                }
+            }
+        }
+        return result;
+    }
+    initMetric(owner, namespace, name, dimensions, now) {
+        let metric = {
+            dimensions,
+            metric: name,
+            namespace,
+            owner,
+            spans: [],
+            version: Version,
+        };
+        for (let sdef of this.spans) {
+            let span = {
+                samples: sdef.samples,
+                period: sdef.period,
+                end: null,
+                points: [],
+            };
+            //  This will set the span.end to the next aligned interval that is >timestamp
+            let interval = span.period / span.samples;
+            // span.end = this.alignTime(span, now + 1)
+            span.end = this.alignTime(span, now + interval);
+            metric.spans.push(span);
+        }
+        return metric;
+    }
+    async getMetric(owner, namespace, metric, dimensions, log) {
+        let command = new client_dynamodb_1.GetItemCommand({
+            TableName: this.table,
+            Key: {
+                [this.primaryKey]: { S: `${this.prefix}#${Version}#${owner}` },
+                [this.sortKey]: { S: `${this.prefix}#${namespace}#${metric}#${dimensions}` },
+            },
+            ConsistentRead: this.consistent,
+        });
+        let data = await this.client.send(command);
+        let result = null;
+        if (data && data.Item) {
+            let item = (0, util_dynamodb_1.unmarshall)(data.Item);
+            result = this.mapItemFromDB(item);
+        }
+        if (log == true) {
+            let chan = log == true ? 'info' : 'trace';
+            this.log[chan](`GetMetric ${namespace}, ${metric} ${dimensions}`, { cmd: command, result });
+        }
+        return result;
+    }
+    async findMetrics(owner, namespace, metric, limit, startKey, fields = '') {
+        let key = [namespace];
+        if (metric) {
+            key.push(metric);
+        }
+        /* istanbul ignore next */
+        let start = startKey ? (0, util_dynamodb_1.marshall)(startKey) : undefined;
+        let project = `${this.primaryKey}, ${this.sortKey}`;
+        if (fields) {
+            project += `, ${fields}`;
+        }
+        let command = new client_dynamodb_1.QueryCommand({
+            TableName: this.table,
+            ExpressionAttributeNames: {
+                '#_0': this.primaryKey,
+                '#_1': this.sortKey,
+            },
+            ExpressionAttributeValues: {
+                ':_0': { S: `${this.prefix}#${Version}#${owner}` },
+                ':_1': { S: `${this.prefix}#${key.join('#')}` },
+            },
+            KeyConditionExpression: '#_0 = :_0 and begins_with(#_1, :_1)',
+            ConsistentRead: this.consistent,
+            Limit: limit,
+            ScanIndexForward: true,
+            ExclusiveStartKey: start,
+            ProjectionExpression: project,
+        });
+        let result = await this.client.send(command);
+        let items = [];
+        if (result.Items) {
+            for (let i = 0; i < result.Items.length; i++) {
+                let item = (0, util_dynamodb_1.unmarshall)(result.Items[i]);
+                items.push(this.mapItemFromDB(item));
+            }
+        }
+        let next = undefined;
+        /* istanbul ignore next */
+        if (result.LastEvaluatedKey) {
+            next = (0, util_dynamodb_1.unmarshall)(result.LastEvaluatedKey);
+        }
+        return { items, next, command };
+    }
+    /*
+        Use a sequence number to detect simultaneous updated. If collision, will throw
+        a ConditionalCheckFailedException and emit() will then retry.
+    */
+    async putMetric(item, options) {
+        let ConditionExpression, ExpressionAttributeValues;
+        let seq;
+        if (item.seq != undefined) {
+            /* istanbul ignore next */
+            seq = item.seq = item.seq || 0;
+            /* istanbul ignore next */
+            if (item.seq++ >= MaxSeq) {
+                item.seq = 0;
+            }
+            ConditionExpression = `seq = :_0`;
+            ExpressionAttributeValues = { ':_0': { N: seq.toString() } };
+        }
+        else {
+            item.seq = 0;
+        }
+        let mapped = this.mapItemToDB(item);
+        let params = {
+            TableName: this.table,
+            ReturnValues: 'NONE',
+            Item: (0, util_dynamodb_1.marshall)(mapped, { removeUndefinedValues: true }),
+            ConditionExpression,
+            ExpressionAttributeValues,
+        };
+        let command = new client_dynamodb_1.PutItemCommand(params);
+        /* istanbul ignore next */
+        let chan = options.log == true ? 'info' : 'trace';
+        this.log[chan](`Put metric ${item.namespace}, ${item.metric}`, {
+            dimensions: item.dimensions,
+            command,
+            params,
+            item,
+        });
+        try {
+            await this.client.send(command);
+            return true;
+        }
+        catch (err) /* istanbul ignore next */ {
+            ;
+            (function (err, log) {
+                //  SDK V3 puts the code in err.name (Ugh!)
+                let code = err.code || err.name;
+                if (code == 'ConditionalCheckFailedException') {
+                    log.trace(`Update collision`, { err });
+                }
+                else if (code == 'ProvisionedThroughputExceededException') {
+                    log.info(`Provisioned throughput exceeded: ${err.message}`, { err, cmd: command, item });
+                }
+                else {
+                    log.error(`Emit exception code ${err.name} ${err.code} message ${err.message}`, {
+                        err,
+                        cmd: command,
+                        item,
+                    });
+                    throw err;
+                }
+                return false;
+            })(err, this.log);
+        }
+    }
+    mapItemFromDB(data) {
+        let pk = data[this.primaryKey];
+        let sk = data[this.sortKey];
+        let owner = pk.split('#').pop();
+        let [, namespace, metric, dimensions] = sk.split('#');
+        let spans;
+        if (data.spans) {
+            spans = data.spans.map((s) => {
+                return {
+                    end: s.se,
+                    period: s.sp,
+                    samples: s.ss,
+                    points: s.pt.map((p) => {
+                        let point = { count: Number(p.c), sum: Number(p.s) };
+                        if (p.x != null) {
+                            point.max = Number(p.x);
+                        }
+                        if (p.m != null) {
+                            point.min = Number(p.m);
+                        }
+                        if (p.v) {
+                            point.pvalues = p.v;
+                        }
+                        return point;
+                    }),
+                };
+            });
+        }
+        let expires = data[this.expires];
+        let seq = data.seq;
+        return { dimensions, expires, metric, namespace, owner, seq, spans };
+    }
+    mapItemToDB(item) {
+        let result = {
+            [this.primaryKey]: `${this.prefix}#${Version}#${item.owner}`,
+            [this.sortKey]: `${this.prefix}#${item.namespace}#${item.metric}#${item.dimensions}`,
+            [this.expires]: item.expires,
+            spans: item.spans.map((i) => {
+                return {
+                    se: i.end,
+                    sp: i.period,
+                    ss: i.samples,
+                    pt: i.points.map((point) => {
+                        let p = { c: point.count, s: this.round(point.sum) };
+                        if (point.max != null) {
+                            p.x = this.round(point.max);
+                        }
+                        if (point.min != null) {
+                            p.m = this.round(point.min);
+                        }
+                        if (point.pvalues) {
+                            p.v = point.pvalues;
+                        }
+                        return p;
+                    }),
+                };
+            }),
+            seq: item.seq,
+            _source: item._source,
+        };
+        if (this.type) {
+            let [key, model] = Object.entries(this.type)[0];
+            result[key] = model;
+        }
+        return result;
+    }
+    static freeInstanceByKey(key) {
+        delete Instances[key];
+    }
+    static saveInstance(tags, metrics) {
+        let key = JSON.stringify(tags);
+        Instances[key] = metrics;
+    }
+    /*
+        Align a timestamp that is >timestamp and rounded up in seconds to be interval aligned
+        Note: this may be in the future
+     */
+    alignTime(span, timestamp) {
+        let interval = span.period / span.samples;
+        return Math.ceil(timestamp / interval) * interval;
+    }
+    /* istanbul ignore next */
+    assert(c) {
+        if (!c && Assert) {
+            let msg = { stack: '' };
+            if (typeof Error.captureStackTrace === 'function') {
+                Error.captureStackTrace(msg);
+            }
+            else {
+                msg.stack = new Error('Assert').stack;
+            }
+            this.log.error(`Assertion failed`, { stack: msg.stack });
+        }
+    }
+    /* istanbul ignore next */
+    info(message, context = {}) {
+        console.log('INFO: ' + message, context);
+    }
+    /* istanbul ignore next */
+    error(message, context = {}) {
+        console.log('ERROR: ' + message, context);
+    }
+    /* istanbul ignore next */
+    trace(message, context = {}) {
+        console.log('TRACE: ' + message, context);
+    }
+    //  Overcome Javascript number precision issues
+    round(n) {
+        /* istanbul ignore next */
+        if (isNaN(n) || n == null) {
+            return 0;
+        }
+        let places = 16 - n.toFixed(0).length;
+        return Number(n.toFixed(places)) - 0;
+    }
+    /* istanbul ignore next */
+    jitter(msecs) {
+        return Math.min(10 * 1000, Math.floor(msecs / 2 + msecs * Math.random()));
+    }
+    /* istanbul ignore next */
+    async delay(time) {
+        return new Promise(function (resolve, reject) {
+            setTimeout(() => resolve(true), time);
+        });
+    }
+}
+exports.CustomMetrics = CustomMetrics;
+//  Emulate the SenseLogs logger
+/* istanbul ignore next */
+class Log {
+    senselogs = null;
+    logger = null;
+    verbose = false;
+    constructor(dest) {
+        if (dest === true) {
+            this.logger = this.defaultLogger;
+        }
+        else if (dest == 'verbose') {
+            this.logger = this.defaultLogger;
+            this.verbose = true;
+        }
+        else if (dest && typeof dest.info == 'function') {
+            this.senselogs = dest;
+        }
+    }
+    error(message, context) {
+        this.process('error', message, context);
+    }
+    info(message, context) {
+        this.process('info', message, context);
+    }
+    trace(message, context) {
+        this.process('trace', message, context);
+    }
+    process(chan, message, context) {
+        if (this.logger) {
+            this.logger(chan, message, context);
+        }
+        else if (this.senselogs) {
+            this.senselogs[chan](message, context);
+        }
+    }
+    /* istanbul ignore next */
+    defaultLogger(chan, message, context) {
+        if (chan == 'trace' && !this.verbose) {
+            //  params.log: true will cause the chan to be changed to 'info'
+            return;
+        }
+        let tag = chan.toUpperCase();
+        if (context) {
+            try {
+                console.log(tag, message, JSON.stringify(context, null, 4));
+            }
+            catch (err) {
+                let buf = ['{'];
+                for (let [key, value] of Object.entries(context)) {
+                    try {
+                        buf.push(`    ${key}: ${JSON.stringify(value, null, 4)}`);
+                    }
+                    catch (err) {
+                        /* continue */
+                    }
+                }
+                buf.push('}');
+                console.log(tag, message, buf.join('\n'));
+            }
+        }
+        else {
+            console.log(tag, message);
+        }
+    }
+}
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/accum.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/accum.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/accum.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/accum.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/accum.js
new file mode 100644
index 0000000..813198c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/accum.js
@@ -0,0 +1,27 @@
+"use strict";
+Object.defineProperty(exports, "__esModule", { value: true });
+/*
+    accum.ts - Test accumulated queries
+ */
+const init_1 = require("./utils/init");
+// jest.setTimeout(7200 * 1000)
+test('Test', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, log: true });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let span = init_1.DefaultSpans[2];
+    let interval = span.period / span.samples;
+    for (let i = 0; i < 4; i++) {
+        await metrics.emit('test/accum', 'FirstMetric', 10, [], { timestamp });
+        timestamp += interval * 1000;
+    }
+    // timestamp = timestamp - interval * 1000 + 1000
+    let r = await metrics.query('test/accum', 'FirstMetric', {}, 86400, 'sum', { timestamp, accumulate: true });
+    expect(r).toBeDefined();
+    expect(r.metric).toBe('FirstMetric');
+    expect(r.namespace).toBe('test/accum');
+    expect(r.period).toBe(span.period);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(1);
+    expect(r.points[0].value).toBe(40);
+    expect(r.points[0].count).toBe(4);
+});
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/api.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/api.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/api.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/api.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/api.js
new file mode 100644
index 0000000..714b6d7
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/api.js
@@ -0,0 +1,13 @@
+"use strict";
+Object.defineProperty(exports, "__esModule", { value: true });
+/*
+    api.ts - Test misc api routines
+ */
+const init_1 = require("./utils/init");
+// jest.setTimeout(7200 * 1000)
+test('Test flush', async () => {
+    let metrics = new init_1.CustomMetrics({ table: init_1.table });
+    await metrics.flush();
+    await init_1.CustomMetrics.flushAll();
+    await init_1.CustomMetrics.terminate();
+});
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/basic.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/basic.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/basic.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/basic.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/basic.js
new file mode 100644
index 0000000..5b6c61a
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/basic.js
@@ -0,0 +1,22 @@
+"use strict";
+Object.defineProperty(exports, "__esModule", { value: true });
+/*
+    basic.ts - base operations: emit / query
+ */
+const init_1 = require("./utils/init");
+// jest.setTimeout(7200 * 1000)
+test('Basic test harness', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, log: true });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    //  This first emit will initialize the metric
+    let metric = await metrics.emit('test/basic', 'FirstMetric', 10, [], { timestamp });
+    expect(metric).toBeDefined();
+    //  The second emit will read the metric and update
+    metric = await metrics.emit('test/basic', 'FirstMetric', 10, [{}, { Rocket: 'SaturnV' }], { timestamp });
+    let r = await metrics.query('test/basic', 'FirstMetric', {}, 300, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    let list = await metrics.getMetricList('test/basic');
+    expect(list).toBeDefined();
+    list = await metrics.getMetricList('test/basic', 'FirstMetric');
+    expect(list).toBeDefined();
+});
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/buffer.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/buffer.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/buffer.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/buffer.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/buffer.js
new file mode 100644
index 0000000..0fde382
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/buffer.js
@@ -0,0 +1,121 @@
+"use strict";
+Object.defineProperty(exports, "__esModule", { value: true });
+/*
+    buffer.ts - Test buffered emits
+ */
+const init_1 = require("./utils/init");
+// jest.setTimeout(7200 * 1000)
+test('Test Buffer Basic', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, log: true });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let span = init_1.DefaultSpans[0];
+    let interval = span.period / span.samples;
+    /*
+        Buffer some metrics
+     */
+    for (let i = 0; i < 4; i++) {
+        let metric = await metrics.emit('test/buffer', 'BasicMetric', 10, [], { buffer: { elapsed: 1800 }, timestamp });
+        expect(metric).toBeDefined();
+        expect(metric.metric).toBe('BasicMetric');
+        expect(metric.spans.length).toBe(1);
+        expect(metric.spans[0].points.length).toBe(1);
+        expect(metric.spans[0].points[0].count).toBe(i + 1);
+        timestamp += interval * 1000;
+    }
+    //  Query will flush
+    let r = await metrics.query('test/buffer', 'BasicMetric', {}, 3600, 'avg', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.metric).toBe('BasicMetric');
+    expect(r.namespace).toBe('test/buffer');
+    expect(r.period).toBe(3600);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[11].value).toBe(10);
+    expect(r.points[11].count).toBe(4);
+});
+test('Test elapsed buffers', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, log: true });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let span = init_1.DefaultSpans[0];
+    let interval = span.period / span.samples;
+    /*
+        Buffer some metrics and then flush
+     */
+    for (let i = 0; i < 4; i++) {
+        let metric = await metrics.emit('test/buffer', 'ElapsedMetric', 1, [], { buffer: { elapsed: 1800 }, timestamp });
+        expect(metric).toBeDefined();
+        expect(metric.metric).toBe('ElapsedMetric');
+        expect(metric.spans.length).toBe(1);
+        expect(metric.spans[0].points.length).toBe(1);
+        expect(metric.spans[0].points[0].count).toBe(i + 1);
+        timestamp += interval * 1000;
+    }
+    /*
+        Emit again after long delay this should cause the prior buffer to be flushed
+     */
+    timestamp += 3600 * 1000;
+    await metrics.emit('test/buffer', 'ElapsedMetric', 7, [], { buffer: { elapsed: 1800 }, timestamp });
+    let r = await metrics.query('test/buffer', 'ElapsedMetric', {}, 86400, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.metric).toBe('ElapsedMetric');
+    expect(r.namespace).toBe('test/buffer');
+    expect(r.period).toBe(86400);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[11].value).toBe(11);
+    expect(r.points[11].count).toBe(5);
+});
+test('Test buffer API', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table });
+    let metric = await metrics.emit('test/buffer', 'CoverageMetric', 1, [], { buffer: { sum: 1 } });
+    expect(metric).toBeDefined();
+    metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, buffer: { elapsed: 1800 } });
+    metric = await metrics.emit('test/buffer', 'CoverageMetric', 1, []);
+    expect(metric).toBeDefined();
+    metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, buffer: { elapsed: 1800 } });
+    metric = await metrics.emit('test/buffer', 'CoverageMetric', 1, []);
+    expect(metric).toBeDefined();
+    metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table });
+    metric = await metrics.emit('test/buffer', 'CoverageMetric', 1, [], { buffer: { count: 1 } });
+    metric = await metrics.emit('test/buffer', 'CoverageMetric', 1, [], { buffer: { count: 1 } });
+    expect(metric).toBeDefined();
+});
+test('Test stale buffered data', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, log: true });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    //  Emit a non-buffered metric and query
+    let metric = await metrics.emit('test/buffer', 'StaleMetric', 7, [], { timestamp });
+    expect(metric.spans[0].points[0].sum).toBe(7);
+    let r = await metrics.query('test/buffer', 'StaleMetric', {}, 86400, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.points[11].value).toBe(7);
+    /*
+        Emit a stale buffered metric - should be discarded
+     */
+    timestamp -= 365 * 86400 * 1000;
+    await metrics.emit('test/buffer', 'StaleMetric', 100, [], { buffer: { elapsed: 1800, force: true }, timestamp });
+    //  Result should be the original metric emitted
+    timestamp += 365 * 86400 * 1000;
+    r = await metrics.query('test/buffer', 'StaleMetric', {}, 86400, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.points[11].value).toBe(7);
+});
+test('Buffered metric return', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, log: true });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let interval = 1;
+    for (let i = 0; i < 5; i++) {
+        let metric = await metrics.emit('test/buffer', 'ReturnMetric', 1, [], {
+            buffer: { sum: 5 },
+            timestamp,
+        });
+        if (i < 4) {
+            expect(metric).toBeDefined();
+            expect(metric.spans.length).toBe(1);
+        }
+        else {
+            expect(metric.spans.length).toBe(6);
+        }
+        timestamp += interval * 1000;
+    }
+});
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/constructor.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/constructor.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/constructor.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/constructor.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/constructor.js
new file mode 100644
index 0000000..21db5cd
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/constructor.js
@@ -0,0 +1,105 @@
+"use strict";
+Object.defineProperty(exports, "__esModule", { value: true });
+/*
+    constructor.ts - test constructor options
+ */
+const init_1 = require("./utils/init");
+// jest.setTimeout(7200 * 1000)
+test('Constructor with table name', async () => {
+    let metrics = new init_1.CustomMetrics({ table: init_1.table });
+    expect(metrics).toBeDefined();
+    expect(metrics instanceof init_1.CustomMetrics).toBe(true);
+    expect(typeof metrics.emit == 'function').toBe(true);
+});
+test('Constructor with client', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table });
+    expect(metrics).toBeDefined();
+    expect(metrics instanceof init_1.CustomMetrics).toBe(true);
+    expect(typeof metrics.emit == 'function').toBe(true);
+    let metric = await metrics.emit('test/cons', 'ClientMetric', 10);
+    expect(metric).toBeDefined();
+});
+test('Constructor with custom spans', async () => {
+    const Spans = [{ period: 86400, samples: 24 }];
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, spans: Spans });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let metric;
+    for (let i = 0; i < 26; i++) {
+        metric = await metrics.emit('test/custom', 'CustomMetric', 10, [], { timestamp });
+        timestamp += 3600 * 1000;
+    }
+    expect(metric.spans[0].points.length).toBe(24);
+    let r = await metrics.query('test/custom', 'CustomMetric', {}, 86400, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.period).toBe(86400);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(24);
+    expect(r.points[0].value).toBe(10);
+    expect(r.points[0].count).toBe(1);
+});
+test('Constructor with options', async () => {
+    //  Log true
+    let metrics = new init_1.CustomMetrics({ table: init_1.table });
+    expect(metrics).toBeDefined();
+    //  Verbose log
+    metrics = new init_1.CustomMetrics({ table: init_1.table, log: 'verbose' });
+    expect(metrics).toBeDefined();
+    //  Custom log
+    metrics = new init_1.CustomMetrics({ table: init_1.table, log: {
+            info: (message, context) => null,
+            error: (message, context) => null,
+        } });
+    expect(metrics).toBeDefined();
+    //  Verbose log
+    metrics = new init_1.CustomMetrics({ table: init_1.table, log: 'verbose' });
+    expect(metrics).toBeDefined();
+    //  DynamoDB prefix
+    metrics = new init_1.CustomMetrics({ table: init_1.table, prefix: 'met' });
+    expect(metrics).toBeDefined();
+    //  TTL
+    metrics = new init_1.CustomMetrics({ table: init_1.table, ttl: 86400 });
+    expect(metrics).toBeDefined();
+    //  Consistent
+    metrics = new init_1.CustomMetrics({ table: init_1.table, consistent: true });
+    expect(metrics).toBeDefined();
+    expect(() => {
+        //  empty spans
+        new init_1.CustomMetrics({ table: init_1.table, spans: [] });
+    }).toThrow();
+    expect(() => {
+        //  Invalid pResolution
+        new init_1.CustomMetrics({ table: init_1.table, pResolution: -1 });
+    }).toThrow();
+    expect(() => {
+        //  Invalid buffer
+        new init_1.CustomMetrics({ table: init_1.table, buffer: true });
+    }).toThrow();
+    expect(() => {
+        //  Bad TTL
+        new init_1.CustomMetrics({ table: init_1.table, ttl: true });
+    }).toThrow();
+    expect(() => {
+        //  Bad consistent
+        new init_1.CustomMetrics({ table: init_1.table, consistent: 42 });
+    }).toThrow();
+    expect(() => {
+        //  Bad Source
+        new init_1.CustomMetrics({ table: init_1.table, source: true });
+    }).toThrow();
+    expect(() => {
+        //  Missing database
+        new init_1.CustomMetrics({});
+    }).toThrow();
+    expect(() => {
+        //  Missing table name
+        new init_1.CustomMetrics({ client: init_1.client });
+    }).toThrow();
+    expect(() => {
+        //  Missing options
+        new init_1.CustomMetrics();
+    }).toThrow();
+});
+test('Constructor coverage', async () => {
+    new init_1.CustomMetrics({ table: init_1.table, buffer: { sum: 100 } });
+    new init_1.CustomMetrics({ table: init_1.table, source: 'internal' });
+});
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/debug.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/debug.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/debug.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/debug.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/debug.js
new file mode 100644
index 0000000..85c1a22
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/debug.js
@@ -0,0 +1,6 @@
+"use strict";
+Object.defineProperty(exports, "__esModule", { value: true });
+// jest.setTimeout(7200 * 1000)
+test('Test', async () => {
+    expect(true).toBe(true);
+});
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/emit.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/emit.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/emit.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/emit.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/emit.js
new file mode 100644
index 0000000..d8b07a3
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/emit.js
@@ -0,0 +1,111 @@
+"use strict";
+Object.defineProperty(exports, "__esModule", { value: true });
+/*
+    emit.ts - Test basic emit functionality
+ */
+const init_1 = require("./utils/init");
+// jest.setTimeout(7200 * 1000)
+test('Test basic emit', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, owner: 'service', log: true });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let metric = await metrics.emit('test/emit', 'FirstMetric', 10, [], { timestamp });
+    expect(metric).toBeDefined();
+    expect(metric.namespace).toBe('test/emit');
+    expect(metric.metric).toBe('FirstMetric');
+    expect(metric.owner).toBe('service');
+    expect(metric.spans.length).toBe(init_1.DefaultSpans.length);
+    expect(metric.version).toBe(1);
+    expect(metric.expires).toBeDefined();
+    let span = metric.spans[0];
+    let points = span.points;
+    expect(points.length).toBe(1);
+    expect(span.samples).toBe(init_1.DefaultSpans[0].samples);
+    expect(span.period).toBe(init_1.DefaultSpans[0].period);
+    expect(points[0].count).toBe(1);
+    expect(points[0].sum).toBe(10);
+    expect(points[0].max).toBe(10);
+    expect(points[0].min).toBe(10);
+    /*
+        Query to ensure results are committed
+     */
+    let r = await metrics.query('test/emit', 'FirstMetric', {}, 300, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.metric).toBe('FirstMetric');
+    expect(r.namespace).toBe('test/emit');
+    expect(r.period).toBe(300);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points.at(-1)?.value).toBe(10);
+    expect(r.points.at(-1)?.count).toBe(1);
+    //  The last point bucket will end at timestamp + interval
+    expect(r.points.at(-1)?.timestamp).toBe(timestamp + 30000);
+});
+test('Test emit with dimensions', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, log: true });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    await metrics.emit('test/emit', 'Launches', 10, [{}, { Rocket: 'SaturnV' }], { timestamp });
+    await metrics.emit('test/emit', 'Launches', 10, [{}, { Rocket: 'Falcon9' }], { timestamp });
+    /*
+        Query total launches
+     */
+    let r = await metrics.query('test/emit', 'Launches', {}, 300, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.dimensions).toBeDefined();
+    expect(Object.keys(r.dimensions).length).toBe(0);
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points.at(-1)?.value).toBe(20);
+    expect(r.points.at(-1)?.count).toBe(2);
+    //  Query just one dimension
+    r = await metrics.query('test/emit', 'Launches', { Rocket: 'Falcon9' }, 300, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.dimensions).toBeDefined();
+    expect(r.dimensions.Rocket).toBe('Falcon9');
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points.at(-1)?.value).toBe(10);
+    expect(r.points.at(-1)?.count).toBe(1);
+    //  Query unknown dimension
+    r = await metrics.query('test/emit', 'Launches', { Rocket: 'Starship' }, 300, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.dimensions).toBeDefined();
+    expect(r.dimensions.Rocket).toBe('Starship');
+    expect(r.points.length).toBe(0);
+});
+test('Emit Series', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let span = init_1.DefaultSpans[0];
+    let interval = span.period / span.samples;
+    let metric;
+    for (let i = 0; i < span.samples; i++) {
+        metric = await metrics.emit('test/emit', 'SeriesMetric', i, [], { timestamp });
+        metric = await metrics.emit('test/emit', 'SeriesMetric', i, [], { timestamp: timestamp + 1 });
+        timestamp += interval * 1000;
+    }
+    let r = await metrics.query('test/emit', 'SeriesMetric', {}, 300, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.metric).toBe('SeriesMetric');
+    expect(r.namespace).toBe('test/emit');
+    expect(r.period).toBe(300);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(10);
+});
+test('Emit API', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table });
+    expect(async () => {
+        await metrics.emit('test/emit', 'Launches', null);
+    }).rejects.toThrow();
+    expect(async () => {
+        await metrics.emit('test/emit', 'Launches', undefined);
+    }).rejects.toThrow();
+    expect(async () => {
+        await metrics.emit('test/emit', 'Launches', 'invalid');
+    }).rejects.toThrow();
+    expect(async () => {
+        await metrics.emit(null, 'Launches', 10);
+    }).rejects.toThrow();
+    expect(async () => {
+        await metrics.emit('namespace', null, 10);
+    }).rejects.toThrow();
+    //  Emit with ttl
+    await metrics.emit('test/emit', 'ShortLived', 10, [], { ttl: 3600 });
+});
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/gap.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/gap.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/gap.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/gap.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/gap.js
new file mode 100644
index 0000000..56418ab
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/gap.js
@@ -0,0 +1,94 @@
+"use strict";
+Object.defineProperty(exports, "__esModule", { value: true });
+/*
+    gap.ts - Test gaps in metrics
+ */
+const init_1 = require("./utils/init");
+// jest.setTimeout(7200 * 1000)
+test('Test gaps between emit and query', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let span = init_1.DefaultSpans[0];
+    let interval = span.period / span.samples;
+    let metric;
+    for (let i = 0; i < span.samples * 20; i++) {
+        metric = await metrics.emit('test/gap', 'GapMetric', 10, [], { timestamp });
+        timestamp += interval * 1000;
+    }
+    expect(metric.spans[2].points.length).toBe(1);
+    let r = await metrics.query('test/gap', 'GapMetric', {}, 86400, 'sum', { timestamp });
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points.at(-1)?.count).toBe(20 * span.samples);
+    timestamp += 2 * 86400 * 1000;
+    r = await metrics.query('test/gap', 'GapMetric', {}, 86400, 'sum', { timestamp });
+    expect(r.points.length).toBe(r.samples);
+    for (let i = 0; i < r.samples; i++) {
+        expect(r.points[i].count).toBe(0);
+    }
+});
+test('Test data aging beyond highest span', async () => {
+    const Spans = [{ period: 3600, samples: 4 }];
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, owner: 'service2', log: false, spans: Spans });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let span = Spans[0];
+    let interval = span.period / span.samples;
+    //  Emit more data than will fit in the span
+    let metric;
+    for (let i = 0; i < span.samples * 2; i++) {
+        metric = await metrics.emit('test/gap', 'MyMetric', 1, [], { timestamp });
+        timestamp += interval * 1000;
+    }
+    expect(metric.spans[0].points.length).toBe(4);
+    let r = await metrics.query('test/gap', 'MyMetric', {}, 86400, 'sum', { timestamp, accumulate: true });
+    expect(r.points.length).toBe(1);
+    expect(r.points[0].value).toBe(4);
+});
+test('Test predated data', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table });
+    //  Get at least one point in the span
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let metric = await metrics.emit('test/gap', 'PreDate', 1, [], { timestamp });
+    expect(metric).toBeDefined();
+    //  This emit should be discarded as it is too early
+    timestamp -= 365 * 86400 * 1000;
+    metric = await metrics.emit('test/gap', 'PreDate', 1, [], { timestamp });
+    expect(metric).toBeDefined();
+    expect(metric.spans[0].points.length).toBe(1);
+    expect(metric.spans[5].points.length).toBe(0);
+    timestamp += 365 * 86400 * 1000;
+    let r = await metrics.query('test/gap', 'PreDate', {}, 365 * 86400, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[0].value).toBe(0);
+    expect(r.points[11].count).toBe(1);
+});
+test('Test that points before data and after data are filled', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table });
+    let timestamp = new Date(2000, 0, 1).getTime() + 10 * 3600 * 1000;
+    //  Use the hour span
+    let span = init_1.DefaultSpans[1];
+    let interval = span.period / span.samples;
+    //  Emit two data values separated by point gaps
+    let metric = await metrics.emit('test/gap', 'FillMetric', 10, [], { timestamp });
+    timestamp += 2 * interval * 1000;
+    expect(metric.spans[0].points.length).toBe(1);
+    expect(metric.spans[0].points[0].sum).toBe(10);
+    expect(metric.spans[1].points.length).toBe(0);
+    metric = await metrics.emit('test/gap', 'FillMetric', 20, [], { timestamp });
+    expect(metric.spans[0].points.length).toBe(1);
+    expect(metric.spans[0].points[0].sum).toBe(20);
+    expect(metric.spans[1].points.length).toBe(1);
+    expect(metric.spans[1].points[0].sum).toBe(10);
+    let r = await metrics.query('test/gap', 'FillMetric', {}, 3600, 'sum', { timestamp });
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points.at(-1)?.value).toBe(20);
+    expect(r.points.at(-3)?.value).toBe(10);
+    //  Move time on by 4 intervals
+    //  This takes us outside the special case of query with same timestamp as last emit
+    timestamp += 4 * interval * 1000;
+    r = await metrics.query('test/gap', 'FillMetric', {}, 3600, 'sum', { timestamp });
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points.at(-4)?.value).toBe(20);
+    expect(r.points.at(-6)?.value).toBe(10);
+});
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/list.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/list.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/list.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/list.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/list.js
new file mode 100644
index 0000000..f5c5aae
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/list.js
@@ -0,0 +1,59 @@
+"use strict";
+Object.defineProperty(exports, "__esModule", { value: true });
+/*
+    list.ts - Get metric list
+ */
+const init_1 = require("./utils/init");
+// jest.setTimeout(7200 * 1000)
+test('Test get metric list', async () => {
+    /*
+        Must have unique owner to isolate own namespaces
+     */
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, owner: 'list', log: true });
+    let list = await metrics.getMetricList();
+    expect(list).toBeDefined();
+    expect(list.namespaces).toBeDefined();
+    expect(list.namespaces.length).toBe(0);
+    expect(list.metrics).toBeUndefined();
+    expect(list.dimensions).toBeUndefined();
+    //  Create some metrics
+    await metrics.emit('test/list', 'Launches', 10, [{}, { Rocket: 'SaturnV' }]);
+    await metrics.emit('test/another-list', 'Crashes', 1, [{}, { Rocket: 'SaturnV' }]);
+    //  Should see two namespaces
+    list = await metrics.getMetricList();
+    expect(list).toBeDefined();
+    expect(list.namespaces).toBeDefined();
+    expect(list.namespaces.length).toBe(2);
+    expect(list.namespaces.indexOf('test/list') >= 0).toBe(true);
+    expect(list.namespaces.indexOf('test/another-list') >= 0).toBe(true);
+    expect(list.metrics).toBeUndefined();
+    expect(list.dimensions).toBeUndefined();
+    //  Should see namespaces and metrics
+    list = await metrics.getMetricList('test/list');
+    expect(list).toBeDefined();
+    expect(list.namespaces).toBeDefined();
+    expect(list.namespaces.length).toBe(1);
+    expect(list.namespaces[0]).toBe('test/list');
+    expect(list.metrics).toBeDefined();
+    expect(list.metrics.length).toBe(1);
+    expect(list.metrics[0]).toBe('Launches');
+    expect(list.dimensions).toBeUndefined();
+    //  Should see namespace, metrics and dimensions
+    list = await metrics.getMetricList('test/list', 'Launches');
+    expect(list).toBeDefined();
+    expect(list.namespaces).toBeDefined();
+    expect(list.namespaces.length).toBe(1);
+    expect(list.namespaces[0]).toBe('test/list');
+    expect(list.metrics).toBeDefined();
+    expect(list.metrics.length).toBe(1);
+    expect(list.metrics[0]).toBe('Launches');
+    expect(list.dimensions.length).toBe(2);
+    expect(JSON.stringify(list.dimensions[0])).toBe('{}');
+    expect(JSON.stringify(list.dimensions[1])).toBe('{"Rocket":"SaturnV"}');
+});
+test('List API', async () => {
+    //  With logging to pass through to OneTable find
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table });
+    let list = await metrics.getMetricList('test/list', 'Launches', { log: false });
+    expect(list).toBeDefined();
+});
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/log.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/log.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/log.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/log.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/log.js
new file mode 100644
index 0000000..2b70002
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/log.js
@@ -0,0 +1,25 @@
+"use strict";
+Object.defineProperty(exports, "__esModule", { value: true });
+/*
+    log.ts - Logging
+ */
+const init_1 = require("./utils/init");
+// jest.setTimeout(7200 * 1000)
+test('Constructor without logging', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table });
+    let metric = await metrics.emit('test/log', 'FirstMetric', 10);
+    expect(metric).toBeDefined();
+    let r = await metrics.query('test/log', 'FirstMetric', {}, 300, 'sum');
+    expect(r).toBeDefined();
+    let list = await metrics.getMetricList('test/log');
+    expect(list).toBeDefined();
+});
+test('Constructor with logging', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, log: true });
+    let metric = await metrics.emit('test/log', 'FirstMetric', 10);
+    expect(metric).toBeDefined();
+    let r = await metrics.query('test/log', 'FirstMetric', {}, 300, 'sum');
+    expect(r).toBeDefined();
+    let list = await metrics.getMetricList('test/log');
+    expect(list).toBeDefined();
+});
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/owner.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/owner.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/owner.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/owner.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/owner.js
new file mode 100644
index 0000000..af4ca97
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/owner.js
@@ -0,0 +1,41 @@
+"use strict";
+Object.defineProperty(exports, "__esModule", { value: true });
+/*
+    owner.ts - test owner scoping
+ */
+const init_1 = require("./utils/init");
+// jest.setTimeout(7200 * 1000)
+test('Constructor no owner', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table });
+    expect(metrics).toBeDefined();
+});
+test('Constructor with different owners', async () => {
+    let m1 = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, owner: 'app1' });
+    let m2 = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, owner: 'service2' });
+    //  These should not clash
+    await m1.emit('test/owner', 'Launches', 5);
+    await m2.emit('test/owner', 'Launches', 10);
+    let r1 = await m1.query('test/owner', 'Launches', {}, 86400, 'sum');
+    expect(r1).toBeDefined();
+    expect(r1.owner).toBe('app1');
+    expect(r1.points.length).toBe(r1.samples);
+    expect(r1.points[11].value).toBe(5);
+    let r2 = await m2.query('test/owner', 'Launches', {}, 86400, 'sum');
+    expect(r2).toBeDefined();
+    expect(r2.owner).toBe('service2');
+    expect(r2.points.length).toBe(r1.samples);
+    expect(r2.points[11].value).toBe(10);
+});
+test('Owner with namespaces', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table });
+    let metric = await metrics.emit('test/owner', 'FirstMetric', 10, [{}, { Rocket: 'SaturnV' }]);
+    expect(metric).toBeDefined();
+    await metrics.emit('test/owner', 'SecondMetric', 10);
+    await metrics.emit('test/owner/2', 'ThirdMetric', 10);
+    let list = await metrics.getMetricList('test/owner');
+    expect(list).toBeDefined();
+    expect(list.namespaces).toBeDefined();
+    list = await metrics.getMetricList('test/owner', 'FirstMetric');
+    expect(list).toBeDefined();
+    expect(list.namespaces).toBeDefined();
+});
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/propagate.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/propagate.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/propagate.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/propagate.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/propagate.js
new file mode 100644
index 0000000..f5c07c1
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/propagate.js
@@ -0,0 +1,30 @@
+"use strict";
+Object.defineProperty(exports, "__esModule", { value: true });
+/*
+    propagate.ts - Test emit will propagate from span to span
+ */
+const init_1 = require("./utils/init");
+// jest.setTimeout(7200 * 1000)
+test('Test', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let span = init_1.DefaultSpans[2];
+    let interval = span.period / span.samples;
+    for (let i = 0; i < 4; i++) {
+        await metrics.emit('test/propagate', 'FirstMetric', 10, [], { timestamp });
+        timestamp += interval * 1000;
+    }
+    timestamp -= (interval * 1000);
+    let r = await metrics.query('test/propagate', 'FirstMetric', {}, 86400, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.metric).toBe('FirstMetric');
+    expect(r.namespace).toBe('test/propagate');
+    expect(r.period).toBe(span.period);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[8].value).toBe(10);
+    expect(r.points[8].count).toBe(1);
+    expect(r.points[9].value).toBe(10);
+    expect(r.points[10].value).toBe(10);
+    expect(r.points[11].value).toBe(10);
+});
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/pvalues.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/pvalues.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/pvalues.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/pvalues.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/pvalues.js
new file mode 100644
index 0000000..f6820ef
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/pvalues.js
@@ -0,0 +1,33 @@
+"use strict";
+Object.defineProperty(exports, "__esModule", { value: true });
+/*
+    pvalues.ts - Test emit and query with P-values
+ */
+const init_1 = require("./utils/init");
+// jest.setTimeout(7200 * 1000)
+test('Test emit with P-Values', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, pResolution: 10 });
+    for (let i = 0; i < 10; i++) {
+        await metrics.emit('test/pvalues', 'PMetric', i);
+    }
+    //  p90
+    let r = await metrics.query('test/pvalues', 'PMetric', {}, 300, 'p90');
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[9].value).toBe(9);
+    expect(r.points[9].count).toBe(10);
+    //  p50
+    r = await metrics.query('test/pvalues', 'PMetric', {}, 300, 'p50');
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[9].value).toBe(6);
+    expect(r.points[9].count).toBe(10);
+    //  Accumulate
+    r = await metrics.query('test/pvalues', 'PMetric', {}, 300, 'p50', { accumulate: true });
+    expect(r.points.length).toBe(1);
+    expect(r.points[0].value).toBe(6);
+    expect(r.points[0].count).toBe(10);
+    //  Higher span
+    r = await metrics.query('test/pvalues', 'PMetric', {}, 86400, 'p90');
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[11].value).toBe(9);
+    expect(r.points[11].count).toBe(10);
+});
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/query.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/query.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/query.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/query.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/query.js
new file mode 100644
index 0000000..c017d85
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/query.js
@@ -0,0 +1,192 @@
+"use strict";
+Object.defineProperty(exports, "__esModule", { value: true });
+/*
+    query.ts - Test metric query
+ */
+const init_1 = require("./utils/init");
+// jest.setTimeout(7200 * 1000)
+test('Test basic query', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, log: false });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let metric;
+    for (let i = 0; i < 10; i++) {
+        metric = await metrics.emit('test/query', 'BasicMetric', 7, [], { timestamp });
+        timestamp += 30 * 1000;
+    }
+    expect(metric.spans[0].points.length).toBe(10);
+    let r = await metrics.query('test/query', 'BasicMetric', {}, 300, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.period).toBe(init_1.DefaultSpans[0].period);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(10);
+    expect(r.points.at(-1)?.value).toBe(7);
+    expect(r.points.at(-1)?.count).toBe(1);
+});
+test('Test query period', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, log: false });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let metric;
+    for (let i = 0; i < 10; i++) {
+        metric = await metrics.emit('test/query', 'PeriodMetric', 7, [], { timestamp });
+        timestamp += 30 * 1000;
+    }
+    // timestamp -= 30 * 1000
+    expect(metric.spans[0].points.length).toBe(10);
+    //  With a period shorter than the lowest span - only one interval
+    let r = await metrics.query('test/query', 'PeriodMetric', {}, 30, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.period).toBe(init_1.DefaultSpans[0].period);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(1);
+    expect(r.points[0].value).toBe(7);
+    expect(r.points[0].count).toBe(1);
+    //  With a period above the span emitted
+    r = await metrics.query('test/query', 'PeriodMetric', {}, 3600, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.period).toBe(3600);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[11].value).toBe(70);
+    expect(r.points[11].count).toBe(10);
+    //  With a period above the highest span
+    let period = init_1.DefaultSpans.at(-1).period;
+    r = await metrics.query('test/query', 'PeriodMetric', {}, period + 1000, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.period).toBe(period);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[11].value).toBe(70);
+    expect(r.points[11].count).toBe(10);
+});
+test('Test query statistics', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let span = init_1.DefaultSpans[0];
+    let interval = span.period / span.samples;
+    let metric;
+    for (let i = 0; i < 4; i++) {
+        await metrics.emit('test/query', 'StatMetric', i, [], { timestamp });
+        //  Emit a second data point 1ms after
+        metric = await metrics.emit('test/query', 'StatMetric', i + 1, [], { timestamp: timestamp + 1 });
+        timestamp += interval * 1000;
+    }
+    timestamp -= interval * 1000;
+    //  Average
+    let r = await metrics.query('test/query', 'StatMetric', {}, 300, 'avg', { timestamp });
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[6].value).toBe(0.5);
+    expect(r.points[6].count).toBe(2);
+    expect(r.points[7].value).toBe(1.5);
+    expect(r.points[7].count).toBe(2);
+    expect(r.points[8].value).toBe(2.5);
+    expect(r.points[8].count).toBe(2);
+    expect(r.points[9].value).toBe(3.5);
+    expect(r.points[9].count).toBe(2);
+    //  Min
+    r = await metrics.query('test/query', 'StatMetric', {}, 300, 'min', { timestamp });
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[0].value).toBe(0);
+    expect(r.points[6].count).toBe(2);
+    //  Max
+    r = await metrics.query('test/query', 'StatMetric', {}, 300, 'max', { timestamp });
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[0].value).toBe(0);
+    expect(r.points[9].value).toBe(4);
+    expect(r.points[9].count).toBe(2);
+    //  Count
+    r = await metrics.query('test/query', 'StatMetric', {}, 300, 'count', { timestamp });
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[0].value).toBe(0);
+    expect(r.points[9].count).toBe(2);
+    expect(r.points[9].value).toBe(2);
+});
+test('Test query statistics with accumulate', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let span = init_1.DefaultSpans[0];
+    let interval = span.period / span.samples;
+    let metric;
+    for (let i = 0; i < span.samples; i++) {
+        // Multiple points
+        metric = await metrics.emit('test/query', 'AccMetric', i, [], { timestamp });
+        metric = await metrics.emit('test/query', 'AccMetric', i, [], { timestamp: timestamp + 1 });
+        timestamp += interval * 1000;
+    }
+    timestamp -= interval * 1000;
+    //  Average
+    let r = await metrics.query('test/query', 'AccMetric', {}, 300, 'avg', { accumulate: true, timestamp });
+    expect(r.points.length).toBe(1);
+    expect(r.points[0].value).toBe(4.5);
+    expect(r.points[0].count).toBe(20);
+    //  Min
+    r = await metrics.query('test/query', 'AccMetric', {}, 300, 'min', { accumulate: true, timestamp });
+    expect(r.points.length).toBe(1);
+    expect(r.points[0].value).toBe(0);
+    expect(r.points[0].count).toBe(20);
+    //  Max
+    r = await metrics.query('test/query', 'AccMetric', {}, 300, 'max', { accumulate: true, timestamp });
+    expect(r.points.length).toBe(1);
+    expect(r.points[0].value).toBe(9);
+    expect(r.points[0].count).toBe(20);
+    //  Count
+    r = await metrics.query('test/query', 'AccMetric', {}, 300, 'count', { accumulate: true, timestamp });
+    expect(r.points.length).toBe(1);
+    expect(r.points[0].value).toBe(20);
+    expect(r.points[0].count).toBe(20);
+});
+test('Test query p values', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, pResolution: 10 });
+    // let timestamp = new Date(2000, 0, 1).getTime()
+    for (let i = 0; i < 10; i++) {
+        await metrics.emit('test/query', 'PMetric', i, []);
+    }
+    //  p90
+    let r = await metrics.query('test/query', 'PMetric', {}, 300, 'p90');
+    expect(r.period).toBe(300);
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[9].value).toBe(9);
+    expect(r.points[9].count).toBe(10);
+    //  p50
+    r = await metrics.query('test/query', 'PMetric', {}, 300, 'p50');
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[9].value).toBe(6);
+    expect(r.points[9].count).toBe(10);
+});
+test('Test missing metrics', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    //  Missing namespace
+    let r = await metrics.query('Unknown', 'Unknown', {}, 300, 'avg', { timestamp });
+    expect(r.points.length).toBe(0);
+    //  Missing metric
+    await metrics.emit('test/query', 'MMetric', 1, [], { timestamp });
+    r = await metrics.query('test/query', 'Unknown', {}, 300, 'avg', { timestamp });
+    expect(r.points.length).toBe(0);
+    //  Missing span, but still return data point
+    r = await metrics.query('test/query', 'MMetric', {}, 86400, 'avg', { timestamp });
+    expect(r.points.length).toBe(r.samples);
+});
+test('Test query with non-standard period', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, log: false });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let metric;
+    for (let i = 0; i < 140; i++) {
+        metric = await metrics.emit('test/query', 'BasicMetric', 7, [], { timestamp });
+        timestamp += 30 * 1000;
+    }
+    // timestamp -= 30 * 1000
+    expect(metric.spans[0].points.length).toBe(10);
+    /*
+        Query 15 minutes
+        This will return 3 points from the next span up (1 hr)
+     */
+    let r = await metrics.query('test/query', 'BasicMetric', {}, 900, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.period).toBe(init_1.DefaultSpans[1].period);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(3);
+    expect(r.points[0].count).toBe(10);
+    expect(r.points[0].value).toBe(70);
+    expect(r.points[1].value).toBe(70);
+    expect(r.points[2].value).toBe(70);
+});
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/ranged.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/ranged.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/ranged.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/ranged.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/ranged.js
new file mode 100644
index 0000000..84e0ff1
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/ranged.js
@@ -0,0 +1,35 @@
+"use strict";
+Object.defineProperty(exports, "__esModule", { value: true });
+/*
+    ranged.ts - Get a range of data
+ */
+const init_1 = require("./utils/init");
+// jest.setTimeout(7200 * 1000)
+test('Test that points before data and after data are filled', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table });
+    let timestamp = new Date(2000, 0, 1).getTime() + 10 * 3600 * 1000;
+    //  Use the year span
+    let span = init_1.DefaultSpans[5];
+    let interval = span.period / span.samples;
+    /*
+        Emit one year worth of data
+     */
+    for (let i = 0; i < 12; i++) {
+        await metrics.emit('test/gg', 'FillMetric', i + 1, [], { timestamp });
+        timestamp += interval * 1000;
+    }
+    /*
+        Query 1/4 starting 7 months back
+     */
+    let period = span.period / 4;
+    let start = timestamp - (interval * 7 * 1000);
+    let r = await metrics.query('test/gg', 'FillMetric', {}, period, 'sum', { start, timestamp });
+    expect(r.points.length).toBe(3);
+    expect(r.points[0].value).toBe(7);
+    expect(r.points[1].value).toBe(8);
+    expect(r.points[2].value).toBe(9);
+    //  Query accumulate
+    r = await metrics.query('test/gg', 'FillMetric', {}, period, 'sum', { start, timestamp, accumulate: true });
+    expect(r.points.length).toBe(1);
+    expect(r.points[0].value).toBe(24);
+});
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/series.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/series.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/series.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/series.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/series.js
new file mode 100644
index 0000000..9d76c4d
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/series.js
@@ -0,0 +1,31 @@
+"use strict";
+Object.defineProperty(exports, "__esModule", { value: true });
+/*
+    series.ts - Test query with series results
+ */
+const init_1 = require("./utils/init");
+// jest.setTimeout(7200 * 1000)
+test('Test query with series', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let span = init_1.DefaultSpans[2];
+    let interval = span.period / span.samples;
+    let metric;
+    for (let i = 0; i < 4; i++) {
+        metric = await metrics.emit('test/series', 'FirstMetric', 10 * (i + 1), [], { timestamp });
+        timestamp += interval * 1000;
+    }
+    timestamp -= (interval * 1000);
+    let r = await metrics.query('test/series', 'FirstMetric', {}, 86400, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.metric).toBe('FirstMetric');
+    expect(r.namespace).toBe('test/series');
+    expect(r.period).toBe(span.period);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[8].value).toBe(10);
+    expect(r.points[8].count).toBe(1);
+    expect(r.points[9].value).toBe(20);
+    expect(r.points[10].value).toBe(30);
+    expect(r.points[11].value).toBe(40);
+});
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/spans.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/spans.d.ts
new file mode 100644
index 0000000..12f7f4a
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/spans.d.ts
@@ -0,0 +1,2 @@
+import { SpanDef } from './utils/init';
+export declare const Spans: SpanDef[];
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/spans.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/spans.js
new file mode 100644
index 0000000..47340fc
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/spans.js
@@ -0,0 +1,34 @@
+"use strict";
+Object.defineProperty(exports, "__esModule", { value: true });
+exports.Spans = void 0;
+/*
+    spans.ts - Custom spans
+ */
+const init_1 = require("./utils/init");
+// jest.setTimeout(7200 * 1000)
+exports.Spans = [
+    // {period: 1 * 60, samples: 12}, //  60, 1 mins, interval: 5 secs
+    { period: 5 * 60, samples: 10 }, //  300, 5 mins, interval: 30 secs
+    { period: 60 * 60, samples: 12 }, //  3600, 1 hr, interval: 5 mins
+    { period: 3 * 60 * 60, samples: 12 }, // 10800, 3 hrs, interval: 15 mins
+    { period: 6 * 60 * 60, samples: 12 }, // 21600, 6 hrs, interval: 30 mins
+    { period: 24 * 60 * 60, samples: 12 }, // 86400, 24 hrs, interval: 2 hrs
+    { period: 7 * 24 * 60 * 60, samples: 14 }, // 604,800, 7 days, interval: 1/2 day
+    { period: 28 * 24 * 60 * 60, samples: 14 }, // 2,419,200, 28 days, interval: 2 days
+    { period: 3 * 28 * 24 * 60 * 60, samples: 12 }, // 7,257,600, 1 quarter, interval: 1 week
+    { period: 6 * 28 * 24 * 60 * 60, samples: 12 }, // 14,515,200, 2 quarters, interval: 2 weeks
+    { period: 365 * 24 * 60 * 60, samples: 12 }, // 31,536,000, 1 year, interval: 1 month
+];
+test('Basic test harness', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, log: true, spans: exports.Spans });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let interval = 60 * 15;
+    for (let i = 0; i < 10; i++) {
+        let metric = await metrics.emit('test/spans', 'MyMetric', 10, [], { timestamp });
+        for (let span of metric.spans) {
+            span.ee = new Date(span.end * 1000);
+        }
+        expect(metric).toBeDefined();
+        timestamp += interval * 1000;
+    }
+});
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/start.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/start.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/start.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/start.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/start.js
new file mode 100644
index 0000000..4771f43
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/start.js
@@ -0,0 +1,44 @@
+"use strict";
+Object.defineProperty(exports, "__esModule", { value: true });
+/*
+    start.ts - Test metric query with start time
+ */
+const init_1 = require("./utils/init");
+// jest.setTimeout(7200 * 1000)
+test('Test query with start', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, log: false });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let metric;
+    //  One week of data
+    for (let i = 0; i < 24 * 7; i++) {
+        metric = await metrics.emit('test/query', 'StartMetric', 7, [], { timestamp });
+        timestamp += 3600 * 1000;
+    }
+    expect(metric.spans.length).toBe(6);
+    expect(metric.spans.at(0).points.length).toBe(1);
+    expect(metric.spans.at(1).points.length).toBe(1);
+    expect(metric.spans.at(2).points.length).toBe(12);
+    expect(metric.spans.at(3).points.length).toBe(12);
+    //  Get last day
+    let r = await metrics.query('test/query', 'StartMetric', {}, 86400, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.period).toBe(init_1.DefaultSpans[2].period);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(12);
+    expect(r.points[0].value).toBe(14);
+    expect(r.points[0].count).toBe(2);
+    /*
+        Get last 2 days of data starting 4 days ago
+        This is using the week span with 1/2 day intervals
+     */
+    let start = timestamp - 86400 * 4 * 1000;
+    r = await metrics.query('test/query', 'StartMetric', {}, 86400 * 2, 'sum', { start, timestamp });
+    expect(r).toBeDefined();
+    expect(r.period).toBe(init_1.DefaultSpans[3].period);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(4);
+    expect(r.points.at(-1)?.value).toBe(84);
+    expect(r.points.at(-1)?.count).toBe(12);
+    //  MOB - more tests with start before spans
+    //  MOB test with start + period after ...
+});
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/table.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/table.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/table.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/table.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/table.js
new file mode 100644
index 0000000..9e5d5bd
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/table.js
@@ -0,0 +1,23 @@
+"use strict";
+Object.defineProperty(exports, "__esModule", { value: true });
+/*
+    table.ts - Test get metric table of dimensions
+ */
+const init_1 = require("./utils/init");
+jest.setTimeout(7200 * 1000);
+test('Test get metric table', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, log: true });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let metric = await metrics.emit('test/table', 'Temp', 10, [], { timestamp });
+    metric = await metrics.emit('test/table', 'Temp', 10, [{}, { Rocket: 'SaturnV' }], { timestamp });
+    metric = await metrics.emit('test/table', 'Temp', 10, [{}, { Rocket: 'Falcon9' }], { timestamp });
+    let list = await metrics.queryMetrics('test/table', 'Temp', 300, 'sum', { timestamp });
+    expect(list).toBeDefined();
+    expect(list.length).toBe(3);
+    expect(list[0].dimensions).toEqual({});
+    expect(list[0].points.length).toBe(1);
+    expect(list[0].points[0].value).toBe(30);
+    expect(list[1].dimensions).toEqual({ Rocket: 'Falcon9' });
+    expect(list[1].points.length).toBe(1);
+    expect(list[1].points[0].value).toBe(10);
+});
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/upgrade.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/upgrade.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/upgrade.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/upgrade.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/upgrade.js
new file mode 100644
index 0000000..b9bf5bc
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/upgrade.js
@@ -0,0 +1,79 @@
+"use strict";
+Object.defineProperty(exports, "__esModule", { value: true });
+/*
+    upgrade.ts - Upgrade spans
+ */
+const init_1 = require("./utils/init");
+// jest.setTimeout(7200 * 1000)
+const LessSpans = [
+    { period: 24 * 60 * 60, samples: 12 }, // 86400, 24 hrs, interval: 2 hrs
+    { period: 365 * 24 * 60 * 60, samples: 12 }, // 31,536,000, 1 year, interval: 1 month
+];
+const MoreSpans = [
+    { period: 1 * 60, samples: 12 }, //  60, 1 min, interval: 5 secs
+    { period: 5 * 60, samples: 10 }, //  300, 5 mins, interval: 30 secs
+    { period: 60 * 60, samples: 12 }, //  3600, 1 hr, interval: 5 mins
+    { period: 3 * 60 * 60, samples: 12 }, //  10,800, 3 hrs, interval: 15 mins
+    { period: 6 * 60 * 60, samples: 12 }, //  21600, 6 hr, interval: 30 mins
+    { period: 24 * 60 * 60, samples: 12 }, // 86400, 24 hrs, interval: 2 hrs
+    { period: 7 * 24 * 60 * 60, samples: 14 }, // 604,800, 7 days, interval: 1/2 day
+    { period: 28 * 24 * 60 * 60, samples: 14 }, // 2,419,200, 28 days, interval: 2 days
+    { period: 365 * 24 * 60 * 60, samples: 12 }, // 31,536,000, 1 year, interval: 1 month
+];
+test('Upgrade Spans', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, log: true });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let metric;
+    let count = 4;
+    for (let i = 0; i < count; i++) {
+        metric = await metrics.emit('test/upgrade', 'UpMetric', 7, [], { timestamp });
+        timestamp += 30 * 1000;
+    }
+    expect(metric).toBeDefined();
+    expect(metric.spans.length).toBe(6);
+    let sum = 0;
+    for (let span of metric.spans) {
+        sum += span.points.reduce((total, point) => total + point.count, 0);
+    }
+    expect(sum).toBe(count);
+    //  Test upgrade
+    metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, log: true, spans: MoreSpans });
+    metric = await metrics.upgrade('test/upgrade', 'UpMetric', []);
+    expect(metric).toBeDefined();
+    expect(metric.spans.length).toBe(9);
+    sum = 0;
+    for (let span of metric.spans) {
+        sum += span.points.reduce((total, point) => total + point.count, 0);
+    }
+    expect(sum).toBe(count);
+    //  Test downgrade
+    metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, log: true, spans: LessSpans });
+    metric = await metrics.upgrade('test/upgrade', 'UpMetric', []);
+    expect(metric).toBeDefined();
+    expect(metric.spans.length).toBe(2);
+    sum = 0;
+    for (let span of metric.spans) {
+        sum += span.points.reduce((total, point) => total + point.count, 0);
+    }
+    expect(sum).toBe(count);
+    //  Test already upgraded
+    metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, log: true, spans: LessSpans });
+    metric = await metrics.upgrade('test/upgrade', 'UpMetric', []);
+    expect(metric).toBeDefined();
+    expect(metric.spans.length).toBe(2);
+    sum = 0;
+    for (let span of metric.spans) {
+        sum += span.points.reduce((total, point) => total + point.count, 0);
+    }
+    expect(sum).toBe(count);
+    //  Test inline upgrade with emit
+    metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, log: true, spans: LessSpans });
+    metric = await metrics.emit('test/upgrade', 'UpMetric', 7, [], { upgrade: true });
+    expect(metric).toBeDefined();
+    expect(metric.spans.length).toBe(2);
+    sum = 0;
+    for (let span of metric.spans) {
+        sum += span.points.reduce((total, point) => total + point.count, 0);
+    }
+    expect(sum).toBe(count + 1);
+});
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/utils/init.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/utils/init.d.ts
new file mode 100644
index 0000000..0f77457
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/utils/init.d.ts
@@ -0,0 +1,11 @@
+import { CustomMetrics, DefaultSpans, Metric, MetricQueryResult, SpanDef } from '../../src/index';
+import SenseLogs from 'senselogs';
+declare const log: SenseLogs;
+declare const client: any;
+declare const table: any;
+declare const dump: (...args: any[]) => string;
+declare const dumpMetric: (metric: Metric) => void;
+declare const dumpQuery: (metric: MetricQueryResult) => void;
+declare const print: (...args: any[]) => void;
+declare const delay: (time: number) => Promise<unknown>;
+export { table, client, CustomMetrics, DefaultSpans, SpanDef, delay, dump, dumpMetric, dumpQuery, log, print };
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/utils/init.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/utils/init.js
new file mode 100644
index 0000000..3a3f674
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/utils/init.js
@@ -0,0 +1,92 @@
+"use strict";
+var __importDefault = (this && this.__importDefault) || function (mod) {
+    return (mod && mod.__esModule) ? mod : { "default": mod };
+};
+Object.defineProperty(exports, "__esModule", { value: true });
+exports.print = exports.log = exports.dumpQuery = exports.dumpMetric = exports.dump = exports.delay = exports.DefaultSpans = exports.CustomMetrics = exports.client = exports.table = void 0;
+const index_1 = require("../../src/index");
+Object.defineProperty(exports, "CustomMetrics", { enumerable: true, get: function () { return index_1.CustomMetrics; } });
+Object.defineProperty(exports, "DefaultSpans", { enumerable: true, get: function () { return index_1.DefaultSpans; } });
+const senselogs_1 = __importDefault(require("senselogs"));
+const log = new senselogs_1.default({ destination: 'stdout', format: 'human' });
+exports.log = log;
+/*
+    Share the client and table created in setup.ts
+ */
+const client = globalThis.DynamoDBClient;
+exports.client = client;
+const table = globalThis.TableName;
+exports.table = table;
+//  Format date
+function fmtdate(n) {
+    function padTo2Digits(num) {
+        return num.toString().padStart(2, '0');
+    }
+    let date = new Date(n);
+    const year = date.getFullYear().toString().slice(-2); // Get last two digits of the year
+    const month = padTo2Digits(date.getMonth() + 1); // Months are zero-indexed
+    const day = padTo2Digits(date.getDate());
+    const hours = padTo2Digits(date.getHours());
+    const minutes = padTo2Digits(date.getMinutes());
+    const seconds = padTo2Digits(date.getSeconds());
+    return `${year}-${month}-${day} ${hours}:${minutes}:${seconds}`;
+}
+function dt(n) {
+    return fmtdate(n * 1000);
+}
+const dump = (...args) => {
+    let s = [];
+    for (let item of args) {
+        let values = JSON.stringify(item, function (key, value) {
+            if (this[key] instanceof Date) {
+                return fmtdate(this[key].getTime());
+            }
+            return value;
+        }, 4);
+        s.push(values);
+    }
+    let result = s.join(' ');
+    console.log(result);
+    return result;
+};
+exports.dump = dump;
+const dumpMetric = function (metric) {
+    let buf = [];
+    buf.push(`${metric.namespace}/${metric.metric}/${JSON.stringify(metric.dimensions)}`);
+    for (let span of metric.spans) {
+        let interval = span.period / span.samples;
+        let start = span.end - span.points.length * interval;
+        buf.push(` ${span.period} secs ${fmtdate(start * 1000)} => ${fmtdate(span.end * 1000)} ${span.points.length} points`);
+        for (let point of span.points) {
+            buf.push(`     count ${point.count} = sum ${point.sum}`);
+        }
+    }
+    print(buf.join('\n'));
+};
+exports.dumpMetric = dumpMetric;
+const dumpQuery = function (metric) {
+    let points = metric.points.slice(0);
+    let buf = [];
+    buf.push(`${metric.namespace}/${metric.metric}/${JSON.stringify(metric.dimensions)} ${metric.period} ${points.length} points`);
+    for (let point of points) {
+        buf.push(`     ${fmtdate(point.timestamp || 0)} = ${point.value || '-'} / ${point.count}`);
+    }
+    print(buf.join('\n'));
+};
+exports.dumpQuery = dumpQuery;
+const print = (...args) => {
+    console.log(...args);
+};
+exports.print = print;
+globalThis.dt = dt;
+globalThis.fmtdate = fmtdate;
+globalThis.dump = dump;
+globalThis.dumpMetric = dumpMetric;
+globalThis.dumpQuery = dumpQuery;
+globalThis.print = print;
+const delay = async (time) => {
+    return new Promise(function (resolve, reject) {
+        setTimeout(() => resolve(true), time);
+    });
+};
+exports.delay = delay;
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/utils/setup.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/utils/setup.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/utils/setup.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/utils/setup.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/utils/setup.js
new file mode 100644
index 0000000..4b2ad0a
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/utils/setup.js
@@ -0,0 +1,110 @@
+"use strict";
+var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
+    if (k2 === undefined) k2 = k;
+    var desc = Object.getOwnPropertyDescriptor(m, k);
+    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
+      desc = { enumerable: true, get: function() { return m[k]; } };
+    }
+    Object.defineProperty(o, k2, desc);
+}) : (function(o, m, k, k2) {
+    if (k2 === undefined) k2 = k;
+    o[k2] = m[k];
+}));
+var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
+    Object.defineProperty(o, "default", { enumerable: true, value: v });
+}) : function(o, v) {
+    o["default"] = v;
+});
+var __importStar = (this && this.__importStar) || (function () {
+    var ownKeys = function(o) {
+        ownKeys = Object.getOwnPropertyNames || function (o) {
+            var ar = [];
+            for (var k in o) if (Object.prototype.hasOwnProperty.call(o, k)) ar[ar.length] = k;
+            return ar;
+        };
+        return ownKeys(o);
+    };
+    return function (mod) {
+        if (mod && mod.__esModule) return mod;
+        var result = {};
+        if (mod != null) for (var k = ownKeys(mod), i = 0; i < k.length; i++) if (k[i] !== "default") __createBinding(result, mod, k[i]);
+        __setModuleDefault(result, mod);
+        return result;
+    };
+})();
+var __importDefault = (this && this.__importDefault) || function (mod) {
+    return (mod && mod.__esModule) ? mod : { "default": mod };
+};
+Object.defineProperty(exports, "__esModule", { value: true });
+/*
+    Setup -- setup for the test run
+ */
+const client_dynamodb_1 = require("@aws-sdk/client-dynamodb");
+const client_dynamodb_2 = require("@aws-sdk/client-dynamodb");
+const DynamoDbLocal = __importStar(require("dynamo-db-local"));
+const wait_port_1 = __importDefault(require("wait-port"));
+const PORT = parseInt(process.env.PORT || '4765');
+module.exports = async () => {
+    /*
+        Start the local dynamodb
+     */
+    let dynamodb = DynamoDbLocal.spawn({ port: PORT });
+    console.info('\nSpawn DynamoDB', dynamodb.pid);
+    await (0, wait_port_1.default)({ host: '0.0.0.0', port: PORT, timeout: 10000 });
+    process.env.DYNAMODB_PID = String(dynamodb.pid);
+    process.env.DYNAMODB_PORT = String(PORT);
+    /*
+        Create the AWS client
+     */
+    const client = new client_dynamodb_1.DynamoDBClient({
+        endpoint: `http://localhost:${PORT}`,
+        region: 'local',
+        credentials: { accessKeyId: 'test', secretAccessKey: 'test' },
+    });
+    await createTable(client, 'CustomMetrics');
+    globalThis.DynamoDBClient = client;
+    // When jest throws anything unhandled, ensure we kill the spawned process
+    process.on('unhandledRejection', (error) => {
+        let pid = parseInt(process.env.DYNAMODB_PID || '');
+        if (pid) {
+            process.kill(pid);
+        }
+    });
+};
+async function createTable(client, table) {
+    let def = {
+        AttributeDefinitions: [
+            { AttributeName: 'pk', AttributeType: 'S' },
+            { AttributeName: 'sk', AttributeType: 'S' },
+        ],
+        KeySchema: [
+            { AttributeName: 'pk', KeyType: 'HASH' },
+            { AttributeName: 'sk', KeyType: 'RANGE' },
+        ],
+        TableName: table,
+        BillingMode: 'PAY_PER_REQUEST',
+    };
+    let command = new client_dynamodb_2.CreateTableCommand(def);
+    await client.send(command);
+    /*
+        Wait for the table to become live
+     */
+    let deadline = Date.now() + 10 * 1000;
+    do {
+        let command = new client_dynamodb_2.DescribeTableCommand({ TableName: 'CustomMetrics' });
+        let info = await client.send(command);
+        if (info.Table.TableStatus == 'ACTIVE') {
+            break;
+        }
+        if (deadline < Date.now()) {
+            throw new Error('Table has not become active');
+        }
+        await delay(1000);
+    } while (Date.now() < deadline);
+    globalThis.TableName = table;
+}
+const delay = async (time) => {
+    return new Promise(function (resolve, reject) {
+        setTimeout(() => resolve(true), time);
+    });
+};
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/utils/teardown.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/utils/teardown.d.ts
new file mode 100644
index 0000000..e69de29
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/utils/teardown.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/utils/teardown.js
new file mode 100644
index 0000000..5a587ca
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/utils/teardown.js
@@ -0,0 +1,6 @@
+module.exports = async () => {
+    let pid = parseInt(process.env.DYNAMODB_PID || '');
+    if (pid) {
+        process.kill(pid);
+    }
+};
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/year.d.ts b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/year.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/year.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/cjs/metrics/test/year.js b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/year.js
new file mode 100644
index 0000000..ff1528a
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/cjs/metrics/test/year.js
@@ -0,0 +1,34 @@
+"use strict";
+Object.defineProperty(exports, "__esModule", { value: true });
+/*
+    year.ts - Test emit functionality for one year
+ */
+const init_1 = require("./utils/init");
+// jest.setTimeout(7200 * 1000)
+test('Test year span', async () => {
+    let metrics = new init_1.CustomMetrics({ client: init_1.client, table: init_1.table, owner: 'service', log: true });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let span = init_1.DefaultSpans[5];
+    let interval = span.period / span.samples;
+    for (let i = 0; i < 12; i++) {
+        let metric = await metrics.emit('test/year', 'FirstMetric', i + 1, [], { timestamp });
+        // dumpMetric(metric)
+        timestamp += interval * 1000;
+    }
+    /*
+        Expect results to be span bucket aligned. i.e. first point timestamp will be 00-02-24 and
+        the last bucket will be partial 00-12-31
+     */
+    let r = await metrics.query('test/year', 'FirstMetric', {}, span.period, 'sum', { timestamp });
+    // dumpQuery(r)
+    expect(r).toBeDefined();
+    expect(r.metric).toBe('FirstMetric');
+    expect(r.namespace).toBe('test/year');
+    expect(r.period).toBe(span.period);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points.at(-2)?.value).toBe(12);
+    expect(r.points.at(-2)?.count).toBe(1);
+    expect(r.points.at(-1)?.timestamp).toBe(timestamp);
+    expect(r.points.at(-1)?.count).toBe(0);
+});
diff --git a/node_modules/dynamodb-onetable/dist/cjs/utils.d.ts b/node_modules/dynamodb-onetable/dist/cjs/utils.d.ts
index 1b29bfd..f3010de 100644
--- a/node_modules/dynamodb-onetable/dist/cjs/utils.d.ts
+++ b/node_modules/dynamodb-onetable/dist/cjs/utils.d.ts
@@ -10,4 +10,5 @@ type UndefinedProperties<T> = {
     then excludes those undefined properties from the orginal object to only have the required properties.
     The result of merging these two objects end up being the original object with those properties that can be undefined marked as optional.
 */
-export type UndefinedToOptional<T> = Partial<Pick<T, UndefinedProperties<T>>> & Pick<T, Exclude<keyof T, UndefinedProperties<T>>>
+export type UndefinedToOptional<T> = Partial<Pick<T, UndefinedProperties<T>>> &
+    Pick<T, Exclude<keyof T, UndefinedProperties<T>>>
diff --git a/node_modules/dynamodb-onetable/dist/mjs/Dynamo.d.ts b/node_modules/dynamodb-onetable/dist/mjs/Dynamo.d.ts
index bf9688a..2543ab4 100644
--- a/node_modules/dynamodb-onetable/dist/mjs/Dynamo.d.ts
+++ b/node_modules/dynamodb-onetable/dist/mjs/Dynamo.d.ts
@@ -1,13 +1,12 @@
-
 /*
 export type DynamoParams {
     client?: DynamoDBClient,
 }; */
 
 export class Dynamo {
-    constructor(params?: {});
-    client: any;
-    V3: boolean;
+    constructor(params?: {})
+    client: any
+    V3: boolean
 }
 
 export default Dynamo
diff --git a/node_modules/dynamodb-onetable/dist/mjs/Dynamo.js b/node_modules/dynamodb-onetable/dist/mjs/Dynamo.js
index 0efd3b4..6672fb7 100644
--- a/node_modules/dynamodb-onetable/dist/mjs/Dynamo.js
+++ b/node_modules/dynamodb-onetable/dist/mjs/Dynamo.js
@@ -3,15 +3,8 @@
 
     This module provides a wrapper and convenience API over the AWS V3 SDK.
     It is used by OneTable internally and is not a public API.
-
-    Use:
-        import {Model, Table} from 'dynamodb-onetable'
-        import Dynamo from 'dynamodb-onetable/Dynamo'
-
-        const dynamo = new Dynamo(params)
-        const table = new Table({ dynamo, ... })
 */
-import { BatchGetItemCommand, BatchWriteItemCommand, CreateTableCommand, DeleteItemCommand, DeleteTableCommand, DescribeTableCommand, GetItemCommand, ListTablesCommand, PutItemCommand, QueryCommand, ScanCommand, TransactGetItemsCommand, TransactWriteItemsCommand, UpdateItemCommand, } from '@aws-sdk/client-dynamodb';
+import { BatchGetItemCommand, BatchWriteItemCommand, CreateTableCommand, DeleteItemCommand, DeleteTableCommand, DescribeTableCommand, GetItemCommand, ListTablesCommand, PutItemCommand, QueryCommand, ScanCommand, TransactGetItemsCommand, TransactWriteItemsCommand, UpdateItemCommand, UpdateTableCommand, UpdateTimeToLiveCommand, } from '@aws-sdk/client-dynamodb';
 import { marshall, unmarshall } from '@aws-sdk/util-dynamodb';
 export class Dynamo {
     constructor(params = {}) {
@@ -61,6 +54,14 @@ export class Dynamo {
         let command = new UpdateItemCommand(params);
         return await this.send(command);
     }
+    async updateTable(params) {
+        let command = new UpdateTableCommand(params);
+        return await this.send(command);
+    }
+    async updateTimeToLive(params) {
+        let command = new UpdateTimeToLiveCommand(params);
+        return await this.send(command);
+    }
     async batchGet(params) {
         let command = new BatchGetItemCommand(params);
         return await this.send(command);
diff --git a/node_modules/dynamodb-onetable/dist/mjs/Error.d.ts b/node_modules/dynamodb-onetable/dist/mjs/Error.d.ts
index 5135d50..000cf5f 100644
--- a/node_modules/dynamodb-onetable/dist/mjs/Error.d.ts
+++ b/node_modules/dynamodb-onetable/dist/mjs/Error.d.ts
@@ -1,10 +1,10 @@
 export class OneTableError extends Error {
-    constructor(message: any, context: any);
-    context: any;
-    code?: string;
+    constructor(message: any, context: any)
+    context: any
+    code?: string
 }
 
 export class OneTableArgError extends Error {
-    constructor(message: any, context?: any);
-    code: any;
+    constructor(message: any, context?: any)
+    code: any
 }
diff --git a/node_modules/dynamodb-onetable/dist/mjs/Error.js b/node_modules/dynamodb-onetable/dist/mjs/Error.js
index b30b47e..bf5c2e0 100644
--- a/node_modules/dynamodb-onetable/dist/mjs/Error.js
+++ b/node_modules/dynamodb-onetable/dist/mjs/Error.js
@@ -18,7 +18,7 @@ function init(self, message, context) {
         Error.captureStackTrace(self, self.constructor);
     }
     else {
-        self.stack = (new Error(message)).stack;
+        self.stack = new Error(message).stack;
     }
 }
 export class OneTableError extends Error {
diff --git a/node_modules/dynamodb-onetable/dist/mjs/Expression.d.ts b/node_modules/dynamodb-onetable/dist/mjs/Expression.d.ts
index 77e5a96..ecd64ab 100644
--- a/node_modules/dynamodb-onetable/dist/mjs/Expression.d.ts
+++ b/node_modules/dynamodb-onetable/dist/mjs/Expression.d.ts
@@ -1,21 +1,21 @@
-import { OneParams, OneProperties, OneIndex } from './Model'
+import {OneParams, OneProperties, OneIndex} from './Model.js'
 export class Expression<ModelT> {
-    constructor(model: ModelT, op: string, properties: OneProperties, params?: OneParams);
-    add(field: string, value: any): void;
-    expand(where: any): any;
-    addFilter(att: string, value: any): void;
-    addKey(op: string, field: string, value: any): void;
-    addUpdate(field: string, value: any): void;
-    makeTarget(fields: string, name: string): string;
-    command(): any;
-    and(terms: string[]): string;
-    addName(name: string): number;
-    addValue(value: any): number;
+    constructor(model: ModelT, op: string, properties: OneProperties, params?: OneParams)
+    add(field: string, value: any): void
+    expand(where: any): any
+    addFilter(att: string, value: any): void
+    addKey(op: string, field: string, value: any): void
+    addUpdate(field: string, value: any): void
+    makeTarget(fields: string, name: string): string
+    command(): any
+    and(terms: string[]): string
+    addName(name: string): number
+    addValue(value: any): number
     // Internal only methods
-    init(model: ModelT, op: string, properties: OneProperties, params: OneParams): void;
-    prepare(): void;
-    addConditions(op: string): void;
-    addFilters(): void;
-    addUpdates(): void;
-    selectIndex(indexes: Record<string, OneIndex>): OneIndex;
+    init(model: ModelT, op: string, properties: OneProperties, params: OneParams): void
+    prepare(): void
+    addConditions(op: string): void
+    addFilters(): void
+    addUpdates(): void
+    selectIndex(indexes: Record<string, OneIndex>): OneIndex
 }
diff --git a/node_modules/dynamodb-onetable/dist/mjs/Expression.js b/node_modules/dynamodb-onetable/dist/mjs/Expression.js
index 47530cd..fdef577 100644
--- a/node_modules/dynamodb-onetable/dist/mjs/Expression.js
+++ b/node_modules/dynamodb-onetable/dist/mjs/Expression.js
@@ -55,10 +55,11 @@ export class Expression {
     prepare() {
         let { op, params, properties } = this;
         let fields = this.model.block.fields;
+        this.canPut = op == 'put' || (this.params.batch && op == 'update');
         if (op == 'find') {
             this.addWhereFilters();
         }
-        else if (op == 'delete' || op == 'put' || op == 'update') {
+        else if (op == 'delete' || op == 'put' || op == 'update' || op == 'check') {
             this.addConditions(op);
         }
         else if (op == 'scan') {
@@ -74,7 +75,8 @@ export class Expression {
                 }
             }
         }
-        this.addProperties(op, fields, properties);
+        //  Batch does not use update expressions (Ugh!)
+        this.puts = this.addProperties(op, this.model.block, properties);
         /*
             Emit mapped attributes that don't correspond to schema fields.
         */
@@ -85,7 +87,9 @@ export class Expression {
                 }
             }
             for (let [k, v] of Object.entries(this.mapped)) {
-                this.add(properties, { attribute: [k], name: k, filter: false }, v, properties);
+                let field = { attribute: [k], name: k, filter: false, path: k };
+                this.add(op, properties, field, k, v);
+                this.puts[k] = v;
             }
         }
         if (params.fields) {
@@ -94,6 +98,10 @@ export class Expression {
                     //  BatchGet params.project must provide attributes not properties
                     this.project.push(`#_${this.addName(name)}`);
                 }
+                else if (this.model.generic) {
+                    // Generic models don't know which attributes exist, so we allow requesting all
+                    this.project.push(`#_${this.addName(name)}`);
+                }
                 else if (fields[name]) {
                     let att = fields[name].attribute[0];
                     this.project.push(`#_${this.addName(att)}`);
@@ -101,82 +109,106 @@ export class Expression {
             }
         }
     }
-    addProperties(op, fields, properties) {
+    /*
+        Add properties to the command. This calls itself recursively for each schema nest level.
+        Emit update/filter expressions if emit is true
+     */
+    addProperties(op, block, properties, ppath = '', emit = true) {
+        let rec = {};
+        let fields = block.fields;
+        if (!properties || typeof properties != 'object') {
+            return properties;
+        }
         for (let [name, value] of Object.entries(properties)) {
-            if (this.already[name]) {
-                continue;
+            let field = fields[name];
+            if (!field) {
+                field = { attribute: [name], name, path: name };
+                if (this.model.generic) {
+                    this.add(op, properties, field, name, value);
+                }
             }
-            if (fields[name]) {
-                if (op != 'put' && this.table.partial && this.params.partial !== false) {
-                    if (fields[name].schema) {
-                        this.addProperties(op, fields[name].block.fields, value);
+            else {
+                let attribute = field.attribute[0];
+                let path = ppath ? `${ppath}.${attribute}` : attribute;
+                if (!field.schema) {
+                    this.add(op, properties, field, path, value, emit);
+                }
+                else {
+                    let partial = this.model.getPartial(field, this.params);
+                    if (field.isArray && Array.isArray(value)) {
+                        value = value.slice(0);
+                        for (let [key, v] of Object.entries(value)) {
+                            let ipath = `${path}[${key}]`;
+                            value[key] = this.addProperties(op, field.block, v, ipath, emit && partial);
+                        }
+                        if (emit && !partial) {
+                            this.add(op, properties, field, path, value, emit);
+                        }
                     }
                     else {
-                        this.add(properties, fields[name], value);
+                        value = this.addProperties(op, field.block, value, path, emit && partial);
+                        if (emit && !partial) {
+                            this.add(op, properties, field, path, value, true);
+                        }
                     }
                 }
-                else {
-                    this.add(properties, fields[name], value);
-                }
-            }
-            else if (this.model.generic) {
-                this.add(properties, { attribute: [name], name }, value);
             }
+            rec[field.attribute[0]] = value;
         }
+        return rec;
     }
     /*
         Add a field to the command expression
+        If emit is true, then emit update/filter expressions for this property
      */
-    add(properties, field, value) {
-        let op = this.op;
-        let attribute = field.attribute;
+    add(op, properties, field, path, value, emit = true) {
+        if (this.already[path]) {
+            return;
+        }
         /*
             Handle mapped and packed attributes.
-            The attribute[0] contains the top level attribute name. Attribute[1] contains a nested mapping name.
+            The attribute[0] contains the top level attribute name and
+            Attribute[1] contains a nested mapping name.
         */
+        let attribute = field.attribute;
         if (attribute.length > 1) {
+            /*
+                Save in mapped[] the mapped attributes which will be processed soon
+             */
             let mapped = this.mapped;
             let [k, v] = attribute;
             mapped[k] = mapped[k] || {};
             mapped[k][v] = value;
-            properties[k] = value;
+            if (op == 'put') {
+                properties[k] = value;
+            }
             return;
         }
-        //  Pathname may contain a '.'
-        let path = attribute[0];
         if (path == this.hash || path == this.sort) {
             if (op == 'find') {
                 this.addKey(op, field, value);
             }
             else if (op == 'scan') {
                 if (properties[field.name] !== undefined && field.filter !== false) {
-                    this.addFilter(field, value);
+                    this.addFilter(field, path, value);
                 }
             }
-            else if ((op == 'delete' || op == 'get' || op == 'update') && field.isIndexed) {
+            else if ((op == 'delete' || op == 'get' || op == 'update' || op == 'check') && field.isIndexed) {
                 this.addKey(op, field, value);
             }
-            else if (op == 'put' || (this.params.batch && op == 'update')) {
-                //  Batch does not use update expressions (Ugh!)
-                this.puts[path] = value;
-            }
         }
-        else {
-            if ((op == 'find' || op == 'scan')) {
+        else if (emit) {
+            if (op == 'find' || op == 'scan') {
                 //  schema.filter == false disables a field from being used in a filter
                 if (properties[field.name] !== undefined && field.filter !== false) {
                     if (!this.params.batch) {
                         //  Batch does not support filter expressions
-                        this.addFilter(field, value);
+                        this.addFilter(field, path, value);
                     }
                 }
             }
-            else if (op == 'put' || (this.params.batch && op == 'update')) {
-                //  Batch does not use update expressions (Ugh!)
-                this.puts[path] = value;
-            }
             else if (op == 'update') {
-                this.addUpdate(field, value);
+                this.addUpdate(field, path, value);
             }
         }
     }
@@ -237,13 +269,13 @@ export class Expression {
                 for (let item of substitutions[name]) {
                     indicies.push(this.addValue(item));
                 }
-                return indicies.map(i => `:_${i}`).join(', ');
+                return indicies.map((i) => `:_${i}`).join(', ');
             }
             index = this.addValue(substitutions[name]);
             return `:_${index}`;
         });
         //  Expand value references and make attribute values. Allow new-lines in values.
-        where = where.replace(/{(.*?)}/sg, (match, value) => {
+        where = where.replace(/{(.*?)}/gs, (match, value) => {
             let index;
             if (value.match(/^[-+]?([0-9]+(\.[0-9]*)?|\.[0-9]+)$/)) {
                 index = this.addValue(+value);
@@ -276,14 +308,12 @@ export class Expression {
             this.filters.push(this.expand(this.params.where));
         }
     }
-    addFilter(field, value) {
+    addFilter(field, path, value) {
         let { filters } = this;
-        let att = field.attribute[0];
-        let pathname = field.pathname || att;
-        if (pathname == this.hash || pathname == this.sort) {
+        if (path == this.hash || path == this.sort) {
             return;
         }
-        let [target, variable] = this.prepareKeyValue(pathname, value);
+        let [target, variable] = this.prepareKeyValue(path, value);
         filters.push(`${target} = ${variable}`);
     }
     /*
@@ -342,11 +372,9 @@ export class Expression {
             return [target, this.addValueExp(value)];
         }
     }
-    addUpdate(field, value) {
+    addUpdate(field, path, value) {
         let { params, updates } = this;
-        let att = field.attribute[0];
-        let pathname = field.pathname || att;
-        if (pathname == this.hash || pathname == this.sort) {
+        if (path == this.hash || path == this.sort) {
             return;
         }
         if (field.name == this.model.typeField) {
@@ -358,8 +386,7 @@ export class Expression {
         if (params.remove && params.remove.indexOf(field.name) >= 0) {
             return;
         }
-        // let [target, variable] = this.prepareKeyValue(pathname, value)
-        let target = this.prepareKey(pathname);
+        let target = this.prepareKey(path);
         let variable = this.addValueExp(value);
         updates.set.push(`${target} = ${variable}`);
     }
@@ -490,11 +517,11 @@ export class Expression {
             args = {
                 ConditionExpression: conditions.length ? this.and(conditions) : undefined,
                 ExpressionAttributeNames: namesLen > 0 ? names : undefined,
-                ExpressionAttributeValues: (namesLen > 0 && valuesLen > 0) ? values : undefined,
+                ExpressionAttributeValues: namesLen > 0 && valuesLen > 0 ? values : undefined,
                 FilterExpression: filters.length ? this.and(filters) : undefined,
                 KeyConditionExpression: keys.length ? keys.join(' and ') : undefined,
                 ProjectionExpression: project.length ? project.join(', ') : undefined,
-                TableName: this.tableName
+                TableName: this.tableName,
             };
             if (params.select) {
                 //  Select: ALL_ATTRIBUTES | ALL_PROJECTED_ATTRIBUTES | SPECIFIC_ATTRIBUTES | COUNT
@@ -518,7 +545,7 @@ export class Expression {
                 if (params.return === true) {
                     returnValues = op === 'delete' ? 'ALL_OLD' : 'ALL_NEW';
                 }
-                else if (params.return === false) {
+                else if (params.return === false || params.return == 'none') {
                     returnValues = 'NONE';
                 }
                 else if (params.return != 'get') {
@@ -542,12 +569,12 @@ export class Expression {
             else if (op == 'delete') {
                 args.ReturnValues = returnValues || 'ALL_OLD';
             }
-            if (op == 'delete' || op == 'get' || op == 'update') {
+            if (op == 'delete' || op == 'get' || op == 'update' || op == 'check') {
                 args.Key = key;
             }
             if (op == 'find' || op == 'get' || op == 'scan') {
-                args.ConsistentRead = params.consistent ? true : false,
-                    args.IndexName = params.index ? params.index : null;
+                args.ConsistentRead = params.consistent ? true : false;
+                args.IndexName = params.index ? params.index : null;
             }
             if (op == 'find' || op == 'scan') {
                 args.Limit = params.limit ? params.limit : undefined;
@@ -555,9 +582,28 @@ export class Expression {
                     Scan reverse if either reverse or prev is true but not both. (XOR)
                     If both are true, then requesting the previous page of a reverse scan which is actually forwards.
                 */
-                args.ScanIndexForward = (params.reverse == true ^ (params.prev != null && params.next == null)) ? false : true;
-                if (params.next || params.prev) {
-                    args.ExclusiveStartKey = this.table.marshall(params.next || params.start || params.prev, params);
+                args.ScanIndexForward =
+                    (params.reverse == true) ^ (params.prev != null && params.next == null) ? false : true;
+                /*
+                    Cherry pick the required properties from the next/prev param
+                 */
+                let cursor = params.next || params.prev;
+                if (cursor) {
+                    let { hash, sort } = this.index;
+                    let start = { [hash]: cursor[hash] };
+                    if (sort && cursor[sort]) {
+                        start[sort] = cursor[sort];
+                    }
+                    if (this.params.index != 'primary') {
+                        let { hash, sort } = this.model.indexes.primary;
+                        start[hash] = cursor[hash];
+                        if (sort && cursor[sort] != null) {
+                            start[sort] = cursor[sort];
+                        }
+                    }
+                    if (start[hash]) {
+                        args.ExclusiveStartKey = this.table.marshall(start, params);
+                    }
                 }
             }
             if (op == 'scan') {
@@ -585,7 +631,7 @@ export class Expression {
         if (terms.length == 1) {
             return terms.join('');
         }
-        return terms.map(t => `(${t})`).join(' and ');
+        return terms.map((t) => `(${t})`).join(' and ');
     }
     /*
         Add a name to the ExpressionAttribute names. Optimize duplicates and only store unique names once.
diff --git a/node_modules/dynamodb-onetable/dist/mjs/Metrics.d.ts b/node_modules/dynamodb-onetable/dist/mjs/Metrics.d.ts
index 6242d88..9fcb36f 100644
--- a/node_modules/dynamodb-onetable/dist/mjs/Metrics.d.ts
+++ b/node_modules/dynamodb-onetable/dist/mjs/Metrics.d.ts
@@ -4,6 +4,7 @@ export class Metrics {
     log: any;
     metrics: {
         chan: string;
+        custom: boolean;
         dimensions: string[];
         enable: boolean;
         env: boolean;
@@ -16,9 +17,11 @@ export class Metrics {
         source: string;
         tenant: any;
     };
-    add(model: any, op: any, result: any, params: any, mark: any): void;
+    add(model: any, op: any, result: any, params: any, mark: any): Promise<void>;
     addMetricGroup(values: any, dimensionValues: any, properties: any): void;
     addMetric(key: any, values: any, dimensions: any, dimensionValues: any, properties: any): void;
-    flushMetrics(timestamp?: number): void;
-    emitMetrics(timestamp: any, rec: any): void;
+    flush(timestamp?: number): Promise<void>;
+    emit(timestamp: any, rec: any): Promise<void>;
+    terminate(): Promise<void>;
+    setLog(log: any): void
 }
diff --git a/node_modules/dynamodb-onetable/dist/mjs/Metrics.js b/node_modules/dynamodb-onetable/dist/mjs/Metrics.js
index 920c195..5e57412 100644
--- a/node_modules/dynamodb-onetable/dist/mjs/Metrics.js
+++ b/node_modules/dynamodb-onetable/dist/mjs/Metrics.js
@@ -1,20 +1,27 @@
 /*
     Metrics.js - DynamoDB metrics class
  */
+import { CustomMetrics } from 'custom-metrics';
 const DefaultMetrics = {
-    chan: 'dbmetrics',
+    chan: 'dbmetrics', //  Default channel
+    custom: true,
     dimensions: [
-        'Table', 'Tenant', 'Source', 'Index', 'Model', 'Operation' //  Default dimensions
+        // Default dimensions
+        'Table',
+        'Tenant',
+        'Source',
+        'Index',
+        'Model',
+        'Operation',
     ],
-    enable: true,
-    env: true,
-    hot: false,
-    max: 100,
-    namespace: 'SingleTable/Metrics.1',
-    period: 60,
-    properties: {},
-    queries: true,
-    source: process.env.AWS_LAMBDA_FUNCTION_NAME || 'Default',
+    enable: true, //  Enabled
+    env: true, //  Observe LOG_FILTER for dbmetrics
+    hot: false, //  Hot partition tracking
+    max: 100, //  Buffer metrics for 100 requests
+    namespace: 'SingleTable/Metrics.1', //  CloudWatch metrics namespace
+    period: 60, //  or buffer for 60 seconds
+    properties: {}, //  Additional properties to emit
+    source: process.env.AWS_LAMBDA_FUNCTION_NAME || 'Default', //  Default source name
     tenant: null,
 };
 const DynamoOps = {
@@ -41,9 +48,7 @@ const ReadWrite = {
     transactGet: 'read',
     transactWrite: 'write',
 };
-/*
-    Represent a single DynamoDB table
- */
+var Instances = {};
 export class Metrics {
     constructor(table, params = {}, prior = {}) {
         this.table = table;
@@ -56,17 +61,34 @@ export class Metrics {
             //  Params takes priority
             metrics = Object.assign({}, DefaultMetrics, params);
         }
+        if (metrics.custom && table.V3) {
+            let { hash, sort } = table.schema.indexes.primary;
+            this.custom = new CustomMetrics({
+                table: table.name,
+                client: table.client,
+                primaryKey: hash,
+                sortKey: sort,
+                log: this.log,
+            });
+            Instances[`${table.name}`] = this;
+        }
         if (metrics.env && process.env) {
-            //  Need a better senselogs test than 'metrics'. Senselogs relies on the dbmetrics channel to be enabled.
-            if (!this.log.metrics) {
-                let filter = process.env.LOG_FILTER;
-                if (!filter || filter.indexOf('dbmetrics') < 0) {
-                    metrics.enable = false;
+            let filter = process.env.LOG_FILTER;
+            metrics.enable = false;
+            if (filter && filter.indexOf('dbmetrics') >= 0) {
+                metrics.enable = true;
+            }
+            else {
+                if (process.env.LOG_OVERRIDE != null) {
+                    let [expire, filter] = process.env.LOG_OVERRIDE.split(':');
+                    if (filter && filter.indexOf('dbmetrics') >= 0 && expire > Date.now()) {
+                        metrics.enable = true;
+                    }
                 }
             }
             metrics.dimensions = process.env.LOG_ONETABLE_DIMENSIONS || metrics.dimensions;
             if (!Array.isArray(metrics.dimensions)) {
-                metrics.dimensions = metrics.dimensions.split(',').map(i => i.trim());
+                metrics.dimensions = metrics.dimensions.split(',').map((i) => i.trim());
             }
         }
         metrics.map = { Profile: true };
@@ -81,7 +103,7 @@ export class Metrics {
         metrics.properties = metrics.properties || prior.properties;
         this.metrics = metrics;
     }
-    add(model, op, result, params, mark) {
+    async add(model, op, result, params, mark) {
         let metrics = this.metrics;
         if (!metrics.enable || !this.log.enabled(metrics.chan)) {
             return;
@@ -107,16 +129,22 @@ export class Metrics {
             count: result.Count || 1,
             latency: timestamp - mark,
             scanned: result.ScannedCount || 1,
-            op, capacity,
+            op,
+            capacity,
         };
-        let dimensionValues = {
+        let dimensions = {
             Table: this.table.name,
-            Tenant: metrics.tenant,
             Source: params.source || metrics.source,
             Index: params.index || 'primary',
             Model: model,
             Operation: DynamoOps[op],
         };
+        if (metrics.tenant) {
+            dimensions.Tenant = metrics.tenant;
+        }
+        /*
+            Add properties to be added to EMF records
+         */
         let properties;
         if (typeof metrics.properties == 'function') {
             properties = metrics.properties(op, params, result);
@@ -124,35 +152,40 @@ export class Metrics {
         else {
             properties = metrics.properties || {};
         }
-        this.addMetricGroup(values, dimensionValues, properties);
-        if (metrics.queries && params.profile) {
-            dimensionValues.Profile = params.profile;
-            this.addMetric('Profile', values, ['Profile'], dimensionValues, properties);
+        this.addResultsToGroup(values, dimensions, properties);
+        if (params.profile) {
+            // dimensionValues.Profile = params.profile
+            this.addResults(`Profile-${params.profile}`, values, { Profile: params.profile }, properties);
         }
-        if (++metrics.count >= metrics.max || (metrics.lastFlushed + metrics.period) < timestamp) {
-            this.flushMetrics(timestamp);
+        if (++metrics.count >= metrics.max || metrics.lastFlushed + metrics.period < timestamp) {
+            await this.flush(timestamp);
             metrics.count = 0;
             metrics.lastFlushed = timestamp;
         }
     }
-    addMetricGroup(values, dimensionValues, properties) {
-        let dimensions = [], keys = [];
+    /*
+        Add results to a group of dimensions
+     */
+    addResultsToGroup(values, allDimensions, properties) {
+        let dimensions = {}, keys = [];
         for (let name of this.metrics.dimensions) {
-            let dimension = dimensionValues[name];
+            let dimension = allDimensions[name];
             if (dimension) {
                 keys.push(dimension);
-                dimensions.push(name);
-                this.addMetric(keys.join('.'), values, dimensions, dimensionValues, properties);
+                dimensions[name] = dimension;
+                this.addResults(keys.join('.'), values, dimensions, properties);
             }
         }
     }
-    addMetric(key, values, dimensions, dimensionValues, properties) {
-        let rec = this.metrics.counters[key] = this.metrics.counters[key] || {
+    /*
+        Add results to a specific dimension set
+     */
+    addResults(key, values, dimensions, properties) {
+        let rec = (this.metrics.counters[key] = this.metrics.counters[key] || {
             totals: { count: 0, latency: 0, read: 0, requests: 0, scanned: 0, write: 0 },
-            dimensions: dimensions.slice(0),
-            dimensionValues,
+            dimensions: Object.assign({}, dimensions),
             properties,
-        };
+        });
         let totals = rec.totals;
         totals[ReadWrite[values.op]] += values.capacity; //  RCU, WCU
         totals.latency += values.latency; //  Latency in ms
@@ -160,41 +193,62 @@ export class Metrics {
         totals.scanned += values.scanned; //  Items scanned
         totals.requests++; //  Number of requests
     }
-    flushMetrics(timestamp = Date.now()) {
+    static async terminate() {
+        await Metrics.flushAll();
+    }
+    static async flushAll() {
+        for (let instance of Object.values(Instances)) {
+            await instance.flush();
+        }
+    }
+    async flush(timestamp = Date.now()) {
         if (!this.metrics.enable)
             return;
         for (let rec of Object.values(this.metrics.counters)) {
-            Object.keys(rec).forEach(field => rec[field] === 0 && delete rec[field]);
-            this.emitMetrics(timestamp, rec);
+            Object.keys(rec.totals).forEach((field) => rec.totals[field] === 0 && delete rec.totals[field]);
+            await this.emitMetrics(timestamp, rec);
+        }
+        if (this.custom) {
+            await this.custom.flush();
         }
         this.metrics.counters = {};
     }
-    emitMetrics(timestamp, rec) {
-        let { dimensionValues, dimensions, properties, totals } = rec;
-        let metrics = this.metrics;
+    async emitMetrics(timestamp, rec) {
+        let { dimensions, properties, totals } = rec;
         let requests = totals.requests;
         totals.latency = totals.latency / requests;
         totals.count = totals.count / requests;
         totals.scanned = totals.scanned / requests;
-        if (this.log.metrics) {
-            let chan = metrics.chan || 'dbmetrics';
-            this.log.metrics(chan, `OneTable Custom Metrics ${dimensions}`, metrics.namespace, totals, dimensions, { latency: 'Milliseconds', default: 'Count' }, Object.assign({}, dimensionValues, properties));
+        let namespace = this.metrics.namespace;
+        let dkeys = Object.keys(dimensions);
+        if (this.custom) {
+            for (let [metric, value] of Object.entries(totals)) {
+                await this.custom.emit(namespace, metric, value, [dimensions], { buffer: { elapsed: 10 * 1000 } });
+            }
+        }
+        else if (this.log.metrics) {
+            this.log.metrics(this.metrics.chan || 'dbmetrics', `OneTable Custom Metrics`, namespace, totals, dkeys, { latency: 'Milliseconds', default: 'Count' }, Object.assign({}, dimensions, properties));
         }
         else {
-            let metrics = dimensions.map(v => {
+            let metrics = dkeys.map((v) => {
                 return { Name: v, Unit: v == 'latency' ? 'Milliseconds' : 'Count' };
             });
             let data = Object.assign({
                 _aws: {
                     Timestamp: timestamp,
-                    CloudWatchMetrics: [{
-                            Dimensions: [dimensions],
-                            Namespace: metrics.namespace,
+                    CloudWatchMetrics: [
+                        {
+                            dkeys,
+                            Namespace: namespace,
                             Metrics: metrics,
-                        }]
+                        },
+                    ],
                 },
-            }, totals, dimensionValues, properties);
-            console.log(`OneTable Custom Metrics ${dimensions}` + JSON.stringify(data));
+            }, totals, dimensions, properties);
+            console.log(`OneTable Custom Metrics ` + JSON.stringify(data));
         }
     }
+    setLog(log) {
+        this.log = log;
+    }
 }
diff --git a/node_modules/dynamodb-onetable/dist/mjs/Model.d.ts b/node_modules/dynamodb-onetable/dist/mjs/Model.d.ts
index b09c5e5..a9b60c5 100644
--- a/node_modules/dynamodb-onetable/dist/mjs/Model.d.ts
+++ b/node_modules/dynamodb-onetable/dist/mjs/Model.d.ts
@@ -3,60 +3,62 @@
 
     Supports dynamic definition of types based on the Schema.js
 */
-import { Expression } from './Expression'
+import {Expression} from './Expression.js'
 
 /*
     Possible types for a schema field "type" property
  */
 export type OneType =
-    ArrayConstructor |
-    BooleanConstructor |
-    DateConstructor |
-    NumberConstructor |
-    ObjectConstructor |
-    StringConstructor |
-    SetConstructor |
-    ArrayBufferConstructor |
-    string;
+    | ArrayConstructor
+    | BooleanConstructor
+    | DateConstructor
+    | NumberConstructor
+    | ObjectConstructor
+    | StringConstructor
+    | SetConstructor
+    | ArrayBufferConstructor
+    | string
 
 /*
     Schema.indexes signature
  */
 export type OneIndex = {
-    hash?: string,
-    sort?: string,
-    description?: string,
-    project?: string | readonly string[],
-    follow?: boolean,
-    type?: string,
-};
+    hash?: string
+    sort?: string
+    description?: string
+    project?: string | readonly string[]
+    follow?: boolean
+    type?: string
+}
 
 /*
     Schema.models.Model.Field signature
  */
 export type OneField = {
-    crypt?: boolean,
-    default?: string | number | boolean | object,
-    encode?: readonly string[],
-    enum?: readonly string[],
-    filter?: boolean,
-    generate?: string | boolean,
-    hidden?: boolean,
-    map?: string,
-    nulls?: boolean,
-    reference?: string,
-    required?: boolean,
-    timestamp?: boolean,
-    type: OneType,
-    unique?: boolean,
-    validate?: RegExp | string | boolean,
-    value?: boolean | string,
-    schema?: OneModel,
-    ttl?: boolean,
+    crypt?: boolean
+    default?: string | number | boolean | object | Array<any>
+    encode?: readonly (string | RegExp | number)[] | string
+    enum?: readonly string[]
+    filter?: boolean
+    generate?: string | boolean | Function
+    hidden?: boolean
     items?: OneField
+    map?: string
+    nulls?: boolean
+    partial?: boolean
+    reference?: string
+    required?: boolean
+    schema?: OneModel
+    scope?: string
+    timestamp?: boolean
+    ttl?: boolean
+    type: OneType
+    unique?: boolean
+    validate?: RegExp | string | boolean
+    value?: boolean | string
 
     //  DEPRECATE 2.3
-    uuid?: boolean | string,
+    uuid?: boolean | string
 }
 
 /*
@@ -64,79 +66,97 @@ export type OneField = {
  */
 export type OneModel = {
     [key: string]: OneField
-};
+}
 
 /*
     Schema signature
  */
 export type OneSchema = {
-    name?: string,
-    version: string,
-    format?: string,
-    params?: OneSchemaParams,
+    name?: string
+    version: string
+    format?: string
+    params?: OneSchemaParams
     models: {
         [key: string]: OneModel
-    },
+    }
+    process?: object
     indexes: {
         [key: string]: OneIndex
-    },
-    queries?: {},
-};
+    }
+    queries?: {}
+}
 
 export type OneSchemaParams = {
-    createdField?: string,          //  Name of "created" timestamp attribute. Default to 'created'.
-    hidden?: boolean,               //  Hide key attributes in Javascript properties. Default false.
-    isoDates?: boolean,             //  Set to true to store dates as Javascript ISO Date strings. Default false.
-    nulls?: boolean,                //  Store nulls in database attributes. Default false.
-    timestamps?: boolean | string,  //  Make "created" and "updated" timestamps. Set to true, 'create' or 'update'. Default true.
-    typeField?: string,             //  Name of model type attribute. Default "_type".
-    updatedField?: string,          //  Name of "updated" timestamp attribute. Default 'updated'.
+    createdField?: string //  Name of "created" timestamp attribute. Default to 'created'.
+    hidden?: boolean //  Hide key attributes in Javascript properties. Default false.
+    isoDates?: boolean //  Set to true to store dates as Javascript ISO Date strings. Default false.
+    nulls?: boolean //  Store nulls in database attributes. Default false.
+    timestamps?: boolean | string //  Make "created" and "updated" timestamps. Set to true, 'create' or 'update'. Default true.
+    separator?: string // Separator string uses in value templates
+    typeField?: string //  Name of model type attribute. Default "_type".
+    updatedField?: string //  Name of "updated" timestamp attribute. Default 'updated'.
+    warn?: boolean // Emit warnings for some conditions. Default false.
+
+    legacyEmpties?: boolean // Remove empty strings
 }
 
 /*
     Entity field signature generated from the schema
  */
-type EntityField<T extends OneField> =
-    T['enum'] extends readonly EntityFieldFromType<T>[] ? T['enum'][number] : (EntityFieldFromType<T>);
-
-type EntityFieldFromType<T extends OneField> =
-      T['type'] extends (ArrayConstructor | 'array') ? ArrayItemType<T>[]
-    : T['type'] extends (BooleanConstructor | 'boolean') ? boolean
-    : T['type'] extends (NumberConstructor | 'number') ? number
-    : T['type'] extends (ObjectConstructor | 'object') ? Entity<Exclude<T["schema"], undefined>>
-    : T['type'] extends (DateConstructor | 'date') ? Date
-    : T['type'] extends (ArrayBufferConstructor) ? ArrayBuffer
-    : T['type'] extends (StringConstructor | 'string') ? string
-    : T['type'] extends (SetConstructor | 'set') ? Set<any>
-    : T['type'] extends 'typed-array' ? EntityFieldFromType<Exclude<T["items"], undefined>>[]
-    : never;
-
-type ArrayItemType<T extends OneField> =
-    T extends {items: OneField} ? EntityFieldFromType<T["items"]> : any
+type EntityField<T extends OneField> = T['enum'] extends readonly EntityFieldFromType<T>[]
+    ? T['enum'][number]
+    : EntityFieldFromType<T>
+
+type EntityFieldFromType<T extends OneField> = T['type'] extends ArrayConstructor | 'array'
+    ? ArrayItemType<T>[]
+    : T['type'] extends BooleanConstructor | 'boolean'
+    ? boolean
+    : T['type'] extends NumberConstructor | 'number'
+    ? number
+    : T['type'] extends ObjectConstructor | 'object'
+    ? (T['schema'] extends object ? Entity<Exclude<T['schema'], undefined>> : Record<any, any>)
+    : T['type'] extends DateConstructor | 'date'
+    ? Date
+    : T['type'] extends ArrayBufferConstructor
+    ? ArrayBuffer
+    : T['type'] extends StringConstructor | 'string'
+    ? string
+    : T['type'] extends SetConstructor | 'set'
+    ? Set<any>
+    : T['type'] extends 'typed-array'
+    ? EntityFieldFromType<Exclude<T['items'], undefined>>[]
+    : never
+
+type ArrayItemType<T extends OneField> = T extends {items: OneField}
+    ? EntityField<T['items']>
+    : any
 /*
     Select the required properties from a model
 */
 export type Required<T extends OneModel> = {
     -readonly [P in keyof T as T[P]['required'] extends true ? P : never]: EntityField<T[P]>
-};
+}
 
 /*
     Select the optional properties from a model
 */
 export type Optional<T extends OneModel> = {
     -readonly [P in keyof T as T[P]['required'] extends true ? never : P]?: EntityField<T[P]>
-};
+}
 
 type OptionalOrNull<T extends OneModel> = {
-    -readonly [P in keyof T as T[P]['required'] extends true ? never : P]?: (EntityField<T[P]> | null)
-};
+    -readonly [P in keyof T as T[P]['required'] extends true ? never : P]?: EntityField<T[P]> | null
+}
+type OptionalOrUndefined<T extends OneModel> = {
+    -readonly [P in keyof T as T[P]['required'] extends true ? never : P]?: EntityField<T[P]> | undefined
+}
 
 /*
     Select properties with generated values
 */
 export type Generated<T extends OneModel> = {
-    -readonly [P in keyof T as T[P]['generate'] extends (string | boolean) ? P : never]?: EntityField<T[P]>
-};
+    -readonly [P in keyof T as T[P]['generate'] extends string | boolean ? P : never]?: EntityField<T[P]>
+}
 
 /*
     Select properties with default values
@@ -144,36 +164,36 @@ export type Generated<T extends OneModel> = {
 type DefinedValue = string | number | bigint | boolean | symbol | object
 export type Defaulted<T extends OneModel> = {
     -readonly [P in keyof T as T[P]['default'] extends DefinedValue ? P : never]: EntityField<T[P]>
-};
+}
 
 /*
     Select value template properties
 */
 export type ValueTemplates<T extends OneModel> = {
     -readonly [P in keyof T as T[P]['value'] extends string ? P : never]: EntityField<T[P]>
-};
+}
 
 /*
     Select timestamp properties
 */
 export type TimestampValue<T extends OneModel> = {
     -readonly [P in keyof T as T[P]['timestamp'] extends true ? P : never]: EntityField<T[P]>
-};
+}
 
 /*
     Merge the properties of two types given preference to A.
 */
 type Merge<A extends any, B extends any> = {
-    [P in keyof (A & B)]: P extends keyof A ? A[P] : (P extends keyof B ? B[P] : never)
-};
+    [P in keyof (A & B)]: P extends keyof A ? A[P] : P extends keyof B ? B[P] : never
+}
 
 /*
     Create entity type which includes required and optional types
     An entity type is not used by the user and is only required internally.
     Merge gives better intellisense, but requires Flatten to make <infer X> work.
 */
-type Flatten<T> = { [P in keyof T]: T[P] };
-type Entity<T extends OneModel> = Flatten<Merge<Required<T>, Optional<T>>>
+type Flatten<T> = {[P in keyof T]: T[P]}
+type Entity<T extends OneModel> = Flatten<Merge<Required<T>, OptionalOrUndefined<T>>>
 
 /*
     Entity Parameters are partial Entities.
@@ -184,7 +204,8 @@ type EntityParameters<Entity> = Partial<Entity>
     Special case for find to allow query operators
 */
 type EntityParametersForFind<T> = Partial<{
-    [K in keyof T]: T[K]
+    [K in keyof T]:
+        | T[K]
         | Begins<T, K>
         | BeginsWith<T, K>
         | Between<T, K>
@@ -196,104 +217,109 @@ type EntityParametersForFind<T> = Partial<{
         | GreaterThan<T, K>
 }>
 
-type Begins<T, K extends keyof T> = { begins: T[K] }
-type BeginsWith<T, K extends keyof T> = { begins_with: T[K] }
-type Between<T, K extends keyof T> = { between: [T[K], T[K]] }
-type LessThan<T, K extends keyof T> = { '<': T[K] }
-type LessThanOrEqual<T, K extends keyof T> = { '<=': T[K] }
-type Equal<T, K extends keyof T> = { '=': T[K] }
-type NotEqual<T, K extends keyof T> = { '<>': T[K] }
-type GreaterThanOrEqual<T, K extends keyof T> = { '>=': T[K] }
-type GreaterThan<T, K extends keyof T> = { '>': T[K] }
+type Begins<T, K extends keyof T> = {begins: T[K]}
+type BeginsWith<T, K extends keyof T> = {begins_with: T[K]}
+type Between<T, K extends keyof T> = {between: [T[K], T[K]]}
+type LessThan<T, K extends keyof T> = {'<': T[K]}
+type LessThanOrEqual<T, K extends keyof T> = {'<=': T[K]}
+type Equal<T, K extends keyof T> = {'=': T[K]}
+type NotEqual<T, K extends keyof T> = {'<>': T[K]}
+type GreaterThanOrEqual<T, K extends keyof T> = {'>=': T[K]}
+type GreaterThan<T, K extends keyof T> = {'>': T[K]}
 
 /*
     Any entity. Essentially untyped.
  */
 export type AnyEntity = {
     [key: string]: any
-};
+}
 
 type ModelConstructorOptions = {
     fields?: OneModel
     indexes?: {
         [key: string]: OneIndex
-    },
-    timestamps?: boolean | string,
-};
+    }
+    timestamps?: boolean | string
+}
 
 /*
     Possible params options for all APIs
  */
 export type OneParams = {
-    add?: object,
-    batch?: object,
-    capacity?: string,
-    consistent?: boolean,
-    context?: object,
-    count?: boolean,
-    delete?: object,
-    execute?: boolean,
-    exists?: boolean | null,
-    fields?: string[],
-    follow?: boolean,
-    hidden?: boolean,
-    index?: string,
-    limit?: number,
-    log?: boolean,
-    many?: boolean,
-    maxPages?: number,
-    next?: object,
-    parse?: boolean,
-    partial?: boolean,
-    postFormat?: (model: AnyModel, cmd: {}) => {},
-    prev?: object,
-    push?: object,
-    remove?: string[],
-    reprocess?: boolean,
-    return?: string | boolean,
-    reverse?: boolean,
-    segment?: number,
-    segments?: number,
-    select?: string,
-    set?: object,
-    stats?: object,
-    substitutions?: object,
-    throw?: boolean,
-    transform?: (model: AnyModel, op: string, name: string, value: any, properties: OneProperties) => any,
-    transaction?: object,
-    type?: string,
-    tunnel?: object,
-    where?: string,
-};
+    add?: object
+    batch?: object
+    capacity?: string
+    consistent?: boolean
+    context?: object
+    count?: boolean
+    delete?: object
+    execute?: boolean
+    exists?: boolean | null
+    fields?: string[]
+    follow?: boolean
+    hidden?: boolean
+    index?: string
+    limit?: number
+    log?: boolean
+    many?: boolean
+    maxPages?: number
+    next?: object
+    //  DEPRECATED
+    noerror?: boolean
+    parse?: boolean
+    partial?: boolean
+    postFormat?: (model: AnyModel, cmd: {}) => {}
+    prev?: object
+    push?: object
+    remove?: string[]
+    reprocess?: boolean
+    return?: string | boolean
+    reverse?: boolean
+    segment?: number
+    segments?: number
+    select?: string
+    set?: object
+    stats?: object
+    substitutions?: object
+    timestamps?: boolean
+    throw?: boolean
+    transform?: (model: AnyModel, op: string, name: string, value: any, properties: OneProperties) => any
+    transaction?: object
+    type?: string
+    tunnel?: object
+    warn?: Boolean
+    where?: string
+    profile?: string
+}
 
 /*
     Properties for most APIs. Essentially untyped.
  */
 export type OneProperties = {
     [key: string]: any
-};
+}
 
 export class Paged<T> extends Array<T> {
-    count?: number;
-    next?: object;
-    prev?: object;
+    count?: number
+    next?: object
+    prev?: object
 }
 
 export type AnyModel = {
-    constructor(table: any, name: string, options?: ModelConstructorOptions): AnyModel;
-    create(properties: OneProperties, params?: OneParams): Promise<AnyEntity>;
-    find(properties?: OneProperties, params?: OneParams): Promise<Paged<AnyEntity>>;
-    get(properties: OneProperties, params?: OneParams): Promise<AnyEntity | undefined>;
-    load(properties: OneProperties, params?: OneParams): Promise<AnyEntity | undefined>;
-    init(properties?: OneProperties, params?: OneParams): AnyEntity;
-    remove(properties: OneProperties, params?: OneParams): Promise<AnyEntity | Array<AnyEntity> | undefined>;
-    scan(properties?: OneProperties, params?: OneParams): Promise<Paged<AnyEntity>>;
-    update(properties: OneProperties, params?: OneParams): Promise<AnyEntity>;
-    upsert(properties: OneProperties, params?: OneParams): Promise<AnyEntity>;
-};
+    constructor(table: any, name: string, options?: ModelConstructorOptions): AnyModel
+    create(properties: OneProperties, params?: OneParams): Promise<AnyEntity>
+    find(properties?: OneProperties, params?: OneParams): Promise<Paged<AnyEntity>>
+    get(properties: OneProperties, params?: OneParams): Promise<AnyEntity | undefined>
+    load(properties: OneProperties, params?: OneParams): Promise<AnyEntity | undefined>
+    init(properties?: OneProperties, params?: OneParams): AnyEntity
+    remove(properties: OneProperties, params?: OneParams): Promise<AnyEntity | Array<AnyEntity> | undefined>
+    scan(properties?: OneProperties, params?: OneParams): Promise<Paged<AnyEntity>>
+    update(properties: OneProperties, params?: OneParams): Promise<AnyEntity>
+    upsert(properties: OneProperties, params?: OneParams): Promise<AnyEntity>
+}
 
 type ExtractModel<M> = M extends Entity<infer X> ? X : never
-type GetKeys<T> = T extends T ? keyof T: never;
+type GetKeys<T> = T extends T ? keyof T : never
 
 /*
     Create the type for create properties.
@@ -302,30 +328,30 @@ type GetKeys<T> = T extends T ? keyof T: never;
 
     type EntityParametersForCreate<M extends OneModel> = Required<M> & Optional<M>
 */
-type EntityParametersForCreate<T extends OneModel> =
-    Omit<
-        Omit<
-            Omit<
-                Omit<
-                    Required<T>,
-                    GetKeys<Defaulted<T>>
-                >,
-                GetKeys<Generated<T>>
-            >, GetKeys<ValueTemplates<T>>
-        >, GetKeys<TimestampValue<T>>
-    > & Optional<T> & Partial<Generated<T>> & Partial<Defaulted<T>> & Partial<ValueTemplates<T>> & Partial<TimestampValue<T>>
+type EntityParametersForCreate<T extends OneModel> = Omit<
+    Omit<Omit<Omit<Required<T>, GetKeys<Defaulted<T>>>, GetKeys<Generated<T>>>, GetKeys<ValueTemplates<T>>>,
+    GetKeys<TimestampValue<T>>
+> &
+    Optional<T> &
+    Partial<Generated<T>> &
+    Partial<Defaulted<T>> &
+    Partial<ValueTemplates<T>> &
+    Partial<TimestampValue<T>>
 
 type EntityParametersForUpdate<T extends OneModel> = Partial<Required<T> & OptionalOrNull<T>>
 
+type TransactionalOneParams = OneParams & {transaction: object}
+
 export class Model<T> {
-    constructor(table: any, name: string, options?: ModelConstructorOptions);
-    create(properties: EntityParametersForCreate<ExtractModel<T>>, params?: OneParams): Promise<T>;
-    find(properties?: EntityParametersForFind<T>, params?: OneParams): Promise<Paged<T>>;
-    get(properties: EntityParameters<T>, params?: OneParams): Promise<T | undefined>;
-    load(properties: EntityParameters<T>, params?: OneParams): Promise<T | undefined>;
-    init(properties?: EntityParameters<T>, params?: OneParams): T;
-    remove(properties: EntityParameters<T>, params?: OneParams): Promise<T | Array<T> | undefined>;
-    scan(properties?: EntityParameters<T>, params?: OneParams): Promise<Paged<T>>;
-    update(properties: EntityParametersForUpdate<ExtractModel<T>>, params?: OneParams): Promise<T>;
-    upsert(properties: EntityParameters<T>, params?: OneParams): Promise<T>;
+    constructor(table: any, name: string, options?: ModelConstructorOptions)
+    create(properties: EntityParametersForCreate<ExtractModel<T>>, params?: OneParams): Promise<T>
+    find(properties?: EntityParametersForFind<T>, params?: OneParams): Promise<Paged<T>>
+    get(properties: EntityParameters<T>, params?: OneParams): Promise<T | undefined>
+    load(properties: EntityParameters<T>, params?: OneParams): Promise<T | undefined>
+    init(properties?: EntityParameters<T>, params?: OneParams): T
+    remove(properties: EntityParameters<T>, params?: OneParams): Promise<T | Array<T> | undefined>
+    scan(properties?: EntityParameters<T>, params?: OneParams): Promise<Paged<T>>
+    update(properties: EntityParametersForUpdate<ExtractModel<T>>, params?: OneParams): Promise<T>
+    upsert(properties: EntityParameters<T>, params?: OneParams): Promise<T>
+    check(properties: EntityParameters<T>, params: TransactionalOneParams): void
 }
diff --git a/node_modules/dynamodb-onetable/dist/mjs/Model.js b/node_modules/dynamodb-onetable/dist/mjs/Model.js
index 9d2ab21..3d9cdd9 100644
--- a/node_modules/dynamodb-onetable/dist/mjs/Model.js
+++ b/node_modules/dynamodb-onetable/dist/mjs/Model.js
@@ -3,6 +3,7 @@
 
     A model represents a DynamoDB single-table entity.
 */
+import { Buffer } from 'buffer';
 import { Expression } from './Expression.js';
 import { OneTableError, OneTableArgError } from './Error.js';
 /*
@@ -14,7 +15,7 @@ const ReadWrite = {
     find: 'read',
     put: 'write',
     scan: 'read',
-    update: 'write'
+    update: 'write',
 };
 const TransformParseResponseAs = {
     delete: 'get',
@@ -22,10 +23,10 @@ const TransformParseResponseAs = {
     find: 'find',
     put: 'get',
     scan: 'scan',
-    update: 'get'
+    update: 'get',
 };
 const KeysOnly = { delete: true, get: true };
-const TransactOps = { delete: 'Delete', get: 'Get', put: 'Put', update: 'Update' };
+const TransactOps = { delete: 'Delete', get: 'Get', put: 'Put', update: 'Update', check: 'ConditionCheck' };
 const BatchOps = { delete: 'DeleteRequest', put: 'PutRequest', update: 'PutRequest' };
 const ValidTypes = ['array', 'arraybuffer', 'binary', 'boolean', 'buffer', 'date', 'number', 'object', 'set', 'string'];
 const SanityPages = 1000;
@@ -54,16 +55,12 @@ export class Model {
         this.sort = null;
         //  Cache table properties
         this.createdField = table.createdField;
-        this.generic = options.generic;
         this.nested = false;
         this.nulls = table.nulls;
         this.tableName = table.name;
         this.typeField = options.typeField || table.typeField;
         this.generic = options.generic != null ? options.generic : table.generic;
-        this.timestamps = options.timestamps;
-        if (this.timestamps == null) {
-            this.timestamps = table.timestamps;
-        }
+        this.timestamps = options.timestamps != null ? options.timestamps : table.timestamps;
         this.updatedField = table.updatedField;
         this.block = { fields: {}, deps: [] };
         /*
@@ -86,10 +83,10 @@ export class Model {
     /*
         Prepare a model based on the schema and compute the attribute mapping.
      */
-    prepModel(schemaFields, block, prefix = '') {
+    prepModel(schemaFields, block, parent) {
         let { fields } = block;
         schemaFields = this.table.assign({}, schemaFields);
-        if (!prefix) {
+        if (!parent) {
             //  Top level only
             if (!schemaFields[this.typeField]) {
                 schemaFields[this.typeField] = { type: String, hidden: true };
@@ -110,20 +107,34 @@ export class Model {
         let mapTargets = {};
         let map = {};
         for (let [name, field] of Object.entries(schemaFields)) {
-            let pathname = prefix ? `${prefix}.${name}` : name;
             if (!field.type) {
                 field.type = 'string';
-                this.table.log.error(`Missing type field for ${pathname}`, { field });
-                // throw new OneTableArgError(`Missing field type for ${pathname}`)
+                this.table.log.error(`Missing type field for ${field.name}`, { field });
             }
-            field.pathname = pathname;
             field.name = name;
             fields[name] = field;
-            field.isoDates = field.isoDates != null ? field.isoDates : table.isoDates;
-            //  DEPRECATE 2.3
+            field.isoDates = field.isoDates != null ? field.isoDates : table.isoDates || false;
+            if (field.partial == null) {
+                field.partial = parent && parent.partial != null ? parent.partial : this.table.partial;
+            }
             if (field.uuid) {
-                console.warn('The "uuid" schema property is deprecated. Please use "generate": "uuid or ulid" instead');
-                field.generate = field.generate || field.uuid;
+                throw new OneTableArgError('The "uuid" schema property is deprecated. Please use "generate": "uuid or ulid" instead');
+            }
+            if (field.encode) {
+                let schema = this.schema.definition;
+                if (typeof field.encode == 'string' && this.table.separator) {
+                    let def = schema.models[this.name][field.encode];
+                    if (def?.value) {
+                        let parts = def.value.match(/\${(.*?)}/g);
+                        let index = parts.indexOf('${' + field.name + '}');
+                        if (index >= 0) {
+                            field.encode = [field.encode, this.table.separator, index];
+                        }
+                    }
+                    if (typeof field.encode == 'string') {
+                        throw new OneTableArgError(`Cannot resolve encoded reference for ${this.name}.${field.name}`);
+                    }
+                }
             }
             field.type = this.checkType(field);
             /*
@@ -139,7 +150,7 @@ export class Model {
                     }
                     field.attribute = map[name] = [att, sub];
                     if (mapTargets[att].indexOf(sub) >= 0) {
-                        throw new OneTableArgError(`Multiple attributes in ${this.pathname} mapped to the target ${to}`);
+                        throw new OneTableArgError(`Multiple attributes in ${field.name} mapped to the target ${to}`);
                     }
                     mapTargets[att].push(sub);
                 }
@@ -161,10 +172,10 @@ export class Model {
                 Handle index requirements
             */
             let index = this.indexProperties[field.attribute[0]];
-            if (index && !prefix) {
+            if (index && !parent) {
                 field.isIndexed = true;
                 if (field.attribute.length > 1) {
-                    throw new OneTableArgError(`Cannot map property "${pathname}" to a compound attribute "${this.name}.${pathname}"`);
+                    throw new OneTableArgError(`Cannot map property "${field.name}" to a compound attribute"`);
                 }
                 if (index == 'primary') {
                     field.required = true;
@@ -177,31 +188,35 @@ export class Model {
                     }
                 }
             }
+            if (parent && field.partial === undefined && parent.partial !== undefined) {
+                field.partial = parent.partial;
+            }
             if (field.value) {
                 //  Value template properties are hidden by default
                 if (field.hidden == null) {
-                    field.hidden = table.hidden != null ? table.hidden : true;
+                    field.hidden = true;
                 }
             }
             /*
                 Handle nested schema (recursive)
             */
+            if (field.items && field.type == 'array') {
+                field.schema = field.items.schema;
+                field.isArray = true;
+            }
             if (field.schema) {
-                if (field.type == 'array') {
-                    throw new OneTableArgError(`Array types do not (yet) support nested schemas for field "${field.name}" in model "${this.name}"`);
-                }
-                if (field.type == 'object') {
+                if (field.type == 'object' || field.type == 'array') {
                     field.block = { deps: [], fields: {} };
-                    this.prepModel(field.schema, field.block, pathname);
+                    this.prepModel(field.schema, field.block, field);
                     //  FUTURE - better to apply this to the field block
                     this.nested = true;
                 }
                 else {
-                    throw new OneTableArgError(`Nested scheme not supported "${field.type}" types for field "${field.name}" in model "${this.name}"`);
+                    throw new OneTableArgError(`Nested scheme does not supported "${field.type}" types for field "${field.name}" in model "${this.name}"`);
                 }
             }
         }
-        if (Object.values(fields).find(f => f.unique && f.attribute != this.hash && f.attribute != this.sort)) {
+        if (Object.values(fields).find((f) => f.unique && f.attribute != this.hash && f.attribute != this.sort)) {
             this.hasUniqueFields = true;
         }
         this.mappings = mapTargets;
@@ -225,13 +240,13 @@ export class Model {
     }
     orderFields(block, field) {
         let { deps, fields } = block;
-        if (deps.find(i => i.name == field.pathname)) {
+        if (deps.find((i) => i.name == field.name)) {
             return;
         }
         if (field.value) {
             let vars = this.table.getVars(field.value);
-            for (let pathname of vars) {
-                let name = pathname.split('.').shift();
+            for (let path of vars) {
+                let name = path.split(/[.[]/g).shift().trim(']');
                 let ref = fields[name];
                 if (ref && ref != field) {
                     if (ref.schema) {
@@ -248,6 +263,8 @@ export class Model {
     getPropValue(properties, path) {
         let v = properties;
         for (let part of path.split('.')) {
+            if (v == null)
+                return v;
             v = v[part];
         }
         return v;
@@ -258,10 +275,6 @@ export class Model {
      */
     async run(op, expression) {
         let { index, properties, params } = expression;
-        //  UNDOCUMENTED AND DEPRECATED
-        if (params.preFormat) {
-            params.preFormat(this, expression);
-        }
         /*
             Get a string representation of the API request
          */
@@ -269,7 +282,10 @@ export class Model {
         if (!expression.execute) {
             if (params.log !== false) {
                 this.table.log[params.log ? 'info' : 'data'](`OneTable command for "${op}" "${this.name} (not executed)"`, {
-                    cmd, op, properties, params,
+                    cmd,
+                    op,
+                    properties,
+                    params,
                 });
             }
             return cmd;
@@ -285,9 +301,9 @@ export class Model {
             let top = TransactOps[op];
             if (top) {
                 params.expression = expression;
-                let items = t.TransactItems = t.TransactItems || [];
+                let items = (t.TransactItems = t.TransactItems || []);
                 items.push({ [top]: cmd });
-                return this.transformReadItem(op, properties, properties, params);
+                return this.transformReadItem(op, properties, properties, params, expression);
             }
             else {
                 throw new OneTableArgError(`Unknown transaction operation ${op}`);
@@ -299,17 +315,17 @@ export class Model {
         let b = params.batch;
         if (b) {
             params.expression = expression;
-            let ritems = b.RequestItems = b.RequestItems || {};
+            let ritems = (b.RequestItems = b.RequestItems || {});
             if (op == 'get') {
-                let list = ritems[this.tableName] = ritems[this.tableName] || { Keys: [] };
+                let list = (ritems[this.tableName] = ritems[this.tableName] || { Keys: [] });
                 list.Keys.push(cmd.Keys);
-                return this.transformReadItem(op, properties, properties, params);
+                return this.transformReadItem(op, properties, properties, params, expression);
             }
             else {
-                let list = ritems[this.tableName] = ritems[this.tableName] || [];
+                let list = (ritems[this.tableName] = ritems[this.tableName] || []);
                 let bop = BatchOps[op];
                 list.push({ [bop]: cmd });
-                return this.transformReadItem(op, properties, properties, params);
+                return this.transformReadItem(op, properties, properties, params, expression);
             }
         }
         /*
@@ -335,13 +351,6 @@ export class Model {
             }
             if (result.Items) {
                 items = items.concat(result.Items);
-                if (stats) {
-                    stats.count += result.Count;
-                    stats.scanned += result.ScannedCount;
-                    if (result.ConsumedCapacity) {
-                        stats.capacity += result.ConsumedCapacity.CapacityUnits;
-                    }
-                }
             }
             else if (result.Item) {
                 items = [result.Item];
@@ -354,6 +363,17 @@ export class Model {
             else if (params.count || params.select == 'COUNT') {
                 count += result.Count;
             }
+            if (stats) {
+                if (result.Count) {
+                    stats.count += result.Count;
+                }
+                if (result.ScannedCount) {
+                    stats.scanned += result.ScannedCount;
+                }
+                if (result.ConsumedCapacity) {
+                    stats.capacity += result.ConsumedCapacity.CapacityUnits;
+                }
+            }
             if (params.progress) {
                 params.progress({ items, pages, stats, params, cmd });
             }
@@ -374,14 +394,20 @@ export class Model {
                     Can use LastEvaluatedKey for the direction of scanning. Calculate the other end from the returned items.
                     Next/prev will be swapped when the items are reversed below
                 */
-                let { hash, sort } = (params.index && params.index != 'primary') ? index : this.indexes.primary;
+                let { hash, sort } = params.index && params.index != 'primary' ? index : this.indexes.primary;
                 let cursor = { [hash]: items[0][hash], [sort]: items[0][sort] };
                 if (cursor[hash] == null || cursor[sort] == null) {
                     cursor = null;
                 }
-                // next = result.LastEvaluatedKey
                 if (params.next || params.prev) {
                     prev = cursor;
+                    if (cursor && params.index != 'primary') {
+                        let { hash, sort } = this.indexes.primary;
+                        prev[hash] = items[0][hash];
+                        if (sort != null) {
+                            prev[sort] = items[0][sort];
+                        }
+                    }
                 }
             }
         }
@@ -421,7 +447,11 @@ export class Model {
         */
         if (params.log !== false) {
             this.table.log[params.log ? 'info' : 'data'](`OneTable result for "${op}" "${this.name}"`, {
-                cmd, items, op, properties, params,
+                cmd,
+                items,
+                op,
+                properties,
+                params,
             });
         }
         /*
@@ -454,12 +484,13 @@ export class Model {
                 }
                 results.next = items.next;
                 results.prev = items.prev;
+                results.count = items.count;
                 Object.defineProperty(results, 'next', { enumerable: false });
                 Object.defineProperty(results, 'prev', { enumerable: false });
                 return results;
             }
         }
-        return (op == 'find' || op == 'scan') ? items : items[0];
+        return op == 'find' || op == 'scan' ? items : items[0];
     }
     /*
         Parse the response into Javascript objects and transform for the high level API.
@@ -486,7 +517,7 @@ export class Model {
                     //  Special "unique" model for unique fields. Don't return in result.
                     continue;
                 }
-                items[index] = model.transformReadItem(op, item, properties, params);
+                items[index] = model.transformReadItem(op, item, properties, params, expression);
             }
         }
         return items;
@@ -495,6 +526,7 @@ export class Model {
         Create/Put a new item. Will overwrite existing items if exists: null.
     */
     async create(properties, params = {}) {
+        ;
         ({ properties, params } = this.checkArgs(properties, params, { parse: true, high: true, exists: false }));
         let result;
         if (this.hasUniqueFields) {
@@ -513,26 +545,46 @@ export class Model {
             throw new OneTableArgError('Cannot use batch with unique properties which require transactions');
         }
         let transactHere = params.transaction ? false : true;
-        let transaction = params.transaction = params.transaction || {};
+        let transaction = (params.transaction = params.transaction || {});
         let { hash, sort } = this.indexes.primary;
         let fields = this.block.fields;
-        fields = Object.values(fields).filter(f => f.unique && f.attribute != hash && f.attribute != sort);
-        if (this.timestamps === true || this.timestamps == 'create') {
-            properties[this.createdField] = new Date();
-        }
-        if (this.timestamps === true || this.timestamps == 'update') {
-            properties[this.updatedField] = new Date();
+        fields = Object.values(fields).filter((f) => f.unique && f.attribute != hash && f.attribute != sort);
+        let timestamp = (transaction.timestamp = transaction.timestamp || new Date());
+        if (params.timestamps !== false) {
+            if (this.timestamps === true || this.timestamps == 'create') {
+                properties[this.createdField] = timestamp;
+            }
+            if (this.timestamps === true || this.timestamps == 'update') {
+                properties[this.updatedField] = timestamp;
+            }
         }
         params.prepared = properties = this.prepareProperties('put', properties, params);
+        let ttlField = fields.find(f => f.ttl);
         for (let field of fields) {
             if (properties[field.name] !== undefined) {
                 let scope = '';
                 if (field.scope) {
                     scope = this.runTemplate(null, null, field, properties, params, field.scope) + '#';
+                    if (scope == undefined) {
+                        throw new OneTableError('Missing properties to resolve unique scope', {
+                            properties,
+                            field,
+                            scope: field.scope,
+                            code: 'UniqueError',
+                        });
+                    }
                 }
                 let pk = `_unique#${scope}${this.name}#${field.attribute}#${properties[field.name]}`;
                 let sk = '_unique#';
-                await this.schema.uniqueModel.create({ [this.hash]: pk, [this.sort]: sk }, { transaction, exists: false, return: 'NONE' });
+                let uproperties = { [this.hash]: pk, [this.sort]: sk };
+                if (ttlField) {
+                    /*
+                        Add a TTL expiry property to the unique record
+                     */
+                    let value = properties[ttlField.name];
+                    uproperties[ttlField.name] = new Date(new Date(value).getTime() * 1000);
+                }
+                await this.schema.uniqueModel.create(uproperties, { transaction, exists: false, return: 'NONE' });
             }
         }
         let item = await this.putItem(properties, params);
@@ -544,8 +596,10 @@ export class Model {
             await this.table.transact('write', params.transaction, params);
         }
         catch (err) {
-            if (err instanceof OneTableError && err.code === 'TransactionCanceledException' && err.context.err.message.indexOf('ConditionalCheckFailed') !== -1) {
-                let names = fields.map(f => f.name).join(', ');
+            if (err instanceof OneTableError &&
+                err.code === 'TransactionCanceledException' &&
+                err.context.err.message.indexOf('ConditionalCheckFailed') !== -1) {
+                let names = fields.map((f) => f.name).join(', ');
                 throw new OneTableError(`Cannot create unique attributes "${names}" for "${this.name}". An item of the same name already exists.`, { properties, transaction, code: 'UniqueError' });
             }
             throw err;
@@ -553,19 +607,37 @@ export class Model {
         let items = this.parseResponse('put', expression);
         return items[0];
     }
+    async check(properties, params) {
+        ;
+        ({ properties, params } = this.checkArgs(properties, params, { parse: true, high: true }));
+        properties = this.prepareProperties('get', properties, params);
+        const expression = new Expression(this, 'check', properties, params);
+        this.run('check', expression);
+    }
     async find(properties = {}, params = {}) {
+        ;
         ({ properties, params } = this.checkArgs(properties, params, { parse: true, high: true }));
         return await this.queryItems(properties, params);
     }
     async get(properties = {}, params = {}) {
+        ;
         ({ properties, params } = this.checkArgs(properties, params, { parse: true, high: true }));
         properties = this.prepareProperties('get', properties, params);
         if (params.fallback) {
+            if (params.batch) {
+                throw new OneTableError('Need complete keys for batched get operation', {
+                    properties,
+                    code: 'NonUniqueError',
+                });
+            }
             //  Fallback via find when using non-primary indexes
             params.limit = 2;
             let items = await this.find(properties, params);
             if (items.length > 1) {
-                throw new OneTableError('Get without sort key returns more than one result', { properties, code: 'NonUniqueError' });
+                throw new OneTableError('Get without sort key returns more than one result', {
+                    properties,
+                    code: 'NonUniqueError',
+                });
             }
             return items[0];
         }
@@ -574,19 +646,22 @@ export class Model {
         return await this.run('get', expression);
     }
     async load(properties = {}, params = {}) {
+        ;
         ({ properties, params } = this.checkArgs(properties, params));
         properties = this.prepareProperties('get', properties, params);
         let expression = new Expression(this, 'get', properties, params);
         return await this.table.batchLoad(expression);
     }
     init(properties = {}, params = {}) {
+        ;
         ({ properties, params } = this.checkArgs(properties, params, { parse: true, high: true }));
         return this.initItem(properties, params);
     }
     async remove(properties, params = {}) {
+        ;
         ({ properties, params } = this.checkArgs(properties, params, { parse: true, exists: null, high: true }));
         properties = this.prepareProperties('delete', properties, params);
-        if (params.fallback) {
+        if (params.fallback || params.many) {
             return await this.removeByFind(properties, params);
         }
         let expression = new Expression(this, 'delete', properties, params);
@@ -632,12 +707,12 @@ export class Model {
     */
     async removeUnique(properties, params) {
         let transactHere = params.transaction ? false : true;
-        let transaction = params.transaction = params.transaction || {};
+        let transaction = (params.transaction = params.transaction || {});
         let { hash, sort } = this.indexes.primary;
-        let fields = Object.values(this.block.fields).filter(f => f.unique && f.attribute != hash && f.attribute != sort);
+        let fields = Object.values(this.block.fields).filter((f) => f.unique && f.attribute != hash && f.attribute != sort);
         params.prepared = properties = this.prepareProperties('delete', properties, params);
         let keys = {
-            [hash]: properties[hash]
+            [hash]: properties[hash],
         };
         if (sort) {
             keys[sort] = properties[sort];
@@ -658,6 +733,15 @@ export class Model {
             let scope = '';
             if (field.scope) {
                 scope = this.runTemplate(null, null, field, properties, params, field.scope) + '#';
+                if (scope == undefined) {
+                    throw new OneTableError('Missing properties to resolve unique scope', {
+                        properties,
+                        field,
+                        params,
+                        scope: field.scope,
+                        code: 'UniqueError',
+                    });
+                }
             }
             // If we had a prior record, remove unique values that existed
             if (prior && prior[field.name]) {
@@ -669,7 +753,7 @@ export class Model {
                 let pk = `_unique#${scope}${this.name}#${field.attribute}#${properties[field.name]}`;
                 await this.schema.uniqueModel.remove({ [this.hash]: pk, [this.sort]: sk }, {
                     transaction,
-                    exists: params.exists
+                    exists: params.exists,
                 });
             }
         }
@@ -681,10 +765,12 @@ export class Model {
         return removed;
     }
     async scan(properties = {}, params = {}) {
+        ;
         ({ properties, params } = this.checkArgs(properties, params, { parse: true, high: true }));
         return await this.scanItems(properties, params);
     }
     async update(properties, params = {}) {
+        ;
         ({ properties, params } = this.checkArgs(properties, params, { exists: true, parse: true, high: true }));
         if (this.hasUniqueFields) {
             let hasUniqueProperties = Object.entries(properties).find((pair) => {
@@ -701,7 +787,7 @@ export class Model {
         return await this.update(properties, params);
     }
     /*
-        Update an item with unique attributes and actually updating a unique property.
+        Update an item with unique attributes.
         Use a transaction to update a unique item for each unique attribute.
      */
     async updateUnique(properties, params) {
@@ -709,12 +795,12 @@ export class Model {
             throw new OneTableArgError('Cannot use batch with unique properties which require transactions');
         }
         let transactHere = params.transaction ? false : true;
-        let transaction = params.transaction = params.transaction || {};
+        let transaction = (params.transaction = params.transaction || {});
         let index = this.indexes.primary;
         let { hash, sort } = index;
         params.prepared = properties = this.prepareProperties('update', properties, params);
         let keys = {
-            [index.hash]: properties[index.hash]
+            [index.hash]: properties[index.hash],
         };
         if (index.sort) {
             keys[index.sort] = properties[index.sort];
@@ -733,16 +819,25 @@ export class Model {
         /*
             Create all required unique properties. Remove prior unique properties if they have changed.
         */
-        let fields = Object.values(this.block.fields).filter(f => f.unique && f.attribute != hash && f.attribute != sort);
+        let fields = Object.values(this.block.fields).filter((f) => f.unique && f.attribute != hash && f.attribute != sort);
+        let ttlField = fields.find(f => f.ttl);
         for (let field of fields) {
-            let toBeRemoved = (params.remove && params.remove.includes(field.name));
-            let isUnchanged = (prior && properties[field.name] === prior[field.name]);
+            let toBeRemoved = params.remove && params.remove.includes(field.name);
+            let isUnchanged = prior && properties[field.name] === prior[field.name];
             if (isUnchanged) {
                 continue;
             }
             let scope = '';
             if (field.scope) {
                 scope = this.runTemplate(null, null, field, properties, params, field.scope) + '#';
+                if (scope == undefined) {
+                    throw new OneTableError('Missing properties to resolve unique scope', {
+                        properties,
+                        field,
+                        scope: field.scope,
+                        code: 'UniqueError',
+                    });
+                }
             }
             let pk = `_unique#${scope}${this.name}#${field.attribute}#${properties[field.name]}`;
             let sk = `_unique#`;
@@ -765,12 +860,20 @@ export class Model {
             }
             // If value is changing, add new unique value
             if (properties[field.name] !== undefined) {
-                await this.schema.uniqueModel.create({ [this.hash]: pk, [this.sort]: sk }, {
+                let uproperties = { [this.hash]: pk, [this.sort]: sk };
+                if (ttlField) {
+                    /*
+                        Add a TTL expiry property to the unique record
+                     */
+                    let value = properties[ttlField.name];
+                    uproperties[ttlField.name] = new Date(new Date(value).getTime() * 1000);
+                }
+                await this.schema.uniqueModel.create(uproperties, {
                     transaction,
                     exists: false,
                     return: 'NONE',
                     log: params.log,
-                    execute: params.execute
+                    execute: params.execute,
                 });
             }
         }
@@ -785,13 +888,15 @@ export class Model {
             await this.table.transact('write', params.transaction, params);
         }
         catch (err) {
-            if (err instanceof OneTableError && err.code === 'TransactionCanceledException' && err.context.err.message.indexOf('ConditionalCheckFailed') !== -1) {
-                let names = fields.map(f => f.name).join(', ');
+            if (err instanceof OneTableError &&
+                err.code === 'TransactionCanceledException' &&
+                err.context.err.message.indexOf('ConditionalCheckFailed') !== -1) {
+                let names = fields.map((f) => f.name).join(', ');
                 throw new OneTableError(`Cannot update unique attributes "${names}" for "${this.name}". An item of the same name already exists.`, { properties, transaction, code: 'UniqueError' });
             }
             throw err;
         }
-        if (params.return == 'none' || params.return === false) {
+        if (params.return == 'none' || params.return == 'NONE' || params.return === false) {
             return;
         }
         if (params.return == 'get') {
@@ -802,22 +907,16 @@ export class Model {
                 execute: params.execute,
             });
         }
-        if (params.return) {
-            throw new OneTableArgError('Update cannot return an updated item that contain unique attributes');
-        }
-        else {
-            /*
-            if (this.table.warn !== false) {
-                console.warn(`Update with unique items uses transactions and cannot return the updated item.` +
-                             `Use params {return: 'none'} to squelch this warning. ` +
-                             `Use {return: 'get'} to do a non-transactional get of the item after the update. `)
-            } */
-            return properties;
+        if (this.table.warn) {
+            console.warn(`Update with unique items uses transactions and cannot return the updated item.` +
+                `Use params {return: 'none'} to squelch this warning. ` +
+                `Use {return: 'get'} to do a non-transactional get of the item after the update. `);
         }
     }
     //  Low level API
     /* private */
     async deleteItem(properties, params = {}) {
+        ;
         ({ properties, params } = this.checkArgs(properties, params));
         if (!params.prepared) {
             properties = this.prepareProperties('delete', properties, params);
@@ -827,6 +926,7 @@ export class Model {
     }
     /* private */
     async getItem(properties, params = {}) {
+        ;
         ({ properties, params } = this.checkArgs(properties, params));
         properties = this.prepareProperties('get', properties, params);
         let expression = new Expression(this, 'get', properties, params);
@@ -834,6 +934,7 @@ export class Model {
     }
     /* private */
     initItem(properties, params = {}) {
+        ;
         ({ properties, params } = this.checkArgs(properties, params));
         let fields = this.block.fields;
         this.setDefaults('init', fields, properties, params);
@@ -843,18 +944,24 @@ export class Model {
                 properties[key] = null;
             }
         }
-        this.runTemplates('put', this.indexes.primary, this.block.deps, properties, params);
+        this.runTemplates('put', '', this.indexes.primary, this.block.deps, properties, params);
         return properties;
     }
     /* private */
     async putItem(properties, params = {}) {
+        ;
         ({ properties, params } = this.checkArgs(properties, params));
         if (!params.prepared) {
-            if (this.timestamps === true || this.timestamps == 'create') {
-                properties[this.createdField] = new Date();
-            }
-            if (this.timestamps === true || this.timestamps == 'update') {
-                properties[this.updatedField] = new Date();
+            if (params.timestamps !== false) {
+                let timestamp = params.transaction
+                    ? (params.transaction.timestamp = params.transaction.timestamp || new Date())
+                    : new Date();
+                if (this.timestamps === true || this.timestamps == 'create') {
+                    properties[this.createdField] = timestamp;
+                }
+                if (this.timestamps === true || this.timestamps == 'update') {
+                    properties[this.updatedField] = timestamp;
+                }
             }
             properties = this.prepareProperties('put', properties, params);
         }
@@ -863,6 +970,7 @@ export class Model {
     }
     /* private */
     async queryItems(properties = {}, params = {}) {
+        ;
         ({ properties, params } = this.checkArgs(properties, params));
         properties = this.prepareProperties('find', properties, params);
         let expression = new Expression(this, 'find', properties, params);
@@ -871,6 +979,7 @@ export class Model {
     //  Note: scanItems will return all model types
     /* private */
     async scanItems(properties = {}, params = {}) {
+        ;
         ({ properties, params } = this.checkArgs(properties, params));
         properties = this.prepareProperties('scan', properties, params);
         let expression = new Expression(this, 'scan', properties, params);
@@ -878,15 +987,20 @@ export class Model {
     }
     /* private */
     async updateItem(properties, params = {}) {
+        ;
         ({ properties, params } = this.checkArgs(properties, params));
         if (this.timestamps === true || this.timestamps == 'update') {
-            let now = new Date();
-            properties[this.updatedField] = now;
-            if (params.exists == null) {
-                let field = this.block.fields[this.createdField] || this.table;
-                let when = (field.isoDates) ? now.toISOString() : now.getTime();
-                params.set = params.set || {};
-                params.set[this.createdField] = `if_not_exists(\${${this.createdField}}, {${when}})`;
+            if (params.timestamps !== false) {
+                let timestamp = params.transaction
+                    ? (params.transaction.timestamp = params.transaction.timestamp || new Date())
+                    : new Date();
+                properties[this.updatedField] = timestamp;
+                if (params.exists == null) {
+                    let field = this.block.fields[this.createdField] || this.table;
+                    let when = field.isoDates ? timestamp.toISOString() : timestamp.getTime();
+                    params.set = params.set || {};
+                    params.set[this.createdField] = `if_not_exists(\${${this.createdField}}, {${when}})`;
+                }
             }
         }
         properties = this.prepareProperties('update', properties, params);
@@ -895,6 +1009,7 @@ export class Model {
     }
     /* private */
     async fetch(models, properties = {}, params = {}) {
+        ;
         ({ properties, params } = this.checkArgs(properties, params));
         if (models.length == 0) {
             return {};
@@ -917,24 +1032,27 @@ export class Model {
     /*
         Map Dynamo types to Javascript types after reading data
      */
-    transformReadItem(op, raw, properties, params) {
+    transformReadItem(op, raw, properties, params, expression) {
         if (!raw) {
             return raw;
         }
-        return this.transformReadBlock(op, raw, properties, params, this.block.fields);
+        return this.transformReadBlock(op, raw, properties, params, this.block.fields, expression);
     }
-    transformReadBlock(op, raw, properties, params, fields) {
+    transformReadBlock(op, raw, properties, params, fields, expression) {
         let rec = {};
         for (let [name, field] of Object.entries(fields)) {
             //  Skip hidden params. Follow needs hidden params to do the follow.
-            if (field.hidden && params.hidden !== true && params.follow !== true) {
-                continue;
+            if (field.hidden && params.follow !== true) {
+                if (params.hidden === false || (params.hidden == null && this.table.hidden === false)) {
+                    continue;
+                }
             }
             let att, sub;
             if (op == 'put') {
                 att = field.name;
             }
             else {
+                ;
                 [att, sub] = field.attribute;
             }
             let value = raw[att];
@@ -943,35 +1061,44 @@ export class Model {
                     let [att, sep, index] = field.encode;
                     value = (raw[att] || '').split(sep)[index];
                 }
-                if (value === undefined) {
-                    continue;
-                }
             }
-            if (sub) {
+            if (sub && value) {
                 value = value[sub];
             }
             if (field.crypt && params.decrypt !== false) {
                 value = this.decrypt(value);
             }
             if (field.default !== undefined && value === undefined) {
-                if (typeof field.default == 'function') {
-                    // console.warn('WARNING: default functions are DEPRECATED and will be removed soon.')
-                    value = field.default(this, field.name, properties);
-                }
-                else {
-                    value = field.default;
+                if (!params.fields || params.fields.indexOf(name) >= 0) {
+                    rec[name] = field.default;
                 }
             }
             else if (value === undefined) {
                 if (field.required) {
-                    this.table.log.error(`Required field "${name}" in model "${this.name}" not defined in table item`, {
-                        model: this.name, raw, params, field
-                    });
+                    /*
+                        Transactions transform the properties to return something, but
+                        does not have all the properties and required fields may be missing).
+                        Also find operation with fields selections may not include required fields.
+                     */
+                    if (!params.transaction && !params.batch && !params.fields && !field.encode && !expression?.index?.project) {
+                        if (params.warn || this.table.warn) {
+                            this.table.log.error(`Required field "${name}" in model "${this.name}" not defined in table item`, { model: this.name, raw, params, field });
+                        }
+                    }
                 }
-                continue;
             }
-            else if (field.schema && typeof value == 'object') {
-                rec[name] = this.transformReadBlock(op, raw[name], properties[name] || {}, params, field.block.fields);
+            else if (field.schema && value !== null && typeof value == 'object') {
+                if (field.items && Array.isArray(value)) {
+                    rec[name] = [];
+                    let i = 0;
+                    for (let rvalue of raw[att]) {
+                        rec[name][i] = this.transformReadBlock(op, rvalue, properties[name] || [], params, field.block.fields, expression);
+                        i++;
+                    }
+                }
+                else {
+                    rec[name] = this.transformReadBlock(op, raw[att], properties[name] || {}, params, field.block.fields, expression);
+                }
             }
             else {
                 rec[name] = this.transformReadAttribute(field, name, value, params, properties);
@@ -985,7 +1112,10 @@ export class Model {
                 }
             }
         }
-        if (params.hidden == true && rec[this.typeField] === undefined && !this.generic && this.block.fields == fields) {
+        if (params.hidden == true &&
+            rec[this.typeField] === undefined &&
+            !this.generic &&
+            this.block.fields == fields) {
             rec[this.typeField] = this.name;
         }
         if (this.table.params.transform) {
@@ -1026,14 +1156,19 @@ export class Model {
         }
         //  DEPRECATE
         this.tunnelProperties(properties, params);
-        let rec = this.collectProperties(op, this.block, index, properties, params);
+        if (params.filter) {
+            this.convertFilter(properties, params, index);
+        }
+        let rec = this.collectProperties(op, '', this.block, index, properties, params);
         if (params.fallback) {
             return properties;
         }
         if (op != 'scan' && this.getHash(rec, this.block.fields, index, params) == null) {
             this.table.log.error(`Empty hash key`, { properties, params, op, rec, index, model: this.name });
             throw new OneTableError(`Empty hash key. Check hash key and any value template variable references.`, {
-                properties, rec, code: 'MissingError',
+                properties,
+                rec,
+                code: 'MissingError',
             });
         }
         if (this.table.params.transform && ReadWrite[op] == 'write') {
@@ -1041,6 +1176,56 @@ export class Model {
         }
         return rec;
     }
+    /*
+        Convert a full text params.filter into a smart params.where
+        NOTE: this is prototype code and definitely not perfect! Use at own risk.
+     */
+    convertFilter(properties, params, index) {
+        let filter = params.filter.toString();
+        let fields = this.block.fields;
+        let where;
+        //  TODO support > >= < <= ..., AND or ...
+        let [name, value] = filter.split('=');
+        if (value) {
+            name = name.trim();
+            value = value.trim();
+            let field = fields[name];
+            if (field) {
+                name = field.map ? field.map : name;
+                if (field.encode) {
+                    properties[name] = value;
+                }
+                else {
+                    where = `\${${name}} = {"${value}"}`;
+                }
+            }
+            else {
+                where = `\${${name}} = {"${value}"}`;
+            }
+        }
+        else {
+            value = name;
+            where = [];
+            for (let [name, field] of Object.entries(fields)) {
+                let primary = this.indexes.primary;
+                if (primary.hash == name || primary.sort == name || index.hash == name || index.sort == name) {
+                    continue;
+                }
+                if (field.encode) {
+                    continue;
+                }
+                name = field.map ? field.map : name;
+                where.push(`(contains(\${${name}}, {"${filter}"}))`);
+            }
+            if (where) {
+                where = where.join(' or ');
+            }
+        }
+        params.where = where;
+        params.maxPages = params.maxPages || 25;
+        //  Remove limit otherwise the search will only search "limit" items at a time
+        delete params.limit;
+    }
     //  Handle fallback for get/delete as GSIs only support find and scan
     needsFallback(op, index, params) {
         if (index != this.indexes.primary && op != 'find' && op != 'scan') {
@@ -1059,7 +1244,7 @@ export class Model {
         if (generic) {
             return rec[index.hash];
         }
-        let field = Object.values(fields).find(f => f.attribute[0] == index.hash);
+        let field = Object.values(fields).find((f) => f.attribute[0] == index.hash);
         if (!field) {
             return null;
         }
@@ -1083,10 +1268,12 @@ export class Model {
     }
     /*
         Collect the required attribute from the properties and context.
-        This handles tunneled properties, blends context properties, resolves default values, handles Nulls and empty strings,
-        and invokes validations. Nested schemas are handled here.
+        This handles tunneled properties, blends context properties, resolves default values,
+        handles Nulls and empty strings, and invokes validations. Nested schemas are handled here.
+
+        NOTE: pathname is only needed for DEPRECATED and undocumented callbacks.
     */
-    collectProperties(op, block, index, properties, params, context, rec = {}) {
+    collectProperties(op, pathname, block, index, properties, params, context, rec = {}) {
         let fields = block.fields;
         if (!context) {
             context = params.context || this.table.context;
@@ -1095,41 +1282,69 @@ export class Model {
             First process nested schemas recursively
         */
         if (this.nested && !KeysOnly[op]) {
-            //  Process nested schema recursively
-            for (let field of Object.values(fields)) {
-                if (field.schema) {
-                    let name = field.name;
-                    let value = properties[name];
-                    if (op == 'put') {
-                        value = value || field.default;
-                        if (value === undefined && field.required) {
-                            value = field.type == 'array' ? [] : {};
-                        }
-                    }
-                    if (value !== undefined) {
-                        rec[name] = this.collectProperties(op, field.block, index, value, params, context[name] || {});
-                    }
-                }
-            }
+            this.collectNested(op, pathname, fields, index, properties, params, context, rec);
         }
         /*
             Then process the non-schema properties at this level (non-recursive)
         */
         this.addContext(op, fields, index, properties, params, context);
         this.setDefaults(op, fields, properties, params);
-        this.runTemplates(op, index, block.deps, properties, params);
-        this.convertNulls(op, fields, properties, params);
+        this.runTemplates(op, pathname, index, block.deps, properties, params);
+        this.convertNulls(op, pathname, fields, properties, params);
         this.validateProperties(op, fields, properties, params);
         this.selectProperties(op, block, index, properties, params, rec);
         this.transformProperties(op, fields, properties, params, rec);
         return rec;
     }
+    /*
+        Process nested schema recursively
+    */
+    collectNested(op, pathname, fields, index, properties, params, context, rec) {
+        for (let field of Object.values(fields)) {
+            let schema = field.schema || field?.items?.schema;
+            if (schema) {
+                let name = field.name;
+                let value = properties[name];
+                if (op == 'put' && value === undefined) {
+                    value = field.required ? (field.type == 'array' ? [] : {}) : field.default;
+                }
+                let ctx = context[name] || {};
+                let partial = this.getPartial(field, params);
+                if (value === null && field.nulls === true) {
+                    rec[name] = null;
+                }
+                else if (value !== undefined) {
+                    if (field.items && Array.isArray(value)) {
+                        rec[name] = [];
+                        let i = 0;
+                        for (let rvalue of value) {
+                            let path = pathname ? `${pathname}.${name}[${i}]` : `${name}[${i}]`;
+                            let obj = this.collectProperties(op, path, field.block, index, rvalue, params, ctx);
+                            //  Don't update properties if empty and partial and no default
+                            if (!partial || Object.keys(obj).length > 0 || field.default !== undefined) {
+                                rec[name][i++] = obj;
+                            }
+                        }
+                    }
+                    else {
+                        let path = pathname ? `${pathname}.${field.name}` : field.name;
+                        let obj = this.collectProperties(op, path, field.block, index, value, params, ctx);
+                        if (!partial || Object.keys(obj).length > 0 || field.default !== undefined) {
+                            rec[name] = obj;
+                        }
+                    }
+                }
+            }
+        }
+    }
     /*
         DEPRECATE - not needed anymore
     */
     tunnelProperties(properties, params) {
         if (params.tunnel) {
-            console.warn('WARNING: tunnel properties should not be required for typescript and will be removed soon.');
+            if (this.table.warn) {
+                console.warn('WARNING: tunnel properties should not be required for typescript and will be removed soon.');
+            }
             for (let [kind, settings] of Object.entries(params.tunnel)) {
                 for (let [key, value] of Object.entries(settings)) {
                     properties[key] = { [kind]: value };
@@ -1279,6 +1494,9 @@ export class Model {
                     if (generate === true) {
                         value = this.table.generate();
                     }
+                    else if (typeof generate === 'function') {
+                        value = generate();
+                    }
                     else if (generate == 'uuid') {
                         value = this.table.uuid();
                     }
@@ -1302,65 +1520,72 @@ export class Model {
     }
     /*
         Remove null properties from the table unless Table.nulls == true
+        TODO - null conversion would be better done in Expression then pathnames would not be needed.
+        NOTE: pathname is only needed for DEPRECATED callbacks.
     */
-    convertNulls(op, fields, properties, params) {
+    convertNulls(op, pathname, fields, properties, params) {
         for (let [name, value] of Object.entries(properties)) {
             let field = fields[name];
             if (!field || field.schema)
                 continue;
             if (value === null && field.nulls !== true) {
-                if (field.required && (
                 //  create with null/undefined, or update with null property
-                (op == 'put' && properties[field.name] == null) ||
-                    (op == 'update' && properties[field.name] === null))) {
+                if (field.required &&
+                    ((op == 'put' && properties[field.name] == null) ||
+                        (op == 'update' && properties[field.name] === null))) {
                     //  Validation will catch this
                     continue;
                 }
+                delete properties[name];
+                if (this.getPartial(field, params) === false && pathname.match(/[[.]/)) {
+                    /*
+                        Partial disabled for a nested object
+                        Don't create remove entry as the entire object is being created/updated
+                     */
+                    continue;
+                }
                 if (params.remove && !Array.isArray(params.remove)) {
                     params.remove = [params.remove];
                 }
                 else {
                     params.remove = params.remove || [];
                 }
-                params.remove.push(field.pathname);
-                delete properties[name];
+                let path = pathname ? `${pathname}.${field.name}` : field.name;
+                params.remove.push(path);
             }
             else if (typeof value == 'object' && (field.type == 'object' || field.type == 'array')) {
-                properties[name] = this.removeNulls(field, value);
+                //  LEGACY: Remove nested empty strings because DynamoDB cannot handle these nested in objects or arrays
+                if (this.table.params.legacyEmpties === true) {
+                    properties[name] = this.handleEmpties(field, value);
+                }
             }
         }
     }
     /*
         Process value templates and property values that are functions
      */
-    runTemplates(op, index, deps, properties, params) {
+    runTemplates(op, pathname, index, deps, properties, params) {
         for (let field of deps) {
             if (field.schema)
                 continue;
             let name = field.name;
-            if (field.isIndexed && (op != 'put' && op != 'update') &&
-                field.attribute[0] != index.hash && field.attribute[0] != index.sort) {
+            if (field.isIndexed &&
+                op != 'put' &&
+                op != 'update' &&
+                field.attribute[0] != index.hash &&
+                field.attribute[0] != index.sort) {
                 //  Ignore indexes not being used for this call
                 continue;
             }
+            let path = pathname ? `${pathname}.${field.name}` : field.name;
             if (field.value === true && typeof this.table.params.value == 'function') {
-                properties[name] = this.table.params.value(this, field.pathname, properties, params);
-            }
-            else if (typeof properties[name] == 'function') {
-                //  Undocumented and not supported for typescript
-                properties[name] = properties[name](field.pathname, properties);
+                properties[name] = this.table.params.value(this, path, properties, params);
             }
             else if (properties[name] === undefined) {
                 if (field.value) {
-                    if (typeof field.value == 'function') {
-                        // console.warn('WARNING: value functions are DEPRECATED and will be removed soon.')
-                        properties[name] = field.value(field.pathname, properties);
-                    }
-                    else {
-                        let value = this.runTemplate(op, index, field, properties, params, field.value);
-                        if (value != null) {
-                            properties[name] = value;
-                        }
+                    let value = this.runTemplate(op, index, field, properties, params, field.value);
+                    if (value != null) {
+                        properties[name] = value;
                     }
                 }
             }
@@ -1394,7 +1619,7 @@ export class Model {
                 v = match;
             }
             if (typeof v == 'object' && v.toString() == '[object Object]') {
-                throw new OneTableError(`Value for "${field.pathname}" is not a primitive value`, { code: 'TypeError' });
+                throw new OneTableError(`Value for "${field.name}" is not a primitive value`, { code: 'TypeError' });
             }
             return v;
         });
@@ -1402,13 +1627,15 @@ export class Model {
             Consider unresolved template variables. If field is the sort key and doing find,
             then use sort key prefix and begins_with, (provide no where clause).
          */
-        if (value.indexOf('${') >= 0 && index) {
-            if (field.attribute[0] == index.sort) {
-                if (op == 'find') {
-                    //  Strip from first ${ onward and retain fixed prefix portion
-                    value = value.replace(/\${.*/g, '');
-                    if (value) {
-                        return { begins: value };
+        if (value.indexOf('${') >= 0) {
+            if (index) {
+                if (field.attribute[0] == index.sort) {
+                    if (op == 'find') {
+                        //  Strip from first ${ onward and retain fixed prefix portion
+                        value = value.replace(/\${.*/g, '');
+                        if (value) {
+                            return { begins: value };
+                        }
                     }
                 }
             }
@@ -1448,20 +1675,23 @@ export class Model {
         }
         for (let field of Object.values(fields)) {
             //  If required and create, must be defined. If required and update, must not be null.
-            if (field.required && !field.schema && ((op == 'put' && properties[field.name] == null) || (op == 'update' && properties[field.name] === null))) {
+            if (field.required &&
+                !field.schema &&
+                ((op == 'put' && properties[field.name] == null) || (op == 'update' && properties[field.name] === null))) {
                 validation[field.name] = `Value not defined for required field "${field.name}"`;
             }
         }
         if (Object.keys(validation).length > 0) {
-            let error = new OneTableError(`Validation Error in "${this.name}" for "${Object.keys(validation).join(', ')}"`, { validation, code: 'ValidationError' });
-            throw error;
+            throw new OneTableError(`Validation Error in "${this.name}" for "${Object.keys(validation).join(', ')}"`, {
+                validation,
+                code: 'ValidationError',
+                properties,
+            });
         }
     }
     validateProperty(field, value, details, params) {
         let fieldName = field.name;
-        //  DEPRECATE
         if (typeof params.validate == 'function') {
-            // console.warn('WARNING: params.validate functions are DEPRECATED and will be removed soon.')
             let error;
             ({ error, value } = params.validate(this, field, value));
             if (error) {
@@ -1507,10 +1737,11 @@ export class Model {
     }
     transformProperties(op, fields, properties, params, rec) {
         for (let [name, field] of Object.entries(fields)) {
+            //  Nested schemas handled via collectProperties
             if (field.schema)
                 continue;
             let value = rec[name];
-            if (value !== undefined && !field.schema) {
+            if (value !== undefined) {
                 rec[name] = this.transformWriteAttribute(op, field, value, properties, params);
             }
         }
@@ -1537,7 +1768,9 @@ export class Model {
         else if (type == 'number') {
             let num = Number(value);
             if (isNaN(num)) {
-                throw new OneTableError(`Invalid value "${value}" provided for field "${field.name}"`, { code: 'ValidationError' });
+                throw new OneTableError(`Invalid value "${value}" provided for field "${field.name}"`, {
+                    code: 'ValidationError',
+                });
             }
             value = num;
         }
@@ -1558,22 +1791,26 @@ export class Model {
             }
         }
         else if (type == 'array') {
-            //  Heursistics to accept legacy string values for array types. Note: TS would catch this also.
-            if (value != null && !Array.isArray(value)) {
-                if (value == '') {
-                    value = [];
+            if (value != null) {
+                if (Array.isArray(value)) {
+                    value = this.transformNestedWriteFields(field, value);
                 }
                 else {
-                    //  FUTURE: should be moved to validations
-                    throw new OneTableArgError(`Invalid data type for Array field "${field.name}" in "${this.name}"`);
-                    // value = [value]
+                    //  Heursistics to accept legacy string values for array types. Note: TS would catch this also.
+                    if (value == '') {
+                        value = [];
+                    }
+                    else {
+                        //  FUTURE: should be moved to validations
+                        throw new OneTableArgError(`Invalid data type for Array field "${field.name}" in "${this.name}"`);
+                    }
                 }
             }
         }
         else if (type == 'set' && Array.isArray(value)) {
             value = this.transformWriteSet(type, value);
         }
-        else if (type == 'object' && (value != null && typeof value == 'object')) {
+        else if (type == 'object' && value != null && typeof value == 'object') {
             value = this.transformNestedWriteFields(field, value);
         }
         if (field.crypt && value != null) {
@@ -1610,13 +1847,13 @@ export class Model {
         if (type == Set || type == 'Set' || type == 'set') {
             let v = value.values().next().value;
             if (typeof v == 'string') {
-                value = value.map(v => v.toString());
+                value = value.map((v) => v.toString());
             }
             else if (typeof v == 'number') {
-                value = value.map(v => Number(v));
+                value = value.map((v) => Number(v));
             }
             else if (v instanceof Buffer || v instanceof ArrayBuffer || v instanceof DataView) {
-                value = value.map(v => v.toString('base64'));
+                value = value.map((v) => v.toString('base64'));
             }
         }
         else {
@@ -1628,25 +1865,26 @@ export class Model {
         Handle dates. Supports epoch and ISO date transformations.
     */
     transformWriteDate(field, value) {
+        let isoDates = field.isoDates || this.table.isoDates;
         if (field.ttl) {
             //  Convert dates to DynamoDB TTL
             if (value instanceof Date) {
                 value = value.getTime();
             }
             else if (typeof value == 'string') {
-                value = (new Date(Date.parse(value))).getTime();
+                value = new Date(Date.parse(value)).getTime();
             }
             value = Math.ceil(value / 1000);
         }
-        else if (field.isoDates) {
+        else if (isoDates) {
             if (value instanceof Date) {
                 value = value.toISOString();
             }
             else if (typeof value == 'string') {
-                value = (new Date(Date.parse(value))).toISOString();
+                value = new Date(Date.parse(value)).toISOString();
             }
             else if (typeof value == 'number') {
-                value = (new Date(value)).toISOString();
+                value = new Date(value).toISOString();
             }
         }
         else {
@@ -1655,7 +1893,7 @@ export class Model {
                 value = value.getTime();
             }
             else if (typeof value == 'string') {
-                value = (new Date(Date.parse(value))).getTime();
+                value = new Date(Date.parse(value)).getTime();
             }
         }
         return value;
@@ -1705,15 +1943,14 @@ export class Model {
         return { properties, params };
     }
     /*
-        Handle nulls and empty strings properly according to nulls preference.
+        Handle nulls and empty strings properly according to nulls preference in plain objects and arrays.
         NOTE: DynamoDB can handle empty strings as top level non-key string attributes, but not nested in lists or maps. Ugh!
     */
-    removeNulls(field, obj) {
+    handleEmpties(field, obj) {
         let result;
-        /*
-            Loop over plain objects and arrays only
-        */
-        if (obj !== null && typeof obj == 'object' && (obj.constructor.name == 'Object' || obj.constructor.name == 'Array')) {
+        if (obj !== null &&
+            typeof obj == 'object' &&
+            (obj.constructor.name == 'Object' || obj.constructor.name == 'Array')) {
             result = Array.isArray(obj) ? [] : {};
             for (let [key, value] of Object.entries(obj)) {
                 if (value === '') {
@@ -1725,7 +1962,7 @@ export class Model {
                     continue;
                 }
                 else if (typeof value == 'object') {
-                    result[key] = this.removeNulls(field, value);
+                    result[key] = this.handleEmpties(field, value);
                 }
                 else {
                     result[key] = value;
@@ -1737,4 +1974,15 @@ export class Model {
         }
         return result;
     }
+    /*
+        Return if a field supports partial updates of its children.
+        Only relevant for fields with nested schema
+     */
+    getPartial(field, params) {
+        let partial = params.partial;
+        if (partial === undefined) {
+            partial = field.partial;
+        }
+        return partial ? true : false;
+    }
 }
diff --git a/node_modules/dynamodb-onetable/dist/mjs/Schema.d.ts b/node_modules/dynamodb-onetable/dist/mjs/Schema.d.ts
index a2fcb54..abd767d 100644
--- a/node_modules/dynamodb-onetable/dist/mjs/Schema.d.ts
+++ b/node_modules/dynamodb-onetable/dist/mjs/Schema.d.ts
@@ -2,6 +2,7 @@ export class Schema {
     constructor(table: any, schema: any);
     table: any;
     keyTypes: {};
+    process: {};
     params: any;
     getCurrentSchema(): any;
     setSchemaInner(schema: any): any;
@@ -46,6 +47,9 @@ export class Schema {
             type: string;
             required: boolean;
         };
+        process: {
+            type: string;
+        };
         version: {
             type: string;
             required: boolean;
@@ -73,10 +77,15 @@ export class Schema {
             type: string;
             required: boolean;
         };
+        status: {
+            type: string;
+        };
     };
     addModel(name: any, fields: any): void;
     listModels(): string[];
-    getModel(name: any): any;
+    getModel(name: any, options?: {
+        nothrow: boolean;
+    }): any;
     removeModel(name: any): void;
     getKeys(refresh?: boolean): Promise<any>;
     setDefaultParams(params: any): any;
@@ -88,4 +97,4 @@ export class Schema {
     removeSchema(schema: any): Promise<void>;
     saveSchema(schema: any): Promise<any>;
 }
-import { Model } from "./Model.js";
+import { Model } from './Model.js';
diff --git a/node_modules/dynamodb-onetable/dist/mjs/Schema.js b/node_modules/dynamodb-onetable/dist/mjs/Schema.js
index 4b4d384..98436b0 100644
--- a/node_modules/dynamodb-onetable/dist/mjs/Schema.js
+++ b/node_modules/dynamodb-onetable/dist/mjs/Schema.js
@@ -14,6 +14,7 @@ export class Schema {
     constructor(table, schema) {
         this.table = table;
         this.keyTypes = {};
+        this.process = {};
         table.schema = this;
         Object.defineProperty(this, 'table', { enumerable: false });
         this.params = table.getSchemaParams();
@@ -22,7 +23,9 @@ export class Schema {
     getCurrentSchema() {
         if (this.definition) {
             let schema = this.table.assign({}, this.definition, { params: this.params });
-            return this.transformSchemaForWrite(schema);
+            schema = this.transformSchemaForWrite(schema);
+            schema.process = Object.assign({}, this.process);
+            return schema;
         }
         return null;
     }
@@ -39,15 +42,14 @@ export class Schema {
             }
             this.indexes = indexes;
             //  Must set before creating models
-            if (params) {
-                this.table.setSchemaParams(params);
-            }
+            this.table.setSchemaParams(params);
             for (let [name, model] of Object.entries(models)) {
                 if (name == SchemaModel || name == MigrationModel)
                     continue;
                 this.models[name] = new Model(this.table, name, { fields: model });
             }
             this.createStandardModels();
+            this.process = schema.process;
         }
         return this.indexes;
     }
@@ -86,10 +88,6 @@ export class Schema {
                     if (index.sort == null) {
                         throw new OneTableArgError('LSIs must define a sort attribute');
                     }
-                    /*
-                    if (index.project) {
-                        throw new OneTableArgError('Unexpected project definition for LSI')
-                    } */
                     index.hash = primary.hash;
                     lsi++;
                 }
@@ -121,9 +119,7 @@ export class Schema {
         let { indexes, table } = this;
         let primary = indexes.primary;
         let type = this.keyTypes[primary.hash] || 'string';
-        let fields = {
-            [primary.hash]: { type }
-        };
+        let fields = { [primary.hash]: { type } };
         if (primary.sort) {
             let type = this.keyTypes[primary.sort] || 'string';
             fields[primary.sort] = { type };
@@ -148,7 +144,7 @@ export class Schema {
     createSchemaModel() {
         let { indexes, table } = this;
         let primary = indexes.primary;
-        let fields = this.schemaModelFields = {
+        let fields = (this.schemaModelFields = {
             [primary.hash]: { type: 'string', required: true, value: `${SchemaKey}` },
             format: { type: 'string', required: true },
             indexes: { type: 'object', required: true },
@@ -156,8 +152,9 @@ export class Schema {
             models: { type: 'object', required: true },
             params: { type: 'object', required: true },
             queries: { type: 'object', required: true },
+            process: { type: 'object' },
             version: { type: 'string', required: true },
-        };
+        });
         if (primary.sort) {
             fields[primary.sort] = { type: 'string', required: true, value: `${SchemaKey}:\${name}` };
         }
@@ -166,15 +163,16 @@ export class Schema {
     createMigrationModel() {
         let { indexes } = this;
         let primary = indexes.primary;
-        let fields = this.migrationModelFields = {
+        let fields = (this.migrationModelFields = {
             [primary.hash]: { type: 'string', value: `${MigrationKey}` },
             date: { type: 'date', required: true },
             description: { type: 'string', required: true },
             path: { type: 'string', required: true },
             version: { type: 'string', required: true },
-        };
+            status: { type: 'string' },
+        });
         if (primary.sort) {
-            fields[primary.sort] = { type: 'string', value: `${MigrationKey}:\${version}` };
+            fields[primary.sort] = { type: 'string', value: `${MigrationKey}:\${version}:\${date}` };
         }
         this.models[MigrationModel] = new Model(this.table, MigrationModel, { fields, indexes });
     }
@@ -187,8 +185,11 @@ export class Schema {
     /*
         Thows exception if model cannot be found
      */
-    getModel(name) {
+    getModel(name, options = { nothrow: false }) {
         if (!name) {
+            if (options.nothrow) {
+                return null;
+            }
             throw new Error('Undefined model name');
         }
         let model = this.models[name.toString()];
@@ -196,6 +197,9 @@ export class Schema {
             if (name == UniqueModel) {
                 return this.uniqueModel;
             }
+            if (options.nothrow) {
+                return null;
+            }
             throw new Error(`Cannot find model ${name}`);
         }
         return model;
@@ -213,7 +217,7 @@ export class Schema {
         }
         let info = await this.table.describeTable();
         for (let def of info.Table.AttributeDefinitions) {
-            this.keyTypes[def.AttributeName] = (def.AttributeType == 'N') ? 'number' : 'string';
+            this.keyTypes[def.AttributeName] = def.AttributeType == 'N' ? 'number' : 'string';
         }
         let indexes = { primary: {} };
         for (let key of info.Table.KeySchema) {
@@ -222,7 +226,7 @@ export class Schema {
         }
         if (info.Table.GlobalSecondaryIndexes) {
             for (let index of info.Table.GlobalSecondaryIndexes) {
-                let keys = indexes[index.IndexName] = {};
+                let keys = (indexes[index.IndexName] = {});
                 for (let key of index.KeySchema) {
                     let type = key.KeyType.toLowerCase() == 'hash' ? 'hash' : 'sort';
                     keys[type] = key.AttributeName;
@@ -244,11 +248,14 @@ export class Schema {
         if (params.nulls == null) {
             params.nulls = false;
         }
+        if (params.separator == null) {
+            params.separator = '#';
+        }
         if (params.timestamps == null) {
             params.timestamps = false;
         }
-        if (params.hidden == null) {
-            params.hidden = false;
+        if (params.warn == null) {
+            params.warn = false;
         }
         return params;
     }
@@ -268,7 +275,10 @@ export class Schema {
         if (field.validate && field.validate instanceof RegExp) {
             field.validate = `/${field.validate.source}/${field.validate.flags}`;
         }
-        let type = (typeof field.type == 'function') ? field.type.name : field.type;
+        if (field.encode) {
+            field.encode = field.encode.map((e) => (e instanceof RegExp ? `/${e.source}/${e.flags}` : e));
+        }
+        let type = typeof field.type == 'function' ? field.type.name : field.type;
         field.type = type.toLowerCase();
         //  DEPRECATE
         if (field.uuid) {
@@ -321,10 +331,10 @@ export class Schema {
         Read the current schema saved in the table
     */
     async readSchema() {
-        let indexes = this.indexes || await this.getKeys();
+        let indexes = this.indexes || (await this.getKeys());
         let primary = indexes.primary;
         let params = {
-            [primary.hash]: SchemaKey
+            [primary.hash]: SchemaKey,
         };
         if (primary.sort) {
             params[primary.sort] = `${SchemaKey}:Current`;
@@ -333,10 +343,10 @@ export class Schema {
         return this.transformSchemaAfterRead(schema);
     }
     async readSchemas() {
-        let indexes = this.indexes || await this.getKeys();
+        let indexes = this.indexes || (await this.getKeys());
         let primary = indexes.primary;
         let params = {
-            [primary.hash]: `${SchemaKey}`
+            [primary.hash]: `${SchemaKey}`,
         };
         let schemas = await this.table.queryItems(params, { hidden: true, parse: true });
         for (let [index, schema] of Object.entries(schemas)) {
@@ -368,7 +378,7 @@ export class Schema {
                 schema.models = {};
             }
             if (!schema.indexes) {
-                schema.indexes = this.indexes || await this.getKeys();
+                schema.indexes = this.indexes || (await this.getKeys());
             }
             if (!schema.queries) {
                 schema.queries = {};
@@ -387,6 +397,6 @@ export class Schema {
         schema.version = schema.version || '0.0.1';
         schema.format = SchemaFormat;
         let model = this.getModel(SchemaModel);
-        return await model.update(schema, { exists: null });
+        return await model.create(schema, { exists: null });
     }
 }
diff --git a/node_modules/dynamodb-onetable/dist/mjs/Table.d.ts b/node_modules/dynamodb-onetable/dist/mjs/Table.d.ts
index 42a95e3..19f113e 100644
--- a/node_modules/dynamodb-onetable/dist/mjs/Table.d.ts
+++ b/node_modules/dynamodb-onetable/dist/mjs/Table.d.ts
@@ -3,116 +3,156 @@
 */
 
 import {
-    AnyEntity, AnyModel, Model, OneIndex, OneParams, OneProperties, OneModel, OneSchema, Paged, Entity
-} from "./Model";
+    AnyEntity,
+    AnyModel,
+    Model,
+    OneIndex,
+    OneParams,
+    OneProperties,
+    OneModel,
+    OneSchema,
+    Paged,
+    Entity,
+} from './Model.js'
+import {Metrics} from './Metrics.js'
+import {DynamoDBRecord} from 'aws-lambda'
 
 export type EntityGroup = {
     [key: string]: AnyEntity[]
-};
+}
+
+export type StreamEntityGroup = {
+    [key: string]: {
+        type: 'INSERT' | 'MODIFY' | 'REMOVE'
+        new?: AnyEntity
+        old?: AnyEntity
+    }[]
+}
 
 type TableConstructorParams<Schema extends OneSchema> = {
-    client?: {},                    //  Instance of DocumentClient or Dynamo.
-    crypto?: {},                    //  Crypto configuration.
-    generate?: (() => string),      //  Function to generate IDs for field schema that requires.
-    generic?: boolean,              //  Create a generic (low-level) raw model. Default false.
-    logger?: boolean | ((tag: string, message: string, context: {}) => void),      // Logging callback
+    client?: {} //  Instance of DocumentClient or Dynamo.
+    crypto?: {} //  Crypto configuration.
+    generate?: () => string //  Function to generate IDs for field schema that requires.
+    generic?: boolean //  Create a generic (low-level) raw model. Default false.
+    logger?: boolean | ((tag: string, message: string, context: {}) => void) // Logging callback
     //  Intercept table reads and writes
-    intercept?: (model: AnyModel, op: string, rec: {}, params: OneParams, raw?: {}) => void,
-    metrics?: boolean | object,     //  Enable CloudWatch metrics.
-    name?: string,                  //  Table name.
-    schema?: Schema,                //  Table models schema.
-    senselogs?: {},                 //  SenseLogs instance for logging
+    intercept?: (model: AnyModel, op: string, rec: {}, params: OneParams, raw?: {}) => void
+    metrics?: boolean | object //  Enable metrics.
+    name?: string //  Table name.
+    schema?: Schema //  Table models schema.
+    senselogs?: {} //  SenseLogs instance for logging
     //  Transform record for read / write.
-    transform?: (model: AnyModel, op: string, item: AnyEntity, properties: OneProperties, params?: OneParams, raw?: {}) => AnyEntity,
+    transform?: (
+        model: AnyModel,
+        op: string,
+        item: AnyEntity,
+        properties: OneProperties,
+        params?: OneParams,
+        raw?: {}
+    ) => AnyEntity
     //  Validate properties before writing
-    validate?: (model: AnyModel, properties: OneProperties, params?: OneParams) => {},
+    validate?: (model: AnyModel, properties: OneProperties, params?: OneParams) => {}
     //  Compute a value for a value template
-    value?: (model: AnyModel, fieldName: string, properties: OneProperties, params?: OneParams) => string,
+    value?: (model: AnyModel, fieldName: string, properties: OneProperties, params?: OneParams) => string
 
     // https://www.npmjs.com/package/dataloader DataLoader constructor
     dataloader?: new (batchLoadFn: any, options?: any) => any
 
-    partial?: boolean,              //  Allow partial updates of nested schemas. Default false.
-    warn?: boolean,                 //  Issue warnings
-    hidden?: boolean,               //  Hide key attributes in Javascript properties. Default false.
+    partial?: boolean //  Allow partial updates of nested schemas. Default true.
+    warn?: boolean //  Issue warnings
+    hidden?: boolean //  Hide key and value template attributes in Javascript properties. Default true.
 
     //  DEPRECATED 2.3 - Should now be specified via the schema.params
-    createdField?: string,          //  Name of "created" timestamp attribute.
-    isoDates?: boolean,             //  Set to true to store dates as Javascript ISO Date strings.
-    nulls?: boolean,                //  Store nulls in database attributes. Default false.
-    timestamps?: boolean,           //  Make "created" and "updated" timestamps. Default true.
-    typeField?: string,             //  Name of model type attribute. Default "_type".
-    updatedField?: string,          //  Name of "updated" timestamp attribute.
+    createdField?: string //  Name of "created" timestamp attribute.
+    isoDates?: boolean //  Set to true to store dates as Javascript ISO Date strings.
+    nulls?: boolean //  Store nulls in database attributes. Default false.
+    timestamps?: boolean //  Make "created" and "updated" timestamps. Default true.
+    typeField?: string //  Name of model type attribute. Default "_type".
+    updatedField?: string //  Name of "updated" timestamp attribute.
 
     //  DEPRECATED 2.3 - Defer to generate
-    uuid?: (() => string) | string, //  Function to create a UUID if field schema requires it.
-};
+    uuid?: (() => string) | string //  Function to create a UUID if field schema requires it.
+}
 
-type ModelNames<Schema extends OneSchema> = keyof Schema["models"];
+type ModelNames<Schema extends OneSchema> = keyof Schema['models']
 type ExtractModel<M> = M extends Entity<infer X> ? X : never
 
 export class Table<Schema extends OneSchema = any> {
-    name: string;
-    constructor(params: TableConstructorParams<Schema>);
-
-    addContext(context?: {}): Table<Schema>;
-    addModel(name: string, fields: OneModel): void;
-
-    batchGet(batch: any, params?: OneParams): Promise<{}[]>;
-    batchWrite(batch: any, params?: OneParams): Promise<{}>;
-    clearContext(): Table<Schema>;
-    getTableDefinition(params?: {}): {};
-    createTable(params?: {}): Promise<{}>;
-    deleteTable(confirmation: string): Promise<{}>;
-    describeTable(): Promise<{}>;
-    exists(): Promise<Boolean>;
-    getContext(): {};
-    generate(): string;
-    getLog(): any;
-    getKeys(): Promise<OneIndex>;
-    getModel<T>(name: T extends ModelNames<Schema> ? T : ModelNames<Schema>): T extends string ? Model<Entity<Schema["models"][T]>> : Model<Entity<ExtractModel<T>>>;
-    getCurrentSchema(): {};
-    groupByType(items: AnyEntity[], params?: OneParams): EntityGroup;
-    listModels(): AnyModel[];
-    listTables(): string[];
-    readSchema(): Promise<OneSchema>;
-    readSchemas(): Promise<OneSchema[]>;
-    removeModel(name: string): void;
-    removeSchema(schema: OneSchema): Promise<void>;
-    saveSchema(schema?: OneSchema): Promise<OneSchema>;
-    setClient(client: {}): void;
-    setContext(context?: {}, merge?: boolean): Table<Schema>;
-    setGenerate(fn: () => string): void;
-    setLog(log: any): void;
-    setParams(params: OneParams): void;
-    setSchema(schema?: OneSchema): Promise<void>;
-    transact(op: string, transaction: any, params?: OneParams): Promise<void>;
-    uid(size: number): string;
-    ulid(): string;
-    updateTable(params?: {}): Promise<{}>;
-    uuid(): string;
-
-    deleteItem(properties: OneProperties, params?: OneParams): Promise<void>;
-    getItem(properties: OneProperties, params?: OneParams): Promise<AnyEntity | undefined>;
-    putItem(properties: OneProperties, params?: OneParams): Promise<AnyEntity>;
-    queryItems(properties: OneProperties, params?: OneParams): Promise<Paged<AnyEntity>>;
-    scanItems(properties?: OneProperties, params?: OneParams): Promise<Paged<AnyEntity>>;
-    updateItem(properties: OneProperties, params?: OneParams): Promise<AnyEntity>;
-
-    child(context: {}): Table<Schema>;
-
-    create(modelName: string, properties: OneProperties, params?: OneParams): Promise<AnyEntity>;
-    find(modelName: string, properties?: OneProperties, params?: OneParams): Promise<Paged<AnyEntity>>;
-    get(modelName: string, properties: OneProperties, params?: OneParams): Promise<AnyEntity | undefined>;
-    load(modelName: string, properties: OneProperties, params?: OneParams): Promise<AnyEntity | undefined>;
-    init(modelName: string, properties?: OneProperties, params?: OneParams): AnyEntity;
-    remove(modelName: string, properties: OneProperties, params?: OneParams): Promise<void>;
-    scan(modelName: string, properties?: OneProperties, params?: OneParams): Promise<Paged<AnyEntity>>;
-    update(modelName: string, properties: OneProperties, params?: OneParams): Promise<AnyEntity>;
-    upsert(modelName: string, properties: OneProperties, params?: OneParams): Promise<AnyEntity>;
-
-    fetch(models: string[], properties?: OneProperties, params?: OneParams): Promise<EntityGroup>;
-
-    marshall(item: AnyEntity | AnyEntity[], params?: OneParams) : AnyEntity;
-    unmarshall(item: AnyEntity | AnyEntity[], params?: OneParams) : AnyEntity;
+    name: string
+    metrics: Metrics
+    constructor(params: TableConstructorParams<Schema>)
+
+    addContext(context?: {}): Table<Schema>
+    addModel(name: string, fields: OneModel): void
+
+    batchGet<T = {}>(batch: any, params?: OneParams): Promise<T[]>
+    // batchGet(batch: any, params?: OneParams): Promise<{}[]>
+    batchWrite(batch: any, params?: OneParams): Promise<{}>
+    clearContext(): Table<Schema>
+    getTableDefinition(params?: {}): {}
+    createTable(params?: {}): Promise<{}>
+    deleteTable(confirmation: string): Promise<{}>
+    describeTable(): Promise<{}>
+    exists(): Promise<Boolean>
+    flushMetrics(): Promise<void>
+    getContext(): {}
+    generate(): string
+    getLog(): any
+    getKeys(): Promise<OneIndex>
+    getModel<T>(
+        name: T extends ModelNames<Schema> ? T : ModelNames<Schema>,
+        options?: {nothrow?: boolean}
+    ): T extends string ? Model<Entity<Schema['models'][T]>> : Model<Entity<ExtractModel<T>>>
+
+    /* Proposed
+        getModel<T extends ModelNames<Schema>>(name: T, options?: {nothrow?: boolean}): Model<Entity<Schema['models'][T]>>
+    */
+
+    getCurrentSchema(): OneSchema | null
+    groupByType(items: AnyEntity[], params?: OneParams): EntityGroup
+    listModels(): AnyModel[]
+    listTables(): string[]
+    readSchema(): Promise<OneSchema>
+    readSchemas(): Promise<OneSchema[]>
+    removeModel(name: string): void
+    removeSchema(schema: OneSchema): Promise<void>
+    saveSchema(schema?: OneSchema): Promise<OneSchema>
+    setClient(client: {}): void
+    setContext(context?: {}, merge?: boolean): Table<Schema>
+    setGenerate(fn: () => string): void
+    setLog(log: any): void
+    setParams(params: OneParams): void
+    setSchema(schema?: OneSchema): Promise<void>
+    transact(op: string, transaction: any, params?: OneParams): Promise<void>
+    uid(size: number): string
+    ulid(): string
+    updateTable(params?: {}): Promise<{}>
+    uuid(): string
+
+    deleteItem(properties: OneProperties, params?: OneParams): Promise<void>
+    getItem(properties: OneProperties, params?: OneParams): Promise<AnyEntity | undefined>
+    putItem(properties: OneProperties, params?: OneParams): Promise<AnyEntity>
+    queryItems(properties: OneProperties, params?: OneParams): Promise<Paged<AnyEntity>>
+    scanItems(properties?: OneProperties, params?: OneParams): Promise<Paged<AnyEntity>>
+    updateItem(properties: OneProperties, params?: OneParams): Promise<AnyEntity>
+
+    child(context: {}): Table<Schema>
+
+    create(modelName: string, properties: OneProperties, params?: OneParams): Promise<AnyEntity>
+    find(modelName: string, properties?: OneProperties, params?: OneParams): Promise<Paged<AnyEntity>>
+    get(modelName: string, properties: OneProperties, params?: OneParams): Promise<AnyEntity | undefined>
+    load(modelName: string, properties: OneProperties, params?: OneParams): Promise<AnyEntity | undefined>
+    init(modelName: string, properties?: OneProperties, params?: OneParams): AnyEntity
+    remove(modelName: string, properties: OneProperties, params?: OneParams): Promise<void>
+    scan(modelName: string, properties?: OneProperties, params?: OneParams): Promise<Paged<AnyEntity>>
+    update(modelName: string, properties: OneProperties, params?: OneParams): Promise<AnyEntity>
+    upsert(modelName: string, properties: OneProperties, params?: OneParams): Promise<AnyEntity>
+
+    fetch(models: string[], properties?: OneProperties, params?: OneParams): Promise<EntityGroup>
+
+    marshall(item: AnyEntity | AnyEntity[], params?: OneParams): AnyEntity
+    unmarshall(item: AnyEntity | AnyEntity[], params?: OneParams): AnyEntity
+    stream(records: DynamoDBRecord[], params?: OneParams): StreamEntityGroup
+
+    static terminate(): Promise<void>
 }
diff --git a/node_modules/dynamodb-onetable/dist/mjs/Table.js b/node_modules/dynamodb-onetable/dist/mjs/Table.js
index 8c80e57..cc9f6b5 100644
--- a/node_modules/dynamodb-onetable/dist/mjs/Table.js
+++ b/node_modules/dynamodb-onetable/dist/mjs/Table.js
@@ -3,10 +3,11 @@
 
     A OneTable Table represents a single (connected) DynamoDB table
  */
+import process from 'process';
+import { Buffer } from 'buffer';
 import Crypto from 'crypto';
-import UUID from './UUID.js';
-import ULID from './ULID.js';
-import UID from './UID.js';
+import { UID, ULID, UUID } from './UID.js';
+import Dynamo from './Dynamo.js';
 import { Expression } from './Expression.js';
 import { Schema } from './Schema.js';
 import { Metrics } from './Metrics.js';
@@ -46,8 +47,21 @@ const DynamoOps = {
     transactGet: 'transactGet',
     transactWrite: 'transactWrite',
 };
+/*
+    The generic model is used for the low-level API and batch operations
+ */
 const GenericModel = '_Generic';
 const maxBatchSize = 25;
+/*
+    On exit, flush buffered metrics. This requires any Lambda layer to receive this signal.
+    Without lambda layers, users can call flushMetrics() from time to time.
+ */
+process.on('SIGTERM', 
+/* istanbul ignore next */
+async () => {
+    /* istanbul ignore next */
+    await Table.terminate();
+});
 /*
     Represent a single DynamoDB table
  */
@@ -64,100 +78,89 @@ export class Table {
         }
         if (params.crypto) {
             this.initCrypto(params.crypto);
-            this.crypto = Object.assign(params.crypto);
-            for (let [name, crypto] of Object.entries(this.crypto)) {
-                crypto.secret = Crypto.createHash('sha256').update(crypto.password, 'utf8').digest();
-                this.crypto[name] = crypto;
-                this.crypto[name].name = name;
-            }
         }
         this.setParams(params);
+        //  Set schema param defaults
+        this.typeField = '_type';
+        this.createdField = 'created';
+        this.isoDates = false;
+        this.nulls = false;
+        this.separator = '#';
+        this.timestamps = false;
+        this.updatedField = 'updated';
+        this.warn = false;
         this.schema = new Schema(this, params.schema);
+        if (params.metrics) {
+            this.metrics = new Metrics(this, params.metrics);
+        }
         if (params.dataloader) {
-            this.dataloader = new params.dataloader(cmds => this.batchLoaderFunction(cmds), { maxBatchSize });
+            this.dataloader = new params.dataloader((cmds) => this.batchLoaderFunction(cmds), { maxBatchSize });
         }
     }
     setClient(client) {
+        if (client.send && !client.V3) {
+            //  V3 SDK and not yet wrapped by Dynamo
+            client = new Dynamo({ client });
+        }
         this.client = client;
         this.V3 = client.V3;
         this.service = this.V3 ? this.client : this.client.service;
     }
     setParams(params) {
-        //  DEPRECATED - these should be supplied by the schema.params
-        if (params.createdField != null || this.isoDates != null || this.nulls != null ||
-            this.timestamps != null || this.typeField != null || this.updatedField != null) {
-            console.warn('OneTable: Using deprecated Table constructor parameters. Define in the schema.params instead.');
-            //  FUTURE 2.3
-            //  throw new OneTableArgError('Using deprecated Table constructor parameters. Define in the schema.params instead.')
-        }
-        //  DEPRECATE - these should be specified via the Schema params
-        this.createdField = params.createdField || 'created';
-        this.isoDates = params.isoDates || false;
-        this.nulls = params.nulls || false;
-        this.timestamps = params.timestamps != null ? params.timestamps : false;
-        this.typeField = params.typeField || '_type';
-        this.updatedField = params.updatedField || 'updated';
+        if (params.createdField != null ||
+            this.isoDates != null ||
+            this.nulls != null ||
+            this.separator != null ||
+            this.timestamps != null ||
+            this.typeField != null ||
+            this.updatedField != null) {
+            throw new OneTableArgError('Using deprecated Table constructor parameters. Define in the Schema.params instead.');
+        }
         if (params.uuid) {
             console.warn('OneTable: Using deprecated Table constructor "uuid" parameter. Use a "generate" function instead or ' +
                 'Set schema models to use "generate: uuid|ulid" explicitly.');
             params.generate = params.generate | params.uuid;
         }
-        //  MOB - warn if unset. Revert default to true in future
         if (params.partial == null) {
             console.warn('OneTable: Must set Table constructor "partial" param to true or false. ' +
-                'This param permits updating partial nested schemas. Currently defaults to false, ' +
-                'but in a future version will default to true. ' +
-                'Set to false to future proof or set to true for the new behavior.');
-            //  FUTURE 2.5 - change default to true
-            params.partial = false;
+                'This param permits updating partial nested schemas. Defaults to true.');
+            params.partial = true;
         }
-        this.hidden = params.hidden != null ? params.hidden : true;
+        //  Return hidden fields by default. Default is false.
+        this.hidden = params.hidden != null ? params.hidden : false;
         this.partial = params.partial;
-        this.warn = params.warn || true;
+        this.warn = params.warn || false;
         if (typeof params.generate == 'function') {
             this.generate = params.generate || this.uuid;
         }
         else if (params.generate) {
-            //  FUTURE throw exception
-            console.warn('OneTable: Generate can only be a function');
-            if (params.generate == 'uuid') {
-                this.generate = this.uuid;
-            }
-            else if (params.generate == 'ulid') {
-                this.generate = this.ulid;
-            }
-            else {
-                this.generate = this.uuid;
-            }
+            throw new OneTableArgError('OneTable: Generate can only be a function');
         }
         this.name = params.name;
-        if (params.metrics) {
-            this.metrics = new Metrics(this, params.metrics, this.metrics);
-        }
         if (params.monitor) {
             this.monitor = params.monitor;
         }
         this.params = params;
     }
-    setSchemaParams(params) {
+    setSchemaParams(params = {}) {
         this.createdField = params.createdField || 'created';
         this.isoDates = params.isoDates || false;
         this.nulls = params.nulls || false;
+        this.separator = params.separator != null ? params.separator : '#';
         this.timestamps = params.timestamps != null ? params.timestamps : false;
         this.typeField = params.typeField || '_type';
         this.updatedField = params.updatedField || 'updated';
+        this.warn = params.warn || false;
         if (params.hidden != null) {
-            console.warn(`Schema hidden params should be specified via the Table constructor params`);
+            this.log.warn(`Schema hidden params should be specified via the Table constructor params`, { '@stack': true });
         }
-        //  DEPRECATE
-        this.hidden = params.hidden != null ? params.hidden : true;
     }
     getSchemaParams() {
         return {
             createdField: this.createdField,
-            hidden: this.hidden,
             isoDates: this.isoDates,
             nulls: this.nulls,
+            separator: this.separator,
             timestamps: this.timestamps,
             typeField: this.typeField,
             updatedField: this.updatedField,
@@ -233,7 +236,7 @@ export class Table {
                 let project, projection;
                 if (Array.isArray(index.project)) {
                     projection = 'INCLUDE';
-                    project = index.project.filter(a => a != indexes.primary.hash && a != indexes.primary.sort);
+                    project = index.project.filter((a) => a != indexes.primary.hash && a != indexes.primary.sort);
                 }
                 else if (index.project == 'keys') {
                     projection = 'KEYS_ONLY';
@@ -246,7 +249,7 @@ export class Table {
                     KeySchema: keys,
                     Projection: {
                         ProjectionType: projection,
-                    }
+                    },
                 };
                 if (project) {
                     projDef.Projection.NonKeyAttributes = project;
@@ -388,7 +391,7 @@ export class Table {
             let projection, project;
             if (Array.isArray(create.project)) {
                 projection = 'INCLUDE';
-                project = create.project.filter(a => a != create.hash && a != create.sort);
+                project = create.project.filter((a) => a != create.hash && a != create.sort);
             }
             else if (create.project == 'keys') {
                 projection = 'KEYS_ONLY';
@@ -401,7 +404,7 @@ export class Table {
                 KeySchema: keys,
                 Projection: {
                     ProjectionType: projection,
-                }
+                },
             };
             if (project) {
                 projDef.Projection.NonKeyAttributes = project;
@@ -466,7 +469,7 @@ export class Table {
     */
     async exists() {
         let results = await this.listTables();
-        return results && results.find(t => t == this.name) != null ? true : false;
+        return results && results.find((t) => t == this.name) != null ? true : false;
     }
     /*
         Return a list of tables in the AWS region described by the Table instance
@@ -492,12 +495,15 @@ export class Table {
     }
     setLog(log) {
         this.log = log;
+        if (this.metrics) {
+            this.metrics.setLog(log);
+        }
     }
     /*
         Thows exception if model cannot be found
      */
-    getModel(name) {
-        return this.schema.getModel(name);
+    getModel(name, options = { nothrow: false }) {
+        return this.schema.getModel(name, options);
     }
     removeModel(name) {
         return this.schema.removeModel(name);
@@ -562,7 +568,7 @@ export class Table {
         let model = this.getModel(modelName);
         return await model.update(properties, params);
     }
-    async upsert(modelName, properties, params) {
+    async upsert(modelName, properties, params = {}) {
         params.exists = null;
         return this.update(modelName, properties, params);
     }
@@ -593,34 +599,42 @@ export class Table {
             else if (code == 'ConditionalCheckFailedException' && op == 'put') {
                 this.log.info(`Conditional check failed "${op}" on "${model}"`, { err, trace });
                 throw new OneTableError(`Conditional create failed for "${model}"`, {
-                    code, err, trace,
+                    code,
+                    err,
+                    trace,
                 });
             }
             else if (code == 'ProvisionedThroughputExceededException') {
                 throw new OneTableError('Provisioning Throughput Exception', {
-                    code, err, trace,
+                    code,
+                    err,
+                    trace,
                 });
             }
             else if (code == 'TransactionCanceledException') {
                 throw new OneTableError('Transaction Cancelled', {
-                    code, err, trace,
+                    code,
+                    err,
+                    trace,
                 });
             }
             else {
                 result = result || {};
                 result.Error = 1;
                 if (params.log != false) {
-                    this.log.error(`OneTable exception in "${op}" on "${model}"`, { err, trace });
+                    this.log.error(`OneTable exception in "${op}" on "${model} ${err.message}"`, { err, trace });
                 }
-                throw new OneTableError(`OneTable execute failed "${op}" for "${model}. ${err.message}`, {
-                    code, err, trace,
+                throw new OneTableError(`OneTable execute failed "${op}" for "${model}", ${err.message}`, {
+                    code,
+                    err,
+                    trace,
                 });
             }
         }
         finally {
             if (result) {
                 if (this.metrics) {
-                    this.metrics.add(model, op, result, params, mark);
+                    await this.metrics.add(model, op, result, params, mark);
                 }
                 if (this.monitor) {
                     await this.monitor(model, op, result, params, mark);
@@ -652,7 +666,6 @@ export class Table {
             def.ExpressionAttributeNames = cmd.ExpressionAttributeNames;
         }
         def.ConsistentRead = params.consistent ? true : false;
-        // let result = await this.execute(GenericModel, 'batchGet', batch, {}, params)
         let result, retries = 0, more;
         result = params.parse ? [] : { Responses: {} };
         do {
@@ -672,7 +685,7 @@ export class Table {
                                 }
                             }
                             else {
-                                let set = result.Responses[key] = result.Responses[key] || [];
+                                let set = (result.Responses[key] = result.Responses[key] || []);
                                 set.push(item);
                             }
                         }
@@ -687,7 +700,7 @@ export class Table {
                     if (retries > 11) {
                         throw new Error(unprocessed);
                     }
-                    await this.delay(10 * (2 ** retries++));
+                    await this.delay(10 * 2 ** retries++);
                     more = true;
                 }
             }
@@ -700,23 +713,22 @@ export class Table {
         Those will be handled here if possible.
     */
     async batchWrite(batch, params = {}) {
-        if (Object.getOwnPropertyNames(batch).length == 0) {
+        if (Object.getOwnPropertyNames(batch).length === 0) {
             return {};
         }
         let retries = 0, more;
         do {
             more = false;
             let response = await this.execute(GenericModel, 'batchWrite', batch, {}, params);
-            let data = response.data;
-            if (data && data.UnprocessedItems && Object.keys(data.UnprocessedItems).length) {
-                batch.RequestItems = data.UnprocessedItems;
+            if (response && response.UnprocessedItems && Object.keys(response.UnprocessedItems).length) {
+                batch.RequestItems = response.UnprocessedItems;
                 if (params.reprocess === false) {
                     return false;
                 }
                 if (retries > 11) {
                     throw new Error(response.UnprocessedItems);
                 }
-                await this.delay(10 * (2 ** retries++));
+                await this.delay(10 * 2 ** retries++);
                 more = true;
             }
         } while (more);
@@ -756,7 +768,9 @@ export class Table {
         if (params.execute === false) {
             if (params.log !== false) {
                 this.log[params.log ? 'info' : 'data'](`OneTable transaction for "${op}" (not executed)`, {
-                    transaction, op, params,
+                    transaction,
+                    op,
+                    params,
                 });
             }
             return transaction;
@@ -787,7 +801,7 @@ export class Table {
         let result = {};
         for (let item of items) {
             let type = item[this.typeField] || '_unknown';
-            let list = result[type] = result[type] || [];
+            let list = (result[type] = result[type] || []);
             let model = this.schema.models[type];
             let preparedItem;
             if (typeof params.hidden === 'boolean' && !params.hidden) {
@@ -815,7 +829,7 @@ export class Table {
         @returns {Promise<*>}
      */
     async batchLoaderFunction(expressions) {
-        const commands = expressions.map(each => each.command());
+        const commands = expressions.map((each) => each.command());
         const groupedByTableName = commands.reduce((groupedBy, item) => {
             const tableName = item.TableName;
             if (!groupedBy[tableName])
@@ -827,10 +841,10 @@ export class Table {
         const requestItems = Object.keys(groupedByTableName).reduce((requestItems, tableName) => {
             // batch get does not support duplicate Keys, so we need to make them unique
             // it's complex because we have the unmarshalled values on the Keys when it's V3
-            const allKeys = groupedByTableName[tableName].map(each => each.Key);
+            const allKeys = groupedByTableName[tableName].map((each) => each.Key);
             const uniqueKeys = allKeys.filter((key1, index1, self) => {
-                const index2 = self.findIndex(key2 => {
-                    return Object.keys(key2).every(prop => {
+                const index2 = self.findIndex((key2) => {
+                    return Object.keys(key2).every((prop) => {
                         if (this.V3) {
                             const type = Object.keys(key1[prop])[0]; // { S: "XX" } => type is S
                             return key2[prop][type] === key1[prop][type];
@@ -858,7 +872,7 @@ export class Table {
                 return [[key], unmarshalled];
             });
             // finds the matching object in the unmarshalled Responses array with criteria Key above
-            const findByKeyUnmarshalled = (items = []) => items.find(item => {
+            const findByKeyUnmarshalled = (items = []) => items.find((item) => {
                 return criteria.every(([[prop, type], value]) => {
                     if (type)
                         return item[prop][type] === value; // if it has a type it means it is V3
@@ -887,7 +901,7 @@ export class Table {
     /*
         Crypto-grade ID of given length. If >= 10 in length, suitably unique for most use-cases.
      */
-    uid(size) {
+    uid(size = 10) {
         return UID(size);
     }
     setGenerate(fn) {
@@ -928,7 +942,7 @@ export class Table {
             let iv = Crypto.randomBytes(IV_LENGTH);
             let crypt = Crypto.createCipheriv(crypto.cipher, crypto.secret, iv);
             let crypted = crypt.update(text, inCode, outCode) + crypt.final(outCode);
-            let tag = (crypto.cipher.indexOf('-gcm') > 0) ? crypt.getAuthTag().toString(outCode) : '';
+            let tag = crypto.cipher.indexOf('-gcm') > 0 ? crypt.getAuthTag().toString(outCode) : '';
             text = `${crypto.name}:${tag}:${iv.toString('hex')}:${crypted}`;
         }
         return text;
@@ -1020,17 +1034,66 @@ export class Table {
     }
     unmarshallv2(item) {
         for (let [key, value] of Object.entries(item)) {
-            if (value != null && typeof value == 'object' && value.wrapperName == 'Set' && Array.isArray(value.values)) {
+            if (value != null &&
+                typeof value == 'object' &&
+                value.wrapperName == 'Set' &&
+                Array.isArray(value.values)) {
                 let list = value.values;
                 if (value.type == 'Binary') {
                     //  Match AWS SDK V3 behavior
-                    list = list.map(v => new Uint8Array(v));
+                    list = list.map((v) => new Uint8Array(v));
                 }
                 item[key] = new Set(list);
             }
         }
         return item;
     }
+    unmarshallStreamImage(image, params) {
+        let client = params.client ? params.client : this.client;
+        let options = client.params.unmarshall;
+        return client.unmarshall(image, options);
+    }
+    /*
+        Handle DynamoDb Stream Records
+     */
+    stream(records, params = {}) {
+        const tableModels = this.listModels();
+        const result = {};
+        for (const record of records) {
+            if (!record.dynamodb.NewImage && !record.dynamodb.OldImage) {
+                continue;
+            }
+            const model = { type: record.eventName };
+            let typeNew;
+            let typeOld;
+            // Unmarshall and transform the New Image if it exists
+            if (record.dynamodb.NewImage) {
+                const jsonNew = this.unmarshallStreamImage(record.dynamodb.NewImage, params);
+                typeNew = jsonNew[this.typeField];
+                // If type not found then don't do anything
+                if (typeNew && tableModels.includes(typeNew)) {
+                    model.new = this.schema.models[typeNew].transformReadItem('get', jsonNew, {}, params);
+                }
+            }
+            // Unmarshall and transform the Old Image if it exists
+            if (record.dynamodb.OldImage) {
+                const jsonOld = this.unmarshallStreamImage(record.dynamodb.OldImage, params);
+                typeOld = jsonOld[this.typeField];
+                // If type not found then don't do anything
+                if (typeOld && tableModels.includes(typeOld)) {
+                    // If there was a new image of a different type then skip
+                    if (typeNew && typeNew !== typeOld) {
+                        continue;
+                    }
+                    model.old = this.schema.models[typeOld].transformReadItem('get', jsonOld, {}, params);
+                }
+            }
+            const type = typeNew || typeOld;
+            let list = (result[type] = result[type] || []);
+            list.push(model);
+        }
+        return result;
+    }
     /*
         Recursive Object.assign. Will clone dates, regexp, simple objects and arrays.
         Other class instances and primitives are copied not cloned.
@@ -1086,6 +1149,12 @@ export class Table {
             setTimeout(() => resolve(true), time);
         });
     }
+    async flushMetrics() {
+        await this.metrics.flush();
+    }
+    static async terminate() {
+        await Metrics.terminate();
+    }
 }
 /*
     Emulate SenseLogs API
@@ -1137,7 +1206,9 @@ class Log {
                     try {
                         buf.push(`    ${key}: ${JSON.stringify(value, null, 4)}`);
                     }
-                    catch (err) { /* continue */ }
+                    catch (err) {
+                        /* continue */
+                    }
                 }
                 buf.push('}');
                 console.log(level, message, buf.join('\n'));
diff --git a/node_modules/dynamodb-onetable/dist/mjs/UID.d.ts b/node_modules/dynamodb-onetable/dist/mjs/UID.d.ts
index bd8e6c9..3066603 100644
--- a/node_modules/dynamodb-onetable/dist/mjs/UID.d.ts
+++ b/node_modules/dynamodb-onetable/dist/mjs/UID.d.ts
@@ -1 +1,10 @@
-export default function UID(size: any): string;
+export function UID(size: number): string
+export class ULID {
+    constructor(when?: string | number | Date)
+    when: Date
+    toString(): string
+    decode(ulid: string | ULID): number
+    getRandom(): string
+    getTime(now: Date): string
+}
+export function UUID(): string
\ No newline at end of file
diff --git a/node_modules/dynamodb-onetable/dist/mjs/UID.js b/node_modules/dynamodb-onetable/dist/mjs/UID.js
index 5a6d1a7..cc06a06 100644
--- a/node_modules/dynamodb-onetable/dist/mjs/UID.js
+++ b/node_modules/dynamodb-onetable/dist/mjs/UID.js
@@ -1,20 +1,88 @@
 /*
-    UID - Unique Crypto-grade ID of a given length.
-
-    If >= 10 in length, suitably unique for most use-cases.
-    Converted to use safe letters -- base 32 excluding I, L, O and U.
-    Note: Not a ULID and not sortable.
+    UID - UUIDs and ULIDs of crypto and non-crypto varieties
 */
 import Crypto from 'crypto';
+//  Crockford's base 32 excluding I, L, O and U
 //  Repeat Z to make encoding faster for rand == 0xFF
 const Letters = '0123456789ABCDEFGHJKMNPQRSTVWXYZZ';
 const LettersLen = Letters.length - 1;
-export default function UID(size) {
+const RandomLength = 16;
+const TimeLen = 10;
+/*
+    If >= 10 in length, suitably unique for most use-cases.
+    Converted to use safe letters -- base 32 excluding I, L, O and U.
+    Note: Not a ULID and not sortable.
+ */
+export function UID(size) {
     let bytes = [];
     let buffer = Crypto.randomBytes(size);
     for (let i = 0; i < size; i++) {
         //  Letters is one longer than LettersLen
-        bytes[i] = Letters[Math.floor(buffer.readUInt8(i) / 0xFF * LettersLen)];
+        bytes[i] = Letters[Math.floor((buffer.readUInt8(i) / 0xff) * LettersLen)];
     }
     return bytes.join('');
 }
+/*
+    Simple non-crypto UUID
+*/
+export function UUID() {
+    return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function (c) {
+        let r = (Math.random() * 16) | 0, v = c == 'x' ? r : (r & 0x3) | 0x8;
+        return v.toString(16);
+    });
+}
+/*
+    ULID.js -- Universal Unique Lexicographically Sortable Identifier
+    https://github.com/ulid/spec
+ */
+export class ULID {
+    constructor(when) {
+        if (when instanceof Date) {
+            this.when = new Date(when);
+        }
+        else if (typeof when == 'string' || typeof when == 'number') {
+            this.when = new Date(when);
+        }
+        else {
+            this.when = new Date();
+        }
+    }
+    toString() {
+        return this.getTime(this.when) + this.getRandom(RandomLength);
+    }
+    //  Decode the time portion of the ULID and return a number
+    decode(ulid) {
+        ulid = ulid.toString();
+        if (ulid.length !== TimeLen + RandomLength) {
+            throw new Error('Invalid ULID');
+        }
+        let letters = ulid.substr(0, TimeLen).split('').reverse();
+        return letters.reduce((accum, c, index) => {
+            let i = Letters.indexOf(c);
+            if (i < 0) {
+                throw new Error(`Invalid ULID char ${c}`);
+            }
+            accum += index * Math.pow(LettersLen, i);
+            return accum;
+        }, 0);
+    }
+    getRandom(size) {
+        let bytes = [];
+        let buffer = Crypto.randomBytes(size);
+        for (let i = 0; i < size; i++) {
+            //  Letters is one longer than LettersLen
+            bytes[i] = Letters[Math.floor((buffer.readUInt8(i) / 0xff) * LettersLen)];
+        }
+        return bytes.join('');
+    }
+    getTime(now) {
+        now = now.getTime();
+        let bytes = [];
+        for (let i = 0; i < TimeLen; i++) {
+            let mod = now % LettersLen;
+            bytes[i] = Letters.charAt(mod);
+            now = (now - mod) / LettersLen;
+        }
+        return bytes.reverse().join('');
+    }
+}
diff --git a/node_modules/dynamodb-onetable/dist/mjs/ULID.d.ts b/node_modules/dynamodb-onetable/dist/mjs/ULID.d.ts
deleted file mode 100644
index 66ef0d0..0000000
--- a/node_modules/dynamodb-onetable/dist/mjs/ULID.d.ts
+++ /dev/null
@@ -1,8 +0,0 @@
-export default class ULID {
-    constructor(when?: string | number | Date);
-    when: Date;
-    toString(): string;
-    decode(ulid: string | ULID): number;
-    getRandom(): string;
-    getTime(now: Date): string;
-}
diff --git a/node_modules/dynamodb-onetable/dist/mjs/ULID.js b/node_modules/dynamodb-onetable/dist/mjs/ULID.js
deleted file mode 100644
index 2e4a21c..0000000
--- a/node_modules/dynamodb-onetable/dist/mjs/ULID.js
+++ /dev/null
@@ -1,62 +0,0 @@
-/*
-    ULID.js -- Universal Unique Lexicographically Sortable Identifier
-    https://github.com/ulid/spec
- */
-import Crypto from 'crypto';
-//  Crockford's base 32 excluding I, L, O and U
-//  Repeat Z to make encoding faster for rand == 0xFF
-const Letters = '0123456789ABCDEFGHJKMNPQRSTVWXYZZ';
-const LettersLen = Letters.length - 1;
-const RandomLength = 16;
-const TimeLen = 10;
-export default class ULID {
-    constructor(when) {
-        if (when instanceof Date) {
-            this.when = new Date(when);
-        }
-        else if (typeof when == 'string' || typeof when == 'number') {
-            this.when = new Date(when);
-        }
-        else {
-            this.when = new Date();
-        }
-    }
-    toString() {
-        return this.getTime(this.when) + this.getRandom(RandomLength);
-    }
-    //  Decode the time portion of the ULID and return a number
-    decode(ulid) {
-        ulid = ulid.toString();
-        if (ulid.length !== (TimeLen + RandomLength)) {
-            throw new Error('Invalid ULID');
-        }
-        let letters = ulid.substr(0, TimeLen).split('').reverse();
-        return letters.reduce((accum, c, index) => {
-            let i = Letters.indexOf(c);
-            if (i < 0) {
-                throw new Error(`Invalid ULID char ${c}`);
-            }
-            accum += index * Math.pow(LettersLen, i);
-            return accum;
-        }, 0);
-    }
-    getRandom(size) {
-        let bytes = [];
-        let buffer = Crypto.randomBytes(size);
-        for (let i = 0; i < size; i++) {
-            //  Letters is one longer than LettersLen
-            bytes[i] = Letters[Math.floor(buffer.readUInt8(i) / 0xFF * LettersLen)];
-        }
-        return bytes.join('');
-    }
-    getTime(now) {
-        now = now.getTime();
-        let bytes = [];
-        for (let i = 0; i < TimeLen; i++) {
-            let mod = now % LettersLen;
-            bytes[i] = Letters.charAt(mod);
-            now = (now - mod) / LettersLen;
-        }
-        return bytes.reverse().join('');
-    }
-}
diff --git a/node_modules/dynamodb-onetable/dist/mjs/UUID.d.ts b/node_modules/dynamodb-onetable/dist/mjs/UUID.d.ts
deleted file mode 100644
index 5f9bec4..0000000
--- a/node_modules/dynamodb-onetable/dist/mjs/UUID.d.ts
+++ /dev/null
@@ -1 +0,0 @@
-export default function UUID(): string;
diff --git a/node_modules/dynamodb-onetable/dist/mjs/UUID.js b/node_modules/dynamodb-onetable/dist/mjs/UUID.js
deleted file mode 100644
index 0823ca4..0000000
--- a/node_modules/dynamodb-onetable/dist/mjs/UUID.js
+++ /dev/null
@@ -1,10 +0,0 @@
-/*
-    Simple non-crypto UUID. See node-uuid if you require crypto UUIDs.
-    Consider ULIDs which are crypto sortable.
-*/
-export default function UUID() {
-    return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function (c) {
-        let r = Math.random() * 16 | 0, v = c == 'x' ? r : (r & 0x3 | 0x8);
-        return v.toString(16);
-    });
-}
diff --git a/node_modules/dynamodb-onetable/dist/mjs/index.d.ts b/node_modules/dynamodb-onetable/dist/mjs/index.d.ts
index ac08a83..60d44a7 100644
--- a/node_modules/dynamodb-onetable/dist/mjs/index.d.ts
+++ b/node_modules/dynamodb-onetable/dist/mjs/index.d.ts
@@ -14,15 +14,14 @@ import {
     OneProperties,
     OneSchema,
     OneType,
-    Paged
-} from './Model'
+    Paged,
+} from './Model.js'
 
-import { Table } from './Table'
-import { Expression } from './Expression'
-import { OneTableError, OneTableArgError } from './Error'
+import {Table} from './Table.js'
+import {Expression} from './Expression.js'
+import {OneTableError, OneTableArgError} from './Error.js'
 
-import ULID from './ULID.js'
-import UUID from './UUID.js'
+import {UID, ULID, UUID} from './UID.js'
 
 export {
     AnyEntity,
@@ -40,6 +39,7 @@ export {
     OneType,
     Paged,
     Table,
+    UID,
     ULID,
     UUID,
 }
diff --git a/node_modules/dynamodb-onetable/dist/mjs/index.js b/node_modules/dynamodb-onetable/dist/mjs/index.js
index 341cd3e..38e74ec 100644
--- a/node_modules/dynamodb-onetable/dist/mjs/index.js
+++ b/node_modules/dynamodb-onetable/dist/mjs/index.js
@@ -5,6 +5,5 @@ import { Expression } from './Expression.js';
 import { Model } from './Model.js';
 import { Table } from './Table.js';
 import { OneTableError, OneTableArgError } from './Error.js';
-import ULID from './ULID.js';
-import UUID from './UUID.js';
-export { Expression, Model, OneTableArgError, OneTableError, Table, ULID, UUID };
+import { UID, ULID, UUID } from './UID.js';
+export { Expression, Model, OneTableArgError, OneTableError, Table, UID, ULID, UUID };
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/coverage/lcov-report/block-navigation.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/coverage/lcov-report/block-navigation.d.ts
new file mode 100644
index 0000000..a45a494
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/coverage/lcov-report/block-navigation.d.ts
@@ -0,0 +1 @@
+declare function jumpToCode(event: any): void;
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/coverage/lcov-report/block-navigation.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/coverage/lcov-report/block-navigation.js
new file mode 100644
index 0000000..0a8690c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/coverage/lcov-report/block-navigation.js
@@ -0,0 +1,69 @@
+/* eslint-disable */
+var jumpToCode = (function init() {
+    // Classes of code we would like to highlight in the file view
+    var missingCoverageClasses = ['.cbranch-no', '.cstat-no', '.fstat-no'];
+    // Elements to highlight in the file listing view
+    var fileListingElements = ['td.pct.low'];
+    // We don't want to select elements that are direct descendants of another match
+    var notSelector = ':not(' + missingCoverageClasses.join('):not(') + ') > '; // becomes `:not(a):not(b) > `
+    // Selecter that finds elements on the page to which we can jump
+    var selector = fileListingElements.join(', ') +
+        ', ' +
+        notSelector +
+        missingCoverageClasses.join(', ' + notSelector); // becomes `:not(a):not(b) > a, :not(a):not(b) > b`
+    // The NodeList of matching elements
+    var missingCoverageElements = document.querySelectorAll(selector);
+    var currentIndex;
+    function toggleClass(index) {
+        missingCoverageElements
+            .item(currentIndex)
+            .classList.remove('highlighted');
+        missingCoverageElements.item(index).classList.add('highlighted');
+    }
+    function makeCurrent(index) {
+        toggleClass(index);
+        currentIndex = index;
+        missingCoverageElements.item(index).scrollIntoView({
+            behavior: 'smooth',
+            block: 'center',
+            inline: 'center'
+        });
+    }
+    function goToPrevious() {
+        var nextIndex = 0;
+        if (typeof currentIndex !== 'number' || currentIndex === 0) {
+            nextIndex = missingCoverageElements.length - 1;
+        }
+        else if (missingCoverageElements.length > 1) {
+            nextIndex = currentIndex - 1;
+        }
+        makeCurrent(nextIndex);
+    }
+    function goToNext() {
+        var nextIndex = 0;
+        if (typeof currentIndex === 'number' &&
+            currentIndex < missingCoverageElements.length - 1) {
+            nextIndex = currentIndex + 1;
+        }
+        makeCurrent(nextIndex);
+    }
+    return function jump(event) {
+        if (document.getElementById('fileSearch') === document.activeElement &&
+            document.activeElement != null) {
+            // if we're currently focused on the search input, we don't want to navigate
+            return;
+        }
+        switch (event.which) {
+            case 78: // n
+            case 74: // j
+                goToNext();
+                break;
+            case 66: // b
+            case 75: // k
+            case 80: // p
+                goToPrevious();
+                break;
+        }
+    };
+})();
+window.addEventListener('keydown', jumpToCode);
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/coverage/lcov-report/prettify.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/coverage/lcov-report/prettify.d.ts
new file mode 100644
index 0000000..e69de29
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/coverage/lcov-report/prettify.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/coverage/lcov-report/prettify.js
new file mode 100644
index 0000000..a3666c8
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/coverage/lcov-report/prettify.js
@@ -0,0 +1,476 @@
+/* eslint-disable */
+window.PR_SHOULD_USE_CONTINUATION = true;
+(function () { var h = ["break,continue,do,else,for,if,return,while"]; var u = [h, "auto,case,char,const,default,double,enum,extern,float,goto,int,long,register,short,signed,sizeof,static,struct,switch,typedef,union,unsigned,void,volatile"]; var p = [u, "catch,class,delete,false,import,new,operator,private,protected,public,this,throw,true,try,typeof"]; var l = [p, "alignof,align_union,asm,axiom,bool,concept,concept_map,const_cast,constexpr,decltype,dynamic_cast,explicit,export,friend,inline,late_check,mutable,namespace,nullptr,reinterpret_cast,static_assert,static_cast,template,typeid,typename,using,virtual,where"]; var x = [p, "abstract,boolean,byte,extends,final,finally,implements,import,instanceof,null,native,package,strictfp,super,synchronized,throws,transient"]; var R = [x, "as,base,by,checked,decimal,delegate,descending,dynamic,event,fixed,foreach,from,group,implicit,in,interface,internal,into,is,lock,object,out,override,orderby,params,partial,readonly,ref,sbyte,sealed,stackalloc,string,select,uint,ulong,unchecked,unsafe,ushort,var"]; var r = "all,and,by,catch,class,else,extends,false,finally,for,if,in,is,isnt,loop,new,no,not,null,of,off,on,or,return,super,then,true,try,unless,until,when,while,yes"; var w = [p, "debugger,eval,export,function,get,null,set,undefined,var,with,Infinity,NaN"]; var s = "caller,delete,die,do,dump,elsif,eval,exit,foreach,for,goto,if,import,last,local,my,next,no,our,print,package,redo,require,sub,undef,unless,until,use,wantarray,while,BEGIN,END"; var I = [h, "and,as,assert,class,def,del,elif,except,exec,finally,from,global,import,in,is,lambda,nonlocal,not,or,pass,print,raise,try,with,yield,False,True,None"]; var f = [h, "alias,and,begin,case,class,def,defined,elsif,end,ensure,false,in,module,next,nil,not,or,redo,rescue,retry,self,super,then,true,undef,unless,until,when,yield,BEGIN,END"]; var H = [h, "case,done,elif,esac,eval,fi,function,in,local,set,then,until"]; var A = [l, R, w, s + I, f, H]; var e = /^(DIR|FILE|vector|(de|priority_)?queue|list|stack|(const_)?iterator|(multi)?(set|map)|bitset|u?(int|float)\d*)/; var C = "str"; var z = "kwd"; var j = "com"; var O = "typ"; var G = "lit"; var L = "pun"; var F = "pln"; var m = "tag"; var E = "dec"; var J = "src"; var P = "atn"; var n = "atv"; var N = "nocode"; var M = "(?:^^\\.?|[+-]|\\!|\\!=|\\!==|\\#|\\%|\\%=|&|&&|&&=|&=|\\(|\\*|\\*=|\\+=|\\,|\\-=|\\->|\\/|\\/=|:|::|\\;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\@|\\[|\\^|\\^=|\\^\\^|\\^\\^=|\\{|\\||\\|=|\\|\\||\\|\\|=|\\~|break|case|continue|delete|do|else|finally|instanceof|return|throw|try|typeof)\\s*"; function k(Z) { var ad = 0; var S = false; var ac = false; for (var V = 0, U = Z.length; V < U; ++V) {
+    var ae = Z[V];
+    if (ae.ignoreCase) {
+        ac = true;
+    }
+    else {
+        if (/[a-z]/i.test(ae.source.replace(/\\u[0-9a-f]{4}|\\x[0-9a-f]{2}|\\[^ux]/gi, ""))) {
+            S = true;
+            ac = false;
+            break;
+        }
+    }
+} var Y = { b: 8, t: 9, n: 10, v: 11, f: 12, r: 13 }; function ab(ah) { var ag = ah.charCodeAt(0); if (ag !== 92) {
+    return ag;
+} var af = ah.charAt(1); ag = Y[af]; if (ag) {
+    return ag;
+}
+else {
+    if ("0" <= af && af <= "7") {
+        return parseInt(ah.substring(1), 8);
+    }
+    else {
+        if (af === "u" || af === "x") {
+            return parseInt(ah.substring(2), 16);
+        }
+        else {
+            return ah.charCodeAt(1);
+        }
+    }
+} } function T(af) { if (af < 32) {
+    return (af < 16 ? "\\x0" : "\\x") + af.toString(16);
+} var ag = String.fromCharCode(af); if (ag === "\\" || ag === "-" || ag === "[" || ag === "]") {
+    ag = "\\" + ag;
+} return ag; } function X(am) { var aq = am.substring(1, am.length - 1).match(new RegExp("\\\\u[0-9A-Fa-f]{4}|\\\\x[0-9A-Fa-f]{2}|\\\\[0-3][0-7]{0,2}|\\\\[0-7]{1,2}|\\\\[\\s\\S]|-|[^-\\\\]", "g")); var ak = []; var af = []; var ao = aq[0] === "^"; for (var ar = ao ? 1 : 0, aj = aq.length; ar < aj; ++ar) {
+    var ah = aq[ar];
+    if (/\\[bdsw]/i.test(ah)) {
+        ak.push(ah);
+    }
+    else {
+        var ag = ab(ah);
+        var al;
+        if (ar + 2 < aj && "-" === aq[ar + 1]) {
+            al = ab(aq[ar + 2]);
+            ar += 2;
+        }
+        else {
+            al = ag;
+        }
+        af.push([ag, al]);
+        if (!(al < 65 || ag > 122)) {
+            if (!(al < 65 || ag > 90)) {
+                af.push([Math.max(65, ag) | 32, Math.min(al, 90) | 32]);
+            }
+            if (!(al < 97 || ag > 122)) {
+                af.push([Math.max(97, ag) & ~32, Math.min(al, 122) & ~32]);
+            }
+        }
+    }
+} af.sort(function (av, au) { return (av[0] - au[0]) || (au[1] - av[1]); }); var ai = []; var ap = [NaN, NaN]; for (var ar = 0; ar < af.length; ++ar) {
+    var at = af[ar];
+    if (at[0] <= ap[1] + 1) {
+        ap[1] = Math.max(ap[1], at[1]);
+    }
+    else {
+        ai.push(ap = at);
+    }
+} var an = ["["]; if (ao) {
+    an.push("^");
+} an.push.apply(an, ak); for (var ar = 0; ar < ai.length; ++ar) {
+    var at = ai[ar];
+    an.push(T(at[0]));
+    if (at[1] > at[0]) {
+        if (at[1] + 1 > at[0]) {
+            an.push("-");
+        }
+        an.push(T(at[1]));
+    }
+} an.push("]"); return an.join(""); } function W(al) { var aj = al.source.match(new RegExp("(?:\\[(?:[^\\x5C\\x5D]|\\\\[\\s\\S])*\\]|\\\\u[A-Fa-f0-9]{4}|\\\\x[A-Fa-f0-9]{2}|\\\\[0-9]+|\\\\[^ux0-9]|\\(\\?[:!=]|[\\(\\)\\^]|[^\\x5B\\x5C\\(\\)\\^]+)", "g")); var ah = aj.length; var an = []; for (var ak = 0, am = 0; ak < ah; ++ak) {
+    var ag = aj[ak];
+    if (ag === "(") {
+        ++am;
+    }
+    else {
+        if ("\\" === ag.charAt(0)) {
+            var af = +ag.substring(1);
+            if (af && af <= am) {
+                an[af] = -1;
+            }
+        }
+    }
+} for (var ak = 1; ak < an.length; ++ak) {
+    if (-1 === an[ak]) {
+        an[ak] = ++ad;
+    }
+} for (var ak = 0, am = 0; ak < ah; ++ak) {
+    var ag = aj[ak];
+    if (ag === "(") {
+        ++am;
+        if (an[am] === undefined) {
+            aj[ak] = "(?:";
+        }
+    }
+    else {
+        if ("\\" === ag.charAt(0)) {
+            var af = +ag.substring(1);
+            if (af && af <= am) {
+                aj[ak] = "\\" + an[am];
+            }
+        }
+    }
+} for (var ak = 0, am = 0; ak < ah; ++ak) {
+    if ("^" === aj[ak] && "^" !== aj[ak + 1]) {
+        aj[ak] = "";
+    }
+} if (al.ignoreCase && S) {
+    for (var ak = 0; ak < ah; ++ak) {
+        var ag = aj[ak];
+        var ai = ag.charAt(0);
+        if (ag.length >= 2 && ai === "[") {
+            aj[ak] = X(ag);
+        }
+        else {
+            if (ai !== "\\") {
+                aj[ak] = ag.replace(/[a-zA-Z]/g, function (ao) { var ap = ao.charCodeAt(0); return "[" + String.fromCharCode(ap & ~32, ap | 32) + "]"; });
+            }
+        }
+    }
+} return aj.join(""); } var aa = []; for (var V = 0, U = Z.length; V < U; ++V) {
+    var ae = Z[V];
+    if (ae.global || ae.multiline) {
+        throw new Error("" + ae);
+    }
+    aa.push("(?:" + W(ae) + ")");
+} return new RegExp(aa.join("|"), ac ? "gi" : "g"); } function a(V) { var U = /(?:^|\s)nocode(?:\s|$)/; var X = []; var T = 0; var Z = []; var W = 0; var S; if (V.currentStyle) {
+    S = V.currentStyle.whiteSpace;
+}
+else {
+    if (window.getComputedStyle) {
+        S = document.defaultView.getComputedStyle(V, null).getPropertyValue("white-space");
+    }
+} var Y = S && "pre" === S.substring(0, 3); function aa(ab) { switch (ab.nodeType) {
+    case 1:
+        if (U.test(ab.className)) {
+            return;
+        }
+        for (var ae = ab.firstChild; ae; ae = ae.nextSibling) {
+            aa(ae);
+        }
+        var ad = ab.nodeName;
+        if ("BR" === ad || "LI" === ad) {
+            X[W] = "\n";
+            Z[W << 1] = T++;
+            Z[(W++ << 1) | 1] = ab;
+        }
+        break;
+    case 3:
+    case 4:
+        var ac = ab.nodeValue;
+        if (ac.length) {
+            if (!Y) {
+                ac = ac.replace(/[ \t\r\n]+/g, " ");
+            }
+            else {
+                ac = ac.replace(/\r\n?/g, "\n");
+            }
+            X[W] = ac;
+            Z[W << 1] = T;
+            T += ac.length;
+            Z[(W++ << 1) | 1] = ab;
+        }
+        break;
+} } aa(V); return { sourceCode: X.join("").replace(/\n$/, ""), spans: Z }; } function B(S, U, W, T) { if (!U) {
+    return;
+} var V = { sourceCode: U, basePos: S }; W(V); T.push.apply(T, V.decorations); } var v = /\S/; function o(S) { var V = undefined; for (var U = S.firstChild; U; U = U.nextSibling) {
+    var T = U.nodeType;
+    V = (T === 1) ? (V ? S : U) : (T === 3) ? (v.test(U.nodeValue) ? S : V) : V;
+} return V === S ? undefined : V; } function g(U, T) { var S = {}; var V; (function () { var ad = U.concat(T); var ah = []; var ag = {}; for (var ab = 0, Z = ad.length; ab < Z; ++ab) {
+    var Y = ad[ab];
+    var ac = Y[3];
+    if (ac) {
+        for (var ae = ac.length; --ae >= 0;) {
+            S[ac.charAt(ae)] = Y;
+        }
+    }
+    var af = Y[1];
+    var aa = "" + af;
+    if (!ag.hasOwnProperty(aa)) {
+        ah.push(af);
+        ag[aa] = null;
+    }
+} ah.push(/[\0-\uffff]/); V = k(ah); })(); var X = T.length; var W = function (ah) { var Z = ah.sourceCode, Y = ah.basePos; var ad = [Y, F]; var af = 0; var an = Z.match(V) || []; var aj = {}; for (var ae = 0, aq = an.length; ae < aq; ++ae) {
+    var ag = an[ae];
+    var ap = aj[ag];
+    var ai = void 0;
+    var am;
+    if (typeof ap === "string") {
+        am = false;
+    }
+    else {
+        var aa = S[ag.charAt(0)];
+        if (aa) {
+            ai = ag.match(aa[1]);
+            ap = aa[0];
+        }
+        else {
+            for (var ao = 0; ao < X; ++ao) {
+                aa = T[ao];
+                ai = ag.match(aa[1]);
+                if (ai) {
+                    ap = aa[0];
+                    break;
+                }
+            }
+            if (!ai) {
+                ap = F;
+            }
+        }
+        am = ap.length >= 5 && "lang-" === ap.substring(0, 5);
+        if (am && !(ai && typeof ai[1] === "string")) {
+            am = false;
+            ap = J;
+        }
+        if (!am) {
+            aj[ag] = ap;
+        }
+    }
+    var ab = af;
+    af += ag.length;
+    if (!am) {
+        ad.push(Y + ab, ap);
+    }
+    else {
+        var al = ai[1];
+        var ak = ag.indexOf(al);
+        var ac = ak + al.length;
+        if (ai[2]) {
+            ac = ag.length - ai[2].length;
+            ak = ac - al.length;
+        }
+        var ar = ap.substring(5);
+        B(Y + ab, ag.substring(0, ak), W, ad);
+        B(Y + ab + ak, al, q(ar, al), ad);
+        B(Y + ab + ac, ag.substring(ac), W, ad);
+    }
+} ah.decorations = ad; }; return W; } function i(T) { var W = [], S = []; if (T.tripleQuotedStrings) {
+    W.push([C, /^(?:\'\'\'(?:[^\'\\]|\\[\s\S]|\'{1,2}(?=[^\']))*(?:\'\'\'|$)|\"\"\"(?:[^\"\\]|\\[\s\S]|\"{1,2}(?=[^\"]))*(?:\"\"\"|$)|\'(?:[^\\\']|\\[\s\S])*(?:\'|$)|\"(?:[^\\\"]|\\[\s\S])*(?:\"|$))/, null, "'\""]);
+}
+else {
+    if (T.multiLineStrings) {
+        W.push([C, /^(?:\'(?:[^\\\']|\\[\s\S])*(?:\'|$)|\"(?:[^\\\"]|\\[\s\S])*(?:\"|$)|\`(?:[^\\\`]|\\[\s\S])*(?:\`|$))/, null, "'\"`"]);
+    }
+    else {
+        W.push([C, /^(?:\'(?:[^\\\'\r\n]|\\.)*(?:\'|$)|\"(?:[^\\\"\r\n]|\\.)*(?:\"|$))/, null, "\"'"]);
+    }
+} if (T.verbatimStrings) {
+    S.push([C, /^@\"(?:[^\"]|\"\")*(?:\"|$)/, null]);
+} var Y = T.hashComments; if (Y) {
+    if (T.cStyleComments) {
+        if (Y > 1) {
+            W.push([j, /^#(?:##(?:[^#]|#(?!##))*(?:###|$)|.*)/, null, "#"]);
+        }
+        else {
+            W.push([j, /^#(?:(?:define|elif|else|endif|error|ifdef|include|ifndef|line|pragma|undef|warning)\b|[^\r\n]*)/, null, "#"]);
+        }
+        S.push([C, /^<(?:(?:(?:\.\.\/)*|\/?)(?:[\w-]+(?:\/[\w-]+)+)?[\w-]+\.h|[a-z]\w*)>/, null]);
+    }
+    else {
+        W.push([j, /^#[^\r\n]*/, null, "#"]);
+    }
+} if (T.cStyleComments) {
+    S.push([j, /^\/\/[^\r\n]*/, null]);
+    S.push([j, /^\/\*[\s\S]*?(?:\*\/|$)/, null]);
+} if (T.regexLiterals) {
+    var X = ("/(?=[^/*])(?:[^/\\x5B\\x5C]|\\x5C[\\s\\S]|\\x5B(?:[^\\x5C\\x5D]|\\x5C[\\s\\S])*(?:\\x5D|$))+/");
+    S.push(["lang-regex", new RegExp("^" + M + "(" + X + ")")]);
+} var V = T.types; if (V) {
+    S.push([O, V]);
+} var U = ("" + T.keywords).replace(/^ | $/g, ""); if (U.length) {
+    S.push([z, new RegExp("^(?:" + U.replace(/[\s,]+/g, "|") + ")\\b"), null]);
+} W.push([F, /^\s+/, null, " \r\n\t\xA0"]); S.push([G, /^@[a-z_$][a-z_$@0-9]*/i, null], [O, /^(?:[@_]?[A-Z]+[a-z][A-Za-z_$@0-9]*|\w+_t\b)/, null], [F, /^[a-z_$][a-z_$@0-9]*/i, null], [G, new RegExp("^(?:0x[a-f0-9]+|(?:\\d(?:_\\d+)*\\d*(?:\\.\\d*)?|\\.\\d\\+)(?:e[+\\-]?\\d+)?)[a-z]*", "i"), null, "0123456789"], [F, /^\\[\s\S]?/, null], [L, /^.[^\s\w\.$@\'\"\`\/\#\\]*/, null]); return g(W, S); } var K = i({ keywords: A, hashComments: true, cStyleComments: true, multiLineStrings: true, regexLiterals: true }); function Q(V, ag) { var U = /(?:^|\s)nocode(?:\s|$)/; var ab = /\r\n?|\n/; var ac = V.ownerDocument; var S; if (V.currentStyle) {
+    S = V.currentStyle.whiteSpace;
+}
+else {
+    if (window.getComputedStyle) {
+        S = ac.defaultView.getComputedStyle(V, null).getPropertyValue("white-space");
+    }
+} var Z = S && "pre" === S.substring(0, 3); var af = ac.createElement("LI"); while (V.firstChild) {
+    af.appendChild(V.firstChild);
+} var W = [af]; function ae(al) { switch (al.nodeType) {
+    case 1:
+        if (U.test(al.className)) {
+            break;
+        }
+        if ("BR" === al.nodeName) {
+            ad(al);
+            if (al.parentNode) {
+                al.parentNode.removeChild(al);
+            }
+        }
+        else {
+            for (var an = al.firstChild; an; an = an.nextSibling) {
+                ae(an);
+            }
+        }
+        break;
+    case 3:
+    case 4:
+        if (Z) {
+            var am = al.nodeValue;
+            var aj = am.match(ab);
+            if (aj) {
+                var ai = am.substring(0, aj.index);
+                al.nodeValue = ai;
+                var ah = am.substring(aj.index + aj[0].length);
+                if (ah) {
+                    var ak = al.parentNode;
+                    ak.insertBefore(ac.createTextNode(ah), al.nextSibling);
+                }
+                ad(al);
+                if (!ai) {
+                    al.parentNode.removeChild(al);
+                }
+            }
+        }
+        break;
+} } function ad(ak) { while (!ak.nextSibling) {
+    ak = ak.parentNode;
+    if (!ak) {
+        return;
+    }
+} function ai(al, ar) { var aq = ar ? al.cloneNode(false) : al; var ao = al.parentNode; if (ao) {
+    var ap = ai(ao, 1);
+    var an = al.nextSibling;
+    ap.appendChild(aq);
+    for (var am = an; am; am = an) {
+        an = am.nextSibling;
+        ap.appendChild(am);
+    }
+} return aq; } var ah = ai(ak.nextSibling, 0); for (var aj; (aj = ah.parentNode) && aj.nodeType === 1;) {
+    ah = aj;
+} W.push(ah); } for (var Y = 0; Y < W.length; ++Y) {
+    ae(W[Y]);
+} if (ag === (ag | 0)) {
+    W[0].setAttribute("value", ag);
+} var aa = ac.createElement("OL"); aa.className = "linenums"; var X = Math.max(0, ((ag - 1)) | 0) || 0; for (var Y = 0, T = W.length; Y < T; ++Y) {
+    af = W[Y];
+    af.className = "L" + ((Y + X) % 10);
+    if (!af.firstChild) {
+        af.appendChild(ac.createTextNode("\xA0"));
+    }
+    aa.appendChild(af);
+} V.appendChild(aa); } function D(ac) { var aj = /\bMSIE\b/.test(navigator.userAgent); var am = /\n/g; var al = ac.sourceCode; var an = al.length; var V = 0; var aa = ac.spans; var T = aa.length; var ah = 0; var X = ac.decorations; var Y = X.length; var Z = 0; X[Y] = an; var ar, aq; for (aq = ar = 0; aq < Y;) {
+    if (X[aq] !== X[aq + 2]) {
+        X[ar++] = X[aq++];
+        X[ar++] = X[aq++];
+    }
+    else {
+        aq += 2;
+    }
+} Y = ar; for (aq = ar = 0; aq < Y;) {
+    var at = X[aq];
+    var ab = X[aq + 1];
+    var W = aq + 2;
+    while (W + 2 <= Y && X[W + 1] === ab) {
+        W += 2;
+    }
+    X[ar++] = at;
+    X[ar++] = ab;
+    aq = W;
+} Y = X.length = ar; var ae = null; while (ah < T) {
+    var af = aa[ah];
+    var S = aa[ah + 2] || an;
+    var ag = X[Z];
+    var ap = X[Z + 2] || an;
+    var W = Math.min(S, ap);
+    var ak = aa[ah + 1];
+    var U;
+    if (ak.nodeType !== 1 && (U = al.substring(V, W))) {
+        if (aj) {
+            U = U.replace(am, "\r");
+        }
+        ak.nodeValue = U;
+        var ai = ak.ownerDocument;
+        var ao = ai.createElement("SPAN");
+        ao.className = X[Z + 1];
+        var ad = ak.parentNode;
+        ad.replaceChild(ao, ak);
+        ao.appendChild(ak);
+        if (V < S) {
+            aa[ah + 1] = ak = ai.createTextNode(al.substring(W, S));
+            ad.insertBefore(ak, ao.nextSibling);
+        }
+    }
+    V = W;
+    if (V >= S) {
+        ah += 2;
+    }
+    if (V >= ap) {
+        Z += 2;
+    }
+} } var t = {}; function c(U, V) { for (var S = V.length; --S >= 0;) {
+    var T = V[S];
+    if (!t.hasOwnProperty(T)) {
+        t[T] = U;
+    }
+    else {
+        if (window.console) {
+            console.warn("cannot override language handler %s", T);
+        }
+    }
+} } function q(T, S) { if (!(T && t.hasOwnProperty(T))) {
+    T = /^\s*</.test(S) ? "default-markup" : "default-code";
+} return t[T]; } c(K, ["default-code"]); c(g([], [[F, /^[^<?]+/], [E, /^<!\w[^>]*(?:>|$)/], [j, /^<\!--[\s\S]*?(?:-\->|$)/], ["lang-", /^<\?([\s\S]+?)(?:\?>|$)/], ["lang-", /^<%([\s\S]+?)(?:%>|$)/], [L, /^(?:<[%?]|[%?]>)/], ["lang-", /^<xmp\b[^>]*>([\s\S]+?)<\/xmp\b[^>]*>/i], ["lang-js", /^<script\b[^>]*>([\s\S]*?)(<\/script\b[^>]*>)/i], ["lang-css", /^<style\b[^>]*>([\s\S]*?)(<\/style\b[^>]*>)/i], ["lang-in.tag", /^(<\/?[a-z][^<>]*>)/i]]), ["default-markup", "htm", "html", "mxml", "xhtml", "xml", "xsl"]); c(g([[F, /^[\s]+/, null, " \t\r\n"], [n, /^(?:\"[^\"]*\"?|\'[^\']*\'?)/, null, "\"'"]], [[m, /^^<\/?[a-z](?:[\w.:-]*\w)?|\/?>$/i], [P, /^(?!style[\s=]|on)[a-z](?:[\w:-]*\w)?/i], ["lang-uq.val", /^=\s*([^>\'\"\s]*(?:[^>\'\"\s\/]|\/(?=\s)))/], [L, /^[=<>\/]+/], ["lang-js", /^on\w+\s*=\s*\"([^\"]+)\"/i], ["lang-js", /^on\w+\s*=\s*\'([^\']+)\'/i], ["lang-js", /^on\w+\s*=\s*([^\"\'>\s]+)/i], ["lang-css", /^style\s*=\s*\"([^\"]+)\"/i], ["lang-css", /^style\s*=\s*\'([^\']+)\'/i], ["lang-css", /^style\s*=\s*([^\"\'>\s]+)/i]]), ["in.tag"]); c(g([], [[n, /^[\s\S]+/]]), ["uq.val"]); c(i({ keywords: l, hashComments: true, cStyleComments: true, types: e }), ["c", "cc", "cpp", "cxx", "cyc", "m"]); c(i({ keywords: "null,true,false" }), ["json"]); c(i({ keywords: R, hashComments: true, cStyleComments: true, verbatimStrings: true, types: e }), ["cs"]); c(i({ keywords: x, cStyleComments: true }), ["java"]); c(i({ keywords: H, hashComments: true, multiLineStrings: true }), ["bsh", "csh", "sh"]); c(i({ keywords: I, hashComments: true, multiLineStrings: true, tripleQuotedStrings: true }), ["cv", "py"]); c(i({ keywords: s, hashComments: true, multiLineStrings: true, regexLiterals: true }), ["perl", "pl", "pm"]); c(i({ keywords: f, hashComments: true, multiLineStrings: true, regexLiterals: true }), ["rb"]); c(i({ keywords: w, cStyleComments: true, regexLiterals: true }), ["js"]); c(i({ keywords: r, hashComments: 3, cStyleComments: true, multilineStrings: true, tripleQuotedStrings: true, regexLiterals: true }), ["coffee"]); c(g([], [[C, /^[\s\S]+/]]), ["regex"]); function d(V) { var U = V.langExtension; try {
+    var S = a(V.sourceNode);
+    var T = S.sourceCode;
+    V.sourceCode = T;
+    V.spans = S.spans;
+    V.basePos = 0;
+    q(U, T)(V);
+    D(V);
+}
+catch (W) {
+    if ("console" in window) {
+        console.log(W && W.stack ? W.stack : W);
+    }
+} } function y(W, V, U) { var S = document.createElement("PRE"); S.innerHTML = W; if (U) {
+    Q(S, U);
+} var T = { langExtension: V, numberLines: U, sourceNode: S }; d(T); return S.innerHTML; } function b(ad) { function Y(af) { return document.getElementsByTagName(af); } var ac = [Y("pre"), Y("code"), Y("xmp")]; var T = []; for (var aa = 0; aa < ac.length; ++aa) {
+    for (var Z = 0, V = ac[aa].length; Z < V; ++Z) {
+        T.push(ac[aa][Z]);
+    }
+} ac = null; var W = Date; if (!W.now) {
+    W = { now: function () { return +(new Date); } };
+} var X = 0; var S; var ab = /\blang(?:uage)?-([\w.]+)(?!\S)/; var ae = /\bprettyprint\b/; function U() { var ag = (window.PR_SHOULD_USE_CONTINUATION ? W.now() + 250 : Infinity); for (; X < T.length && W.now() < ag; X++) {
+    var aj = T[X];
+    var ai = aj.className;
+    if (ai.indexOf("prettyprint") >= 0) {
+        var ah = ai.match(ab);
+        var am;
+        if (!ah && (am = o(aj)) && "CODE" === am.tagName) {
+            ah = am.className.match(ab);
+        }
+        if (ah) {
+            ah = ah[1];
+        }
+        var al = false;
+        for (var ak = aj.parentNode; ak; ak = ak.parentNode) {
+            if ((ak.tagName === "pre" || ak.tagName === "code" || ak.tagName === "xmp") && ak.className && ak.className.indexOf("prettyprint") >= 0) {
+                al = true;
+                break;
+            }
+        }
+        if (!al) {
+            var af = aj.className.match(/\blinenums\b(?::(\d+))?/);
+            af = af ? af[1] && af[1].length ? +af[1] : true : false;
+            if (af) {
+                Q(aj, af);
+            }
+            S = { langExtension: ah, sourceNode: aj, numberLines: af };
+            d(S);
+        }
+    }
+} if (X < T.length) {
+    setTimeout(U, 250);
+}
+else {
+    if (ad) {
+        ad();
+    }
+} } U(); } window.prettyPrintOne = y; window.prettyPrint = b; window.PR = { createSimpleLexer: g, registerLangHandler: c, sourceDecorator: i, PR_ATTRIB_NAME: P, PR_ATTRIB_VALUE: n, PR_COMMENT: j, PR_DECLARATION: E, PR_KEYWORD: z, PR_LITERAL: G, PR_NOCODE: N, PR_PLAIN: F, PR_PUNCTUATION: L, PR_SOURCE: J, PR_STRING: C, PR_TAG: m, PR_TYPE: O }; })();
+PR.registerLangHandler(PR.createSimpleLexer([], [[PR.PR_DECLARATION, /^<!\w[^>]*(?:>|$)/], [PR.PR_COMMENT, /^<\!--[\s\S]*?(?:-\->|$)/], [PR.PR_PUNCTUATION, /^(?:<[%?]|[%?]>)/], ["lang-", /^<\?([\s\S]+?)(?:\?>|$)/], ["lang-", /^<%([\s\S]+?)(?:%>|$)/], ["lang-", /^<xmp\b[^>]*>([\s\S]+?)<\/xmp\b[^>]*>/i], ["lang-handlebars", /^<script\b[^>]*type\s*=\s*['"]?text\/x-handlebars-template['"]?\b[^>]*>([\s\S]*?)(<\/script\b[^>]*>)/i], ["lang-js", /^<script\b[^>]*>([\s\S]*?)(<\/script\b[^>]*>)/i], ["lang-css", /^<style\b[^>]*>([\s\S]*?)(<\/style\b[^>]*>)/i], ["lang-in.tag", /^(<\/?[a-z][^<>]*>)/i], [PR.PR_DECLARATION, /^{{[#^>/]?\s*[\w.][^}]*}}/], [PR.PR_DECLARATION, /^{{&?\s*[\w.][^}]*}}/], [PR.PR_DECLARATION, /^{{{>?\s*[\w.][^}]*}}}/], [PR.PR_COMMENT, /^{{![^}]*}}/]]), ["handlebars", "hbs"]);
+PR.registerLangHandler(PR.createSimpleLexer([[PR.PR_PLAIN, /^[ \t\r\n\f]+/, null, " \t\r\n\f"]], [[PR.PR_STRING, /^\"(?:[^\n\r\f\\\"]|\\(?:\r\n?|\n|\f)|\\[\s\S])*\"/, null], [PR.PR_STRING, /^\'(?:[^\n\r\f\\\']|\\(?:\r\n?|\n|\f)|\\[\s\S])*\'/, null], ["lang-css-str", /^url\(([^\)\"\']*)\)/i], [PR.PR_KEYWORD, /^(?:url|rgb|\!important|@import|@page|@media|@charset|inherit)(?=[^\-\w]|$)/i, null], ["lang-css-kw", /^(-?(?:[_a-z]|(?:\\[0-9a-f]+ ?))(?:[_a-z0-9\-]|\\(?:\\[0-9a-f]+ ?))*)\s*:/i], [PR.PR_COMMENT, /^\/\*[^*]*\*+(?:[^\/*][^*]*\*+)*\//], [PR.PR_COMMENT, /^(?:<!--|-->)/], [PR.PR_LITERAL, /^(?:\d+|\d*\.\d+)(?:%|[a-z]+)?/i], [PR.PR_LITERAL, /^#(?:[0-9a-f]{3}){1,2}/i], [PR.PR_PLAIN, /^-?(?:[_a-z]|(?:\\[\da-f]+ ?))(?:[_a-z\d\-]|\\(?:\\[\da-f]+ ?))*/i], [PR.PR_PUNCTUATION, /^[^\s\w\'\"]+/]]), ["css"]);
+PR.registerLangHandler(PR.createSimpleLexer([], [[PR.PR_KEYWORD, /^-?(?:[_a-z]|(?:\\[\da-f]+ ?))(?:[_a-z\d\-]|\\(?:\\[\da-f]+ ?))*/i]]), ["css-kw"]);
+PR.registerLangHandler(PR.createSimpleLexer([], [[PR.PR_STRING, /^[^\)\"\']+/]]), ["css-str"]);
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/coverage/lcov-report/sorter.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/coverage/lcov-report/sorter.d.ts
new file mode 100644
index 0000000..a49797a
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/coverage/lcov-report/sorter.d.ts
@@ -0,0 +1 @@
+declare function addSorting(): void;
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/coverage/lcov-report/sorter.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/coverage/lcov-report/sorter.js
new file mode 100644
index 0000000..c6f2213
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/coverage/lcov-report/sorter.js
@@ -0,0 +1,162 @@
+/* eslint-disable */
+var addSorting = (function () {
+    'use strict';
+    var cols, currentSort = {
+        index: 0,
+        desc: false
+    };
+    // returns the summary table element
+    function getTable() {
+        return document.querySelector('.coverage-summary');
+    }
+    // returns the thead element of the summary table
+    function getTableHeader() {
+        return getTable().querySelector('thead tr');
+    }
+    // returns the tbody element of the summary table
+    function getTableBody() {
+        return getTable().querySelector('tbody');
+    }
+    // returns the th element for nth column
+    function getNthColumn(n) {
+        return getTableHeader().querySelectorAll('th')[n];
+    }
+    function onFilterInput() {
+        const searchValue = document.getElementById('fileSearch').value;
+        const rows = document.getElementsByTagName('tbody')[0].children;
+        for (let i = 0; i < rows.length; i++) {
+            const row = rows[i];
+            if (row.textContent
+                .toLowerCase()
+                .includes(searchValue.toLowerCase())) {
+                row.style.display = '';
+            }
+            else {
+                row.style.display = 'none';
+            }
+        }
+    }
+    // loads the search box
+    function addSearchBox() {
+        var template = document.getElementById('filterTemplate');
+        var templateClone = template.content.cloneNode(true);
+        templateClone.getElementById('fileSearch').oninput = onFilterInput;
+        template.parentElement.appendChild(templateClone);
+    }
+    // loads all columns
+    function loadColumns() {
+        var colNodes = getTableHeader().querySelectorAll('th'), colNode, cols = [], col, i;
+        for (i = 0; i < colNodes.length; i += 1) {
+            colNode = colNodes[i];
+            col = {
+                key: colNode.getAttribute('data-col'),
+                sortable: !colNode.getAttribute('data-nosort'),
+                type: colNode.getAttribute('data-type') || 'string'
+            };
+            cols.push(col);
+            if (col.sortable) {
+                col.defaultDescSort = col.type === 'number';
+                colNode.innerHTML =
+                    colNode.innerHTML + '<span class="sorter"></span>';
+            }
+        }
+        return cols;
+    }
+    // attaches a data attribute to every tr element with an object
+    // of data values keyed by column name
+    function loadRowData(tableRow) {
+        var tableCols = tableRow.querySelectorAll('td'), colNode, col, data = {}, i, val;
+        for (i = 0; i < tableCols.length; i += 1) {
+            colNode = tableCols[i];
+            col = cols[i];
+            val = colNode.getAttribute('data-value');
+            if (col.type === 'number') {
+                val = Number(val);
+            }
+            data[col.key] = val;
+        }
+        return data;
+    }
+    // loads all row data
+    function loadData() {
+        var rows = getTableBody().querySelectorAll('tr'), i;
+        for (i = 0; i < rows.length; i += 1) {
+            rows[i].data = loadRowData(rows[i]);
+        }
+    }
+    // sorts the table using the data for the ith column
+    function sortByIndex(index, desc) {
+        var key = cols[index].key, sorter = function (a, b) {
+            a = a.data[key];
+            b = b.data[key];
+            return a < b ? -1 : a > b ? 1 : 0;
+        }, finalSorter = sorter, tableBody = document.querySelector('.coverage-summary tbody'), rowNodes = tableBody.querySelectorAll('tr'), rows = [], i;
+        if (desc) {
+            finalSorter = function (a, b) {
+                return -1 * sorter(a, b);
+            };
+        }
+        for (i = 0; i < rowNodes.length; i += 1) {
+            rows.push(rowNodes[i]);
+            tableBody.removeChild(rowNodes[i]);
+        }
+        rows.sort(finalSorter);
+        for (i = 0; i < rows.length; i += 1) {
+            tableBody.appendChild(rows[i]);
+        }
+    }
+    // removes sort indicators for current column being sorted
+    function removeSortIndicators() {
+        var col = getNthColumn(currentSort.index), cls = col.className;
+        cls = cls.replace(/ sorted$/, '').replace(/ sorted-desc$/, '');
+        col.className = cls;
+    }
+    // adds sort indicators for current column being sorted
+    function addSortIndicators() {
+        getNthColumn(currentSort.index).className += currentSort.desc
+            ? ' sorted-desc'
+            : ' sorted';
+    }
+    // adds event listeners for all sorter widgets
+    function enableUI() {
+        var i, el, ithSorter = function ithSorter(i) {
+            var col = cols[i];
+            return function () {
+                var desc = col.defaultDescSort;
+                if (currentSort.index === i) {
+                    desc = !currentSort.desc;
+                }
+                sortByIndex(i, desc);
+                removeSortIndicators();
+                currentSort.index = i;
+                currentSort.desc = desc;
+                addSortIndicators();
+            };
+        };
+        for (i = 0; i < cols.length; i += 1) {
+            if (cols[i].sortable) {
+                // add the click event handler on the th so users
+                // dont have to click on those tiny arrows
+                el = getNthColumn(i).querySelector('.sorter').parentElement;
+                if (el.addEventListener) {
+                    el.addEventListener('click', ithSorter(i));
+                }
+                else {
+                    el.attachEvent('onclick', ithSorter(i));
+                }
+            }
+        }
+    }
+    // adds sorting functionality to the UI
+    return function () {
+        if (!getTable()) {
+            return;
+        }
+        cols = loadColumns();
+        loadData();
+        addSearchBox();
+        addSortIndicators();
+        enableUI();
+    };
+})();
+window.addEventListener('load', addSorting);
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/dist/cjs/index.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/dist/cjs/index.d.ts
new file mode 100644
index 0000000..bcb27f3
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/dist/cjs/index.d.ts
@@ -0,0 +1,174 @@
+export const __esModule: boolean;
+export const DefaultSpans: {
+    period: number;
+    samples: number;
+}[];
+export class CustomMetrics {
+    static terminate(): Promise<void>;
+    static flushAll(): Promise<void>;
+    static freeInstanceByKey(key: any): void;
+    static saveInstance(tags: any, metrics: any): void;
+    constructor(options?: {});
+    consistent: any;
+    buffers: any;
+    prefix: any;
+    log: Log;
+    buffer: any;
+    expires: any;
+    primaryKey: any;
+    sortKey: any;
+    type: any;
+    client: any;
+    table: any;
+    options: {};
+    owner: any;
+    spans: any;
+    ttl: any;
+    source: any;
+    pResolution: any;
+    emit(namespace: any, metricName: any, value: any, dimensionsList?: {}[], options?: {}): Promise<any>;
+    emitDimensions(namespace: any, metricName: any, point: any, dimensionsList: any, options: any): Promise<any>;
+    bufferMetric(namespace: any, metricName: any, point: any, dimensions: any, options: any): Promise<any>;
+    emitDimensionedMetric(namespace: any, metricName: any, point: any, dimensions: any, options?: {}): Promise<any>;
+    upgrade(namespace: any, metricName: any, dimensionsList?: {}[], options?: {}): Promise<any>;
+    upgradeMetric(old: any): any;
+    flush(): Promise<void>;
+    flushElt(elt: any, timestamp: any): Promise<void>;
+    getBufferKey(namespace: any, metricName: any, dimensions: any): string;
+    query(namespace: any, metricName: any, dimensions: any, period: any, statistic: any, options?: {}): Promise<{
+        dimensions: {};
+        metric: any;
+        namespace: any;
+        owner: any;
+        period: any;
+        points: {
+            value: number;
+            timestamp: any;
+            count: number;
+        }[];
+        samples: any;
+    } | {
+        dimensions: {};
+        metric: any;
+        namespace: any;
+        period: any;
+        points: {
+            value: any;
+            count: any;
+            timestamp: number;
+        }[];
+        owner: any;
+        samples: any;
+    } | {
+        dimensions: any;
+        id: any;
+        metric: any;
+        namespace: any;
+        period: any;
+        points: any[];
+        owner: any;
+        samples: number;
+    }>;
+    accumulateMetric(metric: any, span: any, statistic: any, owner: any, start: any, period: any): {
+        dimensions: {};
+        metric: any;
+        namespace: any;
+        owner: any;
+        period: any;
+        points: {
+            value: number;
+            timestamp: any;
+            count: number;
+        }[];
+        samples: any;
+    };
+    calculateSeries(metric: any, span: any, statistic: any, owner: any, start: any, period: any): {
+        dimensions: {};
+        metric: any;
+        namespace: any;
+        period: any;
+        points: {
+            value: any;
+            count: any;
+            timestamp: number;
+        }[];
+        owner: any;
+        samples: any;
+    };
+    makeDimensionString(dimensions: any): string;
+    makeDimensionObject(dimensions: any): {};
+    addValue(metric: any, timestamp: any, point: any, si: any, querySpanIndex?: any): void;
+    setPoint(span: any, index: any, add: any): void;
+    getMetricList(namespace?: any, metric?: any, options?: {
+        limit: number;
+    }): Promise<{
+        namespaces: string[];
+    }>;
+    initMetric(owner: any, namespace: any, name: any, dimensions: any, timestamp: any): {
+        dimensions: any;
+        metric: any;
+        namespace: any;
+        owner: any;
+        spans: any[];
+        version: number;
+    };
+    getMetric(owner: any, namespace: any, metric: any, dimensions: any, log: any): Promise<{
+        dimensions: any;
+        expires: any;
+        metric: any;
+        namespace: any;
+        owner: any;
+        seq: any;
+        spans: any;
+    }>;
+    findMetrics(owner: any, namespace: any, metric: any, limit: any, startKey: any): Promise<{
+        items: {
+            dimensions: any;
+            expires: any;
+            metric: any;
+            namespace: any;
+            owner: any;
+            seq: any;
+            spans: any;
+        }[];
+        next: Record<string, any>;
+        command: client_dynamodb_1.QueryCommand;
+    }>;
+    putMetric(item: any, options: any): Promise<boolean>;
+    mapItemFromDB(data: any): {
+        dimensions: any;
+        expires: any;
+        metric: any;
+        namespace: any;
+        owner: any;
+        seq: any;
+        spans: any;
+    };
+    mapItemToDB(item: any): {
+        [x: number]: any;
+        spans: any;
+        seq: any;
+        _source: any;
+    };
+    roundTime(span: any, timestamp: any): number;
+    assert(c: any): void;
+    info(message: any, context?: {}): void;
+    error(message: any, context?: {}): void;
+    trace(message: any, context?: {}): void;
+    round(n: any): number;
+    jitter(msecs: any): number;
+    delay(time: any): Promise<any>;
+}
+declare class Log {
+    constructor(dest: any);
+    senselogs: any;
+    logger: (chan: any, message: any, context: any) => void;
+    verbose: boolean;
+    error(message: any, context: any): void;
+    info(message: any, context: any): void;
+    trace(message: any, context: any): void;
+    process(chan: any, message: any, context: any): void;
+    defaultLogger(chan: any, message: any, context: any): void;
+}
+import client_dynamodb_1 = require("@aws-sdk/client-dynamodb");
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/dist/cjs/index.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/dist/cjs/index.js
new file mode 100644
index 0000000..7e8b515
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/dist/cjs/index.js
@@ -0,0 +1,982 @@
+"use strict";
+var __importDefault = (this && this.__importDefault) || function (mod) {
+    return (mod && mod.__esModule) ? mod : { "default": mod };
+};
+Object.defineProperty(exports, "__esModule", { value: true });
+exports.CustomMetrics = exports.DefaultSpans = void 0;
+const process_1 = __importDefault(require("process"));
+const client_dynamodb_1 = require("@aws-sdk/client-dynamodb");
+const util_dynamodb_1 = require("@aws-sdk/util-dynamodb");
+const Version = 1;
+const Assert = true;
+const Buffering = true;
+const DefaultResolution = 0;
+const MaxSeq = Number.MAX_SAFE_INTEGER;
+const MaxRetries = 10;
+const MetricListLimit = 10000;
+exports.DefaultSpans = [
+    { period: 5 * 60, samples: 10 },
+    { period: 60 * 60, samples: 12 },
+    { period: 24 * 60 * 60, samples: 12 },
+    { period: 7 * 24 * 60 * 60, samples: 14 },
+    { period: 28 * 24 * 60 * 60, samples: 14 },
+    { period: 365 * 24 * 60 * 60, samples: 12 },
+];
+var Instances = {};
+process_1.default.on('SIGTERM', async () => {
+    await CustomMetrics.terminate();
+});
+class CustomMetrics {
+    constructor(options = {}) {
+        this.consistent = false;
+        this.buffers = null;
+        this.prefix = 'metric';
+        this.log = new Log(options.log);
+        if (options.ttl && typeof options.ttl != 'number') {
+            throw new Error('Bad type for "ttl" option');
+        }
+        if (options.spans && (!Array.isArray(options.spans) || options.spans.length == 0)) {
+            throw new Error('The "spans" option must be an non-empty array');
+        }
+        if (options.source && typeof options.source != 'string') {
+            throw new Error('Non-string "source" option');
+        }
+        if (options.pResolution != undefined && (options.pResolution < 0 || options.pResolution > 1000)) {
+            throw new Error('Invalid "pResolution" option. Must be between 0 and 1000. Default is 0');
+        }
+        if (options.consistent != null && typeof options.consistent != 'boolean') {
+            throw new Error('Bad type for "consistent" option');
+        }
+        if (options.prefix) {
+            this.prefix = options.prefix;
+        }
+        if (options.buffer) {
+            if (typeof options.buffer != 'object') {
+                throw new Error('Bad type for "buffer" option');
+            }
+            this.buffer = options.buffer;
+        }
+        this.expires = options.expires || 'expires';
+        this.primaryKey = options.primaryKey || 'pk';
+        this.sortKey = options.sortKey || 'sk';
+        this.type = options.type || { _type: 'Metric' };
+        if (options.client) {
+            this.client = options.client;
+        }
+        else {
+            let params = {};
+            if (options.creds) {
+                params.credentials = options.creds;
+                params.region = params.credentials.region;
+            }
+            if (options.region) {
+                params.region = options.region;
+            }
+            this.client = new client_dynamodb_1.DynamoDBClient(params);
+        }
+        if (!options.table) {
+            throw new Error('Missing DynamoDB table name property');
+        }
+        this.table = options.table;
+        this.options = options;
+        this.owner = options.owner || 'default';
+        this.spans = options.spans || exports.DefaultSpans;
+        this.ttl = options.ttl || this.spans[this.spans.length - 1].period;
+        if (options.consistent != null) {
+            this.consistent = options.consistent;
+        }
+        if (options.source) {
+            this.source = options.source;
+        }
+        this.pResolution = options.pResolution || DefaultResolution;
+    }
+    async emit(namespace, metricName, value, dimensionsList = [{}], options = {}) {
+        if (value == undefined || value == null) {
+            throw new Error('Invalid metric value');
+        }
+        if (dimensionsList.length == 0) {
+            dimensionsList = [{}];
+        }
+        value = Number(value);
+        if (isNaN(value)) {
+            throw new Error(`Value to emit is not valid`);
+        }
+        if (!namespace || !metricName) {
+            throw new Error('Missing emit namespace / metric argument');
+        }
+        if (!Array.isArray(dimensionsList)) {
+            throw new Error('Dimensions must be an array');
+        }
+        if (dimensionsList.length == 0) {
+            dimensionsList = [{}];
+        }
+        let point;
+        point = { count: 1, sum: value };
+        return await this.emitDimensions(namespace, metricName, point, dimensionsList, options);
+    }
+    async emitDimensions(namespace, metricName, point, dimensionsList, options) {
+        let result;
+        for (let dim of dimensionsList) {
+            let dimensions = this.makeDimensionString(dim);
+            let buffer = options.buffer || this.buffer;
+            if (buffer && (buffer.elapsed || buffer.force || buffer.sum || buffer.count) && Buffering) {
+                result = await this.bufferMetric(namespace, metricName, point, dimensions, options);
+            }
+            else {
+                result = await this.emitDimensionedMetric(namespace, metricName, point, dimensions, options);
+            }
+        }
+        return result;
+    }
+    async bufferMetric(namespace, metricName, point, dimensions, options) {
+        let buffer = options.buffer || this.buffer;
+        let key = this.getBufferKey(namespace, metricName, dimensions);
+        let buffers = (this.buffers = this.buffers || {});
+        let timestamp = Math.floor((options.timestamp || Date.now()) / 1000);
+        let elapsed = buffer.elapsed || this.spans[0].period / this.spans[0].samples;
+        let elt = (buffers[key] = buffers[key] || {
+            count: 0,
+            sum: 0,
+            timestamp: timestamp + elapsed,
+            elapsed: elapsed,
+            namespace: namespace,
+            metric: metricName,
+            dimensions,
+            spans: [{ points: [{ count: 0, sum: 0 }] }],
+        });
+        let current = elt.spans[0].points.at(-1);
+        if (current) {
+            current.count += point.count;
+            current.sum += point.sum;
+        }
+        elt.count += point.count;
+        elt.sum += point.sum;
+        if (buffer.force ||
+            (buffer.sum && elt.sum >= buffer.sum) ||
+            (buffer.count && elt.count >= buffer.count) ||
+            timestamp >= elt.timestamp) {
+            options = Object.assign({}, options, { timestamp: timestamp * 1000 });
+            let metric = await this.emitDimensionedMetric(namespace, metricName, elt, dimensions, options);
+            elt.count = elt.sum = 0;
+            elt.spans = metric.spans;
+            elt.timestamp = timestamp + (buffer.elapsed || this.spans[0].period / this.spans[0].samples);
+            return metric;
+        }
+        CustomMetrics.saveInstance({ key }, this);
+        return {
+            spans: elt.spans,
+            metric: metricName,
+            namespace: namespace,
+            owner: options.owner || this.owner,
+            version: Version,
+        };
+    }
+    async emitDimensionedMetric(namespace, metricName, point, dimensions, options = {}) {
+        let timestamp = Math.floor((options.timestamp || Date.now()) / 1000);
+        let ttl = options.ttl != undefined ? options.ttl : this.ttl;
+        let retries = MaxRetries;
+        let metric;
+        let backoff = 10;
+        let chan = options.log == true ? 'info' : 'trace';
+        do {
+            let owner = options.owner || this.owner;
+            metric = await this.getMetric(owner, namespace, metricName, dimensions, options.log);
+            if (metric) {
+                if (options.upgrade) {
+                    metric = this.upgradeMetric(metric);
+                }
+            }
+            else {
+                metric = this.initMetric(owner, namespace, metricName, dimensions, timestamp);
+            }
+            if (point.timestamp) {
+                let si = metric.spans.findIndex((s) => s.end - s.period <= point.timestamp || s.end <= point.timestamp);
+                if (si >= 0) {
+                    this.addValue(metric, point.timestamp, point, si);
+                }
+                else {
+                }
+            }
+            else {
+                this.addValue(metric, timestamp, point, 0);
+            }
+            if (this.source) {
+                metric._source = this.source;
+            }
+            if (ttl) {
+                metric.expires = timestamp + ttl;
+            }
+            if (await this.putMetric(metric, options)) {
+                break;
+            }
+            if (retries == 0) {
+                this.log.error(`Metric update has too many retries`, { namespace, metricName, dimensions });
+                break;
+            }
+            this.log[chan](`Retry ${MaxRetries - retries} metric update ${metric.namespace} ${metric.metric} ${metric.dimensions}`, {
+                retries,
+                metric,
+            });
+            backoff = backoff * 2;
+            this.log[chan](`Retry backoff ${backoff} ${this.jitter(backoff)}`);
+            await this.delay(this.jitter(backoff));
+        } while (retries-- > 0);
+        return metric;
+    }
+    async upgrade(namespace, metricName, dimensionsList = [{}], options = {}) {
+        let owner = options.owner || this.owner;
+        if (dimensionsList.length == 0) {
+            dimensionsList = [{}];
+        }
+        let metric;
+        for (let dim of dimensionsList) {
+            let dimensions = this.makeDimensionString(dim);
+            let old = await this.getMetric(owner, namespace, metricName, dimensions, options.log);
+            metric = this.upgradeMetric(old);
+            await this.putMetric(metric, options);
+        }
+        return metric;
+    }
+    upgradeMetric(old) {
+        let required = false;
+        if (this.spans.length == old.spans.length) {
+            for (let [index, span] of Object.entries(old.spans)) {
+                if (span.period != this.spans[index].period || span.samples != this.spans[index].samples) {
+                    required = true;
+                }
+            }
+            if (!required) {
+                return old;
+            }
+        }
+        let timestamp = Math.min(...old.spans.map((span) => span.end - span.period)) || Math.floor(Date.now() / 1000);
+        let metric = this.initMetric(old.owner, old.namespace, old.metric, old.dimensions, timestamp);
+        for (let span of old.spans) {
+            let interval = span.period / span.samples;
+            let timestamp = span.end - span.points.length * interval;
+            let si = metric.spans.findIndex((s) => s.end - s.period <= timestamp || s.end <= timestamp);
+            for (let point of span.points) {
+                this.addValue(metric, timestamp, point, si);
+                timestamp += interval;
+            }
+        }
+        return metric;
+    }
+    static async terminate() {
+        await CustomMetrics.flushAll();
+    }
+    static async flushAll() {
+        for (let [key, instance] of Object.entries(Instances)) {
+            await instance.flush();
+            CustomMetrics.freeInstanceByKey(key);
+        }
+        Instances = {};
+    }
+    async flush() {
+        if (!this.buffers)
+            return;
+        let now = Date.now() / 1000;
+        for (let elt of Object.values(this.buffers)) {
+            await this.flushElt(elt, now);
+        }
+    }
+    async flushElt(elt, timestamp) {
+        elt.timestamp = Math.min(timestamp, elt.timestamp);
+        let metric = await this.emitDimensionedMetric(elt.namespace, elt.metric, elt, elt.dimensions, {
+            timestamp: elt.timestamp * 1000,
+        });
+        elt.count = elt.sum = 0;
+        elt.spans = metric.spans;
+        elt.timestamp = timestamp + (elt.elapsed || this.spans[0].period / this.spans[0].samples);
+    }
+    getBufferKey(namespace, metricName, dimensions) {
+        return `${namespace}|${metricName}|${JSON.stringify(dimensions)}`;
+    }
+    async query(namespace, metricName, dimensions, period, statistic, options = {}) {
+        let owner = options.owner || this.owner;
+        let dimString = this.makeDimensionString(dimensions);
+        if (period > this.spans.at(-1).period) {
+            period = this.spans.at(-1).period;
+        }
+        let timestamp = Math.floor((options.timestamp || Date.now()) / 1000);
+        if (this.buffers) {
+            let key = this.getBufferKey(namespace, metricName, dimString);
+            if (this.buffers[key]) {
+                await this.flushElt(this.buffers[key], timestamp);
+            }
+        }
+        let metric = await this.getMetric(owner, namespace, metricName, dimString, options.log);
+        if (!metric) {
+            return { dimensions, id: options.id, metric: metricName, namespace, period, points: [], owner, samples: 0 };
+        }
+        let start;
+        let si;
+        if (options.start) {
+            start = options.start / 1000;
+            si = metric.spans.findIndex((s) => period <= s.period && s.end - s.period <= start && start <= s.end);
+        }
+        else {
+            let span = metric.spans[0];
+            let interval = span.period / span.samples;
+            let t = this.roundTime(span, timestamp + 1);
+            if (span.end - interval <= t && t <= span.end) {
+                start = t - period;
+            }
+            else {
+                start = timestamp - period;
+            }
+            si = metric.spans.findIndex((s) => period <= s.period);
+        }
+        if (si < 0) {
+            si = metric.spans.length - 1;
+        }
+        let span = metric.spans[si];
+        start = this.roundTime(span, start);
+        this.addValue(metric, timestamp, { count: 0, sum: 0 }, 0, si);
+        let result;
+        if (options.accumulate) {
+            result = this.accumulateMetric(metric, span, statistic, owner, start, period);
+        }
+        else {
+            result = this.calculateSeries(metric, span, statistic, owner, start, period);
+        }
+        result.id = options.id;
+        this.log[options.log == true ? 'info' : 'trace'](`Query metrics ${namespace}, ${metricName}`, {
+            dimensions,
+            period,
+            statistic,
+            options,
+            result,
+        });
+        return result;
+    }
+    accumulateMetric(metric, span, statistic, owner, start, period) {
+        let value = 0, count = 0, pvalues = [];
+        if (statistic == 'max') {
+            value = Number.NEGATIVE_INFINITY;
+        }
+        else if (statistic == 'min') {
+            value = Infinity;
+        }
+        else if (statistic == 'sum') {
+            value = 0;
+            count = 0;
+        }
+        else if (statistic == 'count') {
+            value = 0;
+            count = 0;
+        }
+        else if (statistic == 'current') {
+            value = 0;
+            count = 0;
+        }
+        else if (statistic.match(/^p[0-9]+/)) {
+            pvalues = [];
+        }
+        else {
+            value = 0;
+            count = 0;
+        }
+        let points = span.points;
+        let interval = span.period / span.samples;
+        let t = span.end - span.points.length * interval;
+        for (let i = 0; i < points.length; i++) {
+            let point = points[i];
+            if (start <= t && t < start + period) {
+                if (statistic == 'max') {
+                    if (point.max != undefined) {
+                        value = Math.max(value, point.max);
+                    }
+                    else {
+                        value = Math.max(value, point.sum / (point.count || 1));
+                    }
+                }
+                else if (statistic == 'min') {
+                    if (point.min != undefined) {
+                        value = Math.min(value, point.min);
+                    }
+                    else {
+                        value = Math.min(value, point.sum / (point.count || 1));
+                    }
+                }
+                else if (statistic == 'sum') {
+                    value += point.sum;
+                }
+                else if (statistic == 'current') {
+                    value = point.sum / (point.count || 1);
+                }
+                else if (statistic == 'count') {
+                    value += point.count;
+                }
+                else if (statistic.match(/^p[0-9]+/)) {
+                    pvalues = pvalues.concat(point.pvalues);
+                }
+                else {
+                    value += point.sum;
+                }
+                count += point.count;
+            }
+            t += interval;
+        }
+        if (statistic.match(/^p[0-9]+/)) {
+            let p = parseInt(statistic.slice(1));
+            pvalues.sort((a, b) => a - b);
+            let nth = Math.min(Math.round((pvalues.length * p) / 100 + 1), pvalues.length - 1);
+            value = pvalues[nth];
+        }
+        else if (statistic == 'avg') {
+            value /= Math.max(count, 1);
+        }
+        return {
+            dimensions: this.makeDimensionObject(metric.dimensions),
+            metric: metric.metric,
+            namespace: metric.namespace,
+            owner: owner,
+            period: span.period,
+            points: [{ value, timestamp: start + period, count }],
+            samples: span.samples,
+        };
+    }
+    calculateSeries(metric, span, statistic, owner, start, period) {
+        let points = [];
+        let interval = span.period / span.samples;
+        let t;
+        let firstPoint = span.end - span.points.length * interval;
+        let count = Math.floor((firstPoint - start) / interval);
+        for (t = start; t < firstPoint && points.length < span.samples; t += interval) {
+            points.push({ value: 0, count: 0, timestamp: t * 1000 });
+        }
+        t = firstPoint;
+        for (let point of span.points) {
+            if (start <= t && t < start + period) {
+                let value = undefined;
+                if (point.count > 0) {
+                    if (statistic == 'max') {
+                        if (point.max != undefined) {
+                            if (value == undefined) {
+                                value = point.max;
+                            }
+                            else {
+                                value = Math.max(value, point.max);
+                            }
+                        }
+                    }
+                    else if (statistic == 'min') {
+                        if (point.min != undefined) {
+                            if (value == undefined) {
+                                value = point.min;
+                            }
+                            else {
+                                value = Math.min(value, point.min);
+                            }
+                        }
+                    }
+                    else if (statistic == 'sum') {
+                        value = point.sum;
+                    }
+                    else if (statistic == 'count') {
+                        value = point.count;
+                    }
+                    else if (statistic.match(/^p[0-9]+/)) {
+                        let p = parseInt(statistic.slice(1));
+                        let pvalues = point.pvalues;
+                        pvalues.sort((a, b) => a - b);
+                        let nth = Math.min(Math.round((pvalues.length * p) / 100 + 1), pvalues.length - 1);
+                        value = pvalues[nth];
+                    }
+                    else {
+                        value = point.sum / point.count;
+                    }
+                }
+                else {
+                    value = 0;
+                }
+                points.push({ value, count: point.count, timestamp: (t + interval) * 1000 });
+            }
+            t += interval;
+        }
+        count = Math.ceil(period / interval);
+        while (points.length < count) {
+            points.push({ value: 0, count: 0, timestamp: t * 1000 });
+            t += interval;
+        }
+        return {
+            dimensions: this.makeDimensionObject(metric.dimensions),
+            metric: metric.metric,
+            namespace: metric.namespace,
+            period: span.period,
+            points: points,
+            owner: owner,
+            samples: span.samples,
+        };
+    }
+    makeDimensionString(dimensions) {
+        let result = [];
+        let entries = Object.entries(dimensions).sort((a, b) => a[0].localeCompare(b[0]));
+        for (let [name, value] of entries) {
+            result.push(`${name}=${value}`);
+        }
+        return result.join(',');
+    }
+    makeDimensionObject(dimensions) {
+        let result = {};
+        for (let dimension of dimensions.split(',')) {
+            if (dimension) {
+                let [key, value] = dimension.split('=');
+                result[key] = value;
+            }
+        }
+        return result;
+    }
+    addValue(metric, timestamp, point, si, querySpanIndex = undefined) {
+        this.assert(metric);
+        this.assert(timestamp);
+        this.assert(0 <= si && si < metric.spans.length);
+        let span = metric.spans[si];
+        let interval = span.period / span.samples;
+        let points = span.points || [];
+        let queryRecurse = si < querySpanIndex && si + 1 < metric.spans.length;
+        while (points.length > span.samples) {
+            points.shift();
+        }
+        let first = span.end - points.length * interval;
+        let shift = 0;
+        if (points.length) {
+            if (queryRecurse) {
+                shift = points.length;
+            }
+            else if (timestamp >= first) {
+                shift = Math.floor((timestamp - first) / interval) - span.samples;
+                if (!queryRecurse && point.count && timestamp >= span.end) {
+                    shift += 1;
+                }
+            }
+            shift = Math.max(0, Math.min(shift, points.length));
+            this.assert(0 <= shift && shift <= points.length);
+            for (let i = 0; i < shift; i++) {
+                let p = points.shift();
+                if (p.count && si + 1 < metric.spans.length) {
+                    this.addValue(metric, first, p, si + 1, querySpanIndex);
+                }
+                first += interval;
+            }
+        }
+        if (queryRecurse) {
+            this.addValue(metric, timestamp, point, si + 1, querySpanIndex);
+            return;
+        }
+        if (point.count) {
+            let index;
+            if (points.length == 0) {
+                points.push({ count: 0, sum: 0 });
+                span.end = this.roundTime(span, timestamp + 1);
+                first = span.end - interval;
+                index = 0;
+            }
+            else {
+                if (timestamp < span.end - span.period) {
+                    return;
+                }
+                while (timestamp < first) {
+                    points.unshift({ count: 0, sum: 0 });
+                    first -= interval;
+                }
+                while (timestamp >= span.end) {
+                    points.push({ count: 0, sum: 0 });
+                    span.end += interval;
+                }
+                index = Math.floor((timestamp - first) / interval);
+            }
+            this.assert(points.length <= span.samples);
+            if (!(0 <= index && index < points.length)) {
+                this.assert(0 <= index && index < points.length);
+                if (index > 0) {
+                    index = points.length - 1;
+                }
+            }
+            this.setPoint(span, index, point);
+        }
+    }
+    setPoint(span, index, add) {
+        let points = span.points;
+        this.assert(0 <= index && index < points.length);
+        let point = points[index];
+        if (!point) {
+            this.log.error(`Metric null point`, { span, index, add });
+            return;
+        }
+        if (add.count) {
+            let value = add.sum / add.count;
+            if (point.min == undefined) {
+                point.min = value;
+            }
+            else {
+                point.min = Math.min(value, point.min);
+            }
+            if (point.max == undefined) {
+                point.max = value;
+            }
+            else {
+                point.max = Math.max(value, point.max);
+            }
+        }
+        if (this.pResolution) {
+            point.pvalues = point.pvalues || [];
+            if (add.pvalues) {
+                point.pvalues.push(...add.pvalues);
+            }
+            else {
+                point.pvalues.push(add.sum / add.count);
+            }
+            point.pvalues.splice(0, point.pvalues.length - this.pResolution);
+        }
+        point.sum += add.sum;
+        point.count += add.count;
+    }
+    async getMetricList(namespace = undefined, metric = undefined, options = { limit: MetricListLimit }) {
+        let map = {};
+        let owner = options.owner || this.owner;
+        let next = options.next;
+        let limit = options.limit || MetricListLimit;
+        let chan = options.log == true ? 'info' : 'trace';
+        let items, command;
+        let count = 0;
+        do {
+            ;
+            ({ command, items, next } = await this.findMetrics(owner, namespace, metric, limit, next));
+            this.log[chan](`Find metrics ${namespace}, ${metric}`, { command, items });
+            if (items.length) {
+                for (let item of items) {
+                    let ns = (map[item.namespace] = map[item.namespace] || {});
+                    let met = (ns[item.metric] = ns[item.metric] || []);
+                    met.push(item.dimensions);
+                }
+                count += items.length;
+            }
+        } while (next && count < limit);
+        let result = { namespaces: Object.keys(map) };
+        if (namespace && map[namespace]) {
+            result.metrics = Object.keys(map[namespace]);
+            if (metric) {
+                let dimensions = map[namespace][metric];
+                if (dimensions) {
+                    result.dimensions = [];
+                    dimensions = dimensions.sort().filter((v, index, self) => self.indexOf(v) === index);
+                    for (let dimension of dimensions) {
+                        result.dimensions.push(this.makeDimensionObject(dimension));
+                    }
+                }
+            }
+        }
+        return result;
+    }
+    initMetric(owner, namespace, name, dimensions, timestamp) {
+        let metric = {
+            dimensions,
+            metric: name,
+            namespace,
+            owner,
+            spans: [],
+            version: Version,
+        };
+        for (let sdef of this.spans) {
+            let span = {
+                samples: sdef.samples,
+                period: sdef.period,
+                end: timestamp,
+                points: [],
+            };
+            span.end = this.roundTime(span, timestamp + 1);
+            metric.spans.push(span);
+        }
+        return metric;
+    }
+    async getMetric(owner, namespace, metric, dimensions, log) {
+        let command = new client_dynamodb_1.GetItemCommand({
+            TableName: this.table,
+            Key: {
+                [this.primaryKey]: { S: `${this.prefix}#${Version}#${owner}` },
+                [this.sortKey]: { S: `${this.prefix}#${namespace}#${metric}#${dimensions}` },
+            },
+            ConsistentRead: this.consistent,
+        });
+        let data = await this.client.send(command);
+        let result = null;
+        if (data && data.Item) {
+            let item = (0, util_dynamodb_1.unmarshall)(data.Item);
+            result = this.mapItemFromDB(item);
+        }
+        if (log == true) {
+            let chan = log == true ? 'info' : 'trace';
+            this.log[chan](`GetMetric ${namespace}, ${metric} ${dimensions}`, { cmd: command, result });
+        }
+        return result;
+    }
+    async findMetrics(owner, namespace, metric, limit, startKey) {
+        let key = [namespace];
+        if (metric) {
+            key.push(metric);
+        }
+        let start = startKey ? (0, util_dynamodb_1.marshall)(startKey) : undefined;
+        let command = new client_dynamodb_1.QueryCommand({
+            TableName: this.table,
+            ExpressionAttributeNames: {
+                '#_0': this.primaryKey,
+                '#_1': this.sortKey,
+            },
+            ExpressionAttributeValues: {
+                ':_0': { S: `${this.prefix}#${Version}#${owner}` },
+                ':_1': { S: `${this.prefix}#${key.join('#')}` },
+            },
+            KeyConditionExpression: '#_0 = :_0 and begins_with(#_1, :_1)',
+            ConsistentRead: this.consistent,
+            Limit: limit,
+            ScanIndexForward: true,
+            ExclusiveStartKey: start,
+            ProjectionExpression: `${this.primaryKey}, ${this.sortKey}`,
+        });
+        let result = await this.client.send(command);
+        let items = [];
+        if (result.Items) {
+            for (let i = 0; i < result.Items.length; i++) {
+                let item = (0, util_dynamodb_1.unmarshall)(result.Items[i]);
+                items.push(this.mapItemFromDB(item));
+            }
+        }
+        let next = undefined;
+        if (result.LastEvaluatedKey) {
+            next = (0, util_dynamodb_1.unmarshall)(result.LastEvaluatedKey);
+        }
+        return { items, next, command };
+    }
+    async putMetric(item, options) {
+        let ConditionExpression, ExpressionAttributeValues;
+        let seq;
+        if (item.seq != undefined) {
+            seq = item.seq = item.seq || 0;
+            if (item.seq++ >= MaxSeq) {
+                item.seq = 0;
+            }
+            ConditionExpression = `seq = :_0`;
+            ExpressionAttributeValues = { ':_0': { N: seq.toString() } };
+        }
+        else {
+            item.seq = 0;
+        }
+        let mapped = this.mapItemToDB(item);
+        let params = {
+            TableName: this.table,
+            ReturnValues: 'NONE',
+            Item: (0, util_dynamodb_1.marshall)(mapped, { removeUndefinedValues: true }),
+            ConditionExpression,
+            ExpressionAttributeValues,
+        };
+        let command = new client_dynamodb_1.PutItemCommand(params);
+        let chan = options.log == true ? 'info' : 'trace';
+        this.log[chan](`Put metric ${item.namespace}, ${item.metric}`, {
+            dimensions: item.dimensions,
+            command,
+            params,
+            item,
+        });
+        try {
+            await this.client.send(command);
+            return true;
+        }
+        catch (err) {
+            ;
+            (function (err, log) {
+                let code = err.code || err.name;
+                if (code == 'ConditionalCheckFailedException') {
+                    log.trace(`Update collision`, { err });
+                }
+                else if (code == 'ProvisionedThroughputExceededException') {
+                    log.info(`Provisioned throughput exceeded: ${err.message}`, { err, cmd: command, item });
+                }
+                else {
+                    log.error(`Emit exception code ${err.name} ${err.code} message ${err.message}`, {
+                        err,
+                        cmd: command,
+                        item,
+                    });
+                    throw err;
+                }
+                return false;
+            })(err, this.log);
+        }
+    }
+    mapItemFromDB(data) {
+        let pk = data[this.primaryKey];
+        let sk = data[this.sortKey];
+        let owner = pk.split('#').pop();
+        let [, namespace, metric, dimensions] = sk.split('#');
+        let spans;
+        if (data.spans) {
+            spans = data.spans.map((s) => {
+                return {
+                    end: s.se,
+                    period: s.sp,
+                    samples: s.ss,
+                    points: s.pt.map((p) => {
+                        let point = { count: Number(p.c), sum: Number(p.s) };
+                        if (p.x != null) {
+                            point.max = Number(p.x);
+                        }
+                        if (p.m != null) {
+                            point.min = Number(p.m);
+                        }
+                        if (p.v) {
+                            point.pvalues = p.v;
+                        }
+                        return point;
+                    }),
+                };
+            });
+        }
+        let expires = data[this.expires];
+        let seq = data.seq;
+        return { dimensions, expires, metric, namespace, owner, seq, spans };
+    }
+    mapItemToDB(item) {
+        let result = {
+            [this.primaryKey]: `${this.prefix}#${Version}#${item.owner}`,
+            [this.sortKey]: `${this.prefix}#${item.namespace}#${item.metric}#${item.dimensions}`,
+            [this.expires]: item.expires,
+            spans: item.spans.map((i) => {
+                return {
+                    se: i.end,
+                    sp: i.period,
+                    ss: i.samples,
+                    pt: i.points.map((point) => {
+                        let p = { c: point.count, s: this.round(point.sum) };
+                        if (point.max != null) {
+                            p.x = this.round(point.max);
+                        }
+                        if (point.min != null) {
+                            p.m = this.round(point.min);
+                        }
+                        if (point.pvalues) {
+                            p.v = point.pvalues;
+                        }
+                        return p;
+                    }),
+                };
+            }),
+            seq: item.seq,
+            _source: item._source,
+        };
+        if (this.type) {
+            let [key, model] = Object.entries(this.type)[0];
+            result[key] = model;
+        }
+        return result;
+    }
+    static freeInstanceByKey(key) {
+        delete Instances[key];
+    }
+    static saveInstance(tags, metrics) {
+        let key = JSON.stringify(tags);
+        Instances[key] = metrics;
+    }
+    roundTime(span, timestamp) {
+        let interval = span.period / span.samples;
+        return Math.ceil(timestamp / interval) * interval;
+    }
+    assert(c) {
+        if (!c && Assert) {
+            let msg = { stack: '' };
+            if (typeof Error.captureStackTrace === 'function') {
+                Error.captureStackTrace(msg);
+            }
+            else {
+                msg.stack = new Error('Assert').stack;
+            }
+            this.log.error(`Assertion failed`, { stack: msg.stack });
+        }
+    }
+    info(message, context = {}) {
+        console.log('INFO: ' + message, context);
+    }
+    error(message, context = {}) {
+        console.log('ERROR: ' + message, context);
+    }
+    trace(message, context = {}) {
+        console.log('TRACE: ' + message, context);
+    }
+    round(n) {
+        if (isNaN(n) || n == null) {
+            return 0;
+        }
+        let places = 16 - n.toFixed(0).length;
+        return Number(n.toFixed(places)) - 0;
+    }
+    jitter(msecs) {
+        return Math.min(10 * 1000, Math.floor(msecs / 2 + msecs * Math.random()));
+    }
+    async delay(time) {
+        return new Promise(function (resolve, reject) {
+            setTimeout(() => resolve(true), time);
+        });
+    }
+}
+exports.CustomMetrics = CustomMetrics;
+class Log {
+    constructor(dest) {
+        this.senselogs = null;
+        this.logger = null;
+        this.verbose = false;
+        if (dest === true) {
+            this.logger = this.defaultLogger;
+        }
+        else if (dest == 'verbose') {
+            this.logger = this.defaultLogger;
+            this.verbose = true;
+        }
+        else if (dest && typeof dest.info == 'function') {
+            this.senselogs = dest;
+        }
+    }
+    error(message, context) {
+        this.process('error', message, context);
+    }
+    info(message, context) {
+        this.process('info', message, context);
+    }
+    trace(message, context) {
+        this.process('trace', message, context);
+    }
+    process(chan, message, context) {
+        if (this.logger) {
+            this.logger(chan, message, context);
+        }
+        else if (this.senselogs) {
+            this.senselogs[chan](message, context);
+        }
+    }
+    defaultLogger(chan, message, context) {
+        if (chan == 'trace' && !this.verbose) {
+            return;
+        }
+        let tag = chan.toUpperCase();
+        if (context) {
+            try {
+                console.log(tag, message, JSON.stringify(context, null, 4));
+            }
+            catch (err) {
+                let buf = ['{'];
+                for (let [key, value] of Object.entries(context)) {
+                    try {
+                        buf.push(`    ${key}: ${JSON.stringify(value, null, 4)}`);
+                    }
+                    catch (err) {
+                    }
+                }
+                buf.push('}');
+                console.log(tag, message, buf.join('\n'));
+            }
+        }
+        else {
+            console.log(tag, message);
+        }
+    }
+}
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/dist/mjs/index.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/dist/mjs/index.d.ts
new file mode 100644
index 0000000..10b2449
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/dist/mjs/index.d.ts
@@ -0,0 +1,173 @@
+export const DefaultSpans: {
+    period: number;
+    samples: number;
+}[];
+export class CustomMetrics {
+    static terminate(): Promise<void>;
+    static flushAll(): Promise<void>;
+    static freeInstanceByKey(key: any): void;
+    static saveInstance(tags: any, metrics: any): void;
+    constructor(options?: {});
+    consistent: boolean;
+    buffer: any;
+    buffers: any;
+    client: any;
+    expires: any;
+    log: Log;
+    options: {};
+    owner: any;
+    prefix: string;
+    primaryKey: any;
+    sortKey: any;
+    pResolution: any;
+    source: any;
+    spans: any;
+    table: any;
+    type: any;
+    ttl: any;
+    emit(namespace: any, metricName: any, value: any, dimensionsList?: {}[], options?: {}): Promise<any>;
+    emitDimensions(namespace: any, metricName: any, point: any, dimensionsList: any, options: any): Promise<any>;
+    bufferMetric(namespace: any, metricName: any, point: any, dimensions: any, options: any): Promise<any>;
+    emitDimensionedMetric(namespace: any, metricName: any, point: any, dimensions: any, options?: {}): Promise<any>;
+    upgrade(namespace: any, metricName: any, dimensionsList?: {}[], options?: {}): Promise<any>;
+    upgradeMetric(old: any): any;
+    flush(): Promise<void>;
+    flushElt(elt: any, timestamp: any): Promise<void>;
+    getBufferKey(namespace: any, metricName: any, dimensions: any): string;
+    query(namespace: any, metricName: any, dimensions: any, period: any, statistic: any, options?: {}): Promise<{
+        dimensions: {};
+        metric: any;
+        namespace: any;
+        owner: any;
+        period: any;
+        points: {
+            value: number;
+            timestamp: any;
+            count: number;
+        }[];
+        samples: any;
+    } | {
+        dimensions: {};
+        metric: any;
+        namespace: any;
+        period: any;
+        points: {
+            value: any;
+            count: any;
+            timestamp: number;
+        }[];
+        owner: any;
+        samples: any;
+    } | {
+        dimensions: any;
+        id: any;
+        metric: any;
+        namespace: any;
+        period: any;
+        points: any[];
+        owner: any;
+        samples: number;
+    }>;
+    accumulateMetric(metric: any, span: any, statistic: any, owner: any, start: any, period: any): {
+        dimensions: {};
+        metric: any;
+        namespace: any;
+        owner: any;
+        period: any;
+        points: {
+            value: number;
+            timestamp: any;
+            count: number;
+        }[];
+        samples: any;
+    };
+    calculateSeries(metric: any, span: any, statistic: any, owner: any, start: any, period: any): {
+        dimensions: {};
+        metric: any;
+        namespace: any;
+        period: any;
+        points: {
+            value: any;
+            count: any;
+            timestamp: number;
+        }[];
+        owner: any;
+        samples: any;
+    };
+    makeDimensionString(dimensions: any): string;
+    makeDimensionObject(dimensions: any): {};
+    addValue(metric: any, timestamp: any, point: any, si: any, querySpanIndex?: any): void;
+    setPoint(span: any, index: any, add: any): void;
+    getMetricList(namespace?: any, metric?: any, options?: {
+        limit: number;
+    }): Promise<{
+        namespaces: string[];
+    }>;
+    initMetric(owner: any, namespace: any, name: any, dimensions: any, timestamp: any): {
+        dimensions: any;
+        metric: any;
+        namespace: any;
+        owner: any;
+        spans: any[];
+        version: number;
+    };
+    getMetric(owner: any, namespace: any, metric: any, dimensions: any, log: any): Promise<{
+        dimensions: any;
+        expires: any;
+        metric: any;
+        namespace: any;
+        owner: any;
+        seq: any;
+        spans: any;
+    }>;
+    findMetrics(owner: any, namespace: any, metric: any, limit: any, startKey: any): Promise<{
+        items: {
+            dimensions: any;
+            expires: any;
+            metric: any;
+            namespace: any;
+            owner: any;
+            seq: any;
+            spans: any;
+        }[];
+        next: Record<string, any>;
+        command: QueryCommand;
+    }>;
+    putMetric(item: any, options: any): Promise<boolean>;
+    mapItemFromDB(data: any): {
+        dimensions: any;
+        expires: any;
+        metric: any;
+        namespace: any;
+        owner: any;
+        seq: any;
+        spans: any;
+    };
+    mapItemToDB(item: any): {
+        [x: number]: any;
+        spans: any;
+        seq: any;
+        _source: any;
+    };
+    roundTime(span: any, timestamp: any): number;
+    assert(c: any): void;
+    info(message: any, context?: {}): void;
+    error(message: any, context?: {}): void;
+    trace(message: any, context?: {}): void;
+    round(n: any): number;
+    jitter(msecs: any): number;
+    delay(time: any): Promise<any>;
+}
+declare class Log {
+    constructor(dest: any);
+    senselogs: any;
+    logger: any;
+    verbose: boolean;
+    error(message: any, context: any): void;
+    info(message: any, context: any): void;
+    trace(message: any, context: any): void;
+    process(chan: any, message: any, context: any): void;
+    defaultLogger(chan: any, message: any, context: any): void;
+}
+import { QueryCommand } from '@aws-sdk/client-dynamodb';
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/dist/mjs/index.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/dist/mjs/index.js
new file mode 100644
index 0000000..ab5f5ad
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/dist/mjs/index.js
@@ -0,0 +1,989 @@
+import process from 'process';
+import { DynamoDBClient, GetItemCommand, PutItemCommand, QueryCommand, } from '@aws-sdk/client-dynamodb';
+import { marshall, unmarshall } from '@aws-sdk/util-dynamodb';
+const Version = 1;
+const Assert = true;
+const Buffering = true;
+const DefaultResolution = 0;
+const MaxSeq = Number.MAX_SAFE_INTEGER;
+const MaxRetries = 10;
+const MetricListLimit = 10000;
+export const DefaultSpans = [
+    { period: 5 * 60, samples: 10 },
+    { period: 60 * 60, samples: 12 },
+    { period: 24 * 60 * 60, samples: 12 },
+    { period: 7 * 24 * 60 * 60, samples: 14 },
+    { period: 28 * 24 * 60 * 60, samples: 14 },
+    { period: 365 * 24 * 60 * 60, samples: 12 },
+];
+var Instances = {};
+process.on('SIGTERM', async () => {
+    await CustomMetrics.terminate();
+});
+export class CustomMetrics {
+    consistent = false;
+    buffer;
+    buffers = null;
+    client;
+    expires;
+    log;
+    options;
+    owner;
+    prefix = 'metric';
+    primaryKey;
+    sortKey;
+    pResolution;
+    source;
+    spans;
+    table;
+    type;
+    ttl;
+    constructor(options = {}) {
+        this.log = new Log(options.log);
+        if (options.ttl && typeof options.ttl != 'number') {
+            throw new Error('Bad type for "ttl" option');
+        }
+        if (options.spans && (!Array.isArray(options.spans) || options.spans.length == 0)) {
+            throw new Error('The "spans" option must be an non-empty array');
+        }
+        if (options.source && typeof options.source != 'string') {
+            throw new Error('Non-string "source" option');
+        }
+        if (options.pResolution != undefined && (options.pResolution < 0 || options.pResolution > 1000)) {
+            throw new Error('Invalid "pResolution" option. Must be between 0 and 1000. Default is 0');
+        }
+        if (options.consistent != null && typeof options.consistent != 'boolean') {
+            throw new Error('Bad type for "consistent" option');
+        }
+        if (options.prefix) {
+            this.prefix = options.prefix;
+        }
+        if (options.buffer) {
+            if (typeof options.buffer != 'object') {
+                throw new Error('Bad type for "buffer" option');
+            }
+            this.buffer = options.buffer;
+        }
+        this.expires = options.expires || 'expires';
+        this.primaryKey = options.primaryKey || 'pk';
+        this.sortKey = options.sortKey || 'sk';
+        this.type = options.type || { _type: 'Metric' };
+        if (options.client) {
+            this.client = options.client;
+        }
+        else {
+            let params = {};
+            if (options.creds) {
+                params.credentials = options.creds;
+                params.region = params.credentials.region;
+            }
+            if (options.region) {
+                params.region = options.region;
+            }
+            this.client = new DynamoDBClient(params);
+        }
+        if (!options.table) {
+            throw new Error('Missing DynamoDB table name property');
+        }
+        this.table = options.table;
+        this.options = options;
+        this.owner = options.owner || 'default';
+        this.spans = options.spans || DefaultSpans;
+        this.ttl = options.ttl || this.spans[this.spans.length - 1].period;
+        if (options.consistent != null) {
+            this.consistent = options.consistent;
+        }
+        if (options.source) {
+            this.source = options.source;
+        }
+        this.pResolution = options.pResolution || DefaultResolution;
+    }
+    async emit(namespace, metricName, value, dimensionsList = [{}], options = {}) {
+        if (value == undefined || value == null) {
+            throw new Error('Invalid metric value');
+        }
+        if (dimensionsList.length == 0) {
+            dimensionsList = [{}];
+        }
+        value = Number(value);
+        if (isNaN(value)) {
+            throw new Error(`Value to emit is not valid`);
+        }
+        if (!namespace || !metricName) {
+            throw new Error('Missing emit namespace / metric argument');
+        }
+        if (!Array.isArray(dimensionsList)) {
+            throw new Error('Dimensions must be an array');
+        }
+        if (dimensionsList.length == 0) {
+            dimensionsList = [{}];
+        }
+        let point;
+        point = { count: 1, sum: value };
+        return await this.emitDimensions(namespace, metricName, point, dimensionsList, options);
+    }
+    async emitDimensions(namespace, metricName, point, dimensionsList, options) {
+        let result;
+        for (let dim of dimensionsList) {
+            let dimensions = this.makeDimensionString(dim);
+            let buffer = options.buffer || this.buffer;
+            if (buffer && (buffer.elapsed || buffer.force || buffer.sum || buffer.count) && Buffering) {
+                result = await this.bufferMetric(namespace, metricName, point, dimensions, options);
+            }
+            else {
+                result = await this.emitDimensionedMetric(namespace, metricName, point, dimensions, options);
+            }
+        }
+        return result;
+    }
+    async bufferMetric(namespace, metricName, point, dimensions, options) {
+        let buffer = options.buffer || this.buffer;
+        let key = this.getBufferKey(namespace, metricName, dimensions);
+        let buffers = (this.buffers = this.buffers || {});
+        let timestamp = Math.floor((options.timestamp || Date.now()) / 1000);
+        let elapsed = buffer.elapsed || this.spans[0].period / this.spans[0].samples;
+        let elt = (buffers[key] = buffers[key] || {
+            count: 0,
+            sum: 0,
+            timestamp: timestamp + elapsed,
+            elapsed: elapsed,
+            namespace: namespace,
+            metric: metricName,
+            dimensions,
+            spans: [{ points: [{ count: 0, sum: 0 }] }],
+        });
+        let current = elt.spans[0].points.at(-1);
+        if (current) {
+            current.count += point.count;
+            current.sum += point.sum;
+        }
+        elt.count += point.count;
+        elt.sum += point.sum;
+        if (buffer.force ||
+            (buffer.sum && elt.sum >= buffer.sum) ||
+            (buffer.count && elt.count >= buffer.count) ||
+            timestamp >= elt.timestamp) {
+            options = Object.assign({}, options, { timestamp: timestamp * 1000 });
+            let metric = await this.emitDimensionedMetric(namespace, metricName, elt, dimensions, options);
+            elt.count = elt.sum = 0;
+            elt.spans = metric.spans;
+            elt.timestamp = timestamp + (buffer.elapsed || this.spans[0].period / this.spans[0].samples);
+            return metric;
+        }
+        CustomMetrics.saveInstance({ key }, this);
+        return {
+            spans: elt.spans,
+            metric: metricName,
+            namespace: namespace,
+            owner: options.owner || this.owner,
+            version: Version,
+        };
+    }
+    async emitDimensionedMetric(namespace, metricName, point, dimensions, options = {}) {
+        let timestamp = Math.floor((options.timestamp || Date.now()) / 1000);
+        let ttl = options.ttl != undefined ? options.ttl : this.ttl;
+        let retries = MaxRetries;
+        let metric;
+        let backoff = 10;
+        let chan = options.log == true ? 'info' : 'trace';
+        do {
+            let owner = options.owner || this.owner;
+            metric = await this.getMetric(owner, namespace, metricName, dimensions, options.log);
+            if (metric) {
+                if (options.upgrade) {
+                    metric = this.upgradeMetric(metric);
+                }
+            }
+            else {
+                metric = this.initMetric(owner, namespace, metricName, dimensions, timestamp);
+            }
+            if (point.timestamp) {
+                let si = metric.spans.findIndex((s) => s.end - s.period <= point.timestamp || s.end <= point.timestamp);
+                if (si >= 0) {
+                    this.addValue(metric, point.timestamp, point, si);
+                }
+                else {
+                }
+            }
+            else {
+                this.addValue(metric, timestamp, point, 0);
+            }
+            if (this.source) {
+                metric._source = this.source;
+            }
+            if (ttl) {
+                metric.expires = timestamp + ttl;
+            }
+            if (await this.putMetric(metric, options)) {
+                break;
+            }
+            if (retries == 0) {
+                this.log.error(`Metric update has too many retries`, { namespace, metricName, dimensions });
+                break;
+            }
+            this.log[chan](`Retry ${MaxRetries - retries} metric update ${metric.namespace} ${metric.metric} ${metric.dimensions}`, {
+                retries,
+                metric,
+            });
+            backoff = backoff * 2;
+            this.log[chan](`Retry backoff ${backoff} ${this.jitter(backoff)}`);
+            await this.delay(this.jitter(backoff));
+        } while (retries-- > 0);
+        return metric;
+    }
+    async upgrade(namespace, metricName, dimensionsList = [{}], options = {}) {
+        let owner = options.owner || this.owner;
+        if (dimensionsList.length == 0) {
+            dimensionsList = [{}];
+        }
+        let metric;
+        for (let dim of dimensionsList) {
+            let dimensions = this.makeDimensionString(dim);
+            let old = await this.getMetric(owner, namespace, metricName, dimensions, options.log);
+            metric = this.upgradeMetric(old);
+            await this.putMetric(metric, options);
+        }
+        return metric;
+    }
+    upgradeMetric(old) {
+        let required = false;
+        if (this.spans.length == old.spans.length) {
+            for (let [index, span] of Object.entries(old.spans)) {
+                if (span.period != this.spans[index].period || span.samples != this.spans[index].samples) {
+                    required = true;
+                }
+            }
+            if (!required) {
+                return old;
+            }
+        }
+        let timestamp = Math.min(...old.spans.map((span) => span.end - span.period)) || Math.floor(Date.now() / 1000);
+        let metric = this.initMetric(old.owner, old.namespace, old.metric, old.dimensions, timestamp);
+        for (let span of old.spans) {
+            let interval = span.period / span.samples;
+            let timestamp = span.end - span.points.length * interval;
+            let si = metric.spans.findIndex((s) => s.end - s.period <= timestamp || s.end <= timestamp);
+            for (let point of span.points) {
+                this.addValue(metric, timestamp, point, si);
+                timestamp += interval;
+            }
+        }
+        return metric;
+    }
+    static async terminate() {
+        await CustomMetrics.flushAll();
+    }
+    static async flushAll() {
+        for (let [key, instance] of Object.entries(Instances)) {
+            await instance.flush();
+            CustomMetrics.freeInstanceByKey(key);
+        }
+        Instances = {};
+    }
+    async flush() {
+        if (!this.buffers)
+            return;
+        let now = Date.now() / 1000;
+        for (let elt of Object.values(this.buffers)) {
+            await this.flushElt(elt, now);
+        }
+    }
+    async flushElt(elt, timestamp) {
+        elt.timestamp = Math.min(timestamp, elt.timestamp);
+        let metric = await this.emitDimensionedMetric(elt.namespace, elt.metric, elt, elt.dimensions, {
+            timestamp: elt.timestamp * 1000,
+        });
+        elt.count = elt.sum = 0;
+        elt.spans = metric.spans;
+        elt.timestamp = timestamp + (elt.elapsed || this.spans[0].period / this.spans[0].samples);
+    }
+    getBufferKey(namespace, metricName, dimensions) {
+        return `${namespace}|${metricName}|${JSON.stringify(dimensions)}`;
+    }
+    async query(namespace, metricName, dimensions, period, statistic, options = {}) {
+        let owner = options.owner || this.owner;
+        let dimString = this.makeDimensionString(dimensions);
+        if (period > this.spans.at(-1).period) {
+            period = this.spans.at(-1).period;
+        }
+        let timestamp = Math.floor((options.timestamp || Date.now()) / 1000);
+        if (this.buffers) {
+            let key = this.getBufferKey(namespace, metricName, dimString);
+            if (this.buffers[key]) {
+                await this.flushElt(this.buffers[key], timestamp);
+            }
+        }
+        let metric = await this.getMetric(owner, namespace, metricName, dimString, options.log);
+        if (!metric) {
+            return { dimensions, id: options.id, metric: metricName, namespace, period, points: [], owner, samples: 0 };
+        }
+        let start;
+        let si;
+        if (options.start) {
+            start = options.start / 1000;
+            si = metric.spans.findIndex((s) => period <= s.period && s.end - s.period <= start && start <= s.end);
+        }
+        else {
+            let span = metric.spans[0];
+            let interval = span.period / span.samples;
+            let t = this.roundTime(span, timestamp + 1);
+            if (span.end - interval <= t && t <= span.end) {
+                start = t - period;
+            }
+            else {
+                start = timestamp - period;
+            }
+            si = metric.spans.findIndex((s) => period <= s.period);
+        }
+        if (si < 0) {
+            si = metric.spans.length - 1;
+        }
+        let span = metric.spans[si];
+        start = this.roundTime(span, start);
+        this.addValue(metric, timestamp, { count: 0, sum: 0 }, 0, si);
+        let result;
+        if (options.accumulate) {
+            result = this.accumulateMetric(metric, span, statistic, owner, start, period);
+        }
+        else {
+            result = this.calculateSeries(metric, span, statistic, owner, start, period);
+        }
+        result.id = options.id;
+        this.log[options.log == true ? 'info' : 'trace'](`Query metrics ${namespace}, ${metricName}`, {
+            dimensions,
+            period,
+            statistic,
+            options,
+            result,
+        });
+        return result;
+    }
+    accumulateMetric(metric, span, statistic, owner, start, period) {
+        let value = 0, count = 0, pvalues = [];
+        if (statistic == 'max') {
+            value = Number.NEGATIVE_INFINITY;
+        }
+        else if (statistic == 'min') {
+            value = Infinity;
+        }
+        else if (statistic == 'sum') {
+            value = 0;
+            count = 0;
+        }
+        else if (statistic == 'count') {
+            value = 0;
+            count = 0;
+        }
+        else if (statistic == 'current') {
+            value = 0;
+            count = 0;
+        }
+        else if (statistic.match(/^p[0-9]+/)) {
+            pvalues = [];
+        }
+        else {
+            value = 0;
+            count = 0;
+        }
+        let points = span.points;
+        let interval = span.period / span.samples;
+        let t = span.end - span.points.length * interval;
+        for (let i = 0; i < points.length; i++) {
+            let point = points[i];
+            if (start <= t && t < start + period) {
+                if (statistic == 'max') {
+                    if (point.max != undefined) {
+                        value = Math.max(value, point.max);
+                    }
+                    else {
+                        value = Math.max(value, point.sum / (point.count || 1));
+                    }
+                }
+                else if (statistic == 'min') {
+                    if (point.min != undefined) {
+                        value = Math.min(value, point.min);
+                    }
+                    else {
+                        value = Math.min(value, point.sum / (point.count || 1));
+                    }
+                }
+                else if (statistic == 'sum') {
+                    value += point.sum;
+                }
+                else if (statistic == 'current') {
+                    value = point.sum / (point.count || 1);
+                }
+                else if (statistic == 'count') {
+                    value += point.count;
+                }
+                else if (statistic.match(/^p[0-9]+/)) {
+                    pvalues = pvalues.concat(point.pvalues);
+                }
+                else {
+                    value += point.sum;
+                }
+                count += point.count;
+            }
+            t += interval;
+        }
+        if (statistic.match(/^p[0-9]+/)) {
+            let p = parseInt(statistic.slice(1));
+            pvalues.sort((a, b) => a - b);
+            let nth = Math.min(Math.round((pvalues.length * p) / 100 + 1), pvalues.length - 1);
+            value = pvalues[nth];
+        }
+        else if (statistic == 'avg') {
+            value /= Math.max(count, 1);
+        }
+        return {
+            dimensions: this.makeDimensionObject(metric.dimensions),
+            metric: metric.metric,
+            namespace: metric.namespace,
+            owner: owner,
+            period: span.period,
+            points: [{ value, timestamp: start + period, count }],
+            samples: span.samples,
+        };
+    }
+    calculateSeries(metric, span, statistic, owner, start, period) {
+        let points = [];
+        let interval = span.period / span.samples;
+        let t;
+        let firstPoint = span.end - span.points.length * interval;
+        let count = Math.floor((firstPoint - start) / interval);
+        for (t = start; t < firstPoint && points.length < span.samples; t += interval) {
+            points.push({ value: 0, count: 0, timestamp: t * 1000 });
+        }
+        t = firstPoint;
+        for (let point of span.points) {
+            if (start <= t && t < start + period) {
+                let value = undefined;
+                if (point.count > 0) {
+                    if (statistic == 'max') {
+                        if (point.max != undefined) {
+                            if (value == undefined) {
+                                value = point.max;
+                            }
+                            else {
+                                value = Math.max(value, point.max);
+                            }
+                        }
+                    }
+                    else if (statistic == 'min') {
+                        if (point.min != undefined) {
+                            if (value == undefined) {
+                                value = point.min;
+                            }
+                            else {
+                                value = Math.min(value, point.min);
+                            }
+                        }
+                    }
+                    else if (statistic == 'sum') {
+                        value = point.sum;
+                    }
+                    else if (statistic == 'count') {
+                        value = point.count;
+                    }
+                    else if (statistic.match(/^p[0-9]+/)) {
+                        let p = parseInt(statistic.slice(1));
+                        let pvalues = point.pvalues;
+                        pvalues.sort((a, b) => a - b);
+                        let nth = Math.min(Math.round((pvalues.length * p) / 100 + 1), pvalues.length - 1);
+                        value = pvalues[nth];
+                    }
+                    else {
+                        value = point.sum / point.count;
+                    }
+                }
+                else {
+                    value = 0;
+                }
+                points.push({ value, count: point.count, timestamp: (t + interval) * 1000 });
+            }
+            t += interval;
+        }
+        count = Math.ceil(period / interval);
+        while (points.length < count) {
+            points.push({ value: 0, count: 0, timestamp: t * 1000 });
+            t += interval;
+        }
+        return {
+            dimensions: this.makeDimensionObject(metric.dimensions),
+            metric: metric.metric,
+            namespace: metric.namespace,
+            period: span.period,
+            points: points,
+            owner: owner,
+            samples: span.samples,
+        };
+    }
+    makeDimensionString(dimensions) {
+        let result = [];
+        let entries = Object.entries(dimensions).sort((a, b) => a[0].localeCompare(b[0]));
+        for (let [name, value] of entries) {
+            result.push(`${name}=${value}`);
+        }
+        return result.join(',');
+    }
+    makeDimensionObject(dimensions) {
+        let result = {};
+        for (let dimension of dimensions.split(',')) {
+            if (dimension) {
+                let [key, value] = dimension.split('=');
+                result[key] = value;
+            }
+        }
+        return result;
+    }
+    addValue(metric, timestamp, point, si, querySpanIndex = undefined) {
+        this.assert(metric);
+        this.assert(timestamp);
+        this.assert(0 <= si && si < metric.spans.length);
+        let span = metric.spans[si];
+        let interval = span.period / span.samples;
+        let points = span.points || [];
+        let queryRecurse = si < querySpanIndex && si + 1 < metric.spans.length;
+        while (points.length > span.samples) {
+            points.shift();
+        }
+        let first = span.end - points.length * interval;
+        let shift = 0;
+        if (points.length) {
+            if (queryRecurse) {
+                shift = points.length;
+            }
+            else if (timestamp >= first) {
+                shift = Math.floor((timestamp - first) / interval) - span.samples;
+                if (!queryRecurse && point.count && timestamp >= span.end) {
+                    shift += 1;
+                }
+            }
+            shift = Math.max(0, Math.min(shift, points.length));
+            this.assert(0 <= shift && shift <= points.length);
+            for (let i = 0; i < shift; i++) {
+                let p = points.shift();
+                if (p.count && si + 1 < metric.spans.length) {
+                    this.addValue(metric, first, p, si + 1, querySpanIndex);
+                }
+                first += interval;
+            }
+        }
+        if (queryRecurse) {
+            this.addValue(metric, timestamp, point, si + 1, querySpanIndex);
+            return;
+        }
+        if (point.count) {
+            let index;
+            if (points.length == 0) {
+                points.push({ count: 0, sum: 0 });
+                span.end = this.roundTime(span, timestamp + 1);
+                first = span.end - interval;
+                index = 0;
+            }
+            else {
+                if (timestamp < span.end - span.period) {
+                    return;
+                }
+                while (timestamp < first) {
+                    points.unshift({ count: 0, sum: 0 });
+                    first -= interval;
+                }
+                while (timestamp >= span.end) {
+                    points.push({ count: 0, sum: 0 });
+                    span.end += interval;
+                }
+                index = Math.floor((timestamp - first) / interval);
+            }
+            this.assert(points.length <= span.samples);
+            if (!(0 <= index && index < points.length)) {
+                this.assert(0 <= index && index < points.length);
+                if (index > 0) {
+                    index = points.length - 1;
+                }
+            }
+            this.setPoint(span, index, point);
+        }
+    }
+    setPoint(span, index, add) {
+        let points = span.points;
+        this.assert(0 <= index && index < points.length);
+        let point = points[index];
+        if (!point) {
+            this.log.error(`Metric null point`, { span, index, add });
+            return;
+        }
+        if (add.count) {
+            let value = add.sum / add.count;
+            if (point.min == undefined) {
+                point.min = value;
+            }
+            else {
+                point.min = Math.min(value, point.min);
+            }
+            if (point.max == undefined) {
+                point.max = value;
+            }
+            else {
+                point.max = Math.max(value, point.max);
+            }
+        }
+        if (this.pResolution) {
+            point.pvalues = point.pvalues || [];
+            if (add.pvalues) {
+                point.pvalues.push(...add.pvalues);
+            }
+            else {
+                point.pvalues.push(add.sum / add.count);
+            }
+            point.pvalues.splice(0, point.pvalues.length - this.pResolution);
+        }
+        point.sum += add.sum;
+        point.count += add.count;
+    }
+    async getMetricList(namespace = undefined, metric = undefined, options = { limit: MetricListLimit }) {
+        let map = {};
+        let owner = options.owner || this.owner;
+        let next = options.next;
+        let limit = options.limit || MetricListLimit;
+        let chan = options.log == true ? 'info' : 'trace';
+        let items, command;
+        let count = 0;
+        do {
+            ;
+            ({ command, items, next } = await this.findMetrics(owner, namespace, metric, limit, next));
+            this.log[chan](`Find metrics ${namespace}, ${metric}`, { command, items });
+            if (items.length) {
+                for (let item of items) {
+                    let ns = (map[item.namespace] = map[item.namespace] || {});
+                    let met = (ns[item.metric] = ns[item.metric] || []);
+                    met.push(item.dimensions);
+                }
+                count += items.length;
+            }
+        } while (next && count < limit);
+        let result = { namespaces: Object.keys(map) };
+        if (namespace && map[namespace]) {
+            result.metrics = Object.keys(map[namespace]);
+            if (metric) {
+                let dimensions = map[namespace][metric];
+                if (dimensions) {
+                    result.dimensions = [];
+                    dimensions = dimensions.sort().filter((v, index, self) => self.indexOf(v) === index);
+                    for (let dimension of dimensions) {
+                        result.dimensions.push(this.makeDimensionObject(dimension));
+                    }
+                }
+            }
+        }
+        return result;
+    }
+    initMetric(owner, namespace, name, dimensions, timestamp) {
+        let metric = {
+            dimensions,
+            metric: name,
+            namespace,
+            owner,
+            spans: [],
+            version: Version,
+        };
+        for (let sdef of this.spans) {
+            let span = {
+                samples: sdef.samples,
+                period: sdef.period,
+                end: timestamp,
+                points: [],
+            };
+            span.end = this.roundTime(span, timestamp + 1);
+            metric.spans.push(span);
+        }
+        return metric;
+    }
+    async getMetric(owner, namespace, metric, dimensions, log) {
+        let command = new GetItemCommand({
+            TableName: this.table,
+            Key: {
+                [this.primaryKey]: { S: `${this.prefix}#${Version}#${owner}` },
+                [this.sortKey]: { S: `${this.prefix}#${namespace}#${metric}#${dimensions}` },
+            },
+            ConsistentRead: this.consistent,
+        });
+        let data = await this.client.send(command);
+        let result = null;
+        if (data && data.Item) {
+            let item = unmarshall(data.Item);
+            result = this.mapItemFromDB(item);
+        }
+        if (log == true) {
+            let chan = log == true ? 'info' : 'trace';
+            this.log[chan](`GetMetric ${namespace}, ${metric} ${dimensions}`, { cmd: command, result });
+        }
+        return result;
+    }
+    async findMetrics(owner, namespace, metric, limit, startKey) {
+        let key = [namespace];
+        if (metric) {
+            key.push(metric);
+        }
+        let start = startKey ? marshall(startKey) : undefined;
+        let command = new QueryCommand({
+            TableName: this.table,
+            ExpressionAttributeNames: {
+                '#_0': this.primaryKey,
+                '#_1': this.sortKey,
+            },
+            ExpressionAttributeValues: {
+                ':_0': { S: `${this.prefix}#${Version}#${owner}` },
+                ':_1': { S: `${this.prefix}#${key.join('#')}` },
+            },
+            KeyConditionExpression: '#_0 = :_0 and begins_with(#_1, :_1)',
+            ConsistentRead: this.consistent,
+            Limit: limit,
+            ScanIndexForward: true,
+            ExclusiveStartKey: start,
+            ProjectionExpression: `${this.primaryKey}, ${this.sortKey}`,
+        });
+        let result = await this.client.send(command);
+        let items = [];
+        if (result.Items) {
+            for (let i = 0; i < result.Items.length; i++) {
+                let item = unmarshall(result.Items[i]);
+                items.push(this.mapItemFromDB(item));
+            }
+        }
+        let next = undefined;
+        if (result.LastEvaluatedKey) {
+            next = unmarshall(result.LastEvaluatedKey);
+        }
+        return { items, next, command };
+    }
+    async putMetric(item, options) {
+        let ConditionExpression, ExpressionAttributeValues;
+        let seq;
+        if (item.seq != undefined) {
+            seq = item.seq = item.seq || 0;
+            if (item.seq++ >= MaxSeq) {
+                item.seq = 0;
+            }
+            ConditionExpression = `seq = :_0`;
+            ExpressionAttributeValues = { ':_0': { N: seq.toString() } };
+        }
+        else {
+            item.seq = 0;
+        }
+        let mapped = this.mapItemToDB(item);
+        let params = {
+            TableName: this.table,
+            ReturnValues: 'NONE',
+            Item: marshall(mapped, { removeUndefinedValues: true }),
+            ConditionExpression,
+            ExpressionAttributeValues,
+        };
+        let command = new PutItemCommand(params);
+        let chan = options.log == true ? 'info' : 'trace';
+        this.log[chan](`Put metric ${item.namespace}, ${item.metric}`, {
+            dimensions: item.dimensions,
+            command,
+            params,
+            item,
+        });
+        try {
+            await this.client.send(command);
+            return true;
+        }
+        catch (err) {
+            ;
+            (function (err, log) {
+                let code = err.code || err.name;
+                if (code == 'ConditionalCheckFailedException') {
+                    log.trace(`Update collision`, { err });
+                }
+                else if (code == 'ProvisionedThroughputExceededException') {
+                    log.info(`Provisioned throughput exceeded: ${err.message}`, { err, cmd: command, item });
+                }
+                else {
+                    log.error(`Emit exception code ${err.name} ${err.code} message ${err.message}`, {
+                        err,
+                        cmd: command,
+                        item,
+                    });
+                    throw err;
+                }
+                return false;
+            })(err, this.log);
+        }
+    }
+    mapItemFromDB(data) {
+        let pk = data[this.primaryKey];
+        let sk = data[this.sortKey];
+        let owner = pk.split('#').pop();
+        let [, namespace, metric, dimensions] = sk.split('#');
+        let spans;
+        if (data.spans) {
+            spans = data.spans.map((s) => {
+                return {
+                    end: s.se,
+                    period: s.sp,
+                    samples: s.ss,
+                    points: s.pt.map((p) => {
+                        let point = { count: Number(p.c), sum: Number(p.s) };
+                        if (p.x != null) {
+                            point.max = Number(p.x);
+                        }
+                        if (p.m != null) {
+                            point.min = Number(p.m);
+                        }
+                        if (p.v) {
+                            point.pvalues = p.v;
+                        }
+                        return point;
+                    }),
+                };
+            });
+        }
+        let expires = data[this.expires];
+        let seq = data.seq;
+        return { dimensions, expires, metric, namespace, owner, seq, spans };
+    }
+    mapItemToDB(item) {
+        let result = {
+            [this.primaryKey]: `${this.prefix}#${Version}#${item.owner}`,
+            [this.sortKey]: `${this.prefix}#${item.namespace}#${item.metric}#${item.dimensions}`,
+            [this.expires]: item.expires,
+            spans: item.spans.map((i) => {
+                return {
+                    se: i.end,
+                    sp: i.period,
+                    ss: i.samples,
+                    pt: i.points.map((point) => {
+                        let p = { c: point.count, s: this.round(point.sum) };
+                        if (point.max != null) {
+                            p.x = this.round(point.max);
+                        }
+                        if (point.min != null) {
+                            p.m = this.round(point.min);
+                        }
+                        if (point.pvalues) {
+                            p.v = point.pvalues;
+                        }
+                        return p;
+                    }),
+                };
+            }),
+            seq: item.seq,
+            _source: item._source,
+        };
+        if (this.type) {
+            let [key, model] = Object.entries(this.type)[0];
+            result[key] = model;
+        }
+        return result;
+    }
+    static freeInstanceByKey(key) {
+        delete Instances[key];
+    }
+    static saveInstance(tags, metrics) {
+        let key = JSON.stringify(tags);
+        Instances[key] = metrics;
+    }
+    roundTime(span, timestamp) {
+        let interval = span.period / span.samples;
+        return Math.ceil(timestamp / interval) * interval;
+    }
+    assert(c) {
+        if (!c && Assert) {
+            let msg = { stack: '' };
+            if (typeof Error.captureStackTrace === 'function') {
+                Error.captureStackTrace(msg);
+            }
+            else {
+                msg.stack = new Error('Assert').stack;
+            }
+            this.log.error(`Assertion failed`, { stack: msg.stack });
+        }
+    }
+    info(message, context = {}) {
+        console.log('INFO: ' + message, context);
+    }
+    error(message, context = {}) {
+        console.log('ERROR: ' + message, context);
+    }
+    trace(message, context = {}) {
+        console.log('TRACE: ' + message, context);
+    }
+    round(n) {
+        if (isNaN(n) || n == null) {
+            return 0;
+        }
+        let places = 16 - n.toFixed(0).length;
+        return Number(n.toFixed(places)) - 0;
+    }
+    jitter(msecs) {
+        return Math.min(10 * 1000, Math.floor(msecs / 2 + msecs * Math.random()));
+    }
+    async delay(time) {
+        return new Promise(function (resolve, reject) {
+            setTimeout(() => resolve(true), time);
+        });
+    }
+}
+class Log {
+    senselogs = null;
+    logger = null;
+    verbose = false;
+    constructor(dest) {
+        if (dest === true) {
+            this.logger = this.defaultLogger;
+        }
+        else if (dest == 'verbose') {
+            this.logger = this.defaultLogger;
+            this.verbose = true;
+        }
+        else if (dest && typeof dest.info == 'function') {
+            this.senselogs = dest;
+        }
+    }
+    error(message, context) {
+        this.process('error', message, context);
+    }
+    info(message, context) {
+        this.process('info', message, context);
+    }
+    trace(message, context) {
+        this.process('trace', message, context);
+    }
+    process(chan, message, context) {
+        if (this.logger) {
+            this.logger(chan, message, context);
+        }
+        else if (this.senselogs) {
+            this.senselogs[chan](message, context);
+        }
+    }
+    defaultLogger(chan, message, context) {
+        if (chan == 'trace' && !this.verbose) {
+            return;
+        }
+        let tag = chan.toUpperCase();
+        if (context) {
+            try {
+                console.log(tag, message, JSON.stringify(context, null, 4));
+            }
+            catch (err) {
+                let buf = ['{'];
+                for (let [key, value] of Object.entries(context)) {
+                    try {
+                        buf.push(`    ${key}: ${JSON.stringify(value, null, 4)}`);
+                    }
+                    catch (err) {
+                    }
+                }
+                buf.push('}');
+                console.log(tag, message, buf.join('\n'));
+            }
+        }
+        else {
+            console.log(tag, message);
+        }
+    }
+}
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/doc/schema.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/doc/schema.d.ts
new file mode 100644
index 0000000..2145db9
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/doc/schema.d.ts
@@ -0,0 +1,132 @@
+declare const Version = 1;
+declare const Schema: {
+    format: string;
+    version: string;
+    indexes: {
+        primary: {
+            hash: string;
+            sort: string;
+        };
+    };
+    models: {
+        readonly Metric: {
+            readonly pk: {
+                readonly type: "string";
+                readonly value: "metric#${version}#${owner}";
+            };
+            readonly sk: {
+                readonly type: "string";
+                readonly value: "metric#${namespace}#${metric}#${dimensions}";
+            };
+            readonly dimensions: {
+                readonly type: "string";
+                readonly required: true;
+                readonly encode: readonly ["sk", "#", "3"];
+            };
+            readonly expires: {
+                readonly type: "date";
+                readonly ttl: true;
+            };
+            readonly metric: {
+                readonly type: "string";
+                readonly required: true;
+                readonly encode: readonly ["sk", "#", "2"];
+            };
+            readonly namespace: {
+                readonly type: "string";
+                readonly required: true;
+                readonly encode: readonly ["sk", "#", "1"];
+            };
+            readonly owner: {
+                readonly type: "string";
+                readonly required: true;
+                readonly encode: readonly ["pk", "#", "2"];
+            };
+            readonly version: {
+                readonly type: "number";
+                readonly default: 1;
+                readonly encode: readonly ["pk", "#", "1"];
+            };
+            readonly id: {
+                readonly type: "string";
+            };
+            readonly spans: {
+                readonly type: "array";
+                readonly required: true;
+                readonly default: readonly [];
+                readonly items: {
+                    readonly type: "object";
+                    readonly default: {};
+                    readonly schema: {
+                        readonly end: {
+                            readonly type: "number";
+                            readonly required: true;
+                            readonly map: "se";
+                        };
+                        readonly period: {
+                            readonly type: "number";
+                            readonly required: true;
+                            readonly map: "sp";
+                        };
+                        readonly samples: {
+                            readonly type: "number";
+                            readonly required: true;
+                            readonly map: "ss";
+                        };
+                        readonly points: {
+                            readonly type: "array";
+                            readonly required: true;
+                            readonly map: "pt";
+                            readonly default: readonly [];
+                            readonly items: {
+                                readonly type: "object";
+                                readonly schema: {
+                                    readonly count: {
+                                        readonly type: "number";
+                                        readonly required: true;
+                                        readonly map: "c";
+                                    };
+                                    readonly max: {
+                                        readonly type: "number";
+                                        readonly map: "x";
+                                    };
+                                    readonly min: {
+                                        readonly type: "number";
+                                        readonly map: "m";
+                                    };
+                                    readonly sum: {
+                                        readonly type: "number";
+                                        readonly required: true;
+                                        readonly map: "s";
+                                    };
+                                    readonly pvalues: {
+                                        readonly type: "array";
+                                        readonly map: "v";
+                                    };
+                                    readonly timestamp: {
+                                        readonly type: "number";
+                                        readonly map: "e";
+                                    };
+                                };
+                            };
+                        };
+                    };
+                };
+            };
+            readonly seq: {
+                readonly type: "number";
+                readonly default: 0;
+            };
+            readonly _source: {
+                readonly type: "string";
+            };
+        };
+    };
+    params: {
+        isoDates: boolean;
+        nulls: boolean;
+        timestamps: boolean;
+        typeField: string;
+    };
+};
+export { Schema, Version };
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/doc/schema.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/doc/schema.js
new file mode 100644
index 0000000..541689a
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/doc/schema.js
@@ -0,0 +1,64 @@
+/*
+    schema.ts -- CustomMetrics Schema
+ */
+const Version = 1;
+const Schema = {
+    format: 'onetable:1.1.0',
+    version: '0.0.1',
+    indexes: { primary: { hash: 'pk', sort: 'sk' } },
+    models: {
+        Metric: {
+            pk: { type: 'string', value: 'metric#${version}#${owner}' },
+            sk: { type: 'string', value: 'metric#${namespace}#${metric}#${dimensions}' },
+            dimensions: { type: 'string', required: true, encode: ['sk', '#', '3'] },
+            expires: { type: 'date', ttl: true },
+            metric: { type: 'string', required: true, encode: ['sk', '#', '2'] },
+            namespace: { type: 'string', required: true, encode: ['sk', '#', '1'] },
+            owner: { type: 'string', required: true, encode: ['pk', '#', '2'] },
+            version: { type: 'number', default: Version, encode: ['pk', '#', '1'] },
+            id: { type: 'string' }, // Never stored. Preserved on query
+            spans: {
+                type: 'array',
+                required: true,
+                default: [],
+                items: {
+                    type: 'object',
+                    default: {},
+                    schema: {
+                        // When the points will be full.
+                        end: { type: 'number', required: true, map: 'se' },
+                        period: { type: 'number', required: true, map: 'sp' },
+                        samples: { type: 'number', required: true, map: 'ss' },
+                        points: {
+                            type: 'array',
+                            required: true,
+                            map: 'pt',
+                            default: [],
+                            items: {
+                                type: 'object',
+                                schema: {
+                                    count: { type: 'number', required: true, map: 'c' },
+                                    max: { type: 'number', map: 'x' },
+                                    min: { type: 'number', map: 'm' },
+                                    sum: { type: 'number', required: true, map: 's' },
+                                    //  Never stored
+                                    pvalues: { type: 'array', map: 'v' },
+                                    timestamp: { type: 'number', map: 'e', },
+                                },
+                            },
+                        },
+                    },
+                },
+            },
+            seq: { type: 'number', default: 0 },
+            _source: { type: 'string' }, // When set, bypass DynamoDB steams change detection
+        }
+    },
+    params: {
+        isoDates: false,
+        nulls: false,
+        timestamps: false,
+        typeField: '_type',
+    },
+};
+export { Schema, Version };
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/jest.config.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/jest.config.d.ts
new file mode 100644
index 0000000..a987825
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/jest.config.d.ts
@@ -0,0 +1,14 @@
+export let coveragePathIgnorePatterns: string[];
+export let coverageDirectory: string;
+export namespace globals {
+    let __DYNAMODB__: any;
+}
+export let roots: string[];
+export let testMatch: string[];
+export let globalSetup: string;
+export let globalTeardown: string;
+export let testEnvironment: string;
+export let transform: {
+    '^.+\\.(js|ts)$': string;
+};
+export let verbose: any;
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/jest.config.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/jest.config.js
new file mode 100644
index 0000000..068ad4b
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/jest.config.js
@@ -0,0 +1,34 @@
+/*
+   Jest configuration
+ */
+module.exports = {
+    "coveragePathIgnorePatterns": [
+        "node_modules",
+        "test/utils"
+    ],
+    coverageDirectory: "coverage",
+    globals: {
+        __DYNAMODB__: null,
+    },
+    roots: [
+        "<rootDir>/src",
+        "<rootDir>/test"
+    ],
+    testMatch: [
+        "**/*.[jt]s",
+        "!**/src/*.[jt]s",
+        "!**/setup.[jt]s",
+        "!**/init.[jt]s",
+        "!**/teardown.[jt]s",
+        "!**/helpers.[jt]s",
+        "!**/schemas/*",
+    ],
+    globalSetup: '<rootDir>/test/utils/setup.ts',
+    globalTeardown: '<rootDir>/test/utils/teardown.ts',
+    testEnvironment: "node",
+    transform: {
+        '^.+\\.(js|ts)$': 'ts-jest'
+    },
+    verbose: undefined
+    // setupFiles: ['<rootDir>/test/utils/helpers.ts'],
+};
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/src/index.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/src/index.d.ts
new file mode 100644
index 0000000..a72dd56
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/src/index.d.ts
@@ -0,0 +1,193 @@
+import { DynamoDBClient, QueryCommand } from '@aws-sdk/client-dynamodb';
+export type SpanDef = {
+    period: number;
+    samples: number;
+};
+export declare const DefaultSpans: SpanDef[];
+export type Metric = {
+    dimensions: string;
+    expires?: number;
+    id?: string;
+    metric: string;
+    namespace: string;
+    owner?: string;
+    version?: number;
+    spans: Span[];
+    seq?: number;
+    _source?: string;
+};
+export type Point = {
+    count: number;
+    max?: number;
+    min?: number;
+    pvalues?: number[];
+    sum: number;
+    timestamp?: number;
+};
+export type Span = {
+    end: number;
+    period: number;
+    samples: number;
+    points: Point[];
+};
+export type MetricDimensions = {
+    [key: string]: unknown;
+};
+export type MetricDimensionsList = MetricDimensions[];
+export type MetricList = {
+    namespaces: string[];
+    metrics?: string[];
+    dimensions?: MetricDimensions[];
+};
+export type MetricQueryPoint = {
+    count: number;
+    timestamp?: number;
+    value?: number;
+};
+export type MetricQueryResult = {
+    dimensions: MetricDimensions;
+    id?: string;
+    metric: string;
+    namespace: string;
+    owner: string;
+    period: number;
+    points: MetricQueryPoint[];
+    samples: number;
+};
+export type MetricOptions = {
+    buffer?: MetricBufferOptions;
+    client?: DynamoDBClient;
+    consistent?: boolean;
+    creds?: object;
+    expires?: string;
+    log?: true | 'verbose' | any;
+    owner?: string;
+    prefix?: string;
+    pResolution?: number;
+    primaryKey?: string;
+    region?: string;
+    sortKey?: string;
+    source?: string;
+    spans?: SpanDef[];
+    table?: string;
+    ttl?: number;
+    type?: {
+        [key: string]: string;
+    };
+};
+export type MetricBufferOptions = {
+    sum?: number;
+    count?: number;
+    elapsed?: number;
+    force?: boolean;
+};
+export type MetricEmitOptions = {
+    buffer?: MetricBufferOptions;
+    log?: boolean;
+    owner?: string;
+    timestamp?: number;
+    ttl?: number;
+    upgrade?: boolean;
+};
+export type MetricListOptions = {
+    log?: boolean;
+    limit?: number;
+    owner?: string;
+    next?: object;
+    timestamp?: number;
+};
+export type MetricQueryOptions = {
+    accumulate?: boolean;
+    id?: string;
+    log?: boolean;
+    owner?: string;
+    start?: number;
+    timestamp?: number;
+};
+type BufferElt = {
+    count: number;
+    dimensions: string;
+    metric: string;
+    namespace: string;
+    spans: Span[];
+    sum: number;
+    timestamp: number;
+    elapsed: number;
+};
+export declare class CustomMetrics {
+    private consistent;
+    private buffer;
+    private buffers;
+    private client;
+    private expires;
+    private log;
+    private options;
+    private owner;
+    private prefix;
+    private primaryKey;
+    private sortKey;
+    private pResolution;
+    private source;
+    private spans;
+    private table;
+    private type;
+    private ttl;
+    constructor(options?: MetricOptions);
+    emit(namespace: string, metricName: string, value: number, dimensionsList?: MetricDimensionsList, options?: MetricEmitOptions): Promise<Metric>;
+    private emitDimensions;
+    bufferMetric(namespace: string, metricName: string, point: Point, dimensions: string, options: MetricEmitOptions): Promise<Metric>;
+    private emitDimensionedMetric;
+    upgrade(namespace: string, metricName: string, dimensionsList?: MetricDimensionsList, options?: MetricEmitOptions): Promise<Metric>;
+    upgradeMetric(old: Metric): Metric;
+    static terminate(): Promise<void>;
+    static flushAll(): Promise<void>;
+    flush(options?: MetricQueryOptions): Promise<void>;
+    flushElt(elt: BufferElt, now: number): Promise<void>;
+    getBufferKey(namespace: string, metricName: string, dimensions: string): string;
+    query(namespace: string, metricName: string, dimensions: MetricDimensions, period: number, statistic: string, options?: MetricQueryOptions): Promise<MetricQueryResult>;
+    queryMetrics(namespace: string, metric: string | undefined, period: number, statistic: string, options?: MetricListOptions): Promise<MetricQueryResult[]>;
+    processMetric(metric: Metric, now: number, period: number, statistic: string, options: MetricQueryOptions): MetricQueryResult;
+    private accumulateMetric;
+    private calculateSeries;
+    private makeDimensionString;
+    private makeDimensionObject;
+    private addValue;
+    private setPoint;
+    getMetricList(namespace?: string, metric?: string, options?: MetricListOptions): Promise<MetricList>;
+    private initMetric;
+    getMetric(owner: string, namespace: string, metric: string, dimensions: string, log: boolean): Promise<Metric>;
+    findMetrics(owner: string, namespace: string, metric: string | undefined, limit: number, startKey: object, fields?: string): Promise<{
+        items: Metric[];
+        next: object;
+        command: QueryCommand;
+    }>;
+    putMetric(item: Metric, options: MetricEmitOptions): Promise<boolean>;
+    mapItemFromDB(data: any): Metric;
+    mapItemToDB(item: Metric): {
+        [x: string]: string | number | {
+            se: number;
+            sp: number;
+            ss: number;
+            pt: any[];
+        }[];
+        spans: {
+            se: number;
+            sp: number;
+            ss: number;
+            pt: any[];
+        }[];
+        seq: number;
+        _source: string;
+    };
+    static freeInstanceByKey(key: string): void;
+    static saveInstance(tags: object, metrics: CustomMetrics): void;
+    private alignTime;
+    private assert;
+    private info;
+    private error;
+    private trace;
+    round(n: number): number;
+    jitter(msecs: number): number;
+    delay(time: number): Promise<boolean>;
+}
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/src/index.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/src/index.js
new file mode 100644
index 0000000..d4566e3
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/src/index.js
@@ -0,0 +1,1222 @@
+/*
+    CustomMetrics - Simple, configurable, economical metrics for AWS
+
+    See the README for the Metric schema details.
+ */
+import process from 'process';
+import { DynamoDBClient, GetItemCommand, PutItemCommand, QueryCommand, } from '@aws-sdk/client-dynamodb';
+import { marshall, unmarshall } from '@aws-sdk/util-dynamodb';
+const Version = 1;
+//MOB disable
+const Assert = true; // Enable asserts
+const Buffering = true; // Enable buffered metrics
+const DefaultResolution = 0; // Default number of p-values to store
+const MaxSeq = Number.MAX_SAFE_INTEGER; // Maximum sequence number for collision detection
+const MaxRetries = 10; // Max retries when emitting a metric and encountering collisions
+const MetricListLimit = 10000; // Sanity limit for getting a list of metrics
+/*
+    Default spans are configurable by the constructor
+ */
+export const DefaultSpans = [
+    { period: 5 * 60, samples: 10 }, //  300, 5 mins, interval: 30 secs
+    { period: 60 * 60, samples: 12 }, //  3600, 1 hr, interval: 5 mins
+    { period: 24 * 60 * 60, samples: 12 }, // 86400, 24 hrs, interval: 2 hrs
+    { period: 7 * 24 * 60 * 60, samples: 14 }, // 604,800, 7 days, interval: 1/2 day
+    { period: 28 * 24 * 60 * 60, samples: 14 }, // 2,419,200, 28 days, interval: 2 days
+    { period: 365 * 24 * 60 * 60, samples: 12 }, // 31,536,000, 1 year, interval: 1 month
+];
+var Instances = {};
+/*
+    On exit, flush any buffered metrics. This requires any Lambda Layer to receive this signal
+ */
+process.on('SIGTERM', 
+/* istanbul ignore next */
+async () => {
+    /* istanbul ignore next */
+    await CustomMetrics.terminate();
+});
+export class CustomMetrics {
+    consistent = false;
+    buffer;
+    buffers = null;
+    client;
+    expires;
+    log;
+    options;
+    owner;
+    prefix = 'metric';
+    primaryKey;
+    sortKey;
+    pResolution;
+    source;
+    spans;
+    table;
+    type;
+    ttl;
+    constructor(options = {}) {
+        this.log = new Log(options.log);
+        if (options.ttl && typeof options.ttl != 'number') {
+            throw new Error('Bad type for "ttl" option');
+        }
+        if (options.spans && (!Array.isArray(options.spans) || options.spans.length == 0)) {
+            throw new Error('The "spans" option must be an non-empty array');
+        }
+        if (options.source && typeof options.source != 'string') {
+            throw new Error('Non-string "source" option');
+        }
+        if (options.pResolution != undefined && (options.pResolution < 0 || options.pResolution > 1000)) {
+            throw new Error('Invalid "pResolution" option. Must be between 0 and 1000. Default is 0');
+        }
+        if (options.consistent != null && typeof options.consistent != 'boolean') {
+            throw new Error('Bad type for "consistent" option');
+        }
+        if (options.prefix) {
+            this.prefix = options.prefix;
+        }
+        if (options.buffer) {
+            if (typeof options.buffer != 'object') {
+                throw new Error('Bad type for "buffer" option');
+            }
+            this.buffer = options.buffer;
+        }
+        this.expires = options.expires || 'expires';
+        this.primaryKey = options.primaryKey || 'pk';
+        this.sortKey = options.sortKey || 'sk';
+        this.type = options.type || { _type: 'Metric' };
+        /* istanbul ignore else */
+        if (options.client) {
+            this.client = options.client;
+        }
+        else {
+            let params = {};
+            if (options.creds) {
+                params.credentials = options.creds;
+                //  Allow region in credentials
+                params.region = params.credentials.region;
+            }
+            if (options.region) {
+                params.region = options.region;
+            }
+            this.client = new DynamoDBClient(params);
+        }
+        if (!options.table) {
+            throw new Error('Missing DynamoDB table name property');
+        }
+        /* istanbul ignore next */
+        this.table = options.table;
+        this.options = options;
+        this.owner = options.owner || 'default';
+        this.spans = options.spans || DefaultSpans;
+        this.ttl = options.ttl || this.spans[this.spans.length - 1].period;
+        if (options.consistent != null) {
+            this.consistent = options.consistent;
+        }
+        if (options.source) {
+            this.source = options.source;
+        }
+        this.pResolution = options.pResolution || DefaultResolution;
+    }
+    async emit(namespace, metricName, value, dimensionsList = [{}], options = {}) {
+        if (value == undefined || value == null) {
+            throw new Error('Invalid metric value');
+        }
+        if (dimensionsList.length == 0) {
+            dimensionsList = [{}];
+        }
+        value = Number(value);
+        if (isNaN(value)) {
+            throw new Error(`Value to emit is not valid`);
+        }
+        if (!namespace || !metricName) {
+            throw new Error('Missing emit namespace / metric argument');
+        }
+        /* istanbul ignore next */
+        if (!Array.isArray(dimensionsList)) {
+            throw new Error('Dimensions must be an array');
+        }
+        if (dimensionsList.length == 0) {
+            dimensionsList = [{}];
+        }
+        let point;
+        point = { count: 1, sum: value };
+        return await this.emitDimensions(namespace, metricName, point, dimensionsList, options);
+    }
+    async emitDimensions(namespace, metricName, point, dimensionsList, options) {
+        let result;
+        for (let dim of dimensionsList) {
+            let dimensions = this.makeDimensionString(dim);
+            let buffer = options.buffer || this.buffer;
+            if (buffer && (buffer.elapsed || buffer.force || buffer.sum || buffer.count) && Buffering) {
+                result = await this.bufferMetric(namespace, metricName, point, dimensions, options);
+            }
+            else {
+                result = await this.emitDimensionedMetric(namespace, metricName, point, dimensions, options);
+            }
+        }
+        return result;
+    }
+    /*
+        Buffer a metric for specific dimensions
+        Point values are uniquely buffered in elements indexed by a (namespace, metric, dimensions) key.
+        Buffered values are flushed when a sum, count or timespan parameter is exceeded.
+        The accumulated buffered values are returned as a metric result until the buffered values are
+        flushed. These values will be only the buffered values for this Lambda.
+        When the metric is flushed, the full persisted metric is returned with all spans.
+        This means returned metrics will typically be just accumulated buffered values and won't reflect
+        other lambdas until flushed. If you need consistent return values -- use query().
+     */
+    async bufferMetric(namespace, metricName, point, dimensions, options) {
+        let buffer = options.buffer || this.buffer;
+        let key = this.getBufferKey(namespace, metricName, dimensions);
+        let buffers = (this.buffers = this.buffers || {});
+        let now = Math.floor((options.timestamp || Date.now()) / 1000);
+        let elapsed = buffer.elapsed || this.spans[0].period / this.spans[0].samples;
+        let elt = (buffers[key] = buffers[key] || {
+            count: 0,
+            sum: 0,
+            timestamp: now + elapsed,
+            elapsed: elapsed,
+            namespace: namespace,
+            metric: metricName,
+            dimensions,
+            spans: [{ points: [{ count: 0, sum: 0 }] }],
+        });
+        /*
+            Add point value to the lowest span and to the elt (to manage when to persist)
+         */
+        let current = elt.spans[0].points.at(-1);
+        if (current) {
+            current.count += point.count;
+            current.sum += point.sum;
+        }
+        elt.count += point.count;
+        elt.sum += point.sum;
+        if (buffer.force ||
+            (buffer.sum && elt.sum >= buffer.sum) ||
+            (buffer.count && elt.count >= buffer.count) ||
+            now >= elt.timestamp) {
+            options = Object.assign({}, options, { timestamp: now * 1000 });
+            let metric = await this.emitDimensionedMetric(namespace, metricName, elt, dimensions, options);
+            //  Reset tallies and save higher spans to return for future buffered metrics
+            elt.count = elt.sum = 0;
+            elt.spans = metric.spans;
+            elt.timestamp = now + (buffer.elapsed || this.spans[0].period / this.spans[0].samples);
+            return metric;
+        }
+        CustomMetrics.saveInstance({ key }, this);
+        return {
+            spans: elt.spans,
+            metric: metricName,
+            namespace: namespace,
+            owner: options.owner || this.owner,
+            version: Version,
+        };
+    }
+    /*
+        Emit a metric for specific dimensions
+     */
+    async emitDimensionedMetric(namespace, metricName, point, dimensions, options = {}) {
+        /*
+            Update the metric. May need retries if colliding with other updaters.
+         */
+        let now = Math.floor((options.timestamp || Date.now()) / 1000);
+        let ttl = options.ttl != undefined ? options.ttl : this.ttl;
+        let retries = MaxRetries;
+        let metric;
+        let backoff = 10;
+        /* istanbul ignore next */
+        let chan = options.log == true ? 'info' : 'trace';
+        do {
+            let owner = options.owner || this.owner;
+            metric = await this.getMetric(owner, namespace, metricName, dimensions, options.log);
+            if (metric) {
+                if (options.upgrade) {
+                    metric = this.upgradeMetric(metric);
+                }
+            }
+            else {
+                metric = this.initMetric(owner, namespace, metricName, dimensions, now);
+            }
+            if (point.timestamp) {
+                /*
+                    Buffered points only.
+                    Pick the first span for which the point is after the earliest span start or after the end of the span
+                 */
+                let si = metric.spans.findIndex((s) => s.end - s.period <= point.timestamp || s.end <= point.timestamp);
+                /* istanbul ignore else */
+                if (si >= 0) {
+                    this.addValue(metric, point.timestamp, point, si);
+                }
+                else {
+                    //  Silently discard
+                }
+            }
+            else {
+                this.addValue(metric, now, point, 0);
+            }
+            /* istanbul ignore next */
+            if (this.source) {
+                metric._source = this.source;
+            }
+            /*
+                Set the expiration TTL. Defaults to the longest span.
+                Users may define a shorter TTL to prune metrics for inactive items.
+            */
+            if (ttl) {
+                //  MOB - is this a date, seconds or msec
+                metric.expires = now + ttl;
+            }
+            if (await this.putMetric(metric, options)) {
+                break;
+            }
+            /* istanbul ignore next */
+            if (retries == 0) {
+                this.log.error(`Metric update has too many retries`, { namespace, metricName, dimensions });
+                break;
+            }
+            /* istanbul ignore next */
+            this.log[chan](`Retry ${MaxRetries - retries} metric update ${metric.namespace} ${metric.metric} ${metric.dimensions}`, {
+                retries,
+                metric,
+            });
+            //  Exponential backoff
+            /* istanbul ignore next */
+            backoff = backoff * 2;
+            /* istanbul ignore next */
+            this.log[chan](`Retry backoff ${backoff} ${this.jitter(backoff)}`);
+            /* istanbul ignore next */
+            await this.delay(this.jitter(backoff));
+        } while (retries-- > 0);
+        return metric;
+    }
+    /*
+        Upgrade a metric with new spans. Only the specified dimensions are upgraded.
+     */
+    async upgrade(namespace, metricName, dimensionsList = [{}], options = {}) {
+        let owner = options.owner || this.owner;
+        if (dimensionsList.length == 0) {
+            dimensionsList = [{}];
+        }
+        let metric;
+        for (let dim of dimensionsList) {
+            let dimensions = this.makeDimensionString(dim);
+            let old = await this.getMetric(owner, namespace, metricName, dimensions, options.log);
+            metric = this.upgradeMetric(old);
+            await this.putMetric(metric, options);
+        }
+        return metric;
+    }
+    /*
+        Upgrade a metric and return the upgraded result
+        Optimized for when an upgrade is not required.
+     */
+    upgradeMetric(old) {
+        let required = false;
+        /*
+            Check if upgrade required
+         */
+        if (this.spans.length == old.spans.length) {
+            for (let [index, span] of Object.entries(old.spans)) {
+                if (span.period != this.spans[index].period || span.samples != this.spans[index].samples) {
+                    required = true;
+                }
+            }
+            if (!required) {
+                return old;
+            }
+        }
+        /*
+            This initializes a new metric with the new spans and apportion the old data points to
+            the new metric at the point's timestamp. Pick the earliest timestamp from the old metric.
+         */
+        let now = Math.min(...old.spans.map((span) => span.end - span.period)) || Math.floor(Date.now() / 1000);
+        let metric = this.initMetric(old.owner, old.namespace, old.metric, old.dimensions, now);
+        for (let span of old.spans) {
+            let interval = span.period / span.samples;
+            let firstPoint = span.end - span.points.length * interval;
+            /*
+                Pick the first span for which the point is after the earliest span start or after the end of the span
+            */
+            let si = metric.spans.findIndex((s) => s.end - s.period <= firstPoint || s.end <= firstPoint);
+            let t = firstPoint;
+            for (let point of span.points) {
+                this.addValue(metric, t, point, si);
+                t += interval;
+            }
+        }
+        return metric;
+    }
+    /*
+        Flush metrics for all instances on Lambda termination
+     */
+    static async terminate() {
+        await CustomMetrics.flushAll();
+    }
+    static async flushAll() {
+        for (let [key, instance] of Object.entries(Instances)) {
+            await instance.flush();
+            CustomMetrics.freeInstanceByKey(key);
+        }
+        Instances = {};
+    }
+    async flush(options = {}) {
+        if (!this.buffers)
+            return;
+        let now = Math.floor((options.timestamp || Date.now()) / 1000);
+        for (let elt of Object.values(this.buffers)) {
+            await this.flushElt(elt, now);
+        }
+    }
+    async flushElt(elt, now) {
+        //  Choose timestamp if before the buffer expires, otherwise choose the buffer expiry time
+        elt.timestamp = Math.min(now, elt.timestamp);
+        let metric = await this.emitDimensionedMetric(elt.namespace, elt.metric, elt, elt.dimensions, {
+            timestamp: elt.timestamp * 1000,
+        });
+        elt.count = elt.sum = 0;
+        elt.spans = metric.spans;
+        elt.timestamp = now + (elt.elapsed || this.spans[0].period / this.spans[0].samples);
+    }
+    getBufferKey(namespace, metricName, dimensions) {
+        return `${namespace}|${metricName}|${JSON.stringify(dimensions)}`;
+    }
+    /*
+        Query metrics. Return an array of metrics
+     */
+    async query(namespace, metricName, dimensions, period, statistic, options = {}) {
+        let owner = options.owner || this.owner;
+        let dimString = this.makeDimensionString(dimensions);
+        if (period > this.spans.at(-1).period) {
+            period = this.spans.at(-1).period;
+        }
+        let now = Math.floor((options.timestamp || Date.now()) / 1000);
+        /*
+           Flush buffered metrics for this instance. Will not see buffered metrics in other instances
+           until they are flushed.
+         */
+        if (this.buffers) {
+            let key = this.getBufferKey(namespace, metricName, dimString);
+            if (this.buffers[key]) {
+                await this.flushElt(this.buffers[key], now);
+            }
+        }
+        let metric = await this.getMetric(owner, namespace, metricName, dimString, options.log);
+        if (!metric) {
+            return { dimensions, id: options.id, metric: metricName, namespace, period, points: [], owner, samples: 0 };
+        }
+        let result = this.processMetric(metric, now, period, statistic, options);
+        /* istanbul ignore next */
+        this.log[options.log == true ? 'info' : 'trace'](`Query metrics ${namespace}, ${metricName}`, {
+            dimensions,
+            period,
+            statistic,
+            options,
+            result,
+        });
+        return result;
+    }
+    async queryMetrics(namespace, metric, period, statistic, options = {}) {
+        let owner = options.owner || this.owner;
+        let next = options.next;
+        let limit = options.limit || MetricListLimit;
+        /* istanbul ignore next */
+        let chan = options.log == true ? 'info' : 'trace';
+        let items, command;
+        let count = 0;
+        do {
+            /* istanbul ignore next */
+            ;
+            ({ command, items, next } = await this.findMetrics(owner, namespace, metric, limit, next, 'spans'));
+            this.log[chan](`Find metrics ${namespace}, ${metric}`, { command, items });
+            if (items.length) {
+                count += items.length;
+            }
+        } while (next && count < limit);
+        let now = Math.floor((options.timestamp || Date.now()) / 1000);
+        let results = [];
+        for (let metric of items) {
+            let result = this.processMetric(metric, now, period, statistic, { accumulate: true, timestamp: now });
+            results.push(result);
+        }
+        return results;
+    }
+    /*
+       Process a metric for query() or queryMetrics() and extract the desired series or accumlated value
+     */
+    processMetric(metric, now, period, statistic, options) {
+        let end;
+        let si;
+        let owner = options.owner || this.owner;
+        if (options.start) {
+            /*
+                Find span for the request start: period < span[i+1].period
+            */
+            let start = options.start / 1000;
+            si = metric.spans.findIndex((s) => period <= s.period && s.end - s.period <= start && start < s.end);
+            end = start + period;
+        }
+        else {
+            let span = metric.spans[0];
+            let interval = span.period / span.samples;
+            /*
+                Special case: if now is within the most recent span interval, then set "start" to include this interval.
+            */
+            if (span.end - interval <= now && now < span.end) {
+                end = span.end;
+            }
+            else {
+                end = now;
+            }
+            si = metric.spans.findIndex((s) => period <= s.period);
+        }
+        if (si < 0) {
+            si = metric.spans.length - 1;
+        }
+        /*
+            Aggregate data for all spans up to the desired span. Do this because spans are updated lazily on emit.
+         */
+        this.addValue(metric, now, { count: 0, sum: 0 }, 0, si);
+        let span = metric.spans[si];
+        let result;
+        if (options.accumulate) {
+            result = this.accumulateMetric(metric, span, statistic, owner, end, period);
+        }
+        else {
+            result = this.calculateSeries(metric, span, statistic, owner, end, period);
+        }
+        result.id = options.id;
+        return result;
+    }
+    /*
+        Accumulate the metric data points into a single value.
+        This is useful for gauges and widgets that need a single data value for the metric.
+        According to the desired statistic, this calculates the avg, count, max, min, sum, and pvalues.
+     */
+    accumulateMetric(metric, span, statistic, owner, end, period) {
+        let start = this.alignTime(span, end - period);
+        let value = 0, count = 0, pvalues = [];
+        if (statistic == 'max') {
+            value = Number.NEGATIVE_INFINITY;
+        }
+        else if (statistic == 'min') {
+            value = Infinity;
+        }
+        else if (statistic == 'sum') {
+            value = 0;
+            count = 0;
+        }
+        else if (statistic == 'count') {
+            value = 0;
+            count = 0;
+        }
+        else if (statistic == 'current') {
+            value = 0;
+            count = 0;
+        }
+        else if (statistic.match(/^p[0-9]+/)) {
+            pvalues = [];
+        } /* avg */
+        else {
+            value = 0;
+            count = 0;
+        }
+        let points = span.points;
+        let interval = span.period / span.samples;
+        let t = span.end - span.points.length * interval;
+        for (let i = 0; i < points.length; i++) {
+            let point = points[i];
+            if (start <= t && t < start + period) {
+                if (statistic == 'max') {
+                    if (point.max != undefined) {
+                        value = Math.max(value, point.max);
+                    }
+                    else {
+                        //  For use to accumulate AWS metrics that don't keep min/max in points
+                        value = Math.max(value, point.sum / (point.count || 1));
+                    }
+                }
+                else if (statistic == 'min') {
+                    if (point.min != undefined) {
+                        value = Math.min(value, point.min);
+                    }
+                    else {
+                        //  For use to accumulate AWS metrics that don't keep min/max in points
+                        value = Math.min(value, point.sum / (point.count || 1));
+                    }
+                }
+                else if (statistic == 'sum') {
+                    value += point.sum;
+                }
+                else if (statistic == 'current') {
+                    value = point.sum / (point.count || 1);
+                }
+                else if (statistic == 'count') {
+                    value += point.count;
+                }
+                else if (statistic.match(/^p[0-9]+/)) {
+                    pvalues = pvalues.concat(point.pvalues);
+                } /* avg */
+                else {
+                    value += point.sum;
+                }
+                count += point.count;
+            }
+            t += interval;
+        }
+        if (statistic.match(/^p[0-9]+/)) {
+            let p = parseInt(statistic.slice(1));
+            pvalues.sort((a, b) => a - b);
+            let nth = Math.min(Math.round((pvalues.length * p) / 100 + 1), pvalues.length - 1);
+            value = pvalues[nth];
+        }
+        else if (statistic == 'avg') {
+            value /= Math.max(count, 1);
+        }
+        return {
+            dimensions: this.makeDimensionObject(metric.dimensions),
+            metric: metric.metric,
+            namespace: metric.namespace,
+            owner: owner,
+            period: span.period,
+            points: [{ value, timestamp: start + period, count }],
+            samples: span.samples,
+        };
+    }
+    /*
+        Process the metric points. This is used for graphs that need all the data points.
+        This calculates the avg, max, min, sum, count, pvalues and per-point timestamps.
+        This always returns a full series of points even if there is no data.
+     */
+    calculateSeries(metric, span, statistic, owner, end, period) {
+        let points = [];
+        let interval = span.period / span.samples;
+        /*
+            Start points aligned with span buckets
+         */
+        let start = this.alignTime(span, end - period);
+        let firstPoint = span.end - span.points.length * interval;
+        let t;
+        for (t = start; t < firstPoint && points.length < span.samples; t += interval) {
+            points.push({ value: 0, count: 0, timestamp: t * 1000 });
+        }
+        t = firstPoint;
+        for (let point of span.points) {
+            //  MOB - end was start + period, now end is closer
+            if (start <= t && t < end) {
+                let value = undefined;
+                /* istanbul ignore else */
+                if (point.count > 0) {
+                    if (statistic == 'max') {
+                        if (point.max != undefined) {
+                            if (value == undefined) {
+                                value = point.max;
+                            }
+                            else {
+                                value = Math.max(value, point.max);
+                            }
+                        }
+                    }
+                    else if (statistic == 'min') {
+                        if (point.min != undefined) {
+                            if (value == undefined) {
+                                value = point.min;
+                            }
+                            else {
+                                value = Math.min(value, point.min);
+                            }
+                        }
+                    }
+                    else if (statistic == 'sum') {
+                        value = point.sum;
+                    }
+                    else if (statistic == 'count') {
+                        value = point.count;
+                    }
+                    else if (statistic.match(/^p[0-9]+/)) {
+                        let p = parseInt(statistic.slice(1));
+                        let pvalues = point.pvalues;
+                        pvalues.sort((a, b) => a - b);
+                        let nth = Math.min(Math.round((pvalues.length * p) / 100 + 1), pvalues.length - 1);
+                        value = pvalues[nth];
+                    } /* avg | current */
+                    else {
+                        value = point.sum / point.count;
+                    }
+                }
+                else {
+                    value = 0;
+                }
+                /*
+                    The timestamp is set to be the end of the point bucket not the start, and not after the range
+                */
+                let timestamp = Math.min(t + interval, end) * 1000;
+                points.push({ value, count: point.count, timestamp });
+            }
+            t += interval;
+        }
+        let count = Math.min(Math.ceil(period / interval), span.samples);
+        while (points.length < count) {
+            let timestamp = Math.min(t + interval, end) * 1000;
+            points.push({ value: 0, count: 0, timestamp });
+            t += interval;
+        }
+        return {
+            dimensions: this.makeDimensionObject(metric.dimensions),
+            metric: metric.metric,
+            namespace: metric.namespace,
+            period: span.period,
+            points: points,
+            owner: owner,
+            samples: span.samples,
+        };
+    }
+    /*
+        Convert a dimensions object of the form {key: value, ...} to a string with comma separated "key=value,..." with sorted property keys
+     */
+    makeDimensionString(dimensions) {
+        let result = [];
+        //  Sort dimension properties
+        let entries = Object.entries(dimensions).sort((a, b) => a[0].localeCompare(b[0]));
+        for (let [name, value] of entries) {
+            result.push(`${name}=${value}`);
+        }
+        return result.join(',');
+    }
+    /*
+        Convert a dimensions string of the form "key=value,..." to a a dimensions object {key: value, ...}
+    */
+    makeDimensionObject(dimensions) {
+        let result = {};
+        for (let dimension of dimensions.split(',')) {
+            if (dimension) {
+                let [key, value] = dimension.split('=');
+                result[key] = value;
+            }
+        }
+        return result;
+    }
+    /*
+        Add a point value to the metric the span index with the given timestamp.
+        We aggregate aged out points to upper spans as required.
+        For queries, a span nominates the desired span, all lower span values are aggregated up.
+     */
+    addValue(metric, timestamp, point, si, querySpanIndex = undefined) {
+        this.assert(metric);
+        this.assert(timestamp);
+        this.assert(0 <= si && si < metric.spans.length);
+        let span = metric.spans[si];
+        let interval = span.period / span.samples;
+        /* istanbul ignore next */
+        let points = span.points || [];
+        /*
+            Determine if need to recurse and aggregate earlier spans
+         */
+        let queryRecurse = si < querySpanIndex && si + 1 < metric.spans.length;
+        //  Just for safety, should not happen
+        /* istanbul ignore next */
+        while (points.length > span.samples) {
+            points.shift();
+        }
+        let first = span.end - points.length * interval;
+        /*
+            Aggregate points. Calculate how many points have aged, or if querying, how many must be aggregated.
+        */
+        let shift = 0;
+        if (points.length) {
+            /* istanbul ignore next */
+            if (queryRecurse) {
+                //  Querying and not yet on the target period, so aggregate all points
+                shift = points.length;
+            }
+            else if (timestamp >= first) {
+                //  Count of aged data points
+                shift = Math.floor((timestamp - first) / interval) - span.samples;
+                if (!queryRecurse && point.count && timestamp >= span.end) {
+                    //  Add one more to make room for this point being added
+                    shift += 1;
+                }
+            }
+            shift = Math.max(0, Math.min(shift, points.length));
+            this.assert(0 <= shift && shift <= points.length);
+            /*
+                Add points to the next span by shifting aged points and make room.
+             */
+            for (let i = 0; i < shift; i++) {
+                let p = points.shift();
+                if (p.count && si + 1 < metric.spans.length) {
+                    this.addValue(metric, first, p, si + 1, querySpanIndex);
+                }
+                first += interval;
+            }
+        }
+        if (queryRecurse) {
+            //  Querying and not at the terminal period. Must recurse and aggregate all spans up to the target span.
+            this.addValue(metric, timestamp, point, si + 1, querySpanIndex);
+            return;
+        }
+        if (point.count) {
+            let index;
+            if (points.length == 0) {
+                points.push({ count: 0, sum: 0 });
+                /*
+                    This will set the span.end to the next aligned interval that is >timestamp
+                    NOTE: this may mean that span.start is set before now and before recorded time
+                 */
+                span.end = this.alignTime(span, timestamp + 1);
+                first = span.end - interval;
+                index = 0;
+            }
+            else {
+                if (timestamp < span.end - span.period) {
+                    //  Discard if before the earliest possible point for the span
+                    return;
+                }
+                while (timestamp < first) {
+                    points.unshift({ count: 0, sum: 0 });
+                    first -= interval;
+                }
+                while (timestamp >= span.end) {
+                    points.push({ count: 0, sum: 0 });
+                    span.end += interval;
+                }
+                index = Math.floor((timestamp - first) / interval);
+            }
+            this.assert(points.length <= span.samples);
+            if (!(0 <= index && index < points.length)) {
+                this.assert(0 <= index && index < points.length);
+                //  Just in case - should never happen
+                /* istanbul ignore next */
+                if (index > 0) {
+                    index = points.length - 1;
+                }
+            }
+            this.setPoint(span, index, point);
+        }
+    }
+    /*
+        Add value to a span and update count, min, max, pValues and sum
+        The point "index" defines the point[] to update.
+     */
+    setPoint(span, index, add) {
+        let points = span.points;
+        this.assert(0 <= index && index < points.length);
+        let point = points[index];
+        /* istanbul ignore next */
+        if (!point) {
+            this.log.error(`Metric null point`, { span, index, add });
+            return;
+        }
+        if (add.count) {
+            let value = add.sum / add.count;
+            if (point.min == undefined) {
+                point.min = value;
+            }
+            else {
+                point.min = Math.min(value, point.min);
+            }
+            if (point.max == undefined) {
+                point.max = value;
+            }
+            else {
+                point.max = Math.max(value, point.max);
+            }
+        }
+        if (this.pResolution) {
+            point.pvalues = point.pvalues || [];
+            if (add.pvalues) {
+                point.pvalues.push(...add.pvalues);
+            }
+            else {
+                point.pvalues.push(add.sum / add.count);
+            }
+            point.pvalues.splice(0, point.pvalues.length - this.pResolution);
+        }
+        point.sum += add.sum;
+        point.count += add.count;
+    }
+    /*
+        Get list of metrics at a given level. The args: namespace and metrics may be undefined.
+        Return {namespaces, metrics, dimensions} as possible.
+     */
+    async getMetricList(namespace = undefined, metric = undefined, options = { limit: MetricListLimit }) {
+        let map = {};
+        let owner = options.owner || this.owner;
+        let next = options.next;
+        let limit = options.limit || MetricListLimit;
+        /* istanbul ignore next */
+        let chan = options.log == true ? 'info' : 'trace';
+        let items, command;
+        let count = 0;
+        do {
+            /* istanbul ignore next */
+            ;
+            ({ command, items, next } = await this.findMetrics(owner, namespace, metric, limit, next));
+            this.log[chan](`Find metrics ${namespace}, ${metric}`, { command, items });
+            if (items.length) {
+                for (let item of items) {
+                    let ns = (map[item.namespace] = map[item.namespace] || {});
+                    let met = (ns[item.metric] = ns[item.metric] || []);
+                    met.push(item.dimensions);
+                }
+                count += items.length;
+            }
+        } while (next && count < limit);
+        let result = { namespaces: Object.keys(map) };
+        if (namespace && map[namespace]) {
+            result.metrics = Object.keys(map[namespace]);
+            if (metric) {
+                let dimensions = map[namespace][metric];
+                if (dimensions) {
+                    result.dimensions = [];
+                    dimensions = dimensions.sort().filter((v, index, self) => self.indexOf(v) === index);
+                    for (let dimension of dimensions) {
+                        result.dimensions.push(this.makeDimensionObject(dimension));
+                    }
+                }
+            }
+        }
+        return result;
+    }
+    initMetric(owner, namespace, name, dimensions, now) {
+        let metric = {
+            dimensions,
+            metric: name,
+            namespace,
+            owner,
+            spans: [],
+            version: Version,
+        };
+        for (let sdef of this.spans) {
+            let span = {
+                samples: sdef.samples,
+                period: sdef.period,
+                end: null,
+                points: [],
+            };
+            //  This will set the span.end to the next aligned interval that is >timestamp
+            let interval = span.period / span.samples;
+            // span.end = this.alignTime(span, now + 1)
+            span.end = this.alignTime(span, now + interval);
+            metric.spans.push(span);
+        }
+        return metric;
+    }
+    async getMetric(owner, namespace, metric, dimensions, log) {
+        let command = new GetItemCommand({
+            TableName: this.table,
+            Key: {
+                [this.primaryKey]: { S: `${this.prefix}#${Version}#${owner}` },
+                [this.sortKey]: { S: `${this.prefix}#${namespace}#${metric}#${dimensions}` },
+            },
+            ConsistentRead: this.consistent,
+        });
+        let data = await this.client.send(command);
+        let result = null;
+        if (data && data.Item) {
+            let item = unmarshall(data.Item);
+            result = this.mapItemFromDB(item);
+        }
+        if (log == true) {
+            let chan = log == true ? 'info' : 'trace';
+            this.log[chan](`GetMetric ${namespace}, ${metric} ${dimensions}`, { cmd: command, result });
+        }
+        return result;
+    }
+    async findMetrics(owner, namespace, metric, limit, startKey, fields = '') {
+        let key = [namespace];
+        if (metric) {
+            key.push(metric);
+        }
+        /* istanbul ignore next */
+        let start = startKey ? marshall(startKey) : undefined;
+        let project = `${this.primaryKey}, ${this.sortKey}`;
+        if (fields) {
+            project += `, ${fields}`;
+        }
+        let command = new QueryCommand({
+            TableName: this.table,
+            ExpressionAttributeNames: {
+                '#_0': this.primaryKey,
+                '#_1': this.sortKey,
+            },
+            ExpressionAttributeValues: {
+                ':_0': { S: `${this.prefix}#${Version}#${owner}` },
+                ':_1': { S: `${this.prefix}#${key.join('#')}` },
+            },
+            KeyConditionExpression: '#_0 = :_0 and begins_with(#_1, :_1)',
+            ConsistentRead: this.consistent,
+            Limit: limit,
+            ScanIndexForward: true,
+            ExclusiveStartKey: start,
+            ProjectionExpression: project,
+        });
+        let result = await this.client.send(command);
+        let items = [];
+        if (result.Items) {
+            for (let i = 0; i < result.Items.length; i++) {
+                let item = unmarshall(result.Items[i]);
+                items.push(this.mapItemFromDB(item));
+            }
+        }
+        let next = undefined;
+        /* istanbul ignore next */
+        if (result.LastEvaluatedKey) {
+            next = unmarshall(result.LastEvaluatedKey);
+        }
+        return { items, next, command };
+    }
+    /*
+        Use a sequence number to detect simultaneous updated. If collision, will throw
+        a ConditionalCheckFailedException and emit() will then retry.
+    */
+    async putMetric(item, options) {
+        let ConditionExpression, ExpressionAttributeValues;
+        let seq;
+        if (item.seq != undefined) {
+            /* istanbul ignore next */
+            seq = item.seq = item.seq || 0;
+            /* istanbul ignore next */
+            if (item.seq++ >= MaxSeq) {
+                item.seq = 0;
+            }
+            ConditionExpression = `seq = :_0`;
+            ExpressionAttributeValues = { ':_0': { N: seq.toString() } };
+        }
+        else {
+            item.seq = 0;
+        }
+        let mapped = this.mapItemToDB(item);
+        let params = {
+            TableName: this.table,
+            ReturnValues: 'NONE',
+            Item: marshall(mapped, { removeUndefinedValues: true }),
+            ConditionExpression,
+            ExpressionAttributeValues,
+        };
+        let command = new PutItemCommand(params);
+        /* istanbul ignore next */
+        let chan = options.log == true ? 'info' : 'trace';
+        this.log[chan](`Put metric ${item.namespace}, ${item.metric}`, {
+            dimensions: item.dimensions,
+            command,
+            params,
+            item,
+        });
+        try {
+            await this.client.send(command);
+            return true;
+        }
+        catch (err) /* istanbul ignore next */ {
+            ;
+            (function (err, log) {
+                //  SDK V3 puts the code in err.name (Ugh!)
+                let code = err.code || err.name;
+                if (code == 'ConditionalCheckFailedException') {
+                    log.trace(`Update collision`, { err });
+                }
+                else if (code == 'ProvisionedThroughputExceededException') {
+                    log.info(`Provisioned throughput exceeded: ${err.message}`, { err, cmd: command, item });
+                }
+                else {
+                    log.error(`Emit exception code ${err.name} ${err.code} message ${err.message}`, {
+                        err,
+                        cmd: command,
+                        item,
+                    });
+                    throw err;
+                }
+                return false;
+            })(err, this.log);
+        }
+    }
+    mapItemFromDB(data) {
+        let pk = data[this.primaryKey];
+        let sk = data[this.sortKey];
+        let owner = pk.split('#').pop();
+        let [, namespace, metric, dimensions] = sk.split('#');
+        let spans;
+        if (data.spans) {
+            spans = data.spans.map((s) => {
+                return {
+                    end: s.se,
+                    period: s.sp,
+                    samples: s.ss,
+                    points: s.pt.map((p) => {
+                        let point = { count: Number(p.c), sum: Number(p.s) };
+                        if (p.x != null) {
+                            point.max = Number(p.x);
+                        }
+                        if (p.m != null) {
+                            point.min = Number(p.m);
+                        }
+                        if (p.v) {
+                            point.pvalues = p.v;
+                        }
+                        return point;
+                    }),
+                };
+            });
+        }
+        let expires = data[this.expires];
+        let seq = data.seq;
+        return { dimensions, expires, metric, namespace, owner, seq, spans };
+    }
+    mapItemToDB(item) {
+        let result = {
+            [this.primaryKey]: `${this.prefix}#${Version}#${item.owner}`,
+            [this.sortKey]: `${this.prefix}#${item.namespace}#${item.metric}#${item.dimensions}`,
+            [this.expires]: item.expires,
+            spans: item.spans.map((i) => {
+                return {
+                    se: i.end,
+                    sp: i.period,
+                    ss: i.samples,
+                    pt: i.points.map((point) => {
+                        let p = { c: point.count, s: this.round(point.sum) };
+                        if (point.max != null) {
+                            p.x = this.round(point.max);
+                        }
+                        if (point.min != null) {
+                            p.m = this.round(point.min);
+                        }
+                        if (point.pvalues) {
+                            p.v = point.pvalues;
+                        }
+                        return p;
+                    }),
+                };
+            }),
+            seq: item.seq,
+            _source: item._source,
+        };
+        if (this.type) {
+            let [key, model] = Object.entries(this.type)[0];
+            result[key] = model;
+        }
+        return result;
+    }
+    static freeInstanceByKey(key) {
+        delete Instances[key];
+    }
+    static saveInstance(tags, metrics) {
+        let key = JSON.stringify(tags);
+        Instances[key] = metrics;
+    }
+    /*
+        Align a timestamp that is >timestamp and rounded up in seconds to be interval aligned
+        Note: this may be in the future
+     */
+    alignTime(span, timestamp) {
+        let interval = span.period / span.samples;
+        return Math.ceil(timestamp / interval) * interval;
+    }
+    /* istanbul ignore next */
+    assert(c) {
+        if (!c && Assert) {
+            let msg = { stack: '' };
+            if (typeof Error.captureStackTrace === 'function') {
+                Error.captureStackTrace(msg);
+            }
+            else {
+                msg.stack = new Error('Assert').stack;
+            }
+            this.log.error(`Assertion failed`, { stack: msg.stack });
+        }
+    }
+    /* istanbul ignore next */
+    info(message, context = {}) {
+        console.log('INFO: ' + message, context);
+    }
+    /* istanbul ignore next */
+    error(message, context = {}) {
+        console.log('ERROR: ' + message, context);
+    }
+    /* istanbul ignore next */
+    trace(message, context = {}) {
+        console.log('TRACE: ' + message, context);
+    }
+    //  Overcome Javascript number precision issues
+    round(n) {
+        /* istanbul ignore next */
+        if (isNaN(n) || n == null) {
+            return 0;
+        }
+        let places = 16 - n.toFixed(0).length;
+        return Number(n.toFixed(places)) - 0;
+    }
+    /* istanbul ignore next */
+    jitter(msecs) {
+        return Math.min(10 * 1000, Math.floor(msecs / 2 + msecs * Math.random()));
+    }
+    /* istanbul ignore next */
+    async delay(time) {
+        return new Promise(function (resolve, reject) {
+            setTimeout(() => resolve(true), time);
+        });
+    }
+}
+//  Emulate the SenseLogs logger
+/* istanbul ignore next */
+class Log {
+    senselogs = null;
+    logger = null;
+    verbose = false;
+    constructor(dest) {
+        if (dest === true) {
+            this.logger = this.defaultLogger;
+        }
+        else if (dest == 'verbose') {
+            this.logger = this.defaultLogger;
+            this.verbose = true;
+        }
+        else if (dest && typeof dest.info == 'function') {
+            this.senselogs = dest;
+        }
+    }
+    error(message, context) {
+        this.process('error', message, context);
+    }
+    info(message, context) {
+        this.process('info', message, context);
+    }
+    trace(message, context) {
+        this.process('trace', message, context);
+    }
+    process(chan, message, context) {
+        if (this.logger) {
+            this.logger(chan, message, context);
+        }
+        else if (this.senselogs) {
+            this.senselogs[chan](message, context);
+        }
+    }
+    /* istanbul ignore next */
+    defaultLogger(chan, message, context) {
+        if (chan == 'trace' && !this.verbose) {
+            //  params.log: true will cause the chan to be changed to 'info'
+            return;
+        }
+        let tag = chan.toUpperCase();
+        if (context) {
+            try {
+                console.log(tag, message, JSON.stringify(context, null, 4));
+            }
+            catch (err) {
+                let buf = ['{'];
+                for (let [key, value] of Object.entries(context)) {
+                    try {
+                        buf.push(`    ${key}: ${JSON.stringify(value, null, 4)}`);
+                    }
+                    catch (err) {
+                        /* continue */
+                    }
+                }
+                buf.push('}');
+                console.log(tag, message, buf.join('\n'));
+            }
+        }
+        else {
+            console.log(tag, message);
+        }
+    }
+}
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/accum.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/accum.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/accum.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/accum.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/accum.js
new file mode 100644
index 0000000..e0feedc
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/accum.js
@@ -0,0 +1,25 @@
+/*
+    accum.ts - Test accumulated queries
+ */
+import { client, table, CustomMetrics, DefaultSpans } from './utils/init';
+// jest.setTimeout(7200 * 1000)
+test('Test', async () => {
+    let metrics = new CustomMetrics({ client, table, log: true });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let span = DefaultSpans[2];
+    let interval = span.period / span.samples;
+    for (let i = 0; i < 4; i++) {
+        await metrics.emit('test/accum', 'FirstMetric', 10, [], { timestamp });
+        timestamp += interval * 1000;
+    }
+    // timestamp = timestamp - interval * 1000 + 1000
+    let r = await metrics.query('test/accum', 'FirstMetric', {}, 86400, 'sum', { timestamp, accumulate: true });
+    expect(r).toBeDefined();
+    expect(r.metric).toBe('FirstMetric');
+    expect(r.namespace).toBe('test/accum');
+    expect(r.period).toBe(span.period);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(1);
+    expect(r.points[0].value).toBe(40);
+    expect(r.points[0].count).toBe(4);
+});
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/api.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/api.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/api.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/api.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/api.js
new file mode 100644
index 0000000..7ce57ee
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/api.js
@@ -0,0 +1,11 @@
+/*
+    api.ts - Test misc api routines
+ */
+import { table, CustomMetrics } from './utils/init';
+// jest.setTimeout(7200 * 1000)
+test('Test flush', async () => {
+    let metrics = new CustomMetrics({ table });
+    await metrics.flush();
+    await CustomMetrics.flushAll();
+    await CustomMetrics.terminate();
+});
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/basic.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/basic.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/basic.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/basic.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/basic.js
new file mode 100644
index 0000000..51c3caa
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/basic.js
@@ -0,0 +1,20 @@
+/*
+    basic.ts - base operations: emit / query
+ */
+import { client, table, CustomMetrics } from './utils/init';
+// jest.setTimeout(7200 * 1000)
+test('Basic test harness', async () => {
+    let metrics = new CustomMetrics({ client, table, log: true });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    //  This first emit will initialize the metric
+    let metric = await metrics.emit('test/basic', 'FirstMetric', 10, [], { timestamp });
+    expect(metric).toBeDefined();
+    //  The second emit will read the metric and update
+    metric = await metrics.emit('test/basic', 'FirstMetric', 10, [{}, { Rocket: 'SaturnV' }], { timestamp });
+    let r = await metrics.query('test/basic', 'FirstMetric', {}, 300, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    let list = await metrics.getMetricList('test/basic');
+    expect(list).toBeDefined();
+    list = await metrics.getMetricList('test/basic', 'FirstMetric');
+    expect(list).toBeDefined();
+});
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/buffer.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/buffer.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/buffer.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/buffer.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/buffer.js
new file mode 100644
index 0000000..baa9d6d
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/buffer.js
@@ -0,0 +1,119 @@
+/*
+    buffer.ts - Test buffered emits
+ */
+import { client, table, CustomMetrics, DefaultSpans } from './utils/init';
+// jest.setTimeout(7200 * 1000)
+test('Test Buffer Basic', async () => {
+    let metrics = new CustomMetrics({ client, table, log: true });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let span = DefaultSpans[0];
+    let interval = span.period / span.samples;
+    /*
+        Buffer some metrics
+     */
+    for (let i = 0; i < 4; i++) {
+        let metric = await metrics.emit('test/buffer', 'BasicMetric', 10, [], { buffer: { elapsed: 1800 }, timestamp });
+        expect(metric).toBeDefined();
+        expect(metric.metric).toBe('BasicMetric');
+        expect(metric.spans.length).toBe(1);
+        expect(metric.spans[0].points.length).toBe(1);
+        expect(metric.spans[0].points[0].count).toBe(i + 1);
+        timestamp += interval * 1000;
+    }
+    //  Query will flush
+    let r = await metrics.query('test/buffer', 'BasicMetric', {}, 3600, 'avg', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.metric).toBe('BasicMetric');
+    expect(r.namespace).toBe('test/buffer');
+    expect(r.period).toBe(3600);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[11].value).toBe(10);
+    expect(r.points[11].count).toBe(4);
+});
+test('Test elapsed buffers', async () => {
+    let metrics = new CustomMetrics({ client, table, log: true });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let span = DefaultSpans[0];
+    let interval = span.period / span.samples;
+    /*
+        Buffer some metrics and then flush
+     */
+    for (let i = 0; i < 4; i++) {
+        let metric = await metrics.emit('test/buffer', 'ElapsedMetric', 1, [], { buffer: { elapsed: 1800 }, timestamp });
+        expect(metric).toBeDefined();
+        expect(metric.metric).toBe('ElapsedMetric');
+        expect(metric.spans.length).toBe(1);
+        expect(metric.spans[0].points.length).toBe(1);
+        expect(metric.spans[0].points[0].count).toBe(i + 1);
+        timestamp += interval * 1000;
+    }
+    /*
+        Emit again after long delay this should cause the prior buffer to be flushed
+     */
+    timestamp += 3600 * 1000;
+    await metrics.emit('test/buffer', 'ElapsedMetric', 7, [], { buffer: { elapsed: 1800 }, timestamp });
+    let r = await metrics.query('test/buffer', 'ElapsedMetric', {}, 86400, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.metric).toBe('ElapsedMetric');
+    expect(r.namespace).toBe('test/buffer');
+    expect(r.period).toBe(86400);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[11].value).toBe(11);
+    expect(r.points[11].count).toBe(5);
+});
+test('Test buffer API', async () => {
+    let metrics = new CustomMetrics({ client, table });
+    let metric = await metrics.emit('test/buffer', 'CoverageMetric', 1, [], { buffer: { sum: 1 } });
+    expect(metric).toBeDefined();
+    metrics = new CustomMetrics({ client, table, buffer: { elapsed: 1800 } });
+    metric = await metrics.emit('test/buffer', 'CoverageMetric', 1, []);
+    expect(metric).toBeDefined();
+    metrics = new CustomMetrics({ client, table, buffer: { elapsed: 1800 } });
+    metric = await metrics.emit('test/buffer', 'CoverageMetric', 1, []);
+    expect(metric).toBeDefined();
+    metrics = new CustomMetrics({ client, table });
+    metric = await metrics.emit('test/buffer', 'CoverageMetric', 1, [], { buffer: { count: 1 } });
+    metric = await metrics.emit('test/buffer', 'CoverageMetric', 1, [], { buffer: { count: 1 } });
+    expect(metric).toBeDefined();
+});
+test('Test stale buffered data', async () => {
+    let metrics = new CustomMetrics({ client, table, log: true });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    //  Emit a non-buffered metric and query
+    let metric = await metrics.emit('test/buffer', 'StaleMetric', 7, [], { timestamp });
+    expect(metric.spans[0].points[0].sum).toBe(7);
+    let r = await metrics.query('test/buffer', 'StaleMetric', {}, 86400, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.points[11].value).toBe(7);
+    /*
+        Emit a stale buffered metric - should be discarded
+     */
+    timestamp -= 365 * 86400 * 1000;
+    await metrics.emit('test/buffer', 'StaleMetric', 100, [], { buffer: { elapsed: 1800, force: true }, timestamp });
+    //  Result should be the original metric emitted
+    timestamp += 365 * 86400 * 1000;
+    r = await metrics.query('test/buffer', 'StaleMetric', {}, 86400, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.points[11].value).toBe(7);
+});
+test('Buffered metric return', async () => {
+    let metrics = new CustomMetrics({ client, table, log: true });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let interval = 1;
+    for (let i = 0; i < 5; i++) {
+        let metric = await metrics.emit('test/buffer', 'ReturnMetric', 1, [], {
+            buffer: { sum: 5 },
+            timestamp,
+        });
+        if (i < 4) {
+            expect(metric).toBeDefined();
+            expect(metric.spans.length).toBe(1);
+        }
+        else {
+            expect(metric.spans.length).toBe(6);
+        }
+        timestamp += interval * 1000;
+    }
+});
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/constructor.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/constructor.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/constructor.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/constructor.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/constructor.js
new file mode 100644
index 0000000..6c9e7ba
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/constructor.js
@@ -0,0 +1,103 @@
+/*
+    constructor.ts - test constructor options
+ */
+import { client, table, CustomMetrics } from './utils/init';
+// jest.setTimeout(7200 * 1000)
+test('Constructor with table name', async () => {
+    let metrics = new CustomMetrics({ table });
+    expect(metrics).toBeDefined();
+    expect(metrics instanceof CustomMetrics).toBe(true);
+    expect(typeof metrics.emit == 'function').toBe(true);
+});
+test('Constructor with client', async () => {
+    let metrics = new CustomMetrics({ client, table });
+    expect(metrics).toBeDefined();
+    expect(metrics instanceof CustomMetrics).toBe(true);
+    expect(typeof metrics.emit == 'function').toBe(true);
+    let metric = await metrics.emit('test/cons', 'ClientMetric', 10);
+    expect(metric).toBeDefined();
+});
+test('Constructor with custom spans', async () => {
+    const Spans = [{ period: 86400, samples: 24 }];
+    let metrics = new CustomMetrics({ client, table, spans: Spans });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let metric;
+    for (let i = 0; i < 26; i++) {
+        metric = await metrics.emit('test/custom', 'CustomMetric', 10, [], { timestamp });
+        timestamp += 3600 * 1000;
+    }
+    expect(metric.spans[0].points.length).toBe(24);
+    let r = await metrics.query('test/custom', 'CustomMetric', {}, 86400, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.period).toBe(86400);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(24);
+    expect(r.points[0].value).toBe(10);
+    expect(r.points[0].count).toBe(1);
+});
+test('Constructor with options', async () => {
+    //  Log true
+    let metrics = new CustomMetrics({ table });
+    expect(metrics).toBeDefined();
+    //  Verbose log
+    metrics = new CustomMetrics({ table, log: 'verbose' });
+    expect(metrics).toBeDefined();
+    //  Custom log
+    metrics = new CustomMetrics({ table, log: {
+            info: (message, context) => null,
+            error: (message, context) => null,
+        } });
+    expect(metrics).toBeDefined();
+    //  Verbose log
+    metrics = new CustomMetrics({ table, log: 'verbose' });
+    expect(metrics).toBeDefined();
+    //  DynamoDB prefix
+    metrics = new CustomMetrics({ table, prefix: 'met' });
+    expect(metrics).toBeDefined();
+    //  TTL
+    metrics = new CustomMetrics({ table, ttl: 86400 });
+    expect(metrics).toBeDefined();
+    //  Consistent
+    metrics = new CustomMetrics({ table, consistent: true });
+    expect(metrics).toBeDefined();
+    expect(() => {
+        //  empty spans
+        new CustomMetrics({ table, spans: [] });
+    }).toThrow();
+    expect(() => {
+        //  Invalid pResolution
+        new CustomMetrics({ table, pResolution: -1 });
+    }).toThrow();
+    expect(() => {
+        //  Invalid buffer
+        new CustomMetrics({ table, buffer: true });
+    }).toThrow();
+    expect(() => {
+        //  Bad TTL
+        new CustomMetrics({ table, ttl: true });
+    }).toThrow();
+    expect(() => {
+        //  Bad consistent
+        new CustomMetrics({ table, consistent: 42 });
+    }).toThrow();
+    expect(() => {
+        //  Bad Source
+        new CustomMetrics({ table, source: true });
+    }).toThrow();
+    expect(() => {
+        //  Missing database
+        new CustomMetrics({});
+    }).toThrow();
+    expect(() => {
+        //  Missing table name
+        new CustomMetrics({ client });
+    }).toThrow();
+    expect(() => {
+        //  Missing options
+        new CustomMetrics();
+    }).toThrow();
+});
+test('Constructor coverage', async () => {
+    new CustomMetrics({ table, buffer: { sum: 100 } });
+    new CustomMetrics({ table, source: 'internal' });
+});
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/debug.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/debug.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/debug.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/debug.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/debug.js
new file mode 100644
index 0000000..a87ef1d
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/debug.js
@@ -0,0 +1,5 @@
+// jest.setTimeout(7200 * 1000)
+test('Test', async () => {
+    expect(true).toBe(true);
+});
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/emit.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/emit.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/emit.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/emit.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/emit.js
new file mode 100644
index 0000000..ba2d835
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/emit.js
@@ -0,0 +1,109 @@
+/*
+    emit.ts - Test basic emit functionality
+ */
+import { client, table, CustomMetrics, DefaultSpans } from './utils/init';
+// jest.setTimeout(7200 * 1000)
+test('Test basic emit', async () => {
+    let metrics = new CustomMetrics({ client, table, owner: 'service', log: true });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let metric = await metrics.emit('test/emit', 'FirstMetric', 10, [], { timestamp });
+    expect(metric).toBeDefined();
+    expect(metric.namespace).toBe('test/emit');
+    expect(metric.metric).toBe('FirstMetric');
+    expect(metric.owner).toBe('service');
+    expect(metric.spans.length).toBe(DefaultSpans.length);
+    expect(metric.version).toBe(1);
+    expect(metric.expires).toBeDefined();
+    let span = metric.spans[0];
+    let points = span.points;
+    expect(points.length).toBe(1);
+    expect(span.samples).toBe(DefaultSpans[0].samples);
+    expect(span.period).toBe(DefaultSpans[0].period);
+    expect(points[0].count).toBe(1);
+    expect(points[0].sum).toBe(10);
+    expect(points[0].max).toBe(10);
+    expect(points[0].min).toBe(10);
+    /*
+        Query to ensure results are committed
+     */
+    let r = await metrics.query('test/emit', 'FirstMetric', {}, 300, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.metric).toBe('FirstMetric');
+    expect(r.namespace).toBe('test/emit');
+    expect(r.period).toBe(300);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points.at(-1)?.value).toBe(10);
+    expect(r.points.at(-1)?.count).toBe(1);
+    //  The last point bucket will end at timestamp + interval
+    expect(r.points.at(-1)?.timestamp).toBe(timestamp + 30000);
+});
+test('Test emit with dimensions', async () => {
+    let metrics = new CustomMetrics({ client, table, log: true });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    await metrics.emit('test/emit', 'Launches', 10, [{}, { Rocket: 'SaturnV' }], { timestamp });
+    await metrics.emit('test/emit', 'Launches', 10, [{}, { Rocket: 'Falcon9' }], { timestamp });
+    /*
+        Query total launches
+     */
+    let r = await metrics.query('test/emit', 'Launches', {}, 300, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.dimensions).toBeDefined();
+    expect(Object.keys(r.dimensions).length).toBe(0);
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points.at(-1)?.value).toBe(20);
+    expect(r.points.at(-1)?.count).toBe(2);
+    //  Query just one dimension
+    r = await metrics.query('test/emit', 'Launches', { Rocket: 'Falcon9' }, 300, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.dimensions).toBeDefined();
+    expect(r.dimensions.Rocket).toBe('Falcon9');
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points.at(-1)?.value).toBe(10);
+    expect(r.points.at(-1)?.count).toBe(1);
+    //  Query unknown dimension
+    r = await metrics.query('test/emit', 'Launches', { Rocket: 'Starship' }, 300, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.dimensions).toBeDefined();
+    expect(r.dimensions.Rocket).toBe('Starship');
+    expect(r.points.length).toBe(0);
+});
+test('Emit Series', async () => {
+    let metrics = new CustomMetrics({ client, table });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let span = DefaultSpans[0];
+    let interval = span.period / span.samples;
+    let metric;
+    for (let i = 0; i < span.samples; i++) {
+        metric = await metrics.emit('test/emit', 'SeriesMetric', i, [], { timestamp });
+        metric = await metrics.emit('test/emit', 'SeriesMetric', i, [], { timestamp: timestamp + 1 });
+        timestamp += interval * 1000;
+    }
+    let r = await metrics.query('test/emit', 'SeriesMetric', {}, 300, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.metric).toBe('SeriesMetric');
+    expect(r.namespace).toBe('test/emit');
+    expect(r.period).toBe(300);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(10);
+});
+test('Emit API', async () => {
+    let metrics = new CustomMetrics({ client, table });
+    expect(async () => {
+        await metrics.emit('test/emit', 'Launches', null);
+    }).rejects.toThrow();
+    expect(async () => {
+        await metrics.emit('test/emit', 'Launches', undefined);
+    }).rejects.toThrow();
+    expect(async () => {
+        await metrics.emit('test/emit', 'Launches', 'invalid');
+    }).rejects.toThrow();
+    expect(async () => {
+        await metrics.emit(null, 'Launches', 10);
+    }).rejects.toThrow();
+    expect(async () => {
+        await metrics.emit('namespace', null, 10);
+    }).rejects.toThrow();
+    //  Emit with ttl
+    await metrics.emit('test/emit', 'ShortLived', 10, [], { ttl: 3600 });
+});
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/gap.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/gap.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/gap.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/gap.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/gap.js
new file mode 100644
index 0000000..6811419
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/gap.js
@@ -0,0 +1,92 @@
+/*
+    gap.ts - Test gaps in metrics
+ */
+import { client, table, CustomMetrics, DefaultSpans } from './utils/init';
+// jest.setTimeout(7200 * 1000)
+test('Test gaps between emit and query', async () => {
+    let metrics = new CustomMetrics({ client, table });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let span = DefaultSpans[0];
+    let interval = span.period / span.samples;
+    let metric;
+    for (let i = 0; i < span.samples * 20; i++) {
+        metric = await metrics.emit('test/gap', 'GapMetric', 10, [], { timestamp });
+        timestamp += interval * 1000;
+    }
+    expect(metric.spans[2].points.length).toBe(1);
+    let r = await metrics.query('test/gap', 'GapMetric', {}, 86400, 'sum', { timestamp });
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points.at(-1)?.count).toBe(20 * span.samples);
+    timestamp += 2 * 86400 * 1000;
+    r = await metrics.query('test/gap', 'GapMetric', {}, 86400, 'sum', { timestamp });
+    expect(r.points.length).toBe(r.samples);
+    for (let i = 0; i < r.samples; i++) {
+        expect(r.points[i].count).toBe(0);
+    }
+});
+test('Test data aging beyond highest span', async () => {
+    const Spans = [{ period: 3600, samples: 4 }];
+    let metrics = new CustomMetrics({ client, table, owner: 'service2', log: false, spans: Spans });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let span = Spans[0];
+    let interval = span.period / span.samples;
+    //  Emit more data than will fit in the span
+    let metric;
+    for (let i = 0; i < span.samples * 2; i++) {
+        metric = await metrics.emit('test/gap', 'MyMetric', 1, [], { timestamp });
+        timestamp += interval * 1000;
+    }
+    expect(metric.spans[0].points.length).toBe(4);
+    let r = await metrics.query('test/gap', 'MyMetric', {}, 86400, 'sum', { timestamp, accumulate: true });
+    expect(r.points.length).toBe(1);
+    expect(r.points[0].value).toBe(4);
+});
+test('Test predated data', async () => {
+    let metrics = new CustomMetrics({ client, table });
+    //  Get at least one point in the span
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let metric = await metrics.emit('test/gap', 'PreDate', 1, [], { timestamp });
+    expect(metric).toBeDefined();
+    //  This emit should be discarded as it is too early
+    timestamp -= 365 * 86400 * 1000;
+    metric = await metrics.emit('test/gap', 'PreDate', 1, [], { timestamp });
+    expect(metric).toBeDefined();
+    expect(metric.spans[0].points.length).toBe(1);
+    expect(metric.spans[5].points.length).toBe(0);
+    timestamp += 365 * 86400 * 1000;
+    let r = await metrics.query('test/gap', 'PreDate', {}, 365 * 86400, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[0].value).toBe(0);
+    expect(r.points[11].count).toBe(1);
+});
+test('Test that points before data and after data are filled', async () => {
+    let metrics = new CustomMetrics({ client, table });
+    let timestamp = new Date(2000, 0, 1).getTime() + 10 * 3600 * 1000;
+    //  Use the hour span
+    let span = DefaultSpans[1];
+    let interval = span.period / span.samples;
+    //  Emit two data values separated by point gaps
+    let metric = await metrics.emit('test/gap', 'FillMetric', 10, [], { timestamp });
+    timestamp += 2 * interval * 1000;
+    expect(metric.spans[0].points.length).toBe(1);
+    expect(metric.spans[0].points[0].sum).toBe(10);
+    expect(metric.spans[1].points.length).toBe(0);
+    metric = await metrics.emit('test/gap', 'FillMetric', 20, [], { timestamp });
+    expect(metric.spans[0].points.length).toBe(1);
+    expect(metric.spans[0].points[0].sum).toBe(20);
+    expect(metric.spans[1].points.length).toBe(1);
+    expect(metric.spans[1].points[0].sum).toBe(10);
+    let r = await metrics.query('test/gap', 'FillMetric', {}, 3600, 'sum', { timestamp });
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points.at(-1)?.value).toBe(20);
+    expect(r.points.at(-3)?.value).toBe(10);
+    //  Move time on by 4 intervals
+    //  This takes us outside the special case of query with same timestamp as last emit
+    timestamp += 4 * interval * 1000;
+    r = await metrics.query('test/gap', 'FillMetric', {}, 3600, 'sum', { timestamp });
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points.at(-4)?.value).toBe(20);
+    expect(r.points.at(-6)?.value).toBe(10);
+});
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/list.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/list.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/list.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/list.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/list.js
new file mode 100644
index 0000000..35332ff
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/list.js
@@ -0,0 +1,57 @@
+/*
+    list.ts - Get metric list
+ */
+import { client, table, CustomMetrics } from './utils/init';
+// jest.setTimeout(7200 * 1000)
+test('Test get metric list', async () => {
+    /*
+        Must have unique owner to isolate own namespaces
+     */
+    let metrics = new CustomMetrics({ client, table, owner: 'list', log: true });
+    let list = await metrics.getMetricList();
+    expect(list).toBeDefined();
+    expect(list.namespaces).toBeDefined();
+    expect(list.namespaces.length).toBe(0);
+    expect(list.metrics).toBeUndefined();
+    expect(list.dimensions).toBeUndefined();
+    //  Create some metrics
+    await metrics.emit('test/list', 'Launches', 10, [{}, { Rocket: 'SaturnV' }]);
+    await metrics.emit('test/another-list', 'Crashes', 1, [{}, { Rocket: 'SaturnV' }]);
+    //  Should see two namespaces
+    list = await metrics.getMetricList();
+    expect(list).toBeDefined();
+    expect(list.namespaces).toBeDefined();
+    expect(list.namespaces.length).toBe(2);
+    expect(list.namespaces.indexOf('test/list') >= 0).toBe(true);
+    expect(list.namespaces.indexOf('test/another-list') >= 0).toBe(true);
+    expect(list.metrics).toBeUndefined();
+    expect(list.dimensions).toBeUndefined();
+    //  Should see namespaces and metrics
+    list = await metrics.getMetricList('test/list');
+    expect(list).toBeDefined();
+    expect(list.namespaces).toBeDefined();
+    expect(list.namespaces.length).toBe(1);
+    expect(list.namespaces[0]).toBe('test/list');
+    expect(list.metrics).toBeDefined();
+    expect(list.metrics.length).toBe(1);
+    expect(list.metrics[0]).toBe('Launches');
+    expect(list.dimensions).toBeUndefined();
+    //  Should see namespace, metrics and dimensions
+    list = await metrics.getMetricList('test/list', 'Launches');
+    expect(list).toBeDefined();
+    expect(list.namespaces).toBeDefined();
+    expect(list.namespaces.length).toBe(1);
+    expect(list.namespaces[0]).toBe('test/list');
+    expect(list.metrics).toBeDefined();
+    expect(list.metrics.length).toBe(1);
+    expect(list.metrics[0]).toBe('Launches');
+    expect(list.dimensions.length).toBe(2);
+    expect(JSON.stringify(list.dimensions[0])).toBe('{}');
+    expect(JSON.stringify(list.dimensions[1])).toBe('{"Rocket":"SaturnV"}');
+});
+test('List API', async () => {
+    //  With logging to pass through to OneTable find
+    let metrics = new CustomMetrics({ client, table });
+    let list = await metrics.getMetricList('test/list', 'Launches', { log: false });
+    expect(list).toBeDefined();
+});
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/log.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/log.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/log.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/log.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/log.js
new file mode 100644
index 0000000..fc4fbf8
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/log.js
@@ -0,0 +1,23 @@
+/*
+    log.ts - Logging
+ */
+import { client, table, CustomMetrics } from './utils/init';
+// jest.setTimeout(7200 * 1000)
+test('Constructor without logging', async () => {
+    let metrics = new CustomMetrics({ client, table });
+    let metric = await metrics.emit('test/log', 'FirstMetric', 10);
+    expect(metric).toBeDefined();
+    let r = await metrics.query('test/log', 'FirstMetric', {}, 300, 'sum');
+    expect(r).toBeDefined();
+    let list = await metrics.getMetricList('test/log');
+    expect(list).toBeDefined();
+});
+test('Constructor with logging', async () => {
+    let metrics = new CustomMetrics({ client, table, log: true });
+    let metric = await metrics.emit('test/log', 'FirstMetric', 10);
+    expect(metric).toBeDefined();
+    let r = await metrics.query('test/log', 'FirstMetric', {}, 300, 'sum');
+    expect(r).toBeDefined();
+    let list = await metrics.getMetricList('test/log');
+    expect(list).toBeDefined();
+});
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/owner.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/owner.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/owner.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/owner.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/owner.js
new file mode 100644
index 0000000..d9eacb0
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/owner.js
@@ -0,0 +1,39 @@
+/*
+    owner.ts - test owner scoping
+ */
+import { client, table, CustomMetrics } from './utils/init';
+// jest.setTimeout(7200 * 1000)
+test('Constructor no owner', async () => {
+    let metrics = new CustomMetrics({ client, table });
+    expect(metrics).toBeDefined();
+});
+test('Constructor with different owners', async () => {
+    let m1 = new CustomMetrics({ client, table, owner: 'app1' });
+    let m2 = new CustomMetrics({ client, table, owner: 'service2' });
+    //  These should not clash
+    await m1.emit('test/owner', 'Launches', 5);
+    await m2.emit('test/owner', 'Launches', 10);
+    let r1 = await m1.query('test/owner', 'Launches', {}, 86400, 'sum');
+    expect(r1).toBeDefined();
+    expect(r1.owner).toBe('app1');
+    expect(r1.points.length).toBe(r1.samples);
+    expect(r1.points[11].value).toBe(5);
+    let r2 = await m2.query('test/owner', 'Launches', {}, 86400, 'sum');
+    expect(r2).toBeDefined();
+    expect(r2.owner).toBe('service2');
+    expect(r2.points.length).toBe(r1.samples);
+    expect(r2.points[11].value).toBe(10);
+});
+test('Owner with namespaces', async () => {
+    let metrics = new CustomMetrics({ client, table });
+    let metric = await metrics.emit('test/owner', 'FirstMetric', 10, [{}, { Rocket: 'SaturnV' }]);
+    expect(metric).toBeDefined();
+    await metrics.emit('test/owner', 'SecondMetric', 10);
+    await metrics.emit('test/owner/2', 'ThirdMetric', 10);
+    let list = await metrics.getMetricList('test/owner');
+    expect(list).toBeDefined();
+    expect(list.namespaces).toBeDefined();
+    list = await metrics.getMetricList('test/owner', 'FirstMetric');
+    expect(list).toBeDefined();
+    expect(list.namespaces).toBeDefined();
+});
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/propagate.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/propagate.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/propagate.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/propagate.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/propagate.js
new file mode 100644
index 0000000..32f16b8
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/propagate.js
@@ -0,0 +1,28 @@
+/*
+    propagate.ts - Test emit will propagate from span to span
+ */
+import { client, table, CustomMetrics, DefaultSpans } from './utils/init';
+// jest.setTimeout(7200 * 1000)
+test('Test', async () => {
+    let metrics = new CustomMetrics({ client, table });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let span = DefaultSpans[2];
+    let interval = span.period / span.samples;
+    for (let i = 0; i < 4; i++) {
+        await metrics.emit('test/propagate', 'FirstMetric', 10, [], { timestamp });
+        timestamp += interval * 1000;
+    }
+    timestamp -= (interval * 1000);
+    let r = await metrics.query('test/propagate', 'FirstMetric', {}, 86400, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.metric).toBe('FirstMetric');
+    expect(r.namespace).toBe('test/propagate');
+    expect(r.period).toBe(span.period);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[8].value).toBe(10);
+    expect(r.points[8].count).toBe(1);
+    expect(r.points[9].value).toBe(10);
+    expect(r.points[10].value).toBe(10);
+    expect(r.points[11].value).toBe(10);
+});
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/pvalues.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/pvalues.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/pvalues.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/pvalues.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/pvalues.js
new file mode 100644
index 0000000..b3c249f
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/pvalues.js
@@ -0,0 +1,31 @@
+/*
+    pvalues.ts - Test emit and query with P-values
+ */
+import { client, table, CustomMetrics } from './utils/init';
+// jest.setTimeout(7200 * 1000)
+test('Test emit with P-Values', async () => {
+    let metrics = new CustomMetrics({ client, table, pResolution: 10 });
+    for (let i = 0; i < 10; i++) {
+        await metrics.emit('test/pvalues', 'PMetric', i);
+    }
+    //  p90
+    let r = await metrics.query('test/pvalues', 'PMetric', {}, 300, 'p90');
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[9].value).toBe(9);
+    expect(r.points[9].count).toBe(10);
+    //  p50
+    r = await metrics.query('test/pvalues', 'PMetric', {}, 300, 'p50');
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[9].value).toBe(6);
+    expect(r.points[9].count).toBe(10);
+    //  Accumulate
+    r = await metrics.query('test/pvalues', 'PMetric', {}, 300, 'p50', { accumulate: true });
+    expect(r.points.length).toBe(1);
+    expect(r.points[0].value).toBe(6);
+    expect(r.points[0].count).toBe(10);
+    //  Higher span
+    r = await metrics.query('test/pvalues', 'PMetric', {}, 86400, 'p90');
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[11].value).toBe(9);
+    expect(r.points[11].count).toBe(10);
+});
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/query.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/query.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/query.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/query.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/query.js
new file mode 100644
index 0000000..e5f698d
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/query.js
@@ -0,0 +1,190 @@
+/*
+    query.ts - Test metric query
+ */
+import { client, table, CustomMetrics, DefaultSpans } from './utils/init';
+// jest.setTimeout(7200 * 1000)
+test('Test basic query', async () => {
+    let metrics = new CustomMetrics({ client, table, log: false });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let metric;
+    for (let i = 0; i < 10; i++) {
+        metric = await metrics.emit('test/query', 'BasicMetric', 7, [], { timestamp });
+        timestamp += 30 * 1000;
+    }
+    expect(metric.spans[0].points.length).toBe(10);
+    let r = await metrics.query('test/query', 'BasicMetric', {}, 300, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.period).toBe(DefaultSpans[0].period);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(10);
+    expect(r.points.at(-1)?.value).toBe(7);
+    expect(r.points.at(-1)?.count).toBe(1);
+});
+test('Test query period', async () => {
+    let metrics = new CustomMetrics({ client, table, log: false });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let metric;
+    for (let i = 0; i < 10; i++) {
+        metric = await metrics.emit('test/query', 'PeriodMetric', 7, [], { timestamp });
+        timestamp += 30 * 1000;
+    }
+    // timestamp -= 30 * 1000
+    expect(metric.spans[0].points.length).toBe(10);
+    //  With a period shorter than the lowest span - only one interval
+    let r = await metrics.query('test/query', 'PeriodMetric', {}, 30, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.period).toBe(DefaultSpans[0].period);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(1);
+    expect(r.points[0].value).toBe(7);
+    expect(r.points[0].count).toBe(1);
+    //  With a period above the span emitted
+    r = await metrics.query('test/query', 'PeriodMetric', {}, 3600, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.period).toBe(3600);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[11].value).toBe(70);
+    expect(r.points[11].count).toBe(10);
+    //  With a period above the highest span
+    let period = DefaultSpans.at(-1).period;
+    r = await metrics.query('test/query', 'PeriodMetric', {}, period + 1000, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.period).toBe(period);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[11].value).toBe(70);
+    expect(r.points[11].count).toBe(10);
+});
+test('Test query statistics', async () => {
+    let metrics = new CustomMetrics({ client, table });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let span = DefaultSpans[0];
+    let interval = span.period / span.samples;
+    let metric;
+    for (let i = 0; i < 4; i++) {
+        await metrics.emit('test/query', 'StatMetric', i, [], { timestamp });
+        //  Emit a second data point 1ms after
+        metric = await metrics.emit('test/query', 'StatMetric', i + 1, [], { timestamp: timestamp + 1 });
+        timestamp += interval * 1000;
+    }
+    timestamp -= interval * 1000;
+    //  Average
+    let r = await metrics.query('test/query', 'StatMetric', {}, 300, 'avg', { timestamp });
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[6].value).toBe(0.5);
+    expect(r.points[6].count).toBe(2);
+    expect(r.points[7].value).toBe(1.5);
+    expect(r.points[7].count).toBe(2);
+    expect(r.points[8].value).toBe(2.5);
+    expect(r.points[8].count).toBe(2);
+    expect(r.points[9].value).toBe(3.5);
+    expect(r.points[9].count).toBe(2);
+    //  Min
+    r = await metrics.query('test/query', 'StatMetric', {}, 300, 'min', { timestamp });
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[0].value).toBe(0);
+    expect(r.points[6].count).toBe(2);
+    //  Max
+    r = await metrics.query('test/query', 'StatMetric', {}, 300, 'max', { timestamp });
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[0].value).toBe(0);
+    expect(r.points[9].value).toBe(4);
+    expect(r.points[9].count).toBe(2);
+    //  Count
+    r = await metrics.query('test/query', 'StatMetric', {}, 300, 'count', { timestamp });
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[0].value).toBe(0);
+    expect(r.points[9].count).toBe(2);
+    expect(r.points[9].value).toBe(2);
+});
+test('Test query statistics with accumulate', async () => {
+    let metrics = new CustomMetrics({ client, table });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let span = DefaultSpans[0];
+    let interval = span.period / span.samples;
+    let metric;
+    for (let i = 0; i < span.samples; i++) {
+        // Multiple points
+        metric = await metrics.emit('test/query', 'AccMetric', i, [], { timestamp });
+        metric = await metrics.emit('test/query', 'AccMetric', i, [], { timestamp: timestamp + 1 });
+        timestamp += interval * 1000;
+    }
+    timestamp -= interval * 1000;
+    //  Average
+    let r = await metrics.query('test/query', 'AccMetric', {}, 300, 'avg', { accumulate: true, timestamp });
+    expect(r.points.length).toBe(1);
+    expect(r.points[0].value).toBe(4.5);
+    expect(r.points[0].count).toBe(20);
+    //  Min
+    r = await metrics.query('test/query', 'AccMetric', {}, 300, 'min', { accumulate: true, timestamp });
+    expect(r.points.length).toBe(1);
+    expect(r.points[0].value).toBe(0);
+    expect(r.points[0].count).toBe(20);
+    //  Max
+    r = await metrics.query('test/query', 'AccMetric', {}, 300, 'max', { accumulate: true, timestamp });
+    expect(r.points.length).toBe(1);
+    expect(r.points[0].value).toBe(9);
+    expect(r.points[0].count).toBe(20);
+    //  Count
+    r = await metrics.query('test/query', 'AccMetric', {}, 300, 'count', { accumulate: true, timestamp });
+    expect(r.points.length).toBe(1);
+    expect(r.points[0].value).toBe(20);
+    expect(r.points[0].count).toBe(20);
+});
+test('Test query p values', async () => {
+    let metrics = new CustomMetrics({ client, table, pResolution: 10 });
+    // let timestamp = new Date(2000, 0, 1).getTime()
+    for (let i = 0; i < 10; i++) {
+        await metrics.emit('test/query', 'PMetric', i, []);
+    }
+    //  p90
+    let r = await metrics.query('test/query', 'PMetric', {}, 300, 'p90');
+    expect(r.period).toBe(300);
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[9].value).toBe(9);
+    expect(r.points[9].count).toBe(10);
+    //  p50
+    r = await metrics.query('test/query', 'PMetric', {}, 300, 'p50');
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[9].value).toBe(6);
+    expect(r.points[9].count).toBe(10);
+});
+test('Test missing metrics', async () => {
+    let metrics = new CustomMetrics({ client, table });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    //  Missing namespace
+    let r = await metrics.query('Unknown', 'Unknown', {}, 300, 'avg', { timestamp });
+    expect(r.points.length).toBe(0);
+    //  Missing metric
+    await metrics.emit('test/query', 'MMetric', 1, [], { timestamp });
+    r = await metrics.query('test/query', 'Unknown', {}, 300, 'avg', { timestamp });
+    expect(r.points.length).toBe(0);
+    //  Missing span, but still return data point
+    r = await metrics.query('test/query', 'MMetric', {}, 86400, 'avg', { timestamp });
+    expect(r.points.length).toBe(r.samples);
+});
+test('Test query with non-standard period', async () => {
+    let metrics = new CustomMetrics({ client, table, log: false });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let metric;
+    for (let i = 0; i < 140; i++) {
+        metric = await metrics.emit('test/query', 'BasicMetric', 7, [], { timestamp });
+        timestamp += 30 * 1000;
+    }
+    // timestamp -= 30 * 1000
+    expect(metric.spans[0].points.length).toBe(10);
+    /*
+        Query 15 minutes
+        This will return 3 points from the next span up (1 hr)
+     */
+    let r = await metrics.query('test/query', 'BasicMetric', {}, 900, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.period).toBe(DefaultSpans[1].period);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(3);
+    expect(r.points[0].count).toBe(10);
+    expect(r.points[0].value).toBe(70);
+    expect(r.points[1].value).toBe(70);
+    expect(r.points[2].value).toBe(70);
+});
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/ranged.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/ranged.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/ranged.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/ranged.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/ranged.js
new file mode 100644
index 0000000..e234a6b
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/ranged.js
@@ -0,0 +1,33 @@
+/*
+    ranged.ts - Get a range of data
+ */
+import { client, table, CustomMetrics, DefaultSpans } from './utils/init';
+// jest.setTimeout(7200 * 1000)
+test('Test that points before data and after data are filled', async () => {
+    let metrics = new CustomMetrics({ client, table });
+    let timestamp = new Date(2000, 0, 1).getTime() + 10 * 3600 * 1000;
+    //  Use the year span
+    let span = DefaultSpans[5];
+    let interval = span.period / span.samples;
+    /*
+        Emit one year worth of data
+     */
+    for (let i = 0; i < 12; i++) {
+        await metrics.emit('test/gg', 'FillMetric', i + 1, [], { timestamp });
+        timestamp += interval * 1000;
+    }
+    /*
+        Query 1/4 starting 7 months back
+     */
+    let period = span.period / 4;
+    let start = timestamp - (interval * 7 * 1000);
+    let r = await metrics.query('test/gg', 'FillMetric', {}, period, 'sum', { start, timestamp });
+    expect(r.points.length).toBe(3);
+    expect(r.points[0].value).toBe(7);
+    expect(r.points[1].value).toBe(8);
+    expect(r.points[2].value).toBe(9);
+    //  Query accumulate
+    r = await metrics.query('test/gg', 'FillMetric', {}, period, 'sum', { start, timestamp, accumulate: true });
+    expect(r.points.length).toBe(1);
+    expect(r.points[0].value).toBe(24);
+});
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/series.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/series.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/series.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/series.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/series.js
new file mode 100644
index 0000000..91b0e60
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/series.js
@@ -0,0 +1,29 @@
+/*
+    series.ts - Test query with series results
+ */
+import { client, table, CustomMetrics, DefaultSpans } from './utils/init';
+// jest.setTimeout(7200 * 1000)
+test('Test query with series', async () => {
+    let metrics = new CustomMetrics({ client, table });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let span = DefaultSpans[2];
+    let interval = span.period / span.samples;
+    let metric;
+    for (let i = 0; i < 4; i++) {
+        metric = await metrics.emit('test/series', 'FirstMetric', 10 * (i + 1), [], { timestamp });
+        timestamp += interval * 1000;
+    }
+    timestamp -= (interval * 1000);
+    let r = await metrics.query('test/series', 'FirstMetric', {}, 86400, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.metric).toBe('FirstMetric');
+    expect(r.namespace).toBe('test/series');
+    expect(r.period).toBe(span.period);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points[8].value).toBe(10);
+    expect(r.points[8].count).toBe(1);
+    expect(r.points[9].value).toBe(20);
+    expect(r.points[10].value).toBe(30);
+    expect(r.points[11].value).toBe(40);
+});
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/spans.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/spans.d.ts
new file mode 100644
index 0000000..12f7f4a
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/spans.d.ts
@@ -0,0 +1,2 @@
+import { SpanDef } from './utils/init';
+export declare const Spans: SpanDef[];
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/spans.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/spans.js
new file mode 100644
index 0000000..5b40fa0
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/spans.js
@@ -0,0 +1,31 @@
+/*
+    spans.ts - Custom spans
+ */
+import { client, table, CustomMetrics } from './utils/init';
+// jest.setTimeout(7200 * 1000)
+export const Spans = [
+    // {period: 1 * 60, samples: 12}, //  60, 1 mins, interval: 5 secs
+    { period: 5 * 60, samples: 10 }, //  300, 5 mins, interval: 30 secs
+    { period: 60 * 60, samples: 12 }, //  3600, 1 hr, interval: 5 mins
+    { period: 3 * 60 * 60, samples: 12 }, // 10800, 3 hrs, interval: 15 mins
+    { period: 6 * 60 * 60, samples: 12 }, // 21600, 6 hrs, interval: 30 mins
+    { period: 24 * 60 * 60, samples: 12 }, // 86400, 24 hrs, interval: 2 hrs
+    { period: 7 * 24 * 60 * 60, samples: 14 }, // 604,800, 7 days, interval: 1/2 day
+    { period: 28 * 24 * 60 * 60, samples: 14 }, // 2,419,200, 28 days, interval: 2 days
+    { period: 3 * 28 * 24 * 60 * 60, samples: 12 }, // 7,257,600, 1 quarter, interval: 1 week
+    { period: 6 * 28 * 24 * 60 * 60, samples: 12 }, // 14,515,200, 2 quarters, interval: 2 weeks
+    { period: 365 * 24 * 60 * 60, samples: 12 }, // 31,536,000, 1 year, interval: 1 month
+];
+test('Basic test harness', async () => {
+    let metrics = new CustomMetrics({ client, table, log: true, spans: Spans });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let interval = 60 * 15;
+    for (let i = 0; i < 10; i++) {
+        let metric = await metrics.emit('test/spans', 'MyMetric', 10, [], { timestamp });
+        for (let span of metric.spans) {
+            span.ee = new Date(span.end * 1000);
+        }
+        expect(metric).toBeDefined();
+        timestamp += interval * 1000;
+    }
+});
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/start.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/start.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/start.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/start.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/start.js
new file mode 100644
index 0000000..1979cee
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/start.js
@@ -0,0 +1,42 @@
+/*
+    start.ts - Test metric query with start time
+ */
+import { client, table, CustomMetrics, DefaultSpans } from './utils/init';
+// jest.setTimeout(7200 * 1000)
+test('Test query with start', async () => {
+    let metrics = new CustomMetrics({ client, table, log: false });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let metric;
+    //  One week of data
+    for (let i = 0; i < 24 * 7; i++) {
+        metric = await metrics.emit('test/query', 'StartMetric', 7, [], { timestamp });
+        timestamp += 3600 * 1000;
+    }
+    expect(metric.spans.length).toBe(6);
+    expect(metric.spans.at(0).points.length).toBe(1);
+    expect(metric.spans.at(1).points.length).toBe(1);
+    expect(metric.spans.at(2).points.length).toBe(12);
+    expect(metric.spans.at(3).points.length).toBe(12);
+    //  Get last day
+    let r = await metrics.query('test/query', 'StartMetric', {}, 86400, 'sum', { timestamp });
+    expect(r).toBeDefined();
+    expect(r.period).toBe(DefaultSpans[2].period);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(12);
+    expect(r.points[0].value).toBe(14);
+    expect(r.points[0].count).toBe(2);
+    /*
+        Get last 2 days of data starting 4 days ago
+        This is using the week span with 1/2 day intervals
+     */
+    let start = timestamp - 86400 * 4 * 1000;
+    r = await metrics.query('test/query', 'StartMetric', {}, 86400 * 2, 'sum', { start, timestamp });
+    expect(r).toBeDefined();
+    expect(r.period).toBe(DefaultSpans[3].period);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(4);
+    expect(r.points.at(-1)?.value).toBe(84);
+    expect(r.points.at(-1)?.count).toBe(12);
+    //  MOB - more tests with start before spans
+    //  MOB test with start + period after ...
+});
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/table.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/table.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/table.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/table.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/table.js
new file mode 100644
index 0000000..9c241db
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/table.js
@@ -0,0 +1,21 @@
+/*
+    table.ts - Test get metric table of dimensions
+ */
+import { client, table, CustomMetrics } from './utils/init';
+jest.setTimeout(7200 * 1000);
+test('Test get metric table', async () => {
+    let metrics = new CustomMetrics({ client, table, log: true });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let metric = await metrics.emit('test/table', 'Temp', 10, [], { timestamp });
+    metric = await metrics.emit('test/table', 'Temp', 10, [{}, { Rocket: 'SaturnV' }], { timestamp });
+    metric = await metrics.emit('test/table', 'Temp', 10, [{}, { Rocket: 'Falcon9' }], { timestamp });
+    let list = await metrics.queryMetrics('test/table', 'Temp', 300, 'sum', { timestamp });
+    expect(list).toBeDefined();
+    expect(list.length).toBe(3);
+    expect(list[0].dimensions).toEqual({});
+    expect(list[0].points.length).toBe(1);
+    expect(list[0].points[0].value).toBe(30);
+    expect(list[1].dimensions).toEqual({ Rocket: 'Falcon9' });
+    expect(list[1].points.length).toBe(1);
+    expect(list[1].points[0].value).toBe(10);
+});
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/upgrade.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/upgrade.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/upgrade.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/upgrade.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/upgrade.js
new file mode 100644
index 0000000..21b5383
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/upgrade.js
@@ -0,0 +1,77 @@
+/*
+    upgrade.ts - Upgrade spans
+ */
+import { client, table, CustomMetrics } from './utils/init';
+// jest.setTimeout(7200 * 1000)
+const LessSpans = [
+    { period: 24 * 60 * 60, samples: 12 }, // 86400, 24 hrs, interval: 2 hrs
+    { period: 365 * 24 * 60 * 60, samples: 12 }, // 31,536,000, 1 year, interval: 1 month
+];
+const MoreSpans = [
+    { period: 1 * 60, samples: 12 }, //  60, 1 min, interval: 5 secs
+    { period: 5 * 60, samples: 10 }, //  300, 5 mins, interval: 30 secs
+    { period: 60 * 60, samples: 12 }, //  3600, 1 hr, interval: 5 mins
+    { period: 3 * 60 * 60, samples: 12 }, //  10,800, 3 hrs, interval: 15 mins
+    { period: 6 * 60 * 60, samples: 12 }, //  21600, 6 hr, interval: 30 mins
+    { period: 24 * 60 * 60, samples: 12 }, // 86400, 24 hrs, interval: 2 hrs
+    { period: 7 * 24 * 60 * 60, samples: 14 }, // 604,800, 7 days, interval: 1/2 day
+    { period: 28 * 24 * 60 * 60, samples: 14 }, // 2,419,200, 28 days, interval: 2 days
+    { period: 365 * 24 * 60 * 60, samples: 12 }, // 31,536,000, 1 year, interval: 1 month
+];
+test('Upgrade Spans', async () => {
+    let metrics = new CustomMetrics({ client, table, log: true });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let metric;
+    let count = 4;
+    for (let i = 0; i < count; i++) {
+        metric = await metrics.emit('test/upgrade', 'UpMetric', 7, [], { timestamp });
+        timestamp += 30 * 1000;
+    }
+    expect(metric).toBeDefined();
+    expect(metric.spans.length).toBe(6);
+    let sum = 0;
+    for (let span of metric.spans) {
+        sum += span.points.reduce((total, point) => total + point.count, 0);
+    }
+    expect(sum).toBe(count);
+    //  Test upgrade
+    metrics = new CustomMetrics({ client, table, log: true, spans: MoreSpans });
+    metric = await metrics.upgrade('test/upgrade', 'UpMetric', []);
+    expect(metric).toBeDefined();
+    expect(metric.spans.length).toBe(9);
+    sum = 0;
+    for (let span of metric.spans) {
+        sum += span.points.reduce((total, point) => total + point.count, 0);
+    }
+    expect(sum).toBe(count);
+    //  Test downgrade
+    metrics = new CustomMetrics({ client, table, log: true, spans: LessSpans });
+    metric = await metrics.upgrade('test/upgrade', 'UpMetric', []);
+    expect(metric).toBeDefined();
+    expect(metric.spans.length).toBe(2);
+    sum = 0;
+    for (let span of metric.spans) {
+        sum += span.points.reduce((total, point) => total + point.count, 0);
+    }
+    expect(sum).toBe(count);
+    //  Test already upgraded
+    metrics = new CustomMetrics({ client, table, log: true, spans: LessSpans });
+    metric = await metrics.upgrade('test/upgrade', 'UpMetric', []);
+    expect(metric).toBeDefined();
+    expect(metric.spans.length).toBe(2);
+    sum = 0;
+    for (let span of metric.spans) {
+        sum += span.points.reduce((total, point) => total + point.count, 0);
+    }
+    expect(sum).toBe(count);
+    //  Test inline upgrade with emit
+    metrics = new CustomMetrics({ client, table, log: true, spans: LessSpans });
+    metric = await metrics.emit('test/upgrade', 'UpMetric', 7, [], { upgrade: true });
+    expect(metric).toBeDefined();
+    expect(metric.spans.length).toBe(2);
+    sum = 0;
+    for (let span of metric.spans) {
+        sum += span.points.reduce((total, point) => total + point.count, 0);
+    }
+    expect(sum).toBe(count + 1);
+});
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/utils/init.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/utils/init.d.ts
new file mode 100644
index 0000000..0f77457
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/utils/init.d.ts
@@ -0,0 +1,11 @@
+import { CustomMetrics, DefaultSpans, Metric, MetricQueryResult, SpanDef } from '../../src/index';
+import SenseLogs from 'senselogs';
+declare const log: SenseLogs;
+declare const client: any;
+declare const table: any;
+declare const dump: (...args: any[]) => string;
+declare const dumpMetric: (metric: Metric) => void;
+declare const dumpQuery: (metric: MetricQueryResult) => void;
+declare const print: (...args: any[]) => void;
+declare const delay: (time: number) => Promise<unknown>;
+export { table, client, CustomMetrics, DefaultSpans, SpanDef, delay, dump, dumpMetric, dumpQuery, log, print };
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/utils/init.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/utils/init.js
new file mode 100644
index 0000000..133bf19
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/utils/init.js
@@ -0,0 +1,77 @@
+import { CustomMetrics, DefaultSpans } from '../../src/index';
+import SenseLogs from 'senselogs';
+const log = new SenseLogs({ destination: 'stdout', format: 'human' });
+/*
+    Share the client and table created in setup.ts
+ */
+const client = globalThis.DynamoDBClient;
+const table = globalThis.TableName;
+//  Format date
+function fmtdate(n) {
+    function padTo2Digits(num) {
+        return num.toString().padStart(2, '0');
+    }
+    let date = new Date(n);
+    const year = date.getFullYear().toString().slice(-2); // Get last two digits of the year
+    const month = padTo2Digits(date.getMonth() + 1); // Months are zero-indexed
+    const day = padTo2Digits(date.getDate());
+    const hours = padTo2Digits(date.getHours());
+    const minutes = padTo2Digits(date.getMinutes());
+    const seconds = padTo2Digits(date.getSeconds());
+    return `${year}-${month}-${day} ${hours}:${minutes}:${seconds}`;
+}
+function dt(n) {
+    return fmtdate(n * 1000);
+}
+const dump = (...args) => {
+    let s = [];
+    for (let item of args) {
+        let values = JSON.stringify(item, function (key, value) {
+            if (this[key] instanceof Date) {
+                return fmtdate(this[key].getTime());
+            }
+            return value;
+        }, 4);
+        s.push(values);
+    }
+    let result = s.join(' ');
+    console.log(result);
+    return result;
+};
+const dumpMetric = function (metric) {
+    let buf = [];
+    buf.push(`${metric.namespace}/${metric.metric}/${JSON.stringify(metric.dimensions)}`);
+    for (let span of metric.spans) {
+        let interval = span.period / span.samples;
+        let start = span.end - span.points.length * interval;
+        buf.push(` ${span.period} secs ${fmtdate(start * 1000)} => ${fmtdate(span.end * 1000)} ${span.points.length} points`);
+        for (let point of span.points) {
+            buf.push(`     count ${point.count} = sum ${point.sum}`);
+        }
+    }
+    print(buf.join('\n'));
+};
+const dumpQuery = function (metric) {
+    let points = metric.points.slice(0);
+    let buf = [];
+    buf.push(`${metric.namespace}/${metric.metric}/${JSON.stringify(metric.dimensions)} ${metric.period} ${points.length} points`);
+    for (let point of points) {
+        buf.push(`     ${fmtdate(point.timestamp || 0)} = ${point.value || '-'} / ${point.count}`);
+    }
+    print(buf.join('\n'));
+};
+const print = (...args) => {
+    console.log(...args);
+};
+globalThis.dt = dt;
+globalThis.fmtdate = fmtdate;
+globalThis.dump = dump;
+globalThis.dumpMetric = dumpMetric;
+globalThis.dumpQuery = dumpQuery;
+globalThis.print = print;
+const delay = async (time) => {
+    return new Promise(function (resolve, reject) {
+        setTimeout(() => resolve(true), time);
+    });
+};
+export { table, client, CustomMetrics, DefaultSpans, delay, dump, dumpMetric, dumpQuery, log, print };
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/utils/setup.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/utils/setup.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/utils/setup.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/utils/setup.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/utils/setup.js
new file mode 100644
index 0000000..32108ac
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/utils/setup.js
@@ -0,0 +1,72 @@
+/*
+    Setup -- setup for the test run
+ */
+import { DynamoDBClient } from '@aws-sdk/client-dynamodb';
+import { CreateTableCommand, DescribeTableCommand } from '@aws-sdk/client-dynamodb';
+import * as DynamoDbLocal from 'dynamo-db-local';
+import waitPort from 'wait-port';
+const PORT = parseInt(process.env.PORT || '4765');
+module.exports = async () => {
+    /*
+        Start the local dynamodb
+     */
+    let dynamodb = DynamoDbLocal.spawn({ port: PORT });
+    console.info('\nSpawn DynamoDB', dynamodb.pid);
+    await waitPort({ host: '0.0.0.0', port: PORT, timeout: 10000 });
+    process.env.DYNAMODB_PID = String(dynamodb.pid);
+    process.env.DYNAMODB_PORT = String(PORT);
+    /*
+        Create the AWS client
+     */
+    const client = new DynamoDBClient({
+        endpoint: `http://localhost:${PORT}`,
+        region: 'local',
+        credentials: { accessKeyId: 'test', secretAccessKey: 'test' },
+    });
+    await createTable(client, 'CustomMetrics');
+    globalThis.DynamoDBClient = client;
+    // When jest throws anything unhandled, ensure we kill the spawned process
+    process.on('unhandledRejection', (error) => {
+        let pid = parseInt(process.env.DYNAMODB_PID || '');
+        if (pid) {
+            process.kill(pid);
+        }
+    });
+};
+async function createTable(client, table) {
+    let def = {
+        AttributeDefinitions: [
+            { AttributeName: 'pk', AttributeType: 'S' },
+            { AttributeName: 'sk', AttributeType: 'S' },
+        ],
+        KeySchema: [
+            { AttributeName: 'pk', KeyType: 'HASH' },
+            { AttributeName: 'sk', KeyType: 'RANGE' },
+        ],
+        TableName: table,
+        BillingMode: 'PAY_PER_REQUEST',
+    };
+    let command = new CreateTableCommand(def);
+    await client.send(command);
+    /*
+        Wait for the table to become live
+     */
+    let deadline = Date.now() + 10 * 1000;
+    do {
+        let command = new DescribeTableCommand({ TableName: 'CustomMetrics' });
+        let info = await client.send(command);
+        if (info.Table.TableStatus == 'ACTIVE') {
+            break;
+        }
+        if (deadline < Date.now()) {
+            throw new Error('Table has not become active');
+        }
+        await delay(1000);
+    } while (Date.now() < deadline);
+    globalThis.TableName = table;
+}
+const delay = async (time) => {
+    return new Promise(function (resolve, reject) {
+        setTimeout(() => resolve(true), time);
+    });
+};
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/utils/teardown.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/utils/teardown.d.ts
new file mode 100644
index 0000000..e69de29
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/utils/teardown.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/utils/teardown.js
new file mode 100644
index 0000000..5a587ca
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/utils/teardown.js
@@ -0,0 +1,6 @@
+module.exports = async () => {
+    let pid = parseInt(process.env.DYNAMODB_PID || '');
+    if (pid) {
+        process.kill(pid);
+    }
+};
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/year.d.ts b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/year.d.ts
new file mode 100644
index 0000000..cb0ff5c
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/year.d.ts
@@ -0,0 +1 @@
+export {};
diff --git a/node_modules/dynamodb-onetable/dist/mjs/metrics/test/year.js b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/year.js
new file mode 100644
index 0000000..5c7697d
--- /dev/null
+++ b/node_modules/dynamodb-onetable/dist/mjs/metrics/test/year.js
@@ -0,0 +1,32 @@
+/*
+    year.ts - Test emit functionality for one year
+ */
+import { client, table, CustomMetrics, DefaultSpans } from './utils/init';
+// jest.setTimeout(7200 * 1000)
+test('Test year span', async () => {
+    let metrics = new CustomMetrics({ client, table, owner: 'service', log: true });
+    let timestamp = new Date(2000, 0, 1).getTime();
+    let span = DefaultSpans[5];
+    let interval = span.period / span.samples;
+    for (let i = 0; i < 12; i++) {
+        let metric = await metrics.emit('test/year', 'FirstMetric', i + 1, [], { timestamp });
+        // dumpMetric(metric)
+        timestamp += interval * 1000;
+    }
+    /*
+        Expect results to be span bucket aligned. i.e. first point timestamp will be 00-02-24 and
+        the last bucket will be partial 00-12-31
+     */
+    let r = await metrics.query('test/year', 'FirstMetric', {}, span.period, 'sum', { timestamp });
+    // dumpQuery(r)
+    expect(r).toBeDefined();
+    expect(r.metric).toBe('FirstMetric');
+    expect(r.namespace).toBe('test/year');
+    expect(r.period).toBe(span.period);
+    expect(r.points).toBeDefined();
+    expect(r.points.length).toBe(r.samples);
+    expect(r.points.at(-2)?.value).toBe(12);
+    expect(r.points.at(-2)?.count).toBe(1);
+    expect(r.points.at(-1)?.timestamp).toBe(timestamp);
+    expect(r.points.at(-1)?.count).toBe(0);
+});
diff --git a/node_modules/dynamodb-onetable/dist/mjs/utils.d.ts b/node_modules/dynamodb-onetable/dist/mjs/utils.d.ts
index 1b29bfd..f3010de 100644
--- a/node_modules/dynamodb-onetable/dist/mjs/utils.d.ts
+++ b/node_modules/dynamodb-onetable/dist/mjs/utils.d.ts
@@ -10,4 +10,5 @@ type UndefinedProperties<T> = {
     then excludes those undefined properties from the orginal object to only have the required properties.
     The result of merging these two objects end up being the original object with those properties that can be undefined marked as optional.
 */
-export type UndefinedToOptional<T> = Partial<Pick<T, UndefinedProperties<T>>> & Pick<T, Exclude<keyof T, UndefinedProperties<T>>>
+export type UndefinedToOptional<T> = Partial<Pick<T, UndefinedProperties<T>>> &
+    Pick<T, Exclude<keyof T, UndefinedProperties<T>>>
